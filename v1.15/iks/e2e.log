I0814 21:40:30.471420      17 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-037535427
I0814 21:40:30.471781      17 e2e.go:241] Starting e2e run "f3fc71c6-5770-4c8b-888f-8e7c71359206" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565818829 - Will randomize all specs
Will run 215 of 4413 specs

Aug 14 21:40:30.683: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 21:40:30.686: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 14 21:40:30.746: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 14 21:40:30.826: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 14 21:40:30.826: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Aug 14 21:40:30.826: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 14 21:40:30.852: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Aug 14 21:40:30.852: INFO: e2e test version: v1.15.2
Aug 14 21:40:30.857: INFO: kube-apiserver version: v1.15.2+IKS
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:40:30.858: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
Aug 14 21:40:30.955: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 14 21:40:30.998: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 21:40:37.735: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c122aa3f-e520-42d8-915e-39094989196c"
Aug 14 21:40:37.735: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c122aa3f-e520-42d8-915e-39094989196c" in namespace "pods-5301" to be "terminated due to deadline exceeded"
Aug 14 21:40:37.750: INFO: Pod "pod-update-activedeadlineseconds-c122aa3f-e520-42d8-915e-39094989196c": Phase="Running", Reason="", readiness=true. Elapsed: 15.311591ms
Aug 14 21:40:39.763: INFO: Pod "pod-update-activedeadlineseconds-c122aa3f-e520-42d8-915e-39094989196c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.028558306s
Aug 14 21:40:39.763: INFO: Pod "pod-update-activedeadlineseconds-c122aa3f-e520-42d8-915e-39094989196c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:40:39.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5301" for this suite.
Aug 14 21:40:45.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:40:46.238: INFO: namespace pods-5301 deletion completed in 6.457946223s

• [SLOW TEST:15.380 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:40:46.240: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 21:40:46.447: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:40:54.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-903" for this suite.
Aug 14 21:41:18.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:41:19.017: INFO: namespace init-container-903 deletion completed in 24.410218888s

• [SLOW TEST:32.778 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:41:19.017: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 21:41:19.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-3707'
Aug 14 21:41:19.615: INFO: stderr: ""
Aug 14 21:41:19.615: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 14 21:41:19.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-3707'
Aug 14 21:41:19.942: INFO: stderr: ""
Aug 14 21:41:19.942: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 21:41:20.955: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:20.955: INFO: Found 0 / 1
Aug 14 21:41:21.955: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:21.955: INFO: Found 0 / 1
Aug 14 21:41:22.955: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:22.955: INFO: Found 0 / 1
Aug 14 21:41:23.955: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:23.955: INFO: Found 0 / 1
Aug 14 21:41:24.956: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:24.956: INFO: Found 0 / 1
Aug 14 21:41:25.956: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:25.956: INFO: Found 1 / 1
Aug 14 21:41:25.956: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 21:41:25.968: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:41:25.968: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 21:41:25.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 describe pod redis-master-z6gxj --namespace=kubectl-3707'
Aug 14 21:41:26.134: INFO: stderr: ""
Aug 14 21:41:26.134: INFO: stdout: "Name:           redis-master-z6gxj\nNamespace:      kubectl-3707\nPriority:       0\nNode:           10.195.18.146/10.195.18.146\nStart Time:     Wed, 14 Aug 2019 21:41:19 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.168.118\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://adcf8a923097bfea1f53911565515b3444eebc69a47e5dd82494f3891991ef11\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Aug 2019 21:41:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8xlw5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8xlw5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8xlw5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  7s    default-scheduler       Successfully assigned kubectl-3707/redis-master-z6gxj to 10.195.18.146\n  Normal  Pulling    6s    kubelet, 10.195.18.146  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, 10.195.18.146  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    2s    kubelet, 10.195.18.146  Created container redis-master\n  Normal  Started    2s    kubelet, 10.195.18.146  Started container redis-master\n"
Aug 14 21:41:26.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 describe rc redis-master --namespace=kubectl-3707'
Aug 14 21:41:26.323: INFO: stderr: ""
Aug 14 21:41:26.323: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3707\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  7s    replication-controller  Created pod: redis-master-z6gxj\n"
Aug 14 21:41:26.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 describe service redis-master --namespace=kubectl-3707'
Aug 14 21:41:26.488: INFO: stderr: ""
Aug 14 21:41:26.488: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3707\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.156.211\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.168.118:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 14 21:41:26.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 describe node 10.195.18.146'
Aug 14 21:41:26.676: INFO: stderr: ""
Aug 14 21:41:26.676: INFO: stdout: "Name:               10.195.18.146\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=au-syd\n                    failure-domain.beta.kubernetes.io/zone=syd05\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=135.90.65.40\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.195.18.146\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=au-syd\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bla66o8s0gv1rqqkhfrg-kubee2epvgs-default-000001ad\n                    ibm-cloud.kubernetes.io/worker-pool-id=bla66o8s0gv1rqqkhfrg-844c5e2\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.1_1511\n                    ibm-cloud.kubernetes.io/zone=syd05\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.195.18.146\n                    kubernetes.io/os=linux\n                    privateVLAN=2659723\n                    publicVLAN=2659721\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Aug 2019 20:03:16 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 14 Aug 2019 21:40:53 +0000   Wed, 14 Aug 2019 20:03:16 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 14 Aug 2019 21:40:53 +0000   Wed, 14 Aug 2019 20:03:16 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 14 Aug 2019 21:40:53 +0000   Wed, 14 Aug 2019 20:03:16 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 14 Aug 2019 21:40:53 +0000   Wed, 14 Aug 2019 20:03:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.195.18.146\n  ExternalIP:  135.90.65.40\n  Hostname:    10.195.18.146\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419912Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627464Ki\n pods:               110\nSystem Info:\n Machine ID:                 e8fb78ddb4084815bae653cba225a7b0\n System UUID:                F9542451-7D4F-6A07-7B45-E9A3DF36BDB8\n Boot ID:                    3cd13e1f-1b9b-4a76-b657-08907affc0f9\n Kernel Version:             4.15.0-55-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.15.1+IKS\n Kube-Proxy Version:         v1.15.1+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bla66o8s0gv1rqqkhfrg/kube-bla66o8s0gv1rqqkhfrg-kubee2epvgs-default-000001ad\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-e2e-job-a75c763ea9894b1d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         90s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-026562c801934442-shsbw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         90s\n  ibm-system                 ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-lqjjx       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         95m\n  kube-system                calico-kube-controllers-8b68f5487-qch22                    10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      105m\n  kube-system                calico-node-fpcf6                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         98m\n  kube-system                coredns-64f45bf67-kk44n                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     79m\n  kube-system                ibm-keepalived-watcher-jkfrs                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         98m\n  kube-system                ibm-kube-fluentd-f4cz6                                     25m (0%)      300m (7%)   150Mi (1%)       800M (5%)      97m\n  kube-system                ibm-master-proxy-static-10.195.18.146                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      98m\n  kube-system                ibm-storage-watcher-59d4b77767-6bw8v                       50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         103m\n  kube-system                metrics-server-754f4b484d-wjtqj                            53m (1%)      148m (3%)   154Mi (1%)       404Mi (3%)     97m\n  kube-system                public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-ccxfv        0 (0%)        0 (0%)      0 (0%)           0 (0%)         89m\n  kubectl-3707               redis-master-z6gxj                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         7s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                523m (13%)     948m (24%)\n  memory             644626Ki (4%)  5250274Ki (38%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug 14 21:41:26.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 describe namespace kubectl-3707'
Aug 14 21:41:26.852: INFO: stderr: ""
Aug 14 21:41:26.852: INFO: stdout: "Name:         kubectl-3707\nLabels:       e2e-framework=kubectl\n              e2e-run=f3fc71c6-5770-4c8b-888f-8e7c71359206\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:41:26.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3707" for this suite.
Aug 14 21:41:50.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:41:51.459: INFO: namespace kubectl-3707 deletion completed in 24.588994508s

• [SLOW TEST:32.442 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:41:51.460: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1008
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1008
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1008
Aug 14 21:41:51.705: INFO: Found 0 stateful pods, waiting for 1
Aug 14 21:42:01.720: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 14 21:42:01.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:42:02.273: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 21:42:02.273: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:42:02.273: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 21:42:02.293: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 21:42:12.308: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 21:42:12.308: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:42:12.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998275s
Aug 14 21:42:13.368: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.986711048s
Aug 14 21:42:14.381: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.973776038s
Aug 14 21:42:15.394: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.960725323s
Aug 14 21:42:16.413: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.947953471s
Aug 14 21:42:17.425: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.929033231s
Aug 14 21:42:18.439: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.916290992s
Aug 14 21:42:19.452: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.903108617s
Aug 14 21:42:20.465: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.88974714s
Aug 14 21:42:21.478: INFO: Verifying statefulset ss doesn't scale past 1 for another 876.701066ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1008
Aug 14 21:42:22.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:42:22.910: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 21:42:22.910: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 21:42:22.910: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 21:42:22.922: INFO: Found 1 stateful pods, waiting for 3
Aug 14 21:42:32.936: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:42:32.936: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:42:32.936: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug 14 21:42:42.936: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:42:42.936: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:42:42.936: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 14 21:42:42.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:42:43.389: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 21:42:43.389: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:42:43.389: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 21:42:43.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:42:43.835: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 21:42:43.836: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:42:43.836: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 21:42:43.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:42:44.281: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 21:42:44.281: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:42:44.281: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 21:42:44.281: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:42:44.291: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 14 21:42:54.316: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 21:42:54.316: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 21:42:54.316: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 21:42:54.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998341s
Aug 14 21:42:55.381: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987804368s
Aug 14 21:42:56.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97446226s
Aug 14 21:42:57.409: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.961117161s
Aug 14 21:42:58.423: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.946291421s
Aug 14 21:42:59.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933066818s
Aug 14 21:43:00.450: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919061553s
Aug 14 21:43:01.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.90582916s
Aug 14 21:43:02.478: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.892603256s
Aug 14 21:43:03.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 877.527063ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1008
Aug 14 21:43:04.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:04.933: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 21:43:04.933: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 21:43:04.933: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 21:43:04.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:05.379: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 21:43:05.379: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 21:43:05.379: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 21:43:05.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:05.711: INFO: rc: 1
Aug 14 21:43:05.711: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: failed to load task: no running task found: not found
 [] <nil> 0xc002ca3ce0 exit status 1 <nil> <nil> true [0xc002bae400 0xc002bae418 0xc002bae430] [0xc002bae400 0xc002bae418 0xc002bae430] [0xc002bae410 0xc002bae428] [0x9d17b0 0x9d17b0] 0xc002af23c0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to load task: no running task found: not found

error:
exit status 1
Aug 14 21:43:15.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:15.834: INFO: rc: 1
Aug 14 21:43:15.834: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002c88300 exit status 1 <nil> <nil> true [0xc001d52000 0xc001d52020 0xc001d52038] [0xc001d52000 0xc001d52020 0xc001d52038] [0xc001d52010 0xc001d52030] [0x9d17b0 0x9d17b0] 0xc001c69920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:43:25.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:25.962: INFO: rc: 1
Aug 14 21:43:25.962: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001500030 exit status 1 <nil> <nil> true [0xc002bae438 0xc002bae450 0xc002bae468] [0xc002bae438 0xc002bae450 0xc002bae468] [0xc002bae448 0xc002bae460] [0x9d17b0 0x9d17b0] 0xc002af2a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:43:35.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:36.084: INFO: rc: 1
Aug 14 21:43:36.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca2300 exit status 1 <nil> <nil> true [0xc000b3c618 0xc000b3cae8 0xc000b3d080] [0xc000b3c618 0xc000b3cae8 0xc000b3d080] [0xc000b3ca88 0xc000b3d048] [0x9d17b0 0x9d17b0] 0xc0025cecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:43:46.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:46.233: INFO: rc: 1
Aug 14 21:43:46.233: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca2660 exit status 1 <nil> <nil> true [0xc000b3d118 0xc000b3d448 0xc000b3d638] [0xc000b3d118 0xc000b3d448 0xc000b3d638] [0xc000b3d3d8 0xc000b3d590] [0x9d17b0 0x9d17b0] 0xc0025cf7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:43:56.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:43:56.372: INFO: rc: 1
Aug 14 21:43:56.372: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c6330 exit status 1 <nil> <nil> true [0xc000010028 0xc000010e90 0xc000011120] [0xc000010028 0xc000010e90 0xc000011120] [0xc000010e40 0xc000011078] [0x9d17b0 0x9d17b0] 0xc00247e7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:06.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:06.501: INFO: rc: 1
Aug 14 21:44:06.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aa300 exit status 1 <nil> <nil> true [0xc000166000 0xc000166390 0xc0005ac130] [0xc000166000 0xc000166390 0xc0005ac130] [0xc000166258 0xc0005ac100] [0x9d17b0 0x9d17b0] 0xc002ba0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:16.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:16.656: INFO: rc: 1
Aug 14 21:44:16.656: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aa690 exit status 1 <nil> <nil> true [0xc0005ac230 0xc0005ac4c0 0xc0005ac618] [0xc0005ac230 0xc0005ac4c0 0xc0005ac618] [0xc0005ac490 0xc0005ac5b8] [0x9d17b0 0x9d17b0] 0xc002ba0c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:26.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:26.796: INFO: rc: 1
Aug 14 21:44:26.796: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002616330 exit status 1 <nil> <nil> true [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c080 0xc00200c148] [0x9d17b0 0x9d17b0] 0xc001f98ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:36.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:36.937: INFO: rc: 1
Aug 14 21:44:36.937: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aa9f0 exit status 1 <nil> <nil> true [0xc0005ac6e8 0xc0005ac898 0xc0005ace50] [0xc0005ac6e8 0xc0005ac898 0xc0005ace50] [0xc0005ac7d8 0xc0005acd80] [0x9d17b0 0x9d17b0] 0xc002ba0fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:46.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:47.057: INFO: rc: 1
Aug 14 21:44:47.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aad50 exit status 1 <nil> <nil> true [0xc0005acf78 0xc0005ad218 0xc0005ad3d8] [0xc0005acf78 0xc0005ad218 0xc0005ad3d8] [0xc0005ad1b8 0xc0005ad380] [0x9d17b0 0x9d17b0] 0xc002ba1320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:44:57.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:44:57.191: INFO: rc: 1
Aug 14 21:44:57.191: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025ab080 exit status 1 <nil> <nil> true [0xc0005ad438 0xc0005ad568 0xc0005ad818] [0xc0005ad438 0xc0005ad568 0xc0005ad818] [0xc0005ad538 0xc0005ad6e0] [0x9d17b0 0x9d17b0] 0xc002ba1680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:07.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:07.303: INFO: rc: 1
Aug 14 21:45:07.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c6690 exit status 1 <nil> <nil> true [0xc000011198 0xc000011418 0xc000011510] [0xc000011198 0xc000011418 0xc000011510] [0xc0000112f8 0xc0000114c0] [0x9d17b0 0x9d17b0] 0xc00247f2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:17.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:17.444: INFO: rc: 1
Aug 14 21:45:17.444: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002616690 exit status 1 <nil> <nil> true [0xc00200c230 0xc00200c278 0xc00200c2d0] [0xc00200c230 0xc00200c278 0xc00200c2d0] [0xc00200c260 0xc00200c2b0] [0x9d17b0 0x9d17b0] 0xc001f99740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:27.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:27.573: INFO: rc: 1
Aug 14 21:45:27.574: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025ab410 exit status 1 <nil> <nil> true [0xc0005ad890 0xc0005ad998 0xc0005adbb0] [0xc0005ad890 0xc0005ad998 0xc0005adbb0] [0xc0005ad8a8 0xc0005adb38] [0x9d17b0 0x9d17b0] 0xc002ba1aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:37.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:37.695: INFO: rc: 1
Aug 14 21:45:37.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aa330 exit status 1 <nil> <nil> true [0xc0001660f0 0xc0005ac0b8 0xc0005ac230] [0xc0001660f0 0xc0005ac0b8 0xc0005ac230] [0xc000166390 0xc0005ac130] [0x9d17b0 0x9d17b0] 0xc002ba0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:47.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:47.816: INFO: rc: 1
Aug 14 21:45:47.816: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aa6c0 exit status 1 <nil> <nil> true [0xc0005ac340 0xc0005ac548 0xc0005ac6e8] [0xc0005ac340 0xc0005ac548 0xc0005ac6e8] [0xc0005ac4c0 0xc0005ac618] [0x9d17b0 0x9d17b0] 0xc002ba0c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:45:57.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:45:57.945: INFO: rc: 1
Aug 14 21:45:57.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aaa50 exit status 1 <nil> <nil> true [0xc0005ac7b0 0xc0005acbb8 0xc0005acf78] [0xc0005ac7b0 0xc0005acbb8 0xc0005acf78] [0xc0005ac898 0xc0005ace50] [0x9d17b0 0x9d17b0] 0xc002ba0fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:07.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:08.069: INFO: rc: 1
Aug 14 21:46:08.069: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c6300 exit status 1 <nil> <nil> true [0xc000b3c148 0xc000b3ca88 0xc000b3d048] [0xc000b3c148 0xc000b3ca88 0xc000b3d048] [0xc000b3ca50 0xc000b3ceb0] [0x9d17b0 0x9d17b0] 0xc0025cecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:18.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:18.192: INFO: rc: 1
Aug 14 21:46:18.192: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025aade0 exit status 1 <nil> <nil> true [0xc0005ad0f0 0xc0005ad2f0 0xc0005ad438] [0xc0005ad0f0 0xc0005ad2f0 0xc0005ad438] [0xc0005ad218 0xc0005ad3d8] [0x9d17b0 0x9d17b0] 0xc002ba1320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:28.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:28.324: INFO: rc: 1
Aug 14 21:46:28.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002616360 exit status 1 <nil> <nil> true [0xc000010028 0xc000010e90 0xc000011120] [0xc000010028 0xc000010e90 0xc000011120] [0xc000010e40 0xc000011078] [0x9d17b0 0x9d17b0] 0xc00247e7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:38.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:38.470: INFO: rc: 1
Aug 14 21:46:38.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0026166f0 exit status 1 <nil> <nil> true [0xc000011198 0xc000011418 0xc000011510] [0xc000011198 0xc000011418 0xc000011510] [0xc0000112f8 0xc0000114c0] [0x9d17b0 0x9d17b0] 0xc00247f2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:48.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:48.596: INFO: rc: 1
Aug 14 21:46:48.596: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025ab170 exit status 1 <nil> <nil> true [0xc0005ad4b8 0xc0005ad5d0 0xc0005ad890] [0xc0005ad4b8 0xc0005ad5d0 0xc0005ad890] [0xc0005ad568 0xc0005ad818] [0x9d17b0 0x9d17b0] 0xc002ba1680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:46:58.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:46:58.726: INFO: rc: 1
Aug 14 21:46:58.726: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025ab500 exit status 1 <nil> <nil> true [0xc0005ad898 0xc0005adac0 0xc0005adbc0] [0xc0005ad898 0xc0005adac0 0xc0005adbc0] [0xc0005ad998 0xc0005adbb0] [0x9d17b0 0x9d17b0] 0xc002ba1aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:08.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:08.843: INFO: rc: 1
Aug 14 21:47:08.844: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca2360 exit status 1 <nil> <nil> true [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c080 0xc00200c148] [0x9d17b0 0x9d17b0] 0xc001f98ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:18.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:18.966: INFO: rc: 1
Aug 14 21:47:18.966: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002616c00 exit status 1 <nil> <nil> true [0xc000011570 0xc0000116e8 0xc0000118e0] [0xc000011570 0xc0000116e8 0xc0000118e0] [0xc0000116a8 0xc0000117e0] [0x9d17b0 0x9d17b0] 0xc00247fe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:28.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:29.088: INFO: rc: 1
Aug 14 21:47:29.088: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c6660 exit status 1 <nil> <nil> true [0xc000b3d080 0xc000b3d3d8 0xc000b3d590] [0xc000b3d080 0xc000b3d3d8 0xc000b3d590] [0xc000b3d1c8 0xc000b3d4d0] [0x9d17b0 0x9d17b0] 0xc0025cf7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:39.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:39.207: INFO: rc: 1
Aug 14 21:47:39.207: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028c6330 exit status 1 <nil> <nil> true [0xc0001660f0 0xc000b3c148 0xc000b3ca88] [0xc0001660f0 0xc000b3c148 0xc000b3ca88] [0xc000166390 0xc000b3ca50] [0x9d17b0 0x9d17b0] 0xc0025cecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:49.333: INFO: rc: 1
Aug 14 21:47:49.334: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca2300 exit status 1 <nil> <nil> true [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c010 0xc00200c0a8 0xc00200c1c8] [0xc00200c080 0xc00200c148] [0x9d17b0 0x9d17b0] 0xc001f98ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:47:59.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:47:59.478: INFO: rc: 1
Aug 14 21:47:59.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca2660 exit status 1 <nil> <nil> true [0xc00200c230 0xc00200c278 0xc00200c2d0] [0xc00200c230 0xc00200c278 0xc00200c2d0] [0xc00200c260 0xc00200c2b0] [0x9d17b0 0x9d17b0] 0xc001f99740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Aug 14 21:48:09.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-1008 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:48:09.591: INFO: rc: 1
Aug 14 21:48:09.591: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Aug 14 21:48:09.591: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 21:48:09.625: INFO: Deleting all statefulset in ns statefulset-1008
Aug 14 21:48:09.635: INFO: Scaling statefulset ss to 0
Aug 14 21:48:09.668: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:48:09.678: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:48:09.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1008" for this suite.
Aug 14 21:48:17.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:48:18.173: INFO: namespace statefulset-1008 deletion completed in 8.431432052s

• [SLOW TEST:386.713 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:48:18.173: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8651
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-23225462-3418-455d-ad6c-ad3b95cd5a2d
STEP: Creating secret with name s-test-opt-upd-7b83ae0e-2487-4833-929f-6747af373585
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-23225462-3418-455d-ad6c-ad3b95cd5a2d
STEP: Updating secret s-test-opt-upd-7b83ae0e-2487-4833-929f-6747af373585
STEP: Creating secret with name s-test-opt-create-a718b90c-b479-422c-bd19-ce7379df3184
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:48:28.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8651" for this suite.
Aug 14 21:48:52.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:48:53.215: INFO: namespace projected-8651 deletion completed in 24.414623764s

• [SLOW TEST:35.042 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:48:53.216: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1183
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-bbce7b22-4cbf-4f90-a948-5bf09dfe9bad
STEP: Creating secret with name s-test-opt-upd-c20755bf-c18a-4a2d-8775-5a9a45040b8e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bbce7b22-4cbf-4f90-a948-5bf09dfe9bad
STEP: Updating secret s-test-opt-upd-c20755bf-c18a-4a2d-8775-5a9a45040b8e
STEP: Creating secret with name s-test-opt-create-80f74f8b-0ba9-4d47-ad80-bcb3c2ff4156
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:49:05.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1183" for this suite.
Aug 14 21:49:29.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:49:30.239: INFO: namespace secrets-1183 deletion completed in 24.412629871s

• [SLOW TEST:37.024 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:49:30.240: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 21:49:37.114: INFO: Successfully updated pod "labelsupdate8d5edaa0-5901-49df-89a8-55bbfc1c2cd6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:49:41.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7130" for this suite.
Aug 14 21:50:03.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:50:03.645: INFO: namespace downward-api-7130 deletion completed in 22.430820787s

• [SLOW TEST:33.405 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:50:03.646: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-b4a4ecc2-acc2-4201-a67e-1d5f8244e8dc
STEP: Creating a pod to test consume configMaps
Aug 14 21:50:03.887: INFO: Waiting up to 5m0s for pod "pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6" in namespace "configmap-1023" to be "success or failure"
Aug 14 21:50:03.903: INFO: Pod "pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.875007ms
Aug 14 21:50:05.916: INFO: Pod "pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028680464s
Aug 14 21:50:07.930: INFO: Pod "pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042203009s
STEP: Saw pod success
Aug 14 21:50:07.930: INFO: Pod "pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6" satisfied condition "success or failure"
Aug 14 21:50:07.942: INFO: Trying to get logs from node 10.195.18.184 pod pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 21:50:08.016: INFO: Waiting for pod pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6 to disappear
Aug 14 21:50:08.032: INFO: Pod pod-configmaps-dcfaef81-f985-4c4c-8224-6a43e8b3c2b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:50:08.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1023" for this suite.
Aug 14 21:50:14.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:50:14.454: INFO: namespace configmap-1023 deletion completed in 6.406658987s

• [SLOW TEST:10.809 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:50:14.456: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 21:50:22.870: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 21:50:22.893: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 21:50:24.893: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 21:50:24.906: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 21:50:26.893: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 21:50:26.906: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:50:26.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2201" for this suite.
Aug 14 21:50:50.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:50:51.378: INFO: namespace container-lifecycle-hook-2201 deletion completed in 24.448582948s

• [SLOW TEST:36.922 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:50:51.378: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 21:50:51.604: INFO: Waiting up to 5m0s for pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e" in namespace "emptydir-2231" to be "success or failure"
Aug 14 21:50:51.619: INFO: Pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.726442ms
Aug 14 21:50:53.633: INFO: Pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028996417s
Aug 14 21:50:55.646: INFO: Pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041702517s
Aug 14 21:50:57.658: INFO: Pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054080599s
STEP: Saw pod success
Aug 14 21:50:57.658: INFO: Pod "pod-2a725ce1-03e0-4477-b238-3c015c48af1e" satisfied condition "success or failure"
Aug 14 21:50:57.673: INFO: Trying to get logs from node 10.195.18.184 pod pod-2a725ce1-03e0-4477-b238-3c015c48af1e container test-container: <nil>
STEP: delete the pod
Aug 14 21:50:57.734: INFO: Waiting for pod pod-2a725ce1-03e0-4477-b238-3c015c48af1e to disappear
Aug 14 21:50:57.746: INFO: Pod pod-2a725ce1-03e0-4477-b238-3c015c48af1e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:50:57.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2231" for this suite.
Aug 14 21:51:03.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:04.179: INFO: namespace emptydir-2231 deletion completed in 6.4156647s

• [SLOW TEST:12.801 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:51:04.180: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:51:04.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17" in namespace "projected-2635" to be "success or failure"
Aug 14 21:51:04.423: INFO: Pod "downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17": Phase="Pending", Reason="", readiness=false. Elapsed: 20.294241ms
Aug 14 21:51:06.436: INFO: Pod "downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033368071s
Aug 14 21:51:08.449: INFO: Pod "downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04583605s
STEP: Saw pod success
Aug 14 21:51:08.449: INFO: Pod "downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17" satisfied condition "success or failure"
Aug 14 21:51:08.461: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17 container client-container: <nil>
STEP: delete the pod
Aug 14 21:51:08.521: INFO: Waiting for pod downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17 to disappear
Aug 14 21:51:08.533: INFO: Pod downwardapi-volume-d75cc001-ed78-49ca-b806-f05a8aa09f17 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:51:08.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2635" for this suite.
Aug 14 21:51:14.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:15.005: INFO: namespace projected-2635 deletion completed in 6.456315272s

• [SLOW TEST:10.825 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:51:15.006: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 21:51:17.839: INFO: Successfully updated pod "annotationupdate4cfc5c44-1cd8-4b62-9ca8-3b07123ae643"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:51:19.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5717" for this suite.
Aug 14 21:51:43.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:44.327: INFO: namespace downward-api-5717 deletion completed in 24.418291865s

• [SLOW TEST:29.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:51:44.328: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-5493
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5493 to expose endpoints map[]
Aug 14 21:51:44.574: INFO: successfully validated that service endpoint-test2 in namespace services-5493 exposes endpoints map[] (10.622163ms elapsed)
STEP: Creating pod pod1 in namespace services-5493
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5493 to expose endpoints map[pod1:[80]]
Aug 14 21:51:46.667: INFO: successfully validated that service endpoint-test2 in namespace services-5493 exposes endpoints map[pod1:[80]] (2.071808387s elapsed)
STEP: Creating pod pod2 in namespace services-5493
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5493 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 14 21:51:48.794: INFO: successfully validated that service endpoint-test2 in namespace services-5493 exposes endpoints map[pod1:[80] pod2:[80]] (2.108504623s elapsed)
STEP: Deleting pod pod1 in namespace services-5493
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5493 to expose endpoints map[pod2:[80]]
Aug 14 21:51:48.835: INFO: successfully validated that service endpoint-test2 in namespace services-5493 exposes endpoints map[pod2:[80]] (20.674789ms elapsed)
STEP: Deleting pod pod2 in namespace services-5493
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5493 to expose endpoints map[]
Aug 14 21:51:48.866: INFO: successfully validated that service endpoint-test2 in namespace services-5493 exposes endpoints map[] (9.701504ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:51:48.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5493" for this suite.
Aug 14 21:52:12.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:52:13.336: INFO: namespace services-5493 deletion completed in 24.399130894s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.008 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:52:13.338: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:52:13.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55" in namespace "downward-api-5498" to be "success or failure"
Aug 14 21:52:13.578: INFO: Pod "downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55": Phase="Pending", Reason="", readiness=false. Elapsed: 14.777116ms
Aug 14 21:52:15.667: INFO: Pod "downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104634859s
Aug 14 21:52:17.681: INFO: Pod "downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117830748s
STEP: Saw pod success
Aug 14 21:52:17.681: INFO: Pod "downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55" satisfied condition "success or failure"
Aug 14 21:52:17.693: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55 container client-container: <nil>
STEP: delete the pod
Aug 14 21:52:17.753: INFO: Waiting for pod downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55 to disappear
Aug 14 21:52:17.766: INFO: Pod downwardapi-volume-b1d5d62e-e87b-4e3e-b93a-406cbc82ad55 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:52:17.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5498" for this suite.
Aug 14 21:52:23.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:52:24.215: INFO: namespace downward-api-5498 deletion completed in 6.433269617s

• [SLOW TEST:10.877 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:52:24.216: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 21:52:24.519: INFO: Number of nodes with available pods: 0
Aug 14 21:52:24.519: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 21:52:25.569: INFO: Number of nodes with available pods: 0
Aug 14 21:52:25.569: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 21:52:26.553: INFO: Number of nodes with available pods: 2
Aug 14 21:52:26.553: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 21:52:27.548: INFO: Number of nodes with available pods: 3
Aug 14 21:52:27.548: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 14 21:52:27.616: INFO: Number of nodes with available pods: 2
Aug 14 21:52:27.616: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 21:52:28.645: INFO: Number of nodes with available pods: 2
Aug 14 21:52:28.645: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 21:52:29.645: INFO: Number of nodes with available pods: 3
Aug 14 21:52:29.645: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5549, will wait for the garbage collector to delete the pods
Aug 14 21:52:29.750: INFO: Deleting DaemonSet.extensions daemon-set took: 22.279884ms
Aug 14 21:52:29.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.343593ms
Aug 14 21:52:40.463: INFO: Number of nodes with available pods: 0
Aug 14 21:52:40.463: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 21:52:40.475: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5549/daemonsets","resourceVersion":"22823"},"items":null}

Aug 14 21:52:40.486: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5549/pods","resourceVersion":"22823"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:52:40.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5549" for this suite.
Aug 14 21:52:48.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:52:48.989: INFO: namespace daemonsets-5549 deletion completed in 8.425714972s

• [SLOW TEST:24.774 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:52:48.994: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a7402215-9b97-482e-9d33-9755ba668543
STEP: Creating a pod to test consume secrets
Aug 14 21:52:49.245: INFO: Waiting up to 5m0s for pod "pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376" in namespace "secrets-9394" to be "success or failure"
Aug 14 21:52:49.261: INFO: Pod "pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376": Phase="Pending", Reason="", readiness=false. Elapsed: 15.442881ms
Aug 14 21:52:51.274: INFO: Pod "pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028953155s
Aug 14 21:52:53.287: INFO: Pod "pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041971498s
STEP: Saw pod success
Aug 14 21:52:53.287: INFO: Pod "pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376" satisfied condition "success or failure"
Aug 14 21:52:53.303: INFO: Trying to get logs from node 10.195.18.184 pod pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:52:53.364: INFO: Waiting for pod pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376 to disappear
Aug 14 21:52:53.375: INFO: Pod pod-secrets-39938bc8-7f27-4e2e-b24c-b691e3718376 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:52:53.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9394" for this suite.
Aug 14 21:52:59.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:52:59.796: INFO: namespace secrets-9394 deletion completed in 6.405041645s

• [SLOW TEST:10.802 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:52:59.797: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-3125ea07-e2ac-4420-af5d-7260ef092e23
STEP: Creating a pod to test consume secrets
Aug 14 21:53:00.050: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea" in namespace "projected-7115" to be "success or failure"
Aug 14 21:53:00.065: INFO: Pod "pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.100569ms
Aug 14 21:53:02.078: INFO: Pod "pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028385483s
Aug 14 21:53:04.093: INFO: Pod "pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042944214s
STEP: Saw pod success
Aug 14 21:53:04.093: INFO: Pod "pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea" satisfied condition "success or failure"
Aug 14 21:53:04.105: INFO: Trying to get logs from node 10.195.18.146 pod pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:53:04.167: INFO: Waiting for pod pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea to disappear
Aug 14 21:53:04.179: INFO: Pod pod-projected-secrets-14621e23-a58d-4d1d-9598-e0c155d5feea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:53:04.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7115" for this suite.
Aug 14 21:53:10.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:53:10.631: INFO: namespace projected-7115 deletion completed in 6.436222194s

• [SLOW TEST:10.835 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:53:10.632: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 21:53:10.839: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 21:53:10.863: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 21:53:10.873: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.146 before test
Aug 14 21:53:10.924: INFO: sonobuoy-e2e-job-a75c763ea9894b1d from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container e2e ready: true, restart count 0
Aug 14 21:53:10.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:53:10.924: INFO: calico-kube-controllers-8b68f5487-qch22 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 21:53:10.924: INFO: metrics-server-754f4b484d-wjtqj from kube-system started at 2019-08-14 20:03:51 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 21:53:10.924: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 21:53:10.924: INFO: coredns-64f45bf67-kk44n from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container coredns ready: true, restart count 0
Aug 14 21:53:10.924: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-shsbw from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:53:10.924: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 14 21:53:10.924: INFO: calico-node-fpcf6 from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:53:10.924: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-lqjjx from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 21:53:10.924: INFO: ibm-master-proxy-static-10.195.18.146 from kube-system started at 2019-08-14 20:03:15 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 21:53:10.924: INFO: 	Container pause ready: true, restart count 0
Aug 14 21:53:10.924: INFO: ibm-keepalived-watcher-jkfrs from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:53:10.924: INFO: ibm-storage-watcher-59d4b77767-6bw8v from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.924: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 21:53:10.924: INFO: ibm-kube-fluentd-f4cz6 from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.925: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:53:10.925: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-ccxfv from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 21:53:10.925: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 21:53:10.925: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 21:53:10.925: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 21:53:10.925: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 21:53:10.925: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.148 before test
Aug 14 21:53:10.958: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:39:46 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 21:53:10.958: INFO: coredns-64f45bf67-clbcf from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container coredns ready: true, restart count 0
Aug 14 21:53:10.958: INFO: ibm-keepalived-watcher-5hfbl from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:53:10.958: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 20:15:26 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 21:53:10.958: INFO: ibm-master-proxy-static-10.195.18.148 from kube-system started at 2019-08-14 20:12:10 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 21:53:10.958: INFO: 	Container pause ready: true, restart count 0
Aug 14 21:53:10.958: INFO: vpn-75d8697c68-bh22v from kube-system started at 2019-08-14 20:21:26 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container vpn ready: true, restart count 0
Aug 14 21:53:10.958: INFO: calico-node-dtftv from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:53:10.958: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-vt4jz from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:53:10.958: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 14 21:53:10.958: INFO: ibm-kube-fluentd-qfb85 from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.958: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:53:10.959: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.184 before test
Aug 14 21:53:10.992: INFO: calico-node-zh8s4 from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:53:10.992: INFO: kubernetes-dashboard-596f947ff4-zk8kr from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 21:53:10.992: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-8q9np from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 21:53:10.992: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-fjqdk from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:53:10.992: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 14 21:53:10.992: INFO: ibm-master-proxy-static-10.195.18.184 from kube-system started at 2019-08-14 20:03:13 +0000 UTC (2 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 21:53:10.992: INFO: 	Container pause ready: true, restart count 0
Aug 14 21:53:10.992: INFO: ibm-kube-fluentd-9nqvp from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:53:10.992: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-998s4 from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 21:53:10.992: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 21:53:10.992: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 21:53:10.992: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 21:53:10.992: INFO: ibm-file-plugin-869b6f5676-6b5x2 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 21:53:10.992: INFO: ibm-keepalived-watcher-jp68n from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:53:10.992: INFO: coredns-autoscaler-74cb66766b-2b7jq from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:53:10.992: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.195.18.146
STEP: verifying the node has the label node 10.195.18.148
STEP: verifying the node has the label node 10.195.18.184
Aug 14 21:53:11.130: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.195.18.148
Aug 14 21:53:11.130: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.195.18.148
Aug 14 21:53:11.130: INFO: Pod sonobuoy-e2e-job-a75c763ea9894b1d requesting resource cpu=0m on Node 10.195.18.146
Aug 14 21:53:11.130: INFO: Pod sonobuoy-systemd-logs-daemon-set-026562c801934442-fjqdk requesting resource cpu=0m on Node 10.195.18.184
Aug 14 21:53:11.130: INFO: Pod sonobuoy-systemd-logs-daemon-set-026562c801934442-shsbw requesting resource cpu=0m on Node 10.195.18.146
Aug 14 21:53:11.130: INFO: Pod sonobuoy-systemd-logs-daemon-set-026562c801934442-vt4jz requesting resource cpu=0m on Node 10.195.18.148
Aug 14 21:53:11.130: INFO: Pod ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-8q9np requesting resource cpu=5m on Node 10.195.18.184
Aug 14 21:53:11.130: INFO: Pod ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-lqjjx requesting resource cpu=5m on Node 10.195.18.146
Aug 14 21:53:11.130: INFO: Pod calico-kube-controllers-8b68f5487-qch22 requesting resource cpu=10m on Node 10.195.18.146
Aug 14 21:53:11.130: INFO: Pod calico-node-dtftv requesting resource cpu=250m on Node 10.195.18.148
Aug 14 21:53:11.130: INFO: Pod calico-node-fpcf6 requesting resource cpu=250m on Node 10.195.18.146
Aug 14 21:53:11.130: INFO: Pod calico-node-zh8s4 requesting resource cpu=250m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod coredns-64f45bf67-clbcf requesting resource cpu=100m on Node 10.195.18.148
Aug 14 21:53:11.131: INFO: Pod coredns-64f45bf67-kk44n requesting resource cpu=100m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod coredns-autoscaler-74cb66766b-2b7jq requesting resource cpu=20m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod ibm-file-plugin-869b6f5676-6b5x2 requesting resource cpu=50m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod ibm-keepalived-watcher-5hfbl requesting resource cpu=5m on Node 10.195.18.148
Aug 14 21:53:11.131: INFO: Pod ibm-keepalived-watcher-jkfrs requesting resource cpu=5m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod ibm-keepalived-watcher-jp68n requesting resource cpu=5m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod ibm-kube-fluentd-9nqvp requesting resource cpu=25m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod ibm-kube-fluentd-f4cz6 requesting resource cpu=25m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod ibm-kube-fluentd-qfb85 requesting resource cpu=25m on Node 10.195.18.148
Aug 14 21:53:11.131: INFO: Pod ibm-master-proxy-static-10.195.18.146 requesting resource cpu=25m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod ibm-master-proxy-static-10.195.18.148 requesting resource cpu=25m on Node 10.195.18.148
Aug 14 21:53:11.131: INFO: Pod ibm-master-proxy-static-10.195.18.184 requesting resource cpu=25m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod ibm-storage-watcher-59d4b77767-6bw8v requesting resource cpu=50m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod kubernetes-dashboard-596f947ff4-zk8kr requesting resource cpu=50m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod metrics-server-754f4b484d-wjtqj requesting resource cpu=53m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-998s4 requesting resource cpu=0m on Node 10.195.18.184
Aug 14 21:53:11.131: INFO: Pod public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-ccxfv requesting resource cpu=0m on Node 10.195.18.146
Aug 14 21:53:11.131: INFO: Pod vpn-75d8697c68-bh22v requesting resource cpu=5m on Node 10.195.18.148
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25.15bae89f424e899d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2056/filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25 to 10.195.18.148]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25.15bae89f7ff82259], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25.15bae89f84c17b17], Reason = [Created], Message = [Created container filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25.15bae89f925ae9bf], Reason = [Started], Message = [Started container filler-pod-685e814f-9cfa-436d-808d-b9ba2c72bb25]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c.15bae89f41870818], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2056/filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c to 10.195.18.146]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c.15bae89f80ba0c57], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c.15bae89f8482e00f], Reason = [Created], Message = [Created container filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c.15bae89f9338603c], Reason = [Started], Message = [Started container filler-pod-92097ea3-3624-4967-9ee8-7a9909dcf20c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7.15bae89f4338de88], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2056/filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7 to 10.195.18.184]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7.15bae89f83eaf0c4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7.15bae89f88b6f47a], Reason = [Created], Message = [Created container filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7.15bae89f96e8e3a4], Reason = [Started], Message = [Started container filler-pod-f74e2c55-86cb-4111-a555-59abf8680bb7]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bae8a0365f5a05], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.195.18.146
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.195.18.148
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.195.18.184
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:53:16.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2056" for this suite.
Aug 14 21:53:22.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:53:22.870: INFO: namespace sched-pred-2056 deletion completed in 6.447412074s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.238 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:53:22.871: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:53:29.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4145" for this suite.
Aug 14 21:54:19.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:54:19.615: INFO: namespace kubelet-test-4145 deletion completed in 50.42553117s

• [SLOW TEST:56.745 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:54:19.615: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 21:54:39.954: INFO: DNS probes using dns-test-f1576e06-24e3-4d99-9d72-5f02f359bd11 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 21:55:00.109: INFO: File wheezy_udp@dns-test-service-3.dns-3394.svc.cluster.local from pod  dns-3394/dns-test-535a9acb-4fd3-4b45-9635-dd11bb08dc8b contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 14 21:55:00.127: INFO: File jessie_udp@dns-test-service-3.dns-3394.svc.cluster.local from pod  dns-3394/dns-test-535a9acb-4fd3-4b45-9635-dd11bb08dc8b contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 14 21:55:00.127: INFO: Lookups using dns-3394/dns-test-535a9acb-4fd3-4b45-9635-dd11bb08dc8b failed for: [wheezy_udp@dns-test-service-3.dns-3394.svc.cluster.local jessie_udp@dns-test-service-3.dns-3394.svc.cluster.local]

Aug 14 21:55:05.163: INFO: DNS probes using dns-test-535a9acb-4fd3-4b45-9635-dd11bb08dc8b succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3394.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3394.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 21:55:09.376: INFO: DNS probes using dns-test-4184a062-c18c-435f-b7b0-7ef81da58951 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:55:09.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3394" for this suite.
Aug 14 21:55:17.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:55:17.934: INFO: namespace dns-3394 deletion completed in 8.459286344s

• [SLOW TEST:58.319 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:55:17.935: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 14 21:55:24.457: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-bbdbff69-9df5-4fbb-bd47-4868df5575d2,GenerateName:,Namespace:events-2975,SelfLink:/api/v1/namespaces/events-2975/pods/send-events-bbdbff69-9df5-4fbb-bd47-4868df5575d2,UID:250630ca-78cc-4f6a-9f60-eb1487e256ed,ResourceVersion:23507,Generation:0,CreationTimestamp:2019-08-14 21:55:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 378938395,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fnv4w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fnv4w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-fnv4w true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f769f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f76a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:55:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:55:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:55:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:55:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.125,StartTime:2019-08-14 21:55:18 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-14 21:55:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://953de8f18fd966f159b7e6fa5422027be5889ed5fe698e1cc7aaf6e2a1169e4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 14 21:55:26.469: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 14 21:55:28.495: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:55:28.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2975" for this suite.
Aug 14 21:56:08.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:56:08.953: INFO: namespace events-2975 deletion completed in 40.420077263s

• [SLOW TEST:51.019 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:56:08.953: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9027
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-tbl4
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 21:56:09.219: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-tbl4" in namespace "subpath-9027" to be "success or failure"
Aug 14 21:56:09.233: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.197677ms
Aug 14 21:56:11.246: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.027037008s
Aug 14 21:56:13.260: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 4.040579182s
Aug 14 21:56:15.272: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 6.053115119s
Aug 14 21:56:17.285: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 8.065455774s
Aug 14 21:56:19.297: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 10.078123693s
Aug 14 21:56:21.310: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 12.091139302s
Aug 14 21:56:23.323: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 14.104131856s
Aug 14 21:56:25.336: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 16.116818029s
Aug 14 21:56:27.349: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 18.129649178s
Aug 14 21:56:29.363: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 20.143691028s
Aug 14 21:56:31.376: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Running", Reason="", readiness=true. Elapsed: 22.156653771s
Aug 14 21:56:33.389: INFO: Pod "pod-subpath-test-projected-tbl4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.170108799s
STEP: Saw pod success
Aug 14 21:56:33.389: INFO: Pod "pod-subpath-test-projected-tbl4" satisfied condition "success or failure"
Aug 14 21:56:33.401: INFO: Trying to get logs from node 10.195.18.146 pod pod-subpath-test-projected-tbl4 container test-container-subpath-projected-tbl4: <nil>
STEP: delete the pod
Aug 14 21:56:33.478: INFO: Waiting for pod pod-subpath-test-projected-tbl4 to disappear
Aug 14 21:56:33.505: INFO: Pod pod-subpath-test-projected-tbl4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-tbl4
Aug 14 21:56:33.505: INFO: Deleting pod "pod-subpath-test-projected-tbl4" in namespace "subpath-9027"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:56:33.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9027" for this suite.
Aug 14 21:56:39.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:56:39.953: INFO: namespace subpath-9027 deletion completed in 6.418068271s

• [SLOW TEST:31.000 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:56:39.955: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 14 21:56:40.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 --namespace=kubectl-3330 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 14 21:56:42.418: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 14 21:56:42.418: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:56:44.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3330" for this suite.
Aug 14 21:56:52.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:56:52.862: INFO: namespace kubectl-3330 deletion completed in 8.406306943s

• [SLOW TEST:12.908 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:56:52.863: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-3620/secret-test-87612ade-ce0a-4397-8de0-8249f1adb5f5
STEP: Creating a pod to test consume secrets
Aug 14 21:56:53.107: INFO: Waiting up to 5m0s for pod "pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13" in namespace "secrets-3620" to be "success or failure"
Aug 14 21:56:53.125: INFO: Pod "pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13": Phase="Pending", Reason="", readiness=false. Elapsed: 17.520053ms
Aug 14 21:56:55.138: INFO: Pod "pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031050005s
Aug 14 21:56:57.151: INFO: Pod "pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043365205s
STEP: Saw pod success
Aug 14 21:56:57.151: INFO: Pod "pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13" satisfied condition "success or failure"
Aug 14 21:56:57.165: INFO: Trying to get logs from node 10.195.18.148 pod pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13 container env-test: <nil>
STEP: delete the pod
Aug 14 21:56:57.248: INFO: Waiting for pod pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13 to disappear
Aug 14 21:56:57.264: INFO: Pod pod-configmaps-b969755e-4e60-4f68-afb7-6b20195aac13 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:56:57.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3620" for this suite.
Aug 14 21:57:03.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:57:03.715: INFO: namespace secrets-3620 deletion completed in 6.43389796s

• [SLOW TEST:10.851 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:57:03.715: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 21:57:03.933: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:57:07.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2656" for this suite.
Aug 14 21:57:13.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:57:14.267: INFO: namespace init-container-2656 deletion completed in 6.455165394s

• [SLOW TEST:10.552 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:57:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 14 21:57:14.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-5115'
Aug 14 21:57:14.787: INFO: stderr: ""
Aug 14 21:57:14.787: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 21:57:15.801: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:15.801: INFO: Found 0 / 1
Aug 14 21:57:16.800: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:16.800: INFO: Found 0 / 1
Aug 14 21:57:17.800: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:17.800: INFO: Found 0 / 1
Aug 14 21:57:18.800: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:18.801: INFO: Found 0 / 1
Aug 14 21:57:19.800: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:19.800: INFO: Found 0 / 1
Aug 14 21:57:20.800: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:20.800: INFO: Found 1 / 1
Aug 14 21:57:20.800: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 14 21:57:20.825: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:20.825: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 21:57:20.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 patch pod redis-master-z2zvn --namespace=kubectl-5115 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 14 21:57:20.959: INFO: stderr: ""
Aug 14 21:57:20.959: INFO: stdout: "pod/redis-master-z2zvn patched\n"
STEP: checking annotations
Aug 14 21:57:20.975: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:57:20.975: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:57:20.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5115" for this suite.
Aug 14 21:57:45.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:57:45.431: INFO: namespace kubectl-5115 deletion completed in 24.439720894s

• [SLOW TEST:31.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:57:45.431: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 21:57:45.636: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:57:52.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-611" for this suite.
Aug 14 21:57:58.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:57:59.628: INFO: namespace init-container-611 deletion completed in 6.734689769s

• [SLOW TEST:14.196 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:57:59.628: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 21:57:59.843: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:58:04.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8627" for this suite.
Aug 14 21:58:44.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:58:44.676: INFO: namespace pods-8627 deletion completed in 40.430109596s

• [SLOW TEST:45.048 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:58:44.676: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 21:58:44.902: INFO: Waiting up to 5m0s for pod "pod-811d350d-d418-401d-88bc-22906999d6a6" in namespace "emptydir-5775" to be "success or failure"
Aug 14 21:58:44.916: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.225563ms
Aug 14 21:58:46.929: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026638488s
Aug 14 21:58:48.944: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04139124s
Aug 14 21:58:50.956: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.053708306s
Aug 14 21:58:52.969: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.066568359s
STEP: Saw pod success
Aug 14 21:58:52.969: INFO: Pod "pod-811d350d-d418-401d-88bc-22906999d6a6" satisfied condition "success or failure"
Aug 14 21:58:52.981: INFO: Trying to get logs from node 10.195.18.146 pod pod-811d350d-d418-401d-88bc-22906999d6a6 container test-container: <nil>
STEP: delete the pod
Aug 14 21:58:53.045: INFO: Waiting for pod pod-811d350d-d418-401d-88bc-22906999d6a6 to disappear
Aug 14 21:58:53.057: INFO: Pod pod-811d350d-d418-401d-88bc-22906999d6a6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:58:53.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5775" for this suite.
Aug 14 21:58:59.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:58:59.519: INFO: namespace emptydir-5775 deletion completed in 6.445955105s

• [SLOW TEST:14.844 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:58:59.521: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 21:58:59.731: INFO: Creating deployment "nginx-deployment"
Aug 14 21:58:59.744: INFO: Waiting for observed generation 1
Aug 14 21:59:01.769: INFO: Waiting for all required pods to come up
Aug 14 21:59:01.788: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 14 21:59:03.829: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 14 21:59:03.855: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 14 21:59:03.879: INFO: Updating deployment nginx-deployment
Aug 14 21:59:03.879: INFO: Waiting for observed generation 2
Aug 14 21:59:05.909: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 14 21:59:05.920: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 14 21:59:05.933: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 21:59:05.964: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 14 21:59:05.964: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 14 21:59:05.973: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 21:59:05.995: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 14 21:59:05.995: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 14 21:59:06.020: INFO: Updating deployment nginx-deployment
Aug 14 21:59:06.020: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 14 21:59:06.041: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 14 21:59:08.066: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 21:59:08.091: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-254,SelfLink:/apis/apps/v1/namespaces/deployment-254/deployments/nginx-deployment,UID:c13dffae-b35b-4075-9c5d-2e0328b7278c,ResourceVersion:24699,Generation:3,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-08-14 21:59:06 +0000 UTC 2019-08-14 21:59:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 21:59:08 +0000 UTC 2019-08-14 21:58:59 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Aug 14 21:59:08.109: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-254,SelfLink:/apis/apps/v1/namespaces/deployment-254/replicasets/nginx-deployment-55fb7cb77f,UID:f2470ce8-f4c4-465e-8d83-defb960bb34b,ResourceVersion:24538,Generation:3,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c13dffae-b35b-4075-9c5d-2e0328b7278c 0xc0025d43d7 0xc0025d43d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 21:59:08.109: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 14 21:59:08.109: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-254,SelfLink:/apis/apps/v1/namespaces/deployment-254/replicasets/nginx-deployment-7b8c6f4498,UID:2e06a391-3631-47c1-a271-9d01b48efda5,ResourceVersion:24698,Generation:3,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c13dffae-b35b-4075-9c5d-2e0328b7278c 0xc0025d44a7 0xc0025d44a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Aug 14 21:59:08.141: INFO: Pod "nginx-deployment-55fb7cb77f-282zd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-282zd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-282zd,UID:08ce9e45-5a6b-45e9-885f-d8637e573c5b,ResourceVersion:24562,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d4e17 0xc0025d4e18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d4e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d4eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.142: INFO: Pod "nginx-deployment-55fb7cb77f-59fdr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-59fdr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-59fdr,UID:d68703ee-870e-4484-a5f1-7af88b5d4c56,ResourceVersion:24582,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d4f80 0xc0025d4f81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.142: INFO: Pod "nginx-deployment-55fb7cb77f-76pzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-76pzs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-76pzs,UID:ee0f77ac-f8e7-4e89-a98f-78e560547829,ResourceVersion:24567,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d50f0 0xc0025d50f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d51a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.142: INFO: Pod "nginx-deployment-55fb7cb77f-ft6b8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ft6b8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-ft6b8,UID:805e0eab-23c6-4338-81df-a293679d7323,ResourceVersion:24558,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5270 0xc0025d5271}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.142: INFO: Pod "nginx-deployment-55fb7cb77f-klbhr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-klbhr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-klbhr,UID:9886cde3-e9d4-472a-b8b4-fe2b5920f483,ResourceVersion:24546,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d53f0 0xc0025d53f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d54a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.143: INFO: Pod "nginx-deployment-55fb7cb77f-qs2d6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qs2d6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-qs2d6,UID:5d2e6680-332d-4f7e-8c91-478acce97eda,ResourceVersion:24600,Generation:0,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5570 0xc0025d5571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.70,StartTime:2019-08-14 21:59:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.143: INFO: Pod "nginx-deployment-55fb7cb77f-rb6pp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rb6pp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-rb6pp,UID:e6422a6a-de85-40ad-945f-97a6f16514f4,ResourceVersion:24541,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5710 0xc0025d5711}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d57b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.143: INFO: Pod "nginx-deployment-55fb7cb77f-rfnd2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rfnd2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-rfnd2,UID:1589ac58-1850-45fd-b7bb-abeee93ba596,ResourceVersion:24565,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5880 0xc0025d5881}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.143: INFO: Pod "nginx-deployment-55fb7cb77f-rn5bl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rn5bl,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-rn5bl,UID:5d78d332-0be8-4621-b1f6-64a1d150759d,ResourceVersion:24695,Generation:0,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5a00 0xc0025d5a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:172.30.168.75,StartTime:2019-08-14 21:59:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.144: INFO: Pod "nginx-deployment-55fb7cb77f-v7bmt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-v7bmt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-v7bmt,UID:4f96b2cc-0eaa-4d31-95fb-be07eedcf70e,ResourceVersion:24440,Generation:0,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5bd0 0xc0025d5bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.144: INFO: Pod "nginx-deployment-55fb7cb77f-w68sc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w68sc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-w68sc,UID:d52a9988-e3a0-4783-9b04-6f849dab289b,ResourceVersion:24413,Generation:0,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5d40 0xc0025d5d41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.144: INFO: Pod "nginx-deployment-55fb7cb77f-x9p6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-x9p6x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-x9p6x,UID:0067909f-5937-45a4-96b4-f020203ab079,ResourceVersion:24529,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc0025d5eb0 0xc0025d5eb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025d5f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d5f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.145: INFO: Pod "nginx-deployment-55fb7cb77f-zt6kz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-zt6kz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-55fb7cb77f-zt6kz,UID:8cc2f900-0e6d-4dad-a98b-3a14b1f30f88,ResourceVersion:24688,Generation:0,CreationTimestamp:2019-08-14 21:59:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f2470ce8-f4c4-465e-8d83-defb960bb34b 0xc003156030 0xc003156031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031560b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031560d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:03 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.69,StartTime:2019-08-14 21:59:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.148: INFO: Pod "nginx-deployment-7b8c6f4498-2cfsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2cfsx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-2cfsx,UID:139a54be-3b66-4415-b15a-8065f39db46e,ResourceVersion:24550,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031561c0 0xc0031561c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.149: INFO: Pod "nginx-deployment-7b8c6f4498-2rctj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2rctj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-2rctj,UID:698f5f07-6ef2-4823-8b0d-00ed586c382e,ResourceVersion:24362,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156317 0xc003156318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031563b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.127,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7d54c78f2777ef657c8be8c21f3d9e4c2532ad3f5fccfff2e8ba544cdbb276db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.150: INFO: Pod "nginx-deployment-7b8c6f4498-2wd4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2wd4q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-2wd4q,UID:7a91fe51-1c32-427b-bf9b-200d5a5e2117,ResourceVersion:24535,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156487 0xc003156488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.150: INFO: Pod "nginx-deployment-7b8c6f4498-6gfms" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6gfms,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-6gfms,UID:92cbc9ba-5c56-41d8-96ef-d3786e9310e7,ResourceVersion:24384,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031565e7 0xc0031565e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.253,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://6d319aeec0e5cc093ffe6d04d005a4c685793c983b78b4bf510eafd465bc95ff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.150: INFO: Pod "nginx-deployment-7b8c6f4498-7h49c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7h49c,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-7h49c,UID:46e92be7-f8dc-4177-85a2-a214460c9f8f,ResourceVersion:24367,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156757 0xc003156758}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031567d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031567f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.67,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://5c45529cd4883d6345112a420cdc0d43ad302b12c6eb76e7ddadb8c220268bc2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.151: INFO: Pod "nginx-deployment-7b8c6f4498-9lfvd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9lfvd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-9lfvd,UID:3ffda475-16a0-4655-8fea-d88184e2becf,ResourceVersion:24554,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031568c7 0xc0031568c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.151: INFO: Pod "nginx-deployment-7b8c6f4498-bcnx7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bcnx7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-bcnx7,UID:25d493be-81c1-4419-aa9e-fc20c4f5ea8a,ResourceVersion:24381,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156a27 0xc003156a28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.251,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://345684336e363f7d5ec55bf8bf44ba89fecccccf82c3a81bf4c12569c38f39a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.151: INFO: Pod "nginx-deployment-7b8c6f4498-dlq5k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dlq5k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-dlq5k,UID:60ff9b63-9092-44cc-99d6-f939ff18aee7,ResourceVersion:24378,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156b97 0xc003156b98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.252,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://fa48048d18d187a6fdaccf8d15c2b518e90575e747c08144a9cd70e840074357}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.153: INFO: Pod "nginx-deployment-7b8c6f4498-dmkdz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dmkdz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-dmkdz,UID:1bc56f61-fd57-475a-bf07-8abf5b804c27,ResourceVersion:24364,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156d07 0xc003156d08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:172.30.168.73,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://de6efa06eade29a9bf41bad6bbd657e4b90dce686a6a0a860848c6630d75d939}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.153: INFO: Pod "nginx-deployment-7b8c6f4498-dzqq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dzqq9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-dzqq9,UID:9bf9fe84-ce07-44d8-9218-49acf4133183,ResourceVersion:24581,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156e77 0xc003156e78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003156ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003156f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.153: INFO: Pod "nginx-deployment-7b8c6f4498-hv6bn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hv6bn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-hv6bn,UID:c769521a-f767-4351-86b3-3c2efc535395,ResourceVersion:24560,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003156fd7 0xc003156fd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.153: INFO: Pod "nginx-deployment-7b8c6f4498-kfk4p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kfk4p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-kfk4p,UID:f467bfd4-51b6-4b53-b1fa-0d1c580d1ea1,ResourceVersion:24573,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157137 0xc003157138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031571b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031571d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.154: INFO: Pod "nginx-deployment-7b8c6f4498-lw4ww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lw4ww,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-lw4ww,UID:90d9bfae-7faa-4d37-8ec5-9b7a02a1037b,ResourceVersion:24579,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157297 0xc003157298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.154: INFO: Pod "nginx-deployment-7b8c6f4498-m9v4l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m9v4l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-m9v4l,UID:4f9d0e9a-50b8-4f6b-8130-ae0e477e4b7e,ResourceVersion:24343,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031573f7 0xc0031573f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.249,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://8e641fe80498b4afb8208c8c7a070abd5a731fff23c05580d6c520483aa3da47}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.154: INFO: Pod "nginx-deployment-7b8c6f4498-mnxp4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mnxp4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-mnxp4,UID:3c77ffe4-a2ca-4737-9a64-83cd5824421a,ResourceVersion:24570,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157567 0xc003157568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031575f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.154: INFO: Pod "nginx-deployment-7b8c6f4498-pc68g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pc68g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-pc68g,UID:cfa93c47-819a-46c8-bfa8-e8bcebacad09,ResourceVersion:24694,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031576d7 0xc0031576d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.76,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:07 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://3b27553b1b78395ba9020731aa133c9cf510b7c462c0fd72f8cea89a1d6c3bda}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.155: INFO: Pod "nginx-deployment-7b8c6f4498-qnbz4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qnbz4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-qnbz4,UID:d872cc52-3d05-4755-b38b-b7b0ee30c87c,ResourceVersion:24549,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157847 0xc003157848}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031578c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031578e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.155: INFO: Pod "nginx-deployment-7b8c6f4498-wmdvg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wmdvg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-wmdvg,UID:73b90af4-bede-4563-b09a-39ad42c3e4f0,ResourceVersion:24358,Generation:0,CreationTimestamp:2019-08-14 21:58:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc0031579a7 0xc0031579a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:58:59 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.184,PodIP:172.30.76.72,StartTime:2019-08-14 21:58:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 21:59:01 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a0425d6d17ff21a5829f009ab0abec55bb2d8196bed1e9d800a8359f7a7347f6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.155: INFO: Pod "nginx-deployment-7b8c6f4498-xsnmg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xsnmg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-xsnmg,UID:58b376c5-0057-4f4b-a1ae-bef703a31333,ResourceVersion:24574,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157b17 0xc003157b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 21:59:08.155: INFO: Pod "nginx-deployment-7b8c6f4498-zm56h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zm56h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-254,SelfLink:/api/v1/namespaces/deployment-254/pods/nginx-deployment-7b8c6f4498-zm56h,UID:f7dc35ba-e110-4210-be3b-f9be130ea487,ResourceVersion:24519,Generation:0,CreationTimestamp:2019-08-14 21:59:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 2e06a391-3631-47c1-a271-9d01b48efda5 0xc003157c77 0xc003157c78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6hmbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6hmbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6hmbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003157cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003157d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:59:06 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:,StartTime:2019-08-14 21:59:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:59:08.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-254" for this suite.
Aug 14 21:59:18.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:59:18.604: INFO: namespace deployment-254 deletion completed in 10.431583135s

• [SLOW TEST:19.084 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:59:18.609: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 21:59:21.447: INFO: Successfully updated pod "annotationupdate14058580-20ec-4496-85c3-336119cfbd2f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 21:59:23.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-697" for this suite.
Aug 14 21:59:47.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:59:47.935: INFO: namespace projected-697 deletion completed in 24.421810766s

• [SLOW TEST:29.327 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 21:59:47.936: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 14 21:59:48.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-3520'
Aug 14 21:59:48.409: INFO: stderr: ""
Aug 14 21:59:48.409: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 21:59:48.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 21:59:48.545: INFO: stderr: ""
Aug 14 21:59:48.545: INFO: stdout: "update-demo-nautilus-shqgd update-demo-nautilus-xqntf "
Aug 14 21:59:48.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:48.657: INFO: stderr: ""
Aug 14 21:59:48.657: INFO: stdout: ""
Aug 14 21:59:48.657: INFO: update-demo-nautilus-shqgd is created but not running
Aug 14 21:59:53.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 21:59:53.776: INFO: stderr: ""
Aug 14 21:59:53.776: INFO: stdout: "update-demo-nautilus-shqgd update-demo-nautilus-xqntf "
Aug 14 21:59:53.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:53.886: INFO: stderr: ""
Aug 14 21:59:53.886: INFO: stdout: ""
Aug 14 21:59:53.886: INFO: update-demo-nautilus-shqgd is created but not running
Aug 14 21:59:58.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 21:59:59.005: INFO: stderr: ""
Aug 14 21:59:59.005: INFO: stdout: "update-demo-nautilus-shqgd update-demo-nautilus-xqntf "
Aug 14 21:59:59.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:59.118: INFO: stderr: ""
Aug 14 21:59:59.118: INFO: stdout: "true"
Aug 14 21:59:59.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:59.229: INFO: stderr: ""
Aug 14 21:59:59.229: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 21:59:59.229: INFO: validating pod update-demo-nautilus-shqgd
Aug 14 21:59:59.253: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 21:59:59.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 21:59:59.253: INFO: update-demo-nautilus-shqgd is verified up and running
Aug 14 21:59:59.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-xqntf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:59.375: INFO: stderr: ""
Aug 14 21:59:59.375: INFO: stdout: "true"
Aug 14 21:59:59.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-xqntf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 21:59:59.498: INFO: stderr: ""
Aug 14 21:59:59.498: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 21:59:59.498: INFO: validating pod update-demo-nautilus-xqntf
Aug 14 21:59:59.526: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 21:59:59.526: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 21:59:59.526: INFO: update-demo-nautilus-xqntf is verified up and running
STEP: scaling down the replication controller
Aug 14 21:59:59.528: INFO: scanned /root for discovery docs: <nil>
Aug 14 21:59:59.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3520'
Aug 14 22:00:00.670: INFO: stderr: ""
Aug 14 22:00:00.670: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:00:00.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 22:00:00.794: INFO: stderr: ""
Aug 14 22:00:00.794: INFO: stdout: "update-demo-nautilus-shqgd update-demo-nautilus-xqntf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 14 22:00:05.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 22:00:05.963: INFO: stderr: ""
Aug 14 22:00:05.963: INFO: stdout: "update-demo-nautilus-shqgd "
Aug 14 22:00:05.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:06.108: INFO: stderr: ""
Aug 14 22:00:06.108: INFO: stdout: "true"
Aug 14 22:00:06.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:06.217: INFO: stderr: ""
Aug 14 22:00:06.217: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:00:06.217: INFO: validating pod update-demo-nautilus-shqgd
Aug 14 22:00:06.235: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:00:06.235: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:00:06.235: INFO: update-demo-nautilus-shqgd is verified up and running
STEP: scaling up the replication controller
Aug 14 22:00:06.237: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:00:06.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3520'
Aug 14 22:00:07.391: INFO: stderr: ""
Aug 14 22:00:07.391: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:00:07.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 22:00:07.497: INFO: stderr: ""
Aug 14 22:00:07.497: INFO: stdout: "update-demo-nautilus-bjxwv update-demo-nautilus-shqgd "
Aug 14 22:00:07.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-bjxwv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:07.649: INFO: stderr: ""
Aug 14 22:00:07.649: INFO: stdout: ""
Aug 14 22:00:07.649: INFO: update-demo-nautilus-bjxwv is created but not running
Aug 14 22:00:12.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3520'
Aug 14 22:00:12.769: INFO: stderr: ""
Aug 14 22:00:12.769: INFO: stdout: "update-demo-nautilus-bjxwv update-demo-nautilus-shqgd "
Aug 14 22:00:12.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-bjxwv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:12.895: INFO: stderr: ""
Aug 14 22:00:12.895: INFO: stdout: "true"
Aug 14 22:00:12.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-bjxwv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:13.027: INFO: stderr: ""
Aug 14 22:00:13.027: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:00:13.027: INFO: validating pod update-demo-nautilus-bjxwv
Aug 14 22:00:13.055: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:00:13.055: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:00:13.055: INFO: update-demo-nautilus-bjxwv is verified up and running
Aug 14 22:00:13.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:13.169: INFO: stderr: ""
Aug 14 22:00:13.169: INFO: stdout: "true"
Aug 14 22:00:13.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-shqgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3520'
Aug 14 22:00:13.269: INFO: stderr: ""
Aug 14 22:00:13.269: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:00:13.269: INFO: validating pod update-demo-nautilus-shqgd
Aug 14 22:00:13.288: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:00:13.288: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:00:13.288: INFO: update-demo-nautilus-shqgd is verified up and running
STEP: using delete to clean up resources
Aug 14 22:00:13.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-3520'
Aug 14 22:00:13.409: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:00:13.409: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 22:00:13.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3520'
Aug 14 22:00:13.558: INFO: stderr: "No resources found.\n"
Aug 14 22:00:13.558: INFO: stdout: ""
Aug 14 22:00:13.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -l name=update-demo --namespace=kubectl-3520 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 22:00:13.692: INFO: stderr: ""
Aug 14 22:00:13.692: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:00:13.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3520" for this suite.
Aug 14 22:00:37.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:38.176: INFO: namespace kubectl-3520 deletion completed in 24.466753945s

• [SLOW TEST:50.240 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:00:38.176: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:00:38.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524" in namespace "projected-6261" to be "success or failure"
Aug 14 22:00:38.419: INFO: Pod "downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524": Phase="Pending", Reason="", readiness=false. Elapsed: 13.936287ms
Aug 14 22:00:40.434: INFO: Pod "downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029054892s
STEP: Saw pod success
Aug 14 22:00:40.434: INFO: Pod "downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524" satisfied condition "success or failure"
Aug 14 22:00:40.450: INFO: Trying to get logs from node 10.195.18.184 pod downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524 container client-container: <nil>
STEP: delete the pod
Aug 14 22:00:40.523: INFO: Waiting for pod downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524 to disappear
Aug 14 22:00:40.536: INFO: Pod downwardapi-volume-136fb7ba-0bf2-4381-a5a5-bbd30a336524 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:00:40.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6261" for this suite.
Aug 14 22:00:46.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:46.983: INFO: namespace projected-6261 deletion completed in 6.430246188s

• [SLOW TEST:8.807 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:00:46.984: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 22:00:47.188: INFO: PodSpec: initContainers in spec.initContainers
Aug 14 22:01:30.814: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7e7beb97-498b-444b-90ec-0b5a2c67ab8b", GenerateName:"", Namespace:"init-container-7892", SelfLink:"/api/v1/namespaces/init-container-7892/pods/pod-init-7e7beb97-498b-444b-90ec-0b5a2c67ab8b", UID:"24031882-ab56-4137-b900-5c9374bc7064", ResourceVersion:"25528", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701416847, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"188615391"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ts424", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000da0a00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ts424", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ts424", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ts424", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001ddc088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.195.18.148", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001c68480), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ddc120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ddc150)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001ddc158), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001ddc15c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416847, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416847, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416847, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416847, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.195.18.148", PodIP:"172.30.32.205", StartTime:(*v1.Time)(0xc000bee2c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000406230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0004062a0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://7d6028ab72a5bf7b4a3c83eaf5630c86d6de59ebb95304ad491aaa0e3a031af8"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000bee440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000bee360), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:01:30.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7892" for this suite.
Aug 14 22:01:54.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:01:55.657: INFO: namespace init-container-7892 deletion completed in 24.82372091s

• [SLOW TEST:68.673 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:01:55.658: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:01:58.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4723" for this suite.
Aug 14 22:02:23.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:02:23.412: INFO: namespace replication-controller-4723 deletion completed in 24.429263639s

• [SLOW TEST:27.754 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:02:23.414: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:02:23.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35" in namespace "downward-api-7229" to be "success or failure"
Aug 14 22:02:23.723: INFO: Pod "downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35": Phase="Pending", Reason="", readiness=false. Elapsed: 21.290933ms
Aug 14 22:02:25.736: INFO: Pod "downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035094337s
Aug 14 22:02:27.749: INFO: Pod "downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047601158s
STEP: Saw pod success
Aug 14 22:02:27.749: INFO: Pod "downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35" satisfied condition "success or failure"
Aug 14 22:02:27.761: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35 container client-container: <nil>
STEP: delete the pod
Aug 14 22:02:27.830: INFO: Waiting for pod downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35 to disappear
Aug 14 22:02:27.842: INFO: Pod downwardapi-volume-e1d7eb36-0a44-43d1-bae4-69211b16eb35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:02:27.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7229" for this suite.
Aug 14 22:02:33.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:02:34.361: INFO: namespace downward-api-7229 deletion completed in 6.504038178s

• [SLOW TEST:10.947 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:02:34.362: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5113.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5113.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5113.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5113.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.228.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.228.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.228.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.228.73_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5113.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5113.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5113.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5113.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5113.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5113.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.228.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.228.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.228.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.228.73_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 22:02:38.718: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:38.736: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:38.772: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:38.920: INFO: Unable to read jessie_udp@dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:38.965: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:38.982: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:39.088: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_tcp@dns-test-service.dns-5113.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:02:44.143: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:44.162: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:44.335: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:44.357: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:44.467: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:02:49.150: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:49.174: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:49.341: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:49.370: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:49.477: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:02:54.147: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:54.171: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:54.337: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:54.358: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:54.494: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:02:59.152: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:59.171: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:59.372: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:59.392: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:02:59.502: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:03:04.148: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:03:04.166: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:03:04.372: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:03:04.391: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local from pod dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f: the server could not find the requested resource (get pods dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f)
Aug 14 22:03:04.510: INFO: Lookups using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5113.svc.cluster.local]

Aug 14 22:03:09.502: INFO: DNS probes using dns-5113/dns-test-eb20022f-142a-48a1-be0e-9328352f3f3f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:03:09.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5113" for this suite.
Aug 14 22:03:15.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:03:16.056: INFO: namespace dns-5113 deletion completed in 6.405639367s

• [SLOW TEST:41.695 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:03:16.057: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-248
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-c4865bcf-6738-4f07-a653-b77975e71562
STEP: Creating configMap with name cm-test-opt-upd-24ecfef1-68f1-4c5f-8df9-c8b7e6fdddcc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c4865bcf-6738-4f07-a653-b77975e71562
STEP: Updating configmap cm-test-opt-upd-24ecfef1-68f1-4c5f-8df9-c8b7e6fdddcc
STEP: Creating configMap with name cm-test-opt-create-64516423-830a-4d1c-aab2-2a21ed3022fc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:04:31.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-248" for this suite.
Aug 14 22:04:56.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:04:56.416: INFO: namespace configmap-248 deletion completed in 24.427977852s

• [SLOW TEST:100.359 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:04:56.418: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2491
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 14 22:04:56.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 cluster-info'
Aug 14 22:04:56.739: INFO: stderr: ""
Aug 14 22:04:56.739: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:04:56.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2491" for this suite.
Aug 14 22:05:02.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:05:03.219: INFO: namespace kubectl-2491 deletion completed in 6.466269595s

• [SLOW TEST:6.802 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:05:03.220: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0
Aug 14 22:05:03.450: INFO: Pod name my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0: Found 0 pods out of 1
Aug 14 22:05:08.464: INFO: Pod name my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0: Found 1 pods out of 1
Aug 14 22:05:08.464: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0" are running
Aug 14 22:05:08.476: INFO: Pod "my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0-tsfx2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:05:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:05:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:05:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:05:03 +0000 UTC Reason: Message:}])
Aug 14 22:05:08.476: INFO: Trying to dial the pod
Aug 14 22:05:13.534: INFO: Controller my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0: Got expected result from replica 1 [my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0-tsfx2]: "my-hostname-basic-62c32970-f914-40d8-a8a9-c2a8c9f032d0-tsfx2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:05:13.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5988" for this suite.
Aug 14 22:05:19.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:05:19.959: INFO: namespace replication-controller-5988 deletion completed in 6.408056189s

• [SLOW TEST:16.740 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:05:19.962: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:05:46.236: INFO: Container started at 2019-08-14 22:05:21 +0000 UTC, pod became ready at 2019-08-14 22:05:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:05:46.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7435" for this suite.
Aug 14 22:06:10.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:10.678: INFO: namespace container-probe-7435 deletion completed in 24.425761851s

• [SLOW TEST:50.716 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:06:10.678: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 22:06:10.910: INFO: Waiting up to 5m0s for pod "pod-00ad48fd-15de-4658-8bf2-1166e59c43b0" in namespace "emptydir-8633" to be "success or failure"
Aug 14 22:06:10.925: INFO: Pod "pod-00ad48fd-15de-4658-8bf2-1166e59c43b0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.252525ms
Aug 14 22:06:12.937: INFO: Pod "pod-00ad48fd-15de-4658-8bf2-1166e59c43b0": Phase="Running", Reason="", readiness=true. Elapsed: 2.027664571s
Aug 14 22:06:14.953: INFO: Pod "pod-00ad48fd-15de-4658-8bf2-1166e59c43b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04299494s
STEP: Saw pod success
Aug 14 22:06:14.953: INFO: Pod "pod-00ad48fd-15de-4658-8bf2-1166e59c43b0" satisfied condition "success or failure"
Aug 14 22:06:14.965: INFO: Trying to get logs from node 10.195.18.148 pod pod-00ad48fd-15de-4658-8bf2-1166e59c43b0 container test-container: <nil>
STEP: delete the pod
Aug 14 22:06:15.082: INFO: Waiting for pod pod-00ad48fd-15de-4658-8bf2-1166e59c43b0 to disappear
Aug 14 22:06:15.093: INFO: Pod pod-00ad48fd-15de-4658-8bf2-1166e59c43b0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:06:15.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8633" for this suite.
Aug 14 22:06:21.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:21.518: INFO: namespace emptydir-8633 deletion completed in 6.40994217s

• [SLOW TEST:10.840 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:06:21.519: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 14 22:06:31.931: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 22:06:31.931149      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:06:31.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5960" for this suite.
Aug 14 22:06:39.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:40.356: INFO: namespace gc-5960 deletion completed in 8.411204164s

• [SLOW TEST:18.837 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:06:40.356: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5012/configmap-test-01185b86-b9a7-4fc4-adac-1898835405d3
STEP: Creating a pod to test consume configMaps
Aug 14 22:06:40.602: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835" in namespace "configmap-5012" to be "success or failure"
Aug 14 22:06:40.616: INFO: Pod "pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835": Phase="Pending", Reason="", readiness=false. Elapsed: 13.345171ms
Aug 14 22:06:42.628: INFO: Pod "pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025749044s
STEP: Saw pod success
Aug 14 22:06:42.628: INFO: Pod "pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835" satisfied condition "success or failure"
Aug 14 22:06:42.640: INFO: Trying to get logs from node 10.195.18.148 pod pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835 container env-test: <nil>
STEP: delete the pod
Aug 14 22:06:42.706: INFO: Waiting for pod pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835 to disappear
Aug 14 22:06:42.722: INFO: Pod pod-configmaps-6ec07a91-2622-4721-b77d-16cea4eb1835 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:06:42.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5012" for this suite.
Aug 14 22:06:48.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:49.137: INFO: namespace configmap-5012 deletion completed in 6.399172415s

• [SLOW TEST:8.781 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:06:49.138: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5586
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-49sv
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 22:06:49.391: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-49sv" in namespace "subpath-5586" to be "success or failure"
Aug 14 22:06:49.406: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Pending", Reason="", readiness=false. Elapsed: 15.175137ms
Aug 14 22:06:51.418: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 2.027798195s
Aug 14 22:06:53.432: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 4.040962433s
Aug 14 22:06:55.444: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 6.053412915s
Aug 14 22:06:57.457: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 8.066647223s
Aug 14 22:06:59.471: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 10.08077319s
Aug 14 22:07:01.487: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 12.096626448s
Aug 14 22:07:03.501: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 14.10990318s
Aug 14 22:07:05.514: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 16.123189493s
Aug 14 22:07:07.527: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 18.136137876s
Aug 14 22:07:09.540: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Running", Reason="", readiness=true. Elapsed: 20.149418899s
Aug 14 22:07:11.553: INFO: Pod "pod-subpath-test-downwardapi-49sv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.161878397s
STEP: Saw pod success
Aug 14 22:07:11.553: INFO: Pod "pod-subpath-test-downwardapi-49sv" satisfied condition "success or failure"
Aug 14 22:07:11.564: INFO: Trying to get logs from node 10.195.18.146 pod pod-subpath-test-downwardapi-49sv container test-container-subpath-downwardapi-49sv: <nil>
STEP: delete the pod
Aug 14 22:07:11.631: INFO: Waiting for pod pod-subpath-test-downwardapi-49sv to disappear
Aug 14 22:07:11.644: INFO: Pod pod-subpath-test-downwardapi-49sv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-49sv
Aug 14 22:07:11.644: INFO: Deleting pod "pod-subpath-test-downwardapi-49sv" in namespace "subpath-5586"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:07:11.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5586" for this suite.
Aug 14 22:07:17.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:07:18.112: INFO: namespace subpath-5586 deletion completed in 6.438971181s

• [SLOW TEST:28.975 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:07:18.113: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 22:07:18.358: INFO: Waiting up to 5m0s for pod "downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a" in namespace "downward-api-4563" to be "success or failure"
Aug 14 22:07:18.370: INFO: Pod "downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.835686ms
Aug 14 22:07:20.384: INFO: Pod "downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025782806s
STEP: Saw pod success
Aug 14 22:07:20.384: INFO: Pod "downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a" satisfied condition "success or failure"
Aug 14 22:07:20.396: INFO: Trying to get logs from node 10.195.18.184 pod downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:07:20.472: INFO: Waiting for pod downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a to disappear
Aug 14 22:07:20.487: INFO: Pod downward-api-73b2e4f5-118f-419f-8bc7-c3951457277a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:07:20.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4563" for this suite.
Aug 14 22:07:26.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:07:26.948: INFO: namespace downward-api-4563 deletion completed in 6.443790386s

• [SLOW TEST:8.835 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:07:26.949: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-b2xqd in namespace proxy-5890
I0814 22:07:27.213197      17 runners.go:180] Created replication controller with name: proxy-service-b2xqd, namespace: proxy-5890, replica count: 1
I0814 22:07:28.263797      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:29.263973      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:30.264148      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:31.264378      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:32.264583      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:33.264912      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:34.265129      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:07:35.265361      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:36.265586      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:37.265882      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:38.266102      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:39.266433      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:40.266624      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:41.266828      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:42.266992      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:43.267193      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:07:44.267399      17 runners.go:180] proxy-service-b2xqd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 22:07:44.279: INFO: setup took 17.101096809s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 14 22:07:44.314: INFO: (0) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 34.730296ms)
Aug 14 22:07:44.314: INFO: (0) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 34.719139ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 40.008605ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 40.114032ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 40.046555ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 40.166393ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 40.019918ms)
Aug 14 22:07:44.319: INFO: (0) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 40.437124ms)
Aug 14 22:07:44.322: INFO: (0) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 42.854126ms)
Aug 14 22:07:44.322: INFO: (0) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 43.041213ms)
Aug 14 22:07:44.322: INFO: (0) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 43.144787ms)
Aug 14 22:07:44.328: INFO: (0) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 48.654664ms)
Aug 14 22:07:44.329: INFO: (0) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 50.175971ms)
Aug 14 22:07:44.334: INFO: (0) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 55.577455ms)
Aug 14 22:07:44.334: INFO: (0) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 55.225152ms)
Aug 14 22:07:44.337: INFO: (0) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 57.964928ms)
Aug 14 22:07:44.356: INFO: (1) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 18.402076ms)
Aug 14 22:07:44.356: INFO: (1) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 18.463338ms)
Aug 14 22:07:44.356: INFO: (1) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 18.761736ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 19.54591ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 19.639158ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 19.619185ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 19.46857ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 19.83174ms)
Aug 14 22:07:44.357: INFO: (1) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 19.971319ms)
Aug 14 22:07:44.358: INFO: (1) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 20.36488ms)
Aug 14 22:07:44.362: INFO: (1) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 24.458564ms)
Aug 14 22:07:44.364: INFO: (1) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 26.254646ms)
Aug 14 22:07:44.369: INFO: (1) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 31.722425ms)
Aug 14 22:07:44.369: INFO: (1) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.301834ms)
Aug 14 22:07:44.369: INFO: (1) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 31.383823ms)
Aug 14 22:07:44.369: INFO: (1) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 31.384416ms)
Aug 14 22:07:44.388: INFO: (2) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 18.363928ms)
Aug 14 22:07:44.388: INFO: (2) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 18.226113ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 24.058838ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 24.033321ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 24.374619ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 24.223193ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 24.564616ms)
Aug 14 22:07:44.394: INFO: (2) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 24.95833ms)
Aug 14 22:07:44.395: INFO: (2) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 25.233518ms)
Aug 14 22:07:44.395: INFO: (2) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 24.912275ms)
Aug 14 22:07:44.395: INFO: (2) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 25.44989ms)
Aug 14 22:07:44.400: INFO: (2) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.210507ms)
Aug 14 22:07:44.400: INFO: (2) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.386859ms)
Aug 14 22:07:44.401: INFO: (2) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 31.306886ms)
Aug 14 22:07:44.401: INFO: (2) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.882909ms)
Aug 14 22:07:44.401: INFO: (2) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.059269ms)
Aug 14 22:07:44.418: INFO: (3) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 17.181127ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 21.334599ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.415569ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.653178ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.776814ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 21.52013ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 21.678297ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.949285ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 21.869206ms)
Aug 14 22:07:44.423: INFO: (3) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.265819ms)
Aug 14 22:07:44.427: INFO: (3) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 25.909898ms)
Aug 14 22:07:44.431: INFO: (3) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.122437ms)
Aug 14 22:07:44.432: INFO: (3) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.226169ms)
Aug 14 22:07:44.432: INFO: (3) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 30.535257ms)
Aug 14 22:07:44.432: INFO: (3) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.432685ms)
Aug 14 22:07:44.432: INFO: (3) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 30.842119ms)
Aug 14 22:07:44.449: INFO: (4) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 16.960655ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.239782ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.122991ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.204808ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.986805ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.096218ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.056866ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.234083ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.140352ms)
Aug 14 22:07:44.454: INFO: (4) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.343738ms)
Aug 14 22:07:44.459: INFO: (4) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 27.100268ms)
Aug 14 22:07:44.463: INFO: (4) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.524065ms)
Aug 14 22:07:44.463: INFO: (4) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.666856ms)
Aug 14 22:07:44.463: INFO: (4) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 30.602773ms)
Aug 14 22:07:44.463: INFO: (4) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 31.019157ms)
Aug 14 22:07:44.463: INFO: (4) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.022893ms)
Aug 14 22:07:44.480: INFO: (5) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 17.032099ms)
Aug 14 22:07:44.485: INFO: (5) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.717556ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.692199ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 21.911841ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.122623ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.029836ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.521875ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.184149ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.404207ms)
Aug 14 22:07:44.486: INFO: (5) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.473017ms)
Aug 14 22:07:44.491: INFO: (5) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 27.395068ms)
Aug 14 22:07:44.494: INFO: (5) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 30.452329ms)
Aug 14 22:07:44.494: INFO: (5) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.370283ms)
Aug 14 22:07:44.494: INFO: (5) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.880428ms)
Aug 14 22:07:44.494: INFO: (5) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.088974ms)
Aug 14 22:07:44.494: INFO: (5) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.513945ms)
Aug 14 22:07:44.511: INFO: (6) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 16.46638ms)
Aug 14 22:07:44.516: INFO: (6) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 21.152979ms)
Aug 14 22:07:44.516: INFO: (6) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 21.600737ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.498931ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.215945ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.332631ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.624508ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.007832ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.349032ms)
Aug 14 22:07:44.517: INFO: (6) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.973621ms)
Aug 14 22:07:44.520: INFO: (6) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 24.748946ms)
Aug 14 22:07:44.520: INFO: (6) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 24.871677ms)
Aug 14 22:07:44.525: INFO: (6) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 29.574046ms)
Aug 14 22:07:44.525: INFO: (6) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 29.974981ms)
Aug 14 22:07:44.525: INFO: (6) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 29.976895ms)
Aug 14 22:07:44.525: INFO: (6) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.084437ms)
Aug 14 22:07:44.542: INFO: (7) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 16.626542ms)
Aug 14 22:07:44.547: INFO: (7) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.067229ms)
Aug 14 22:07:44.547: INFO: (7) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.082709ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.369949ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.620751ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.421935ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.419856ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.552078ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.861366ms)
Aug 14 22:07:44.548: INFO: (7) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.751282ms)
Aug 14 22:07:44.551: INFO: (7) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 25.533372ms)
Aug 14 22:07:44.556: INFO: (7) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.287113ms)
Aug 14 22:07:44.556: INFO: (7) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 30.495642ms)
Aug 14 22:07:44.556: INFO: (7) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 30.4028ms)
Aug 14 22:07:44.556: INFO: (7) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.502089ms)
Aug 14 22:07:44.556: INFO: (7) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.470766ms)
Aug 14 22:07:44.574: INFO: (8) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 18.13669ms)
Aug 14 22:07:44.578: INFO: (8) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.046406ms)
Aug 14 22:07:44.578: INFO: (8) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.948018ms)
Aug 14 22:07:44.578: INFO: (8) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.269353ms)
Aug 14 22:07:44.578: INFO: (8) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.349736ms)
Aug 14 22:07:44.579: INFO: (8) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.914568ms)
Aug 14 22:07:44.579: INFO: (8) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.762255ms)
Aug 14 22:07:44.579: INFO: (8) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.851476ms)
Aug 14 22:07:44.579: INFO: (8) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.800236ms)
Aug 14 22:07:44.579: INFO: (8) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.706366ms)
Aug 14 22:07:44.584: INFO: (8) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 28.129041ms)
Aug 14 22:07:44.588: INFO: (8) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 32.379432ms)
Aug 14 22:07:44.589: INFO: (8) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 32.727312ms)
Aug 14 22:07:44.589: INFO: (8) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 32.726791ms)
Aug 14 22:07:44.589: INFO: (8) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 32.627169ms)
Aug 14 22:07:44.589: INFO: (8) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 32.664944ms)
Aug 14 22:07:44.606: INFO: (9) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 17.50775ms)
Aug 14 22:07:44.611: INFO: (9) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 21.601827ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.157237ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.355909ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.216619ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.326923ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.79671ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.251566ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.515627ms)
Aug 14 22:07:44.612: INFO: (9) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 23.307351ms)
Aug 14 22:07:44.615: INFO: (9) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 26.164896ms)
Aug 14 22:07:44.621: INFO: (9) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 31.874386ms)
Aug 14 22:07:44.621: INFO: (9) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 31.593584ms)
Aug 14 22:07:44.621: INFO: (9) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 31.93641ms)
Aug 14 22:07:44.621: INFO: (9) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 32.170285ms)
Aug 14 22:07:44.621: INFO: (9) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.788363ms)
Aug 14 22:07:44.638: INFO: (10) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 16.782602ms)
Aug 14 22:07:44.643: INFO: (10) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 21.435454ms)
Aug 14 22:07:44.643: INFO: (10) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 20.794499ms)
Aug 14 22:07:44.643: INFO: (10) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 21.075295ms)
Aug 14 22:07:44.643: INFO: (10) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 21.879168ms)
Aug 14 22:07:44.643: INFO: (10) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.062272ms)
Aug 14 22:07:44.644: INFO: (10) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.281285ms)
Aug 14 22:07:44.644: INFO: (10) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.835543ms)
Aug 14 22:07:44.644: INFO: (10) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.220593ms)
Aug 14 22:07:44.644: INFO: (10) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.201303ms)
Aug 14 22:07:44.647: INFO: (10) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 26.136196ms)
Aug 14 22:07:44.652: INFO: (10) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 29.859824ms)
Aug 14 22:07:44.652: INFO: (10) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.433902ms)
Aug 14 22:07:44.652: INFO: (10) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.462222ms)
Aug 14 22:07:44.652: INFO: (10) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.646738ms)
Aug 14 22:07:44.652: INFO: (10) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 30.507181ms)
Aug 14 22:07:44.670: INFO: (11) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 17.466583ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.45921ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.500048ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.711765ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.550831ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.381637ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.736523ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 23.079544ms)
Aug 14 22:07:44.675: INFO: (11) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.936838ms)
Aug 14 22:07:44.676: INFO: (11) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 23.463993ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 34.31736ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 34.247153ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 34.342527ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 34.316607ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 34.610587ms)
Aug 14 22:07:44.687: INFO: (11) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 34.141368ms)
Aug 14 22:07:44.705: INFO: (12) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 17.98173ms)
Aug 14 22:07:44.705: INFO: (12) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 17.792029ms)
Aug 14 22:07:44.709: INFO: (12) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.242149ms)
Aug 14 22:07:44.709: INFO: (12) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.124825ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.272009ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.441061ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.421239ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.557849ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.914382ms)
Aug 14 22:07:44.710: INFO: (12) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 23.267473ms)
Aug 14 22:07:44.714: INFO: (12) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 26.162327ms)
Aug 14 22:07:44.718: INFO: (12) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 31.056668ms)
Aug 14 22:07:44.718: INFO: (12) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 31.161662ms)
Aug 14 22:07:44.719: INFO: (12) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 31.224592ms)
Aug 14 22:07:44.719: INFO: (12) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.997478ms)
Aug 14 22:07:44.719: INFO: (12) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 31.048632ms)
Aug 14 22:07:44.736: INFO: (13) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 17.514385ms)
Aug 14 22:07:44.741: INFO: (13) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.84581ms)
Aug 14 22:07:44.741: INFO: (13) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.102359ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.70589ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.410803ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 23.047668ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.993839ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.80588ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 23.147442ms)
Aug 14 22:07:44.742: INFO: (13) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 23.239012ms)
Aug 14 22:07:44.745: INFO: (13) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 26.334459ms)
Aug 14 22:07:44.747: INFO: (13) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 27.816432ms)
Aug 14 22:07:44.749: INFO: (13) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.533766ms)
Aug 14 22:07:44.750: INFO: (13) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.497125ms)
Aug 14 22:07:44.750: INFO: (13) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.609969ms)
Aug 14 22:07:44.750: INFO: (13) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.997768ms)
Aug 14 22:07:44.768: INFO: (14) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 17.483822ms)
Aug 14 22:07:44.772: INFO: (14) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.014882ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.544776ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.334429ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.436043ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.258898ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 22.532935ms)
Aug 14 22:07:44.773: INFO: (14) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.902999ms)
Aug 14 22:07:44.774: INFO: (14) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 23.184597ms)
Aug 14 22:07:44.774: INFO: (14) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 23.491817ms)
Aug 14 22:07:44.782: INFO: (14) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 31.18196ms)
Aug 14 22:07:44.782: INFO: (14) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.295795ms)
Aug 14 22:07:44.782: INFO: (14) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 31.333979ms)
Aug 14 22:07:44.782: INFO: (14) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 31.15748ms)
Aug 14 22:07:44.782: INFO: (14) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 31.287573ms)
Aug 14 22:07:44.783: INFO: (14) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 32.42745ms)
Aug 14 22:07:44.800: INFO: (15) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 16.875981ms)
Aug 14 22:07:44.805: INFO: (15) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.688881ms)
Aug 14 22:07:44.805: INFO: (15) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 21.81904ms)
Aug 14 22:07:44.805: INFO: (15) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.651974ms)
Aug 14 22:07:44.806: INFO: (15) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 23.330475ms)
Aug 14 22:07:44.806: INFO: (15) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 23.376568ms)
Aug 14 22:07:44.806: INFO: (15) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 23.448759ms)
Aug 14 22:07:44.806: INFO: (15) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 23.317095ms)
Aug 14 22:07:44.807: INFO: (15) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 23.515314ms)
Aug 14 22:07:44.806: INFO: (15) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 23.311723ms)
Aug 14 22:07:44.810: INFO: (15) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 26.890861ms)
Aug 14 22:07:44.816: INFO: (15) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 33.025055ms)
Aug 14 22:07:44.816: INFO: (15) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 33.185221ms)
Aug 14 22:07:44.816: INFO: (15) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 33.147658ms)
Aug 14 22:07:44.816: INFO: (15) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 33.414178ms)
Aug 14 22:07:44.816: INFO: (15) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 33.200757ms)
Aug 14 22:07:44.834: INFO: (16) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 17.25728ms)
Aug 14 22:07:44.838: INFO: (16) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 21.694703ms)
Aug 14 22:07:44.842: INFO: (16) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 25.664299ms)
Aug 14 22:07:44.842: INFO: (16) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 25.499545ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 25.700248ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 25.781414ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 25.737286ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 25.836488ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 25.763181ms)
Aug 14 22:07:44.843: INFO: (16) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 25.884836ms)
Aug 14 22:07:44.845: INFO: (16) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 28.032087ms)
Aug 14 22:07:44.847: INFO: (16) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 30.52055ms)
Aug 14 22:07:44.847: INFO: (16) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 30.569488ms)
Aug 14 22:07:44.848: INFO: (16) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 30.730367ms)
Aug 14 22:07:44.848: INFO: (16) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 30.836208ms)
Aug 14 22:07:44.848: INFO: (16) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 30.997373ms)
Aug 14 22:07:44.866: INFO: (17) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 18.021968ms)
Aug 14 22:07:44.870: INFO: (17) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.069541ms)
Aug 14 22:07:44.870: INFO: (17) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.245376ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.572323ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.359965ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.758963ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 22.428369ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.894622ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.956713ms)
Aug 14 22:07:44.871: INFO: (17) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 23.128231ms)
Aug 14 22:07:44.876: INFO: (17) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 27.670194ms)
Aug 14 22:07:44.882: INFO: (17) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 33.352829ms)
Aug 14 22:07:44.882: INFO: (17) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 34.202571ms)
Aug 14 22:07:44.882: INFO: (17) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 33.850117ms)
Aug 14 22:07:44.882: INFO: (17) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 33.593843ms)
Aug 14 22:07:44.883: INFO: (17) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 34.315261ms)
Aug 14 22:07:44.900: INFO: (18) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 17.436763ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 21.395981ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 21.935675ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 21.847626ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 21.930595ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.090672ms)
Aug 14 22:07:44.905: INFO: (18) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 22.651612ms)
Aug 14 22:07:44.906: INFO: (18) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 22.86233ms)
Aug 14 22:07:44.906: INFO: (18) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 22.278634ms)
Aug 14 22:07:44.906: INFO: (18) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 22.407179ms)
Aug 14 22:07:44.909: INFO: (18) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 26.023466ms)
Aug 14 22:07:44.909: INFO: (18) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 26.28931ms)
Aug 14 22:07:44.910: INFO: (18) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 26.526653ms)
Aug 14 22:07:44.910: INFO: (18) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 27.24931ms)
Aug 14 22:07:44.911: INFO: (18) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 27.549676ms)
Aug 14 22:07:44.911: INFO: (18) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 27.532184ms)
Aug 14 22:07:44.928: INFO: (19) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 17.464122ms)
Aug 14 22:07:44.933: INFO: (19) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">... (200; 22.018563ms)
Aug 14 22:07:44.934: INFO: (19) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:1080/proxy/rewriteme">test<... (200; 22.818758ms)
Aug 14 22:07:44.934: INFO: (19) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:460/proxy/: tls baz (200; 23.182249ms)
Aug 14 22:07:44.934: INFO: (19) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:443/proxy/tlsrewritem... (200; 23.324958ms)
Aug 14 22:07:44.934: INFO: (19) /api/v1/namespaces/proxy-5890/pods/http:proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 23.462191ms)
Aug 14 22:07:44.935: INFO: (19) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/: <a href="/api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp/proxy/rewriteme">test</a> (200; 23.522732ms)
Aug 14 22:07:44.935: INFO: (19) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:160/proxy/: foo (200; 23.689813ms)
Aug 14 22:07:44.935: INFO: (19) /api/v1/namespaces/proxy-5890/pods/proxy-service-b2xqd-vsjlp:162/proxy/: bar (200; 23.921142ms)
Aug 14 22:07:44.935: INFO: (19) /api/v1/namespaces/proxy-5890/pods/https:proxy-service-b2xqd-vsjlp:462/proxy/: tls qux (200; 23.848853ms)
Aug 14 22:07:44.939: INFO: (19) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname1/proxy/: foo (200; 28.514198ms)
Aug 14 22:07:44.943: INFO: (19) /api/v1/namespaces/proxy-5890/services/proxy-service-b2xqd:portname2/proxy/: bar (200; 31.755435ms)
Aug 14 22:07:44.943: INFO: (19) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname2/proxy/: tls qux (200; 31.620229ms)
Aug 14 22:07:44.943: INFO: (19) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname2/proxy/: bar (200; 32.075152ms)
Aug 14 22:07:44.943: INFO: (19) /api/v1/namespaces/proxy-5890/services/https:proxy-service-b2xqd:tlsportname1/proxy/: tls baz (200; 32.372819ms)
Aug 14 22:07:44.943: INFO: (19) /api/v1/namespaces/proxy-5890/services/http:proxy-service-b2xqd:portname1/proxy/: foo (200; 32.628784ms)
STEP: deleting ReplicationController proxy-service-b2xqd in namespace proxy-5890, will wait for the garbage collector to delete the pods
Aug 14 22:07:45.027: INFO: Deleting ReplicationController proxy-service-b2xqd took: 23.185904ms
Aug 14 22:07:45.127: INFO: Terminating ReplicationController proxy-service-b2xqd pods took: 100.206437ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:07:50.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5890" for this suite.
Aug 14 22:07:56.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:07:56.857: INFO: namespace proxy-5890 deletion completed in 6.413111311s

• [SLOW TEST:29.908 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:07:56.857: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 14 22:07:57.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 api-versions'
Aug 14 22:07:57.153: INFO: stderr: ""
Aug 14 22:07:57.153: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:07:57.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3195" for this suite.
Aug 14 22:08:03.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:08:03.780: INFO: namespace kubectl-3195 deletion completed in 6.603457928s

• [SLOW TEST:6.923 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:08:03.781: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 14 22:08:04.009: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 14 22:08:09.048: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:08:09.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8965" for this suite.
Aug 14 22:08:15.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:08:15.595: INFO: namespace replication-controller-8965 deletion completed in 6.463986806s

• [SLOW TEST:11.814 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:08:15.595: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:08:15.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9847'
Aug 14 22:08:16.028: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:08:16.028: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 14 22:08:16.044: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 14 22:08:16.058: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 14 22:08:16.069: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:08:16.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9847'
Aug 14 22:08:31.961: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 22:08:31.961: INFO: stdout: "Created e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0\nScaling up e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 14 22:08:31.961: INFO: stdout: "Created e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0\nScaling up e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 14 22:08:31.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9847'
Aug 14 22:08:32.085: INFO: stderr: ""
Aug 14 22:08:32.085: INFO: stdout: "e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0-xhrxc "
Aug 14 22:08:32.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0-xhrxc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9847'
Aug 14 22:08:32.200: INFO: stderr: ""
Aug 14 22:08:32.200: INFO: stdout: "true"
Aug 14 22:08:32.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0-xhrxc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9847'
Aug 14 22:08:32.318: INFO: stderr: ""
Aug 14 22:08:32.318: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 14 22:08:32.318: INFO: e2e-test-nginx-rc-124d6788cf1c6e22603c2867257024c0-xhrxc is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug 14 22:08:32.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete rc e2e-test-nginx-rc --namespace=kubectl-9847'
Aug 14 22:08:32.467: INFO: stderr: ""
Aug 14 22:08:32.467: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:08:32.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9847" for this suite.
Aug 14 22:08:56.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:08:56.894: INFO: namespace kubectl-9847 deletion completed in 24.409862444s

• [SLOW TEST:41.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:08:56.896: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 14 22:08:57.126: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1518" to be "success or failure"
Aug 14 22:08:57.149: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 23.227675ms
Aug 14 22:08:59.165: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038793303s
Aug 14 22:09:01.177: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051234175s
STEP: Saw pod success
Aug 14 22:09:01.177: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 14 22:09:01.189: INFO: Trying to get logs from node 10.195.18.148 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 14 22:09:01.255: INFO: Waiting for pod pod-host-path-test to disappear
Aug 14 22:09:01.267: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:09:01.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1518" for this suite.
Aug 14 22:09:07.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:09:07.692: INFO: namespace hostpath-1518 deletion completed in 6.408881945s

• [SLOW TEST:10.796 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:09:07.692: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6823
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 14 22:09:17.991: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 22:09:17.991079      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:09:17.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6823" for this suite.
Aug 14 22:09:24.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:09:24.426: INFO: namespace gc-6823 deletion completed in 6.424618627s

• [SLOW TEST:16.734 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:09:24.428: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 22:09:24.755: INFO: Number of nodes with available pods: 0
Aug 14 22:09:24.755: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:09:25.785: INFO: Number of nodes with available pods: 0
Aug 14 22:09:25.785: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:09:26.785: INFO: Number of nodes with available pods: 3
Aug 14 22:09:26.785: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 14 22:09:26.857: INFO: Number of nodes with available pods: 2
Aug 14 22:09:26.857: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:27.886: INFO: Number of nodes with available pods: 2
Aug 14 22:09:27.887: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:28.887: INFO: Number of nodes with available pods: 2
Aug 14 22:09:28.887: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:29.886: INFO: Number of nodes with available pods: 2
Aug 14 22:09:29.886: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:30.889: INFO: Number of nodes with available pods: 2
Aug 14 22:09:30.889: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:31.887: INFO: Number of nodes with available pods: 2
Aug 14 22:09:31.887: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:09:32.887: INFO: Number of nodes with available pods: 3
Aug 14 22:09:32.887: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8575, will wait for the garbage collector to delete the pods
Aug 14 22:09:32.979: INFO: Deleting DaemonSet.extensions daemon-set took: 22.316597ms
Aug 14 22:09:33.079: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.352862ms
Aug 14 22:09:43.792: INFO: Number of nodes with available pods: 0
Aug 14 22:09:43.792: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:09:43.802: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8575/daemonsets","resourceVersion":"27542"},"items":null}

Aug 14 22:09:43.814: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8575/pods","resourceVersion":"27542"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:09:43.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8575" for this suite.
Aug 14 22:09:51.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:09:52.352: INFO: namespace daemonsets-8575 deletion completed in 8.478696426s

• [SLOW TEST:27.924 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:09:52.352: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:09:52.560: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 14 22:09:52.583: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 14 22:09:57.597: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 22:09:57.597: INFO: Creating deployment "test-rolling-update-deployment"
Aug 14 22:09:57.625: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 14 22:09:57.649: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 14 22:09:59.672: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 14 22:09:59.690: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417397, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417397, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417397, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417397, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:10:01.703: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 22:10:01.737: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-7031,SelfLink:/apis/apps/v1/namespaces/deployment-7031/deployments/test-rolling-update-deployment,UID:ce28270b-488b-4b21-940f-97b0b9b23f0d,ResourceVersion:27655,Generation:1,CreationTimestamp:2019-08-14 22:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 22:09:57 +0000 UTC 2019-08-14 22:09:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 22:09:59 +0000 UTC 2019-08-14 22:09:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 22:10:01.748: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-7031,SelfLink:/apis/apps/v1/namespaces/deployment-7031/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:dc1bcc00-55b6-4390-8999-722d8a17b94d,ResourceVersion:27644,Generation:1,CreationTimestamp:2019-08-14 22:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ce28270b-488b-4b21-940f-97b0b9b23f0d 0xc0021cff87 0xc0021cff88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 22:10:01.748: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 14 22:10:01.748: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-7031,SelfLink:/apis/apps/v1/namespaces/deployment-7031/replicasets/test-rolling-update-controller,UID:28eb9faf-2083-49e0-876c-7657a9dbeaea,ResourceVersion:27653,Generation:2,CreationTimestamp:2019-08-14 22:09:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ce28270b-488b-4b21-940f-97b0b9b23f0d 0xc0021cfeb7 0xc0021cfeb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:10:01.761: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-hkvpf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-hkvpf,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-7031,SelfLink:/api/v1/namespaces/deployment-7031/pods/test-rolling-update-deployment-79f6b9d75c-hkvpf,UID:9d5cbf01-fafe-48c8-9a71-05a8e0005829,ResourceVersion:27643,Generation:0,CreationTimestamp:2019-08-14 22:09:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c dc1bcc00-55b6-4390-8999-722d8a17b94d 0xc001b1b0f7 0xc001b1b0f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tgt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tgt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tgt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b1b170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b1b190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:09:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:09:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:09:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:09:57 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.224,StartTime:2019-08-14 22:09:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 22:09:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://67a447659593b9579d1772bcd35bbac9cb83666ffe544bf000ef416bfaa29666}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:10:01.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7031" for this suite.
Aug 14 22:10:07.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:10:08.194: INFO: namespace deployment-7031 deletion completed in 6.416471941s

• [SLOW TEST:15.842 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:10:08.195: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 14 22:10:08.407: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 14 22:10:08.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:08.766: INFO: stderr: ""
Aug 14 22:10:08.766: INFO: stdout: "service/redis-slave created\n"
Aug 14 22:10:08.766: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 14 22:10:08.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:09.023: INFO: stderr: ""
Aug 14 22:10:09.023: INFO: stdout: "service/redis-master created\n"
Aug 14 22:10:09.023: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 14 22:10:09.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:09.263: INFO: stderr: ""
Aug 14 22:10:09.263: INFO: stdout: "service/frontend created\n"
Aug 14 22:10:09.264: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 14 22:10:09.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:09.544: INFO: stderr: ""
Aug 14 22:10:09.544: INFO: stdout: "deployment.apps/frontend created\n"
Aug 14 22:10:09.544: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 14 22:10:09.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:09.849: INFO: stderr: ""
Aug 14 22:10:09.849: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 14 22:10:09.849: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 14 22:10:09.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-2249'
Aug 14 22:10:10.208: INFO: stderr: ""
Aug 14 22:10:10.208: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 14 22:10:10.208: INFO: Waiting for all frontend pods to be Running.
Aug 14 22:10:30.259: INFO: Waiting for frontend to serve content.
Aug 14 22:10:35.303: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug 14 22:10:40.626: INFO: Trying to add a new entry to the guestbook.
Aug 14 22:10:40.667: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 14 22:10:40.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:40.865: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:40.865: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:10:40.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:41.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:41.025: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:10:41.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:41.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:41.168: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:10:41.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:41.300: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:41.300: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:10:41.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:41.439: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:41.439: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:10:41.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-2249'
Aug 14 22:10:41.588: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:10:41.588: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:10:41.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2249" for this suite.
Aug 14 22:11:25.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:26.022: INFO: namespace kubectl-2249 deletion completed in 44.416839444s

• [SLOW TEST:77.828 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:11:26.023: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-9a4592f5-1887-4661-b6fb-0139c080d354
STEP: Creating a pod to test consume configMaps
Aug 14 22:11:26.264: INFO: Waiting up to 5m0s for pod "pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed" in namespace "configmap-5708" to be "success or failure"
Aug 14 22:11:26.280: INFO: Pod "pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed": Phase="Pending", Reason="", readiness=false. Elapsed: 15.039405ms
Aug 14 22:11:28.293: INFO: Pod "pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0281227s
Aug 14 22:11:30.313: INFO: Pod "pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048270683s
STEP: Saw pod success
Aug 14 22:11:30.313: INFO: Pod "pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed" satisfied condition "success or failure"
Aug 14 22:11:30.325: INFO: Trying to get logs from node 10.195.18.146 pod pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:11:30.387: INFO: Waiting for pod pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed to disappear
Aug 14 22:11:30.399: INFO: Pod pod-configmaps-3440ad61-e065-48b8-95dc-dabdd2de51ed no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:11:30.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5708" for this suite.
Aug 14 22:11:36.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:36.828: INFO: namespace configmap-5708 deletion completed in 6.413422607s

• [SLOW TEST:10.805 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:11:36.829: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-82575448-1a8f-4012-a00c-82ea4fb359d9
STEP: Creating a pod to test consume configMaps
Aug 14 22:11:37.066: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193" in namespace "projected-9891" to be "success or failure"
Aug 14 22:11:37.077: INFO: Pod "pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193": Phase="Pending", Reason="", readiness=false. Elapsed: 11.686225ms
Aug 14 22:11:39.090: INFO: Pod "pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024136141s
Aug 14 22:11:41.102: INFO: Pod "pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036217553s
STEP: Saw pod success
Aug 14 22:11:41.102: INFO: Pod "pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193" satisfied condition "success or failure"
Aug 14 22:11:41.114: INFO: Trying to get logs from node 10.195.18.184 pod pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:11:41.188: INFO: Waiting for pod pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193 to disappear
Aug 14 22:11:41.199: INFO: Pod pod-projected-configmaps-4aab7249-e097-4f62-b87a-9f0c6f16b193 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:11:41.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9891" for this suite.
Aug 14 22:11:47.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:47.703: INFO: namespace projected-9891 deletion completed in 6.487725666s

• [SLOW TEST:10.874 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:11:47.703: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8768.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8768.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8768.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8768.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8768.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8768.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 22:11:52.113: INFO: DNS probes using dns-8768/dns-test-d8a0e9ba-f8f8-4f33-8f0e-ed97de4a2a3f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:11:52.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8768" for this suite.
Aug 14 22:11:58.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:58.602: INFO: namespace dns-8768 deletion completed in 6.434741475s

• [SLOW TEST:10.899 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:11:58.602: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 14 22:12:00.905: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-037535427 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 14 22:12:16.094: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:12:16.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8978" for this suite.
Aug 14 22:12:22.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:22.519: INFO: namespace pods-8978 deletion completed in 6.400000149s

• [SLOW TEST:23.918 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:12:22.522: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:12:24.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2327" for this suite.
Aug 14 22:12:30.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:31.301: INFO: namespace emptydir-wrapper-2327 deletion completed in 6.393668248s

• [SLOW TEST:8.780 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:12:31.301: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1798cb5a-dbca-4806-a494-89d17df8ac7f
STEP: Creating a pod to test consume configMaps
Aug 14 22:12:31.539: INFO: Waiting up to 5m0s for pod "pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59" in namespace "configmap-9626" to be "success or failure"
Aug 14 22:12:31.555: INFO: Pod "pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59": Phase="Pending", Reason="", readiness=false. Elapsed: 15.56766ms
Aug 14 22:12:33.568: INFO: Pod "pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029080716s
Aug 14 22:12:35.581: INFO: Pod "pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041660623s
STEP: Saw pod success
Aug 14 22:12:35.581: INFO: Pod "pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59" satisfied condition "success or failure"
Aug 14 22:12:35.604: INFO: Trying to get logs from node 10.195.18.146 pod pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:12:35.665: INFO: Waiting for pod pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59 to disappear
Aug 14 22:12:35.677: INFO: Pod pod-configmaps-299750dc-2121-433b-8f14-f2d3bed2ea59 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:12:35.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9626" for this suite.
Aug 14 22:12:41.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:42.108: INFO: namespace configmap-9626 deletion completed in 6.413407194s

• [SLOW TEST:10.807 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:12:42.109: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:12:42.314: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:12:46.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-672" for this suite.
Aug 14 22:13:26.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:13:26.927: INFO: namespace pods-672 deletion completed in 40.418004393s

• [SLOW TEST:44.818 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:13:26.928: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:13:27.131: INFO: Creating deployment "test-recreate-deployment"
Aug 14 22:13:27.145: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 14 22:13:27.167: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 14 22:13:29.203: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 14 22:13:29.215: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:13:31.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:13:33.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417607, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:13:35.239: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 14 22:13:35.266: INFO: Updating deployment test-recreate-deployment
Aug 14 22:13:35.266: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 22:13:35.380: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1526,SelfLink:/apis/apps/v1/namespaces/deployment-1526/deployments/test-recreate-deployment,UID:de1501d4-c59f-440e-8681-84e2ff58d7fb,ResourceVersion:28625,Generation:2,CreationTimestamp:2019-08-14 22:13:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-14 22:13:35 +0000 UTC 2019-08-14 22:13:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 22:13:35 +0000 UTC 2019-08-14 22:13:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 14 22:13:35.392: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1526,SelfLink:/apis/apps/v1/namespaces/deployment-1526/replicasets/test-recreate-deployment-5c8c9cc69d,UID:0c7cc8cf-9706-4274-8f00-5e40a6b8b269,ResourceVersion:28622,Generation:1,CreationTimestamp:2019-08-14 22:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment de1501d4-c59f-440e-8681-84e2ff58d7fb 0xc0032069d7 0xc0032069d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:13:35.392: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 14 22:13:35.392: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1526,SelfLink:/apis/apps/v1/namespaces/deployment-1526/replicasets/test-recreate-deployment-6df85df6b9,UID:9d9f04b3-a474-429f-bbae-550c1f948f78,ResourceVersion:28614,Generation:2,CreationTimestamp:2019-08-14 22:13:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment de1501d4-c59f-440e-8681-84e2ff58d7fb 0xc003206aa7 0xc003206aa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:13:35.405: INFO: Pod "test-recreate-deployment-5c8c9cc69d-nfw8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-nfw8z,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1526,SelfLink:/api/v1/namespaces/deployment-1526/pods/test-recreate-deployment-5c8c9cc69d-nfw8z,UID:aa724437-08e5-4a44-810e-912973b87728,ResourceVersion:28626,Generation:0,CreationTimestamp:2019-08-14 22:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 0c7cc8cf-9706-4274-8f00-5e40a6b8b269 0xc00247ab97 0xc00247ab98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4b24f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4b24f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4b24f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00247ac60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00247ac80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:35 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:,StartTime:2019-08-14 22:13:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:13:35.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1526" for this suite.
Aug 14 22:13:41.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:13:41.839: INFO: namespace deployment-1526 deletion completed in 6.416386046s

• [SLOW TEST:14.911 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:13:41.839: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-423
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0814 22:13:48.141662      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 22:13:48.141: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:13:48.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-423" for this suite.
Aug 14 22:13:56.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:13:56.576: INFO: namespace gc-423 deletion completed in 8.413054232s

• [SLOW TEST:14.737 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:13:56.578: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 22:13:56.808: INFO: Waiting up to 5m0s for pod "pod-a7b7011b-7f87-4e80-a208-838013c25514" in namespace "emptydir-1906" to be "success or failure"
Aug 14 22:13:56.823: INFO: Pod "pod-a7b7011b-7f87-4e80-a208-838013c25514": Phase="Pending", Reason="", readiness=false. Elapsed: 15.245908ms
Aug 14 22:13:58.836: INFO: Pod "pod-a7b7011b-7f87-4e80-a208-838013c25514": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02819882s
STEP: Saw pod success
Aug 14 22:13:58.836: INFO: Pod "pod-a7b7011b-7f87-4e80-a208-838013c25514" satisfied condition "success or failure"
Aug 14 22:13:58.848: INFO: Trying to get logs from node 10.195.18.184 pod pod-a7b7011b-7f87-4e80-a208-838013c25514 container test-container: <nil>
STEP: delete the pod
Aug 14 22:13:58.930: INFO: Waiting for pod pod-a7b7011b-7f87-4e80-a208-838013c25514 to disappear
Aug 14 22:13:58.942: INFO: Pod pod-a7b7011b-7f87-4e80-a208-838013c25514 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:13:58.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1906" for this suite.
Aug 14 22:14:04.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:14:05.380: INFO: namespace emptydir-1906 deletion completed in 6.42237831s

• [SLOW TEST:8.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:14:05.380: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 14 22:14:05.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-9485'
Aug 14 22:14:05.918: INFO: stderr: ""
Aug 14 22:14:05.918: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:14:05.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9485'
Aug 14 22:14:06.053: INFO: stderr: ""
Aug 14 22:14:06.053: INFO: stdout: "update-demo-nautilus-44mpc update-demo-nautilus-qr67r "
Aug 14 22:14:06.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-44mpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9485'
Aug 14 22:14:06.166: INFO: stderr: ""
Aug 14 22:14:06.166: INFO: stdout: ""
Aug 14 22:14:06.166: INFO: update-demo-nautilus-44mpc is created but not running
Aug 14 22:14:11.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9485'
Aug 14 22:14:11.297: INFO: stderr: ""
Aug 14 22:14:11.297: INFO: stdout: "update-demo-nautilus-44mpc update-demo-nautilus-qr67r "
Aug 14 22:14:11.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-44mpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9485'
Aug 14 22:14:11.427: INFO: stderr: ""
Aug 14 22:14:11.428: INFO: stdout: "true"
Aug 14 22:14:11.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-44mpc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9485'
Aug 14 22:14:11.525: INFO: stderr: ""
Aug 14 22:14:11.525: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:14:11.525: INFO: validating pod update-demo-nautilus-44mpc
Aug 14 22:14:11.550: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:14:11.550: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:14:11.550: INFO: update-demo-nautilus-44mpc is verified up and running
Aug 14 22:14:11.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-qr67r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9485'
Aug 14 22:14:11.671: INFO: stderr: ""
Aug 14 22:14:11.671: INFO: stdout: "true"
Aug 14 22:14:11.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-qr67r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9485'
Aug 14 22:14:11.790: INFO: stderr: ""
Aug 14 22:14:11.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:14:11.790: INFO: validating pod update-demo-nautilus-qr67r
Aug 14 22:14:11.813: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:14:11.813: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:14:11.813: INFO: update-demo-nautilus-qr67r is verified up and running
STEP: using delete to clean up resources
Aug 14 22:14:11.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-9485'
Aug 14 22:14:11.945: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:14:11.945: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 22:14:11.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9485'
Aug 14 22:14:12.088: INFO: stderr: "No resources found.\n"
Aug 14 22:14:12.088: INFO: stdout: ""
Aug 14 22:14:12.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -l name=update-demo --namespace=kubectl-9485 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 22:14:12.217: INFO: stderr: ""
Aug 14 22:14:12.217: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:14:12.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9485" for this suite.
Aug 14 22:14:36.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:14:36.724: INFO: namespace kubectl-9485 deletion completed in 24.488400319s

• [SLOW TEST:31.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:14:36.724: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 22:14:36.954: INFO: Waiting up to 5m0s for pod "downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c" in namespace "downward-api-5726" to be "success or failure"
Aug 14 22:14:36.972: INFO: Pod "downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.673721ms
Aug 14 22:14:38.985: INFO: Pod "downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030280453s
Aug 14 22:14:40.998: INFO: Pod "downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043736529s
STEP: Saw pod success
Aug 14 22:14:40.998: INFO: Pod "downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c" satisfied condition "success or failure"
Aug 14 22:14:41.010: INFO: Trying to get logs from node 10.195.18.148 pod downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:14:41.078: INFO: Waiting for pod downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c to disappear
Aug 14 22:14:41.090: INFO: Pod downward-api-0643cc79-8c46-42af-8fa8-2eca06d2740c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:14:41.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5726" for this suite.
Aug 14 22:14:47.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:14:47.541: INFO: namespace downward-api-5726 deletion completed in 6.433983012s

• [SLOW TEST:10.817 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:14:47.543: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:14:52.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4793" for this suite.
Aug 14 22:14:58.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:14:58.509: INFO: namespace kubelet-test-4793 deletion completed in 6.472539506s

• [SLOW TEST:10.966 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:14:58.510: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 22:15:01.839: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:01.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3467" for this suite.
Aug 14 22:15:07.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:08.317: INFO: namespace container-runtime-3467 deletion completed in 6.412231519s

• [SLOW TEST:9.808 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:08.318: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-788
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:15:08.546: INFO: Waiting up to 5m0s for pod "downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c" in namespace "downward-api-788" to be "success or failure"
Aug 14 22:15:08.561: INFO: Pod "downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.941038ms
Aug 14 22:15:10.574: INFO: Pod "downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027251821s
STEP: Saw pod success
Aug 14 22:15:10.574: INFO: Pod "downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c" satisfied condition "success or failure"
Aug 14 22:15:10.586: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c container client-container: <nil>
STEP: delete the pod
Aug 14 22:15:10.647: INFO: Waiting for pod downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c to disappear
Aug 14 22:15:10.660: INFO: Pod downwardapi-volume-774de02c-52e2-4e06-869d-babcdfea7f7c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:10.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-788" for this suite.
Aug 14 22:15:16.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:17.117: INFO: namespace downward-api-788 deletion completed in 6.4237685s

• [SLOW TEST:8.799 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:17.117: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:15:17.350: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69" in namespace "projected-1100" to be "success or failure"
Aug 14 22:15:17.365: INFO: Pod "downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69": Phase="Pending", Reason="", readiness=false. Elapsed: 15.022017ms
Aug 14 22:15:19.379: INFO: Pod "downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028946026s
Aug 14 22:15:21.400: INFO: Pod "downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049621923s
STEP: Saw pod success
Aug 14 22:15:21.400: INFO: Pod "downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69" satisfied condition "success or failure"
Aug 14 22:15:21.412: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69 container client-container: <nil>
STEP: delete the pod
Aug 14 22:15:21.475: INFO: Waiting for pod downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69 to disappear
Aug 14 22:15:21.489: INFO: Pod downwardapi-volume-bb5e24e4-4ef4-40a3-8e2b-5f2f085f3d69 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:21.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1100" for this suite.
Aug 14 22:15:27.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:27.911: INFO: namespace projected-1100 deletion completed in 6.405755014s

• [SLOW TEST:10.794 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:27.911: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:15:28.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc" in namespace "projected-359" to be "success or failure"
Aug 14 22:15:28.151: INFO: Pod "downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.936496ms
Aug 14 22:15:30.165: INFO: Pod "downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027834596s
Aug 14 22:15:32.178: INFO: Pod "downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041127852s
STEP: Saw pod success
Aug 14 22:15:32.178: INFO: Pod "downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc" satisfied condition "success or failure"
Aug 14 22:15:32.191: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc container client-container: <nil>
STEP: delete the pod
Aug 14 22:15:32.255: INFO: Waiting for pod downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc to disappear
Aug 14 22:15:32.267: INFO: Pod downwardapi-volume-091a97cf-50cc-47ee-93b0-2b1ffebd8edc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:32.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-359" for this suite.
Aug 14 22:15:38.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:38.783: INFO: namespace projected-359 deletion completed in 6.42085014s

• [SLOW TEST:10.872 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:38.784: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-01f1e3c1-cb2f-4bd9-8bba-5cd63164137d
STEP: Creating a pod to test consume secrets
Aug 14 22:15:39.023: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306" in namespace "projected-1421" to be "success or failure"
Aug 14 22:15:39.038: INFO: Pod "pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306": Phase="Pending", Reason="", readiness=false. Elapsed: 14.638706ms
Aug 14 22:15:41.053: INFO: Pod "pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306": Phase="Running", Reason="", readiness=true. Elapsed: 2.030045052s
Aug 14 22:15:43.066: INFO: Pod "pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04282699s
STEP: Saw pod success
Aug 14 22:15:43.066: INFO: Pod "pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306" satisfied condition "success or failure"
Aug 14 22:15:43.078: INFO: Trying to get logs from node 10.195.18.148 pod pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:15:43.140: INFO: Waiting for pod pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306 to disappear
Aug 14 22:15:43.152: INFO: Pod pod-projected-secrets-16eabbf1-2c9d-405a-a85d-8b3944b56306 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:43.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1421" for this suite.
Aug 14 22:15:49.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:49.588: INFO: namespace projected-1421 deletion completed in 6.419950871s

• [SLOW TEST:10.804 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:49.590: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5376
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-4ad63b0c-d41d-44cd-a039-3cdc758ab462
STEP: Creating a pod to test consume secrets
Aug 14 22:15:49.825: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf" in namespace "projected-5376" to be "success or failure"
Aug 14 22:15:49.839: INFO: Pod "pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf": Phase="Pending", Reason="", readiness=false. Elapsed: 13.455764ms
Aug 14 22:15:51.853: INFO: Pod "pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027131149s
STEP: Saw pod success
Aug 14 22:15:51.853: INFO: Pod "pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf" satisfied condition "success or failure"
Aug 14 22:15:51.865: INFO: Trying to get logs from node 10.195.18.148 pod pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:15:51.926: INFO: Waiting for pod pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf to disappear
Aug 14 22:15:51.939: INFO: Pod pod-projected-secrets-9d7edcb7-bc0a-4ec6-9ff2-6a5704d180bf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:15:51.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5376" for this suite.
Aug 14 22:15:57.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:58.367: INFO: namespace projected-5376 deletion completed in 6.41098381s

• [SLOW TEST:8.778 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:15:58.368: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-8c23b3bf-5ff4-4540-a3c6-7cb52ae257e1
STEP: Creating secret with name secret-projected-all-test-volume-01ee94fa-e7e1-48f8-8650-452566b458b7
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 14 22:15:58.630: INFO: Waiting up to 5m0s for pod "projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b" in namespace "projected-5834" to be "success or failure"
Aug 14 22:15:58.644: INFO: Pod "projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.566986ms
Aug 14 22:16:00.657: INFO: Pod "projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026361865s
STEP: Saw pod success
Aug 14 22:16:00.657: INFO: Pod "projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b" satisfied condition "success or failure"
Aug 14 22:16:00.669: INFO: Trying to get logs from node 10.195.18.146 pod projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 14 22:16:00.735: INFO: Waiting for pod projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b to disappear
Aug 14 22:16:00.748: INFO: Pod projected-volume-9b25a5ac-148c-4965-8079-514be88fb64b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:16:00.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5834" for this suite.
Aug 14 22:16:06.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:07.214: INFO: namespace projected-5834 deletion completed in 6.449284564s

• [SLOW TEST:8.846 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:16:07.214: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 22:16:21.594: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:21.610: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:23.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:23.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:25.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:25.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:27.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:27.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:29.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:29.622: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:31.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:31.626: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:33.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:33.622: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:35.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:35.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:37.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:37.625: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:39.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:39.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:41.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:41.622: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:43.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:43.622: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:45.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:45.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:47.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:47.624: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:49.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:49.623: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 22:16:51.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 22:16:51.622: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:16:51.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9571" for this suite.
Aug 14 22:17:15.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:17:16.102: INFO: namespace container-lifecycle-hook-9571 deletion completed in 24.464213735s

• [SLOW TEST:68.889 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:17:16.105: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8407
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 14 22:17:56.421: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 22:17:56.421363      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:17:56.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8407" for this suite.
Aug 14 22:18:04.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:04.856: INFO: namespace gc-8407 deletion completed in 8.424211931s

• [SLOW TEST:48.752 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:18:04.857: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-6d196cf5-b22e-42e7-b825-baf5ba306b8d
STEP: Creating a pod to test consume configMaps
Aug 14 22:18:05.103: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214" in namespace "projected-3176" to be "success or failure"
Aug 14 22:18:05.120: INFO: Pod "pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214": Phase="Pending", Reason="", readiness=false. Elapsed: 16.732625ms
Aug 14 22:18:07.134: INFO: Pod "pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030147775s
Aug 14 22:18:09.146: INFO: Pod "pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042944902s
STEP: Saw pod success
Aug 14 22:18:09.147: INFO: Pod "pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214" satisfied condition "success or failure"
Aug 14 22:18:09.159: INFO: Trying to get logs from node 10.195.18.184 pod pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:18:09.220: INFO: Waiting for pod pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214 to disappear
Aug 14 22:18:09.232: INFO: Pod pod-projected-configmaps-13a3f4ff-141a-4da1-a463-9310a801e214 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:18:09.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3176" for this suite.
Aug 14 22:18:15.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:15.732: INFO: namespace projected-3176 deletion completed in 6.483450429s

• [SLOW TEST:10.876 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:18:15.735: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-372b8a7a-b455-40b9-8cd7-bc280206dcd9
STEP: Creating a pod to test consume configMaps
Aug 14 22:18:15.979: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413" in namespace "projected-3897" to be "success or failure"
Aug 14 22:18:15.996: INFO: Pod "pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413": Phase="Pending", Reason="", readiness=false. Elapsed: 16.699091ms
Aug 14 22:18:18.010: INFO: Pod "pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031020313s
STEP: Saw pod success
Aug 14 22:18:18.010: INFO: Pod "pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413" satisfied condition "success or failure"
Aug 14 22:18:18.023: INFO: Trying to get logs from node 10.195.18.148 pod pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:18:18.082: INFO: Waiting for pod pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413 to disappear
Aug 14 22:18:18.098: INFO: Pod pod-projected-configmaps-677b1478-262f-4070-8110-bf2291593413 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:18:18.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3897" for this suite.
Aug 14 22:18:24.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:24.550: INFO: namespace projected-3897 deletion completed in 6.435759652s

• [SLOW TEST:8.816 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:18:24.552: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:18:24.778: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6" in namespace "downward-api-1010" to be "success or failure"
Aug 14 22:18:24.793: INFO: Pod "downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.273317ms
Aug 14 22:18:26.806: INFO: Pod "downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028121013s
STEP: Saw pod success
Aug 14 22:18:26.806: INFO: Pod "downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6" satisfied condition "success or failure"
Aug 14 22:18:26.818: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6 container client-container: <nil>
STEP: delete the pod
Aug 14 22:18:26.883: INFO: Waiting for pod downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6 to disappear
Aug 14 22:18:26.898: INFO: Pod downwardapi-volume-f7f73fa0-2962-437f-b468-d859daa595e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:18:26.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1010" for this suite.
Aug 14 22:18:32.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:33.595: INFO: namespace downward-api-1010 deletion completed in 6.679593832s

• [SLOW TEST:9.043 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:18:33.595: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:18:33.823: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1" in namespace "downward-api-1715" to be "success or failure"
Aug 14 22:18:33.835: INFO: Pod "downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.946163ms
Aug 14 22:18:35.865: INFO: Pod "downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041802411s
Aug 14 22:18:37.878: INFO: Pod "downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054491367s
STEP: Saw pod success
Aug 14 22:18:37.878: INFO: Pod "downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1" satisfied condition "success or failure"
Aug 14 22:18:37.890: INFO: Trying to get logs from node 10.195.18.184 pod downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1 container client-container: <nil>
STEP: delete the pod
Aug 14 22:18:37.956: INFO: Waiting for pod downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1 to disappear
Aug 14 22:18:37.968: INFO: Pod downwardapi-volume-25132aea-49a6-4d5d-9b69-01248c914fe1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:18:37.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1715" for this suite.
Aug 14 22:18:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:46.625: INFO: namespace downward-api-1715 deletion completed in 8.640256053s

• [SLOW TEST:13.029 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:18:46.625: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 14 22:18:46.857: INFO: Waiting up to 5m0s for pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348" in namespace "containers-6367" to be "success or failure"
Aug 14 22:18:46.871: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348": Phase="Pending", Reason="", readiness=false. Elapsed: 14.234395ms
Aug 14 22:18:48.883: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026574643s
Aug 14 22:18:50.897: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040515525s
Aug 14 22:18:52.920: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063416243s
Aug 14 22:18:54.936: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.079627877s
STEP: Saw pod success
Aug 14 22:18:54.936: INFO: Pod "client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348" satisfied condition "success or failure"
Aug 14 22:18:54.948: INFO: Trying to get logs from node 10.195.18.148 pod client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348 container test-container: <nil>
STEP: delete the pod
Aug 14 22:18:55.013: INFO: Waiting for pod client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348 to disappear
Aug 14 22:18:55.025: INFO: Pod client-containers-26e6a349-fb61-4acc-a30f-aa9c85312348 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:18:55.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6367" for this suite.
Aug 14 22:19:01.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:01.460: INFO: namespace containers-6367 deletion completed in 6.416766873s

• [SLOW TEST:14.835 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:19:01.461: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 22:19:01.698: INFO: Waiting up to 5m0s for pod "pod-482ac4df-cff4-4a95-977f-acaf10300fef" in namespace "emptydir-6855" to be "success or failure"
Aug 14 22:19:01.713: INFO: Pod "pod-482ac4df-cff4-4a95-977f-acaf10300fef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.976549ms
Aug 14 22:19:03.729: INFO: Pod "pod-482ac4df-cff4-4a95-977f-acaf10300fef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031007476s
STEP: Saw pod success
Aug 14 22:19:03.729: INFO: Pod "pod-482ac4df-cff4-4a95-977f-acaf10300fef" satisfied condition "success or failure"
Aug 14 22:19:03.741: INFO: Trying to get logs from node 10.195.18.146 pod pod-482ac4df-cff4-4a95-977f-acaf10300fef container test-container: <nil>
STEP: delete the pod
Aug 14 22:19:03.809: INFO: Waiting for pod pod-482ac4df-cff4-4a95-977f-acaf10300fef to disappear
Aug 14 22:19:03.821: INFO: Pod pod-482ac4df-cff4-4a95-977f-acaf10300fef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:19:03.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6855" for this suite.
Aug 14 22:19:09.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:10.283: INFO: namespace emptydir-6855 deletion completed in 6.445787881s

• [SLOW TEST:8.822 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:19:10.283: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6597
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a73fafde-27ab-459b-84ac-3424a4680de2
STEP: Creating a pod to test consume configMaps
Aug 14 22:19:10.522: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4" in namespace "configmap-6597" to be "success or failure"
Aug 14 22:19:10.539: INFO: Pod "pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.458409ms
Aug 14 22:19:12.553: INFO: Pod "pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029954868s
STEP: Saw pod success
Aug 14 22:19:12.553: INFO: Pod "pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4" satisfied condition "success or failure"
Aug 14 22:19:12.564: INFO: Trying to get logs from node 10.195.18.184 pod pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:19:12.634: INFO: Waiting for pod pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4 to disappear
Aug 14 22:19:12.647: INFO: Pod pod-configmaps-1a24ca9e-d79b-4b85-a8f1-6df9492fcfe4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:19:12.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6597" for this suite.
Aug 14 22:19:18.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:19.074: INFO: namespace configmap-6597 deletion completed in 6.410930486s

• [SLOW TEST:8.791 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:19:19.077: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7224
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-a89f1a89-a0da-43b2-9c27-69191c360f3e
STEP: Creating a pod to test consume secrets
Aug 14 22:19:19.326: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8" in namespace "projected-7224" to be "success or failure"
Aug 14 22:19:19.342: INFO: Pod "pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.964216ms
Aug 14 22:19:21.355: INFO: Pod "pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028932053s
STEP: Saw pod success
Aug 14 22:19:21.355: INFO: Pod "pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8" satisfied condition "success or failure"
Aug 14 22:19:21.366: INFO: Trying to get logs from node 10.195.18.148 pod pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:19:21.437: INFO: Waiting for pod pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8 to disappear
Aug 14 22:19:21.450: INFO: Pod pod-projected-secrets-a8cad380-026d-403f-a92d-96177ffa9fa8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:19:21.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7224" for this suite.
Aug 14 22:19:27.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:27.890: INFO: namespace projected-7224 deletion completed in 6.422915914s

• [SLOW TEST:8.813 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:19:27.890: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4468
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 14 22:19:30.688: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4468 pod-service-account-9ab3958c-e7b6-44f4-8e1a-ddc3d8c094c5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 14 22:19:31.232: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4468 pod-service-account-9ab3958c-e7b6-44f4-8e1a-ddc3d8c094c5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 14 22:19:31.666: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4468 pod-service-account-9ab3958c-e7b6-44f4-8e1a-ddc3d8c094c5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:19:32.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4468" for this suite.
Aug 14 22:19:38.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:38.619: INFO: namespace svcaccounts-4468 deletion completed in 6.456128154s

• [SLOW TEST:10.729 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:19:38.619: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9044
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 14 22:19:38.829: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 14 22:19:39.280: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 14 22:19:41.398: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:43.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:45.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:47.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:49.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:51.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:53.411: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:55.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:19:57.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417979, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:20:00.364: INFO: Waited 939.54863ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:20:00.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9044" for this suite.
Aug 14 22:20:06.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:07.365: INFO: namespace aggregator-9044 deletion completed in 6.428828817s

• [SLOW TEST:28.746 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:20:07.365: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 14 22:20:07.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-3423'
Aug 14 22:20:07.878: INFO: stderr: ""
Aug 14 22:20:07.878: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:20:07.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3423'
Aug 14 22:20:08.002: INFO: stderr: ""
Aug 14 22:20:08.002: INFO: stdout: "update-demo-nautilus-nzd27 update-demo-nautilus-zzczn "
Aug 14 22:20:08.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-nzd27 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:08.137: INFO: stderr: ""
Aug 14 22:20:08.137: INFO: stdout: ""
Aug 14 22:20:08.137: INFO: update-demo-nautilus-nzd27 is created but not running
Aug 14 22:20:13.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3423'
Aug 14 22:20:13.258: INFO: stderr: ""
Aug 14 22:20:13.258: INFO: stdout: "update-demo-nautilus-nzd27 update-demo-nautilus-zzczn "
Aug 14 22:20:13.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-nzd27 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:13.370: INFO: stderr: ""
Aug 14 22:20:13.370: INFO: stdout: "true"
Aug 14 22:20:13.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-nzd27 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:13.478: INFO: stderr: ""
Aug 14 22:20:13.478: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:20:13.478: INFO: validating pod update-demo-nautilus-nzd27
Aug 14 22:20:13.503: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:20:13.503: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:20:13.503: INFO: update-demo-nautilus-nzd27 is verified up and running
Aug 14 22:20:13.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-zzczn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:13.626: INFO: stderr: ""
Aug 14 22:20:13.626: INFO: stdout: "true"
Aug 14 22:20:13.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-nautilus-zzczn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:13.752: INFO: stderr: ""
Aug 14 22:20:13.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:20:13.752: INFO: validating pod update-demo-nautilus-zzczn
Aug 14 22:20:13.776: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:20:13.776: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:20:13.776: INFO: update-demo-nautilus-zzczn is verified up and running
STEP: rolling-update to new replication controller
Aug 14 22:20:13.777: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:20:13.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3423'
Aug 14 22:20:42.046: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 22:20:42.046: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:20:42.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3423'
Aug 14 22:20:42.162: INFO: stderr: ""
Aug 14 22:20:42.162: INFO: stdout: "update-demo-kitten-cw696 update-demo-kitten-p7shk update-demo-nautilus-nzd27 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Aug 14 22:20:47.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3423'
Aug 14 22:20:47.297: INFO: stderr: ""
Aug 14 22:20:47.297: INFO: stdout: "update-demo-kitten-cw696 update-demo-kitten-p7shk "
Aug 14 22:20:47.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-kitten-cw696 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:47.414: INFO: stderr: ""
Aug 14 22:20:47.414: INFO: stdout: "true"
Aug 14 22:20:47.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-kitten-cw696 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:47.543: INFO: stderr: ""
Aug 14 22:20:47.543: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 22:20:47.543: INFO: validating pod update-demo-kitten-cw696
Aug 14 22:20:47.568: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 22:20:47.568: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 22:20:47.568: INFO: update-demo-kitten-cw696 is verified up and running
Aug 14 22:20:47.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-kitten-p7shk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:47.690: INFO: stderr: ""
Aug 14 22:20:47.690: INFO: stdout: "true"
Aug 14 22:20:47.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods update-demo-kitten-p7shk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3423'
Aug 14 22:20:47.831: INFO: stderr: ""
Aug 14 22:20:47.831: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 22:20:47.831: INFO: validating pod update-demo-kitten-p7shk
Aug 14 22:20:47.855: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 22:20:47.855: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 22:20:47.855: INFO: update-demo-kitten-p7shk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:20:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3423" for this suite.
Aug 14 22:21:11.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:12.292: INFO: namespace kubectl-3423 deletion completed in 24.41941447s

• [SLOW TEST:64.927 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:21:12.294: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 22:21:15.148: INFO: Successfully updated pod "labelsupdate4aae528b-c01b-4ca5-861d-e7d0582a1f04"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:21:19.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8386" for this suite.
Aug 14 22:21:43.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:43.691: INFO: namespace projected-8386 deletion completed in 24.443810883s

• [SLOW TEST:31.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:21:43.691: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3193
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:21:43.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3193" for this suite.
Aug 14 22:21:49.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:50.359: INFO: namespace services-3193 deletion completed in 6.431758096s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.668 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:21:50.361: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:21:50.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93" in namespace "downward-api-2925" to be "success or failure"
Aug 14 22:21:50.598: INFO: Pod "downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93": Phase="Pending", Reason="", readiness=false. Elapsed: 12.496402ms
Aug 14 22:21:52.611: INFO: Pod "downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025697454s
STEP: Saw pod success
Aug 14 22:21:52.611: INFO: Pod "downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93" satisfied condition "success or failure"
Aug 14 22:21:52.624: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93 container client-container: <nil>
STEP: delete the pod
Aug 14 22:21:52.712: INFO: Waiting for pod downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93 to disappear
Aug 14 22:21:52.723: INFO: Pod downwardapi-volume-b6a226e5-914e-46ca-936e-8f3ea9c97d93 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:21:52.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2925" for this suite.
Aug 14 22:21:58.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:59.185: INFO: namespace downward-api-2925 deletion completed in 6.445672108s

• [SLOW TEST:8.824 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:21:59.186: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:22:03.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3384" for this suite.
Aug 14 22:22:53.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:22:53.940: INFO: namespace kubelet-test-3384 deletion completed in 50.426515753s

• [SLOW TEST:54.754 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:22:53.943: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:22:54.175: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d" in namespace "downward-api-3104" to be "success or failure"
Aug 14 22:22:54.189: INFO: Pod "downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.930404ms
Aug 14 22:22:56.202: INFO: Pod "downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027379234s
STEP: Saw pod success
Aug 14 22:22:56.202: INFO: Pod "downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d" satisfied condition "success or failure"
Aug 14 22:22:56.214: INFO: Trying to get logs from node 10.195.18.146 pod downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d container client-container: <nil>
STEP: delete the pod
Aug 14 22:22:56.275: INFO: Waiting for pod downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d to disappear
Aug 14 22:22:56.291: INFO: Pod downwardapi-volume-2a0ea590-e714-426f-a445-09cae89e553d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:22:56.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3104" for this suite.
Aug 14 22:23:02.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:23:02.726: INFO: namespace downward-api-3104 deletion completed in 6.420198739s

• [SLOW TEST:8.783 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:23:02.726: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7537
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 14 22:23:02.960: INFO: Waiting up to 5m0s for pod "pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4" in namespace "emptydir-7537" to be "success or failure"
Aug 14 22:23:02.977: INFO: Pod "pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.229236ms
Aug 14 22:23:04.989: INFO: Pod "pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02836761s
STEP: Saw pod success
Aug 14 22:23:04.989: INFO: Pod "pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4" satisfied condition "success or failure"
Aug 14 22:23:05.000: INFO: Trying to get logs from node 10.195.18.184 pod pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4 container test-container: <nil>
STEP: delete the pod
Aug 14 22:23:05.072: INFO: Waiting for pod pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4 to disappear
Aug 14 22:23:05.087: INFO: Pod pod-04835d44-b8a4-47d2-b372-bc9e65aaddd4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:23:05.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7537" for this suite.
Aug 14 22:23:11.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:23:11.534: INFO: namespace emptydir-7537 deletion completed in 6.431172514s

• [SLOW TEST:8.809 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:23:11.535: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:23:11.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8468'
Aug 14 22:23:11.974: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:23:11.974: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug 14 22:23:11.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete jobs e2e-test-nginx-job --namespace=kubectl-8468'
Aug 14 22:23:12.154: INFO: stderr: ""
Aug 14 22:23:12.154: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:23:12.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8468" for this suite.
Aug 14 22:23:36.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:23:36.626: INFO: namespace kubectl-8468 deletion completed in 24.45469135s

• [SLOW TEST:25.092 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:23:36.627: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6476
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:23:36.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6476" for this suite.
Aug 14 22:24:00.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:24:01.359: INFO: namespace pods-6476 deletion completed in 24.456283104s

• [SLOW TEST:24.733 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:24:01.361: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 14 22:24:02.227: INFO: Pod name wrapped-volume-race-bb0e7472-bcdb-4520-a19e-09800b414536: Found 0 pods out of 5
Aug 14 22:24:07.253: INFO: Pod name wrapped-volume-race-bb0e7472-bcdb-4520-a19e-09800b414536: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bb0e7472-bcdb-4520-a19e-09800b414536 in namespace emptydir-wrapper-5956, will wait for the garbage collector to delete the pods
Aug 14 22:24:07.398: INFO: Deleting ReplicationController wrapped-volume-race-bb0e7472-bcdb-4520-a19e-09800b414536 took: 22.995998ms
Aug 14 22:24:07.598: INFO: Terminating ReplicationController wrapped-volume-race-bb0e7472-bcdb-4520-a19e-09800b414536 pods took: 200.215884ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 22:24:45.574: INFO: Pod name wrapped-volume-race-a9239bd2-9751-49b1-8955-c6e73547e5ab: Found 0 pods out of 5
Aug 14 22:24:50.613: INFO: Pod name wrapped-volume-race-a9239bd2-9751-49b1-8955-c6e73547e5ab: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a9239bd2-9751-49b1-8955-c6e73547e5ab in namespace emptydir-wrapper-5956, will wait for the garbage collector to delete the pods
Aug 14 22:24:50.758: INFO: Deleting ReplicationController wrapped-volume-race-a9239bd2-9751-49b1-8955-c6e73547e5ab took: 23.151848ms
Aug 14 22:24:50.958: INFO: Terminating ReplicationController wrapped-volume-race-a9239bd2-9751-49b1-8955-c6e73547e5ab pods took: 200.47775ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 22:25:35.410: INFO: Pod name wrapped-volume-race-fdc42445-45ef-4304-b5db-2bb227ac412c: Found 0 pods out of 5
Aug 14 22:25:40.429: INFO: Pod name wrapped-volume-race-fdc42445-45ef-4304-b5db-2bb227ac412c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fdc42445-45ef-4304-b5db-2bb227ac412c in namespace emptydir-wrapper-5956, will wait for the garbage collector to delete the pods
Aug 14 22:25:40.595: INFO: Deleting ReplicationController wrapped-volume-race-fdc42445-45ef-4304-b5db-2bb227ac412c took: 23.826992ms
Aug 14 22:25:40.795: INFO: Terminating ReplicationController wrapped-volume-race-fdc42445-45ef-4304-b5db-2bb227ac412c pods took: 200.440772ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:26:16.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5956" for this suite.
Aug 14 22:26:24.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:25.138: INFO: namespace emptydir-wrapper-5956 deletion completed in 8.531743856s

• [SLOW TEST:143.778 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:26:25.141: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0f91c517-6ac1-4a3e-a972-bb94f3faad2f
STEP: Creating a pod to test consume secrets
Aug 14 22:26:25.398: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6" in namespace "projected-757" to be "success or failure"
Aug 14 22:26:25.414: INFO: Pod "pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.897115ms
Aug 14 22:26:27.427: INFO: Pod "pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029478609s
STEP: Saw pod success
Aug 14 22:26:27.427: INFO: Pod "pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6" satisfied condition "success or failure"
Aug 14 22:26:27.440: INFO: Trying to get logs from node 10.195.18.184 pod pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:26:27.511: INFO: Waiting for pod pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6 to disappear
Aug 14 22:26:27.526: INFO: Pod pod-projected-secrets-8251e8fa-197d-4b33-a421-fcc7347e22b6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:26:27.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-757" for this suite.
Aug 14 22:26:33.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:33.939: INFO: namespace projected-757 deletion completed in 6.397387236s

• [SLOW TEST:8.798 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:26:33.939: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 22:26:38.772: INFO: Successfully updated pod "pod-update-f6d335e9-5790-4152-8b1a-18a1b26e7a5c"
STEP: verifying the updated pod is in kubernetes
Aug 14 22:26:38.799: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:26:38.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7569" for this suite.
Aug 14 22:27:02.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:03.269: INFO: namespace pods-7569 deletion completed in 24.453408804s

• [SLOW TEST:29.330 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:03.270: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 22:27:06.568: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:27:06.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4084" for this suite.
Aug 14 22:27:12.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:13.042: INFO: namespace container-runtime-4084 deletion completed in 6.409324222s

• [SLOW TEST:9.772 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:27:13.333: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d7af400f-1b8b-4856-aa63-550b97d8040f", Controller:(*bool)(0xc0008dcefa), BlockOwnerDeletion:(*bool)(0xc0008dcefb)}}
Aug 14 22:27:13.348: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"52b8be11-5991-468c-964a-d82a54d246d8", Controller:(*bool)(0xc0029eac46), BlockOwnerDeletion:(*bool)(0xc0029eac47)}}
Aug 14 22:27:13.363: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9d6ad289-2ccd-4304-a08c-0b3dd30f6785", Controller:(*bool)(0xc00293e9e6), BlockOwnerDeletion:(*bool)(0xc00293e9e7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:27:18.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7226" for this suite.
Aug 14 22:27:24.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:24.863: INFO: namespace gc-7226 deletion completed in 6.4509048s

• [SLOW TEST:11.821 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:24.863: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3692
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:27:25.093: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8" in namespace "downward-api-3692" to be "success or failure"
Aug 14 22:27:25.110: INFO: Pod "downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.512264ms
Aug 14 22:27:27.124: INFO: Pod "downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030507777s
Aug 14 22:27:29.138: INFO: Pod "downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044841445s
STEP: Saw pod success
Aug 14 22:27:29.138: INFO: Pod "downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8" satisfied condition "success or failure"
Aug 14 22:27:29.150: INFO: Trying to get logs from node 10.195.18.184 pod downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8 container client-container: <nil>
STEP: delete the pod
Aug 14 22:27:29.233: INFO: Waiting for pod downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8 to disappear
Aug 14 22:27:29.250: INFO: Pod downwardapi-volume-0323d758-e0ad-4699-8f44-2cdb4e85c1d8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:27:29.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3692" for this suite.
Aug 14 22:27:35.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:35.698: INFO: namespace downward-api-3692 deletion completed in 6.431922473s

• [SLOW TEST:10.835 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:35.699: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4489
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:27:35.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4489'
Aug 14 22:27:36.041: INFO: stderr: ""
Aug 14 22:27:36.041: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug 14 22:27:36.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete pods e2e-test-nginx-pod --namespace=kubectl-4489'
Aug 14 22:27:37.584: INFO: stderr: ""
Aug 14 22:27:37.584: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:27:37.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4489" for this suite.
Aug 14 22:27:43.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:44.011: INFO: namespace kubectl-4489 deletion completed in 6.410657069s

• [SLOW TEST:8.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:44.012: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b89f0814-5659-4ebd-9a36-53b3f5f429ba
STEP: Creating a pod to test consume secrets
Aug 14 22:27:44.253: INFO: Waiting up to 5m0s for pod "pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8" in namespace "secrets-1306" to be "success or failure"
Aug 14 22:27:44.267: INFO: Pod "pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.52874ms
Aug 14 22:27:46.283: INFO: Pod "pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029549569s
Aug 14 22:27:48.296: INFO: Pod "pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042741226s
STEP: Saw pod success
Aug 14 22:27:48.296: INFO: Pod "pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8" satisfied condition "success or failure"
Aug 14 22:27:48.324: INFO: Trying to get logs from node 10.195.18.146 pod pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:27:48.394: INFO: Waiting for pod pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8 to disappear
Aug 14 22:27:48.406: INFO: Pod pod-secrets-fec6cfa9-1d43-421c-a051-a25d69a264c8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:27:48.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1306" for this suite.
Aug 14 22:27:54.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:27:54.856: INFO: namespace secrets-1306 deletion completed in 6.433660632s

• [SLOW TEST:10.844 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:27:54.856: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1349
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3040
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-978
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:28:01.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1349" for this suite.
Aug 14 22:28:07.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:28:08.007: INFO: namespace namespaces-1349 deletion completed in 6.43867237s
STEP: Destroying namespace "nsdeletetest-3040" for this suite.
Aug 14 22:28:08.018: INFO: Namespace nsdeletetest-3040 was already deleted
STEP: Destroying namespace "nsdeletetest-978" for this suite.
Aug 14 22:28:14.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:28:14.431: INFO: namespace nsdeletetest-978 deletion completed in 6.412332967s

• [SLOW TEST:19.574 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:28:14.434: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-713
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 14 22:28:14.676: INFO: Waiting up to 5m0s for pod "var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8" in namespace "var-expansion-713" to be "success or failure"
Aug 14 22:28:14.692: INFO: Pod "var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.002973ms
Aug 14 22:28:16.705: INFO: Pod "var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029263255s
STEP: Saw pod success
Aug 14 22:28:16.706: INFO: Pod "var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8" satisfied condition "success or failure"
Aug 14 22:28:16.718: INFO: Trying to get logs from node 10.195.18.184 pod var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:28:16.787: INFO: Waiting for pod var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8 to disappear
Aug 14 22:28:16.801: INFO: Pod var-expansion-ee52670b-a2dc-4e36-8073-b3037e1acea8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:28:16.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-713" for this suite.
Aug 14 22:28:22.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:28:23.259: INFO: namespace var-expansion-713 deletion completed in 6.440958423s

• [SLOW TEST:8.825 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:28:23.259: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:28:23.537: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 22:28:23.574: INFO: Number of nodes with available pods: 0
Aug 14 22:28:23.574: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:28:24.606: INFO: Number of nodes with available pods: 0
Aug 14 22:28:24.606: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:28:25.609: INFO: Number of nodes with available pods: 1
Aug 14 22:28:25.609: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:28:26.605: INFO: Number of nodes with available pods: 3
Aug 14 22:28:26.605: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 14 22:28:26.688: INFO: Wrong image for pod: daemon-set-8llm6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:26.688: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:26.688: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:27.713: INFO: Wrong image for pod: daemon-set-8llm6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:27.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:27.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:28.713: INFO: Wrong image for pod: daemon-set-8llm6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:28.713: INFO: Pod daemon-set-8llm6 is not available
Aug 14 22:28:28.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:28.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:29.713: INFO: Pod daemon-set-8pqxx is not available
Aug 14 22:28:29.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:29.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:30.717: INFO: Pod daemon-set-8pqxx is not available
Aug 14 22:28:30.717: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:30.717: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:31.716: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:31.716: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:32.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:32.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:32.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:33.715: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:33.715: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:33.715: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:34.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:34.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:34.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:35.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:35.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:35.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:36.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:36.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:36.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:37.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:37.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:37.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:38.714: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:38.714: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:38.714: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:39.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:39.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:39.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:40.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:40.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:40.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:41.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:41.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:41.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:42.713: INFO: Wrong image for pod: daemon-set-p5w2s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:42.713: INFO: Pod daemon-set-p5w2s is not available
Aug 14 22:28:42.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:43.773: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:44.713: INFO: Pod daemon-set-5dkmg is not available
Aug 14 22:28:44.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:45.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:46.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:47.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:47.713: INFO: Pod daemon-set-xkn4x is not available
Aug 14 22:28:48.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:48.713: INFO: Pod daemon-set-xkn4x is not available
Aug 14 22:28:49.713: INFO: Wrong image for pod: daemon-set-xkn4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 22:28:49.713: INFO: Pod daemon-set-xkn4x is not available
Aug 14 22:28:50.714: INFO: Pod daemon-set-p9hdr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 14 22:28:50.773: INFO: Number of nodes with available pods: 2
Aug 14 22:28:50.773: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:28:51.803: INFO: Number of nodes with available pods: 2
Aug 14 22:28:51.803: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:28:52.803: INFO: Number of nodes with available pods: 2
Aug 14 22:28:52.803: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:28:53.804: INFO: Number of nodes with available pods: 3
Aug 14 22:28:53.804: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4125, will wait for the garbage collector to delete the pods
Aug 14 22:28:53.945: INFO: Deleting DaemonSet.extensions daemon-set took: 23.528864ms
Aug 14 22:28:54.045: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.239001ms
Aug 14 22:29:03.765: INFO: Number of nodes with available pods: 0
Aug 14 22:29:03.765: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:29:03.775: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4125/daemonsets","resourceVersion":"33149"},"items":null}

Aug 14 22:29:03.787: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4125/pods","resourceVersion":"33149"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:29:03.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4125" for this suite.
Aug 14 22:29:11.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:29:12.247: INFO: namespace daemonsets-4125 deletion completed in 8.401925232s

• [SLOW TEST:48.989 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:29:12.248: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6207
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4051
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:29:39.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4498" for this suite.
Aug 14 22:29:46.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:29:46.394: INFO: namespace namespaces-4498 deletion completed in 6.409598737s
STEP: Destroying namespace "nsdeletetest-6207" for this suite.
Aug 14 22:29:46.404: INFO: Namespace nsdeletetest-6207 was already deleted
STEP: Destroying namespace "nsdeletetest-4051" for this suite.
Aug 14 22:29:52.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:29:52.801: INFO: namespace nsdeletetest-4051 deletion completed in 6.396390888s

• [SLOW TEST:40.553 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:29:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 14 22:29:53.031: INFO: Waiting up to 5m0s for pod "var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e" in namespace "var-expansion-6462" to be "success or failure"
Aug 14 22:29:53.046: INFO: Pod "var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.680115ms
Aug 14 22:29:55.059: INFO: Pod "var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02774329s
STEP: Saw pod success
Aug 14 22:29:55.059: INFO: Pod "var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e" satisfied condition "success or failure"
Aug 14 22:29:55.074: INFO: Trying to get logs from node 10.195.18.146 pod var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:29:55.137: INFO: Waiting for pod var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e to disappear
Aug 14 22:29:55.149: INFO: Pod var-expansion-f6d56198-463f-4bec-83f6-37618c36b18e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:29:55.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6462" for this suite.
Aug 14 22:30:01.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:30:01.637: INFO: namespace var-expansion-6462 deletion completed in 6.472707759s

• [SLOW TEST:8.834 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:30:01.642: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:30:01.869: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6" in namespace "projected-7709" to be "success or failure"
Aug 14 22:30:01.893: INFO: Pod "downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.489236ms
Aug 14 22:30:03.905: INFO: Pod "downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036097408s
Aug 14 22:30:05.919: INFO: Pod "downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049370616s
STEP: Saw pod success
Aug 14 22:30:05.919: INFO: Pod "downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6" satisfied condition "success or failure"
Aug 14 22:30:05.931: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6 container client-container: <nil>
STEP: delete the pod
Aug 14 22:30:06.007: INFO: Waiting for pod downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6 to disappear
Aug 14 22:30:06.018: INFO: Pod downwardapi-volume-23fce664-aa8b-4ae5-a77f-5c955bf18be6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:30:06.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7709" for this suite.
Aug 14 22:30:12.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:30:12.442: INFO: namespace projected-7709 deletion completed in 6.407004358s

• [SLOW TEST:10.800 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:30:12.444: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-356
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-f317513b-a9bf-4627-a91f-ffc34fcf185e in namespace container-probe-356
Aug 14 22:30:16.695: INFO: Started pod test-webserver-f317513b-a9bf-4627-a91f-ffc34fcf185e in namespace container-probe-356
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:30:16.713: INFO: Initial restart count of pod test-webserver-f317513b-a9bf-4627-a91f-ffc34fcf185e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:34:16.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-356" for this suite.
Aug 14 22:34:22.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:34:23.271: INFO: namespace container-probe-356 deletion completed in 6.445676309s

• [SLOW TEST:250.827 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:34:23.272: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9069
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 14 22:34:23.508: INFO: Waiting up to 5m0s for pod "client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538" in namespace "containers-9069" to be "success or failure"
Aug 14 22:34:23.521: INFO: Pod "client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538": Phase="Pending", Reason="", readiness=false. Elapsed: 13.029788ms
Aug 14 22:34:25.535: INFO: Pod "client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027020772s
STEP: Saw pod success
Aug 14 22:34:25.535: INFO: Pod "client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538" satisfied condition "success or failure"
Aug 14 22:34:25.547: INFO: Trying to get logs from node 10.195.18.148 pod client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538 container test-container: <nil>
STEP: delete the pod
Aug 14 22:34:25.613: INFO: Waiting for pod client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538 to disappear
Aug 14 22:34:25.626: INFO: Pod client-containers-b71493b4-4f4c-4d2e-9bd3-c20ea0b3e538 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:34:25.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9069" for this suite.
Aug 14 22:34:31.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:34:32.076: INFO: namespace containers-9069 deletion completed in 6.433384812s

• [SLOW TEST:8.805 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:34:32.077: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-93c5b97b-8178-49ea-9939-81bc9dce17ab
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:34:32.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4739" for this suite.
Aug 14 22:34:38.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:34:38.920: INFO: namespace secrets-4739 deletion completed in 6.617889005s

• [SLOW TEST:6.843 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:34:38.920: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0167c06c-8f32-485e-9f60-68957fb13eb3
STEP: Creating a pod to test consume configMaps
Aug 14 22:34:39.164: INFO: Waiting up to 5m0s for pod "pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a" in namespace "configmap-4477" to be "success or failure"
Aug 14 22:34:39.179: INFO: Pod "pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.308361ms
Aug 14 22:34:41.193: INFO: Pod "pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028906528s
STEP: Saw pod success
Aug 14 22:34:41.193: INFO: Pod "pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a" satisfied condition "success or failure"
Aug 14 22:34:41.206: INFO: Trying to get logs from node 10.195.18.184 pod pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:34:41.275: INFO: Waiting for pod pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a to disappear
Aug 14 22:34:41.290: INFO: Pod pod-configmaps-74cfe48c-75a7-4140-a78f-24d2a744124a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:34:41.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4477" for this suite.
Aug 14 22:34:47.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:34:47.733: INFO: namespace configmap-4477 deletion completed in 6.427126092s

• [SLOW TEST:8.812 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:34:47.733: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5253
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 14 22:34:47.978: INFO: Found 0 stateful pods, waiting for 3
Aug 14 22:34:57.993: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:34:57.993: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:34:57.993: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:34:58.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-5253 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:34:58.557: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:34:58.557: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:34:58.557: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 22:35:08.639: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 14 22:35:18.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-5253 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:35:19.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 22:35:19.135: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:35:19.135: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:35:29.230: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
Aug 14 22:35:29.230: INFO: Waiting for Pod statefulset-5253/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 22:35:29.230: INFO: Waiting for Pod statefulset-5253/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 22:35:39.256: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
Aug 14 22:35:39.256: INFO: Waiting for Pod statefulset-5253/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 22:35:49.255: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
STEP: Rolling back to a previous revision
Aug 14 22:35:59.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-5253 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:35:59.671: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:35:59.671: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:35:59.671: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:36:09.753: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 14 22:36:19.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-5253 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:36:20.278: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 22:36:20.278: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:36:20.278: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:36:30.366: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
Aug 14 22:36:30.366: INFO: Waiting for Pod statefulset-5253/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 14 22:36:30.366: INFO: Waiting for Pod statefulset-5253/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 14 22:36:30.366: INFO: Waiting for Pod statefulset-5253/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 14 22:36:40.393: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
Aug 14 22:36:40.393: INFO: Waiting for Pod statefulset-5253/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 14 22:36:40.393: INFO: Waiting for Pod statefulset-5253/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 14 22:36:50.391: INFO: Waiting for StatefulSet statefulset-5253/ss2 to complete update
Aug 14 22:36:50.391: INFO: Waiting for Pod statefulset-5253/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 22:37:00.390: INFO: Deleting all statefulset in ns statefulset-5253
Aug 14 22:37:00.404: INFO: Scaling statefulset ss2 to 0
Aug 14 22:37:20.460: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:37:20.470: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:37:20.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5253" for this suite.
Aug 14 22:37:28.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:37:28.937: INFO: namespace statefulset-5253 deletion completed in 8.406753129s

• [SLOW TEST:161.204 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:37:28.937: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:37:29.212: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 14 22:37:29.236: INFO: Number of nodes with available pods: 0
Aug 14 22:37:29.236: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 14 22:37:29.280: INFO: Number of nodes with available pods: 0
Aug 14 22:37:29.280: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:30.298: INFO: Number of nodes with available pods: 0
Aug 14 22:37:30.298: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:31.294: INFO: Number of nodes with available pods: 0
Aug 14 22:37:31.294: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:32.294: INFO: Number of nodes with available pods: 1
Aug 14 22:37:32.294: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 14 22:37:32.362: INFO: Number of nodes with available pods: 1
Aug 14 22:37:32.362: INFO: Number of running nodes: 0, number of available pods: 1
Aug 14 22:37:33.375: INFO: Number of nodes with available pods: 0
Aug 14 22:37:33.375: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 14 22:37:33.399: INFO: Number of nodes with available pods: 0
Aug 14 22:37:33.399: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:34.413: INFO: Number of nodes with available pods: 0
Aug 14 22:37:34.413: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:35.412: INFO: Number of nodes with available pods: 0
Aug 14 22:37:35.412: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:36.413: INFO: Number of nodes with available pods: 0
Aug 14 22:37:36.413: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:37.413: INFO: Number of nodes with available pods: 0
Aug 14 22:37:37.413: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:37:38.413: INFO: Number of nodes with available pods: 1
Aug 14 22:37:38.413: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5833, will wait for the garbage collector to delete the pods
Aug 14 22:37:38.535: INFO: Deleting DaemonSet.extensions daemon-set took: 21.854207ms
Aug 14 22:37:38.635: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.227936ms
Aug 14 22:37:45.349: INFO: Number of nodes with available pods: 0
Aug 14 22:37:45.349: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:37:45.359: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5833/daemonsets","resourceVersion":"34791"},"items":null}

Aug 14 22:37:45.385: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5833/pods","resourceVersion":"34791"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:37:45.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5833" for this suite.
Aug 14 22:37:51.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:37:51.885: INFO: namespace daemonsets-5833 deletion completed in 6.428049958s

• [SLOW TEST:22.948 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:37:51.885: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:37:52.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-4625'
Aug 14 22:37:52.236: INFO: stderr: ""
Aug 14 22:37:52.236: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 14 22:37:57.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pod e2e-test-nginx-pod --namespace=kubectl-4625 -o json'
Aug 14 22:37:57.403: INFO: stderr: ""
Aug 14 22:37:57.403: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-14T22:37:52Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-4625\",\n        \"resourceVersion\": \"34846\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4625/pods/e2e-test-nginx-pod\",\n        \"uid\": \"21707fef-cd40-4383-b063-6bb0884c9989\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-qvtbt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.195.18.148\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-qvtbt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-qvtbt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T22:37:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T22:37:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T22:37:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T22:37:52Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8fb845e8c282ef9b101a8194a70cdce2c7f87870735ede3b37a966d32797c49a\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-14T22:37:53Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.195.18.148\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.32.210\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-14T22:37:52Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 14 22:37:57.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 replace -f - --namespace=kubectl-4625'
Aug 14 22:37:57.713: INFO: stderr: ""
Aug 14 22:37:57.713: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug 14 22:37:57.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete pods e2e-test-nginx-pod --namespace=kubectl-4625'
Aug 14 22:38:10.410: INFO: stderr: ""
Aug 14 22:38:10.410: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:38:10.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4625" for this suite.
Aug 14 22:38:16.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:38:16.860: INFO: namespace kubectl-4625 deletion completed in 6.432536469s

• [SLOW TEST:24.975 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:38:16.861: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8396
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 14 22:38:17.105: INFO: Waiting up to 5m0s for pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd" in namespace "containers-8396" to be "success or failure"
Aug 14 22:38:17.123: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.239512ms
Aug 14 22:38:19.136: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030118224s
Aug 14 22:38:21.153: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047275274s
Aug 14 22:38:23.166: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060464262s
Aug 14 22:38:25.179: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.073232686s
STEP: Saw pod success
Aug 14 22:38:25.179: INFO: Pod "client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd" satisfied condition "success or failure"
Aug 14 22:38:25.191: INFO: Trying to get logs from node 10.195.18.146 pod client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd container test-container: <nil>
STEP: delete the pod
Aug 14 22:38:25.261: INFO: Waiting for pod client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd to disappear
Aug 14 22:38:25.278: INFO: Pod client-containers-7c0b87fd-0513-4cc3-bce1-491ed781f2fd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:38:25.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8396" for this suite.
Aug 14 22:38:31.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:38:31.705: INFO: namespace containers-8396 deletion completed in 6.411271272s

• [SLOW TEST:14.845 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:38:31.706: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4193
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-c23dd61d-ea74-4be7-ad80-85aa81ef9640 in namespace container-probe-4193
Aug 14 22:38:33.958: INFO: Started pod busybox-c23dd61d-ea74-4be7-ad80-85aa81ef9640 in namespace container-probe-4193
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:38:33.970: INFO: Initial restart count of pod busybox-c23dd61d-ea74-4be7-ad80-85aa81ef9640 is 0
Aug 14 22:39:22.309: INFO: Restart count of pod container-probe-4193/busybox-c23dd61d-ea74-4be7-ad80-85aa81ef9640 is now 1 (48.338710448s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:39:22.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4193" for this suite.
Aug 14 22:39:28.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:39:29.030: INFO: namespace container-probe-4193 deletion completed in 6.663053703s

• [SLOW TEST:57.325 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:39:29.032: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7790
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-7790
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7790 to expose endpoints map[]
Aug 14 22:39:29.289: INFO: successfully validated that service multi-endpoint-test in namespace services-7790 exposes endpoints map[] (9.888829ms elapsed)
STEP: Creating pod pod1 in namespace services-7790
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7790 to expose endpoints map[pod1:[100]]
Aug 14 22:39:31.385: INFO: successfully validated that service multi-endpoint-test in namespace services-7790 exposes endpoints map[pod1:[100]] (2.074428625s elapsed)
STEP: Creating pod pod2 in namespace services-7790
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7790 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 14 22:39:33.508: INFO: successfully validated that service multi-endpoint-test in namespace services-7790 exposes endpoints map[pod1:[100] pod2:[101]] (2.109068815s elapsed)
STEP: Deleting pod pod1 in namespace services-7790
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7790 to expose endpoints map[pod2:[101]]
Aug 14 22:39:33.552: INFO: successfully validated that service multi-endpoint-test in namespace services-7790 exposes endpoints map[pod2:[101]] (23.649484ms elapsed)
STEP: Deleting pod pod2 in namespace services-7790
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7790 to expose endpoints map[]
Aug 14 22:39:33.583: INFO: successfully validated that service multi-endpoint-test in namespace services-7790 exposes endpoints map[] (9.8868ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:39:33.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7790" for this suite.
Aug 14 22:39:57.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:39:58.064: INFO: namespace services-7790 deletion completed in 24.410893546s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.033 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:39:58.064: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug 14 22:39:58.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-6988'
Aug 14 22:39:58.642: INFO: stderr: ""
Aug 14 22:39:58.642: INFO: stdout: "pod/pause created\n"
Aug 14 22:39:58.642: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 14 22:39:58.642: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6988" to be "running and ready"
Aug 14 22:39:58.667: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 25.11435ms
Aug 14 22:40:00.681: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.0385736s
Aug 14 22:40:00.681: INFO: Pod "pause" satisfied condition "running and ready"
Aug 14 22:40:00.681: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 14 22:40:00.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 label pods pause testing-label=testing-label-value --namespace=kubectl-6988'
Aug 14 22:40:00.811: INFO: stderr: ""
Aug 14 22:40:00.811: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 14 22:40:00.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pod pause -L testing-label --namespace=kubectl-6988'
Aug 14 22:40:00.928: INFO: stderr: ""
Aug 14 22:40:00.929: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 14 22:40:00.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 label pods pause testing-label- --namespace=kubectl-6988'
Aug 14 22:40:01.056: INFO: stderr: ""
Aug 14 22:40:01.056: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 14 22:40:01.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pod pause -L testing-label --namespace=kubectl-6988'
Aug 14 22:40:01.183: INFO: stderr: ""
Aug 14 22:40:01.184: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug 14 22:40:01.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-6988'
Aug 14 22:40:01.334: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:40:01.334: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 14 22:40:01.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get rc,svc -l name=pause --no-headers --namespace=kubectl-6988'
Aug 14 22:40:01.463: INFO: stderr: "No resources found.\n"
Aug 14 22:40:01.463: INFO: stdout: ""
Aug 14 22:40:01.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -l name=pause --namespace=kubectl-6988 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 22:40:01.603: INFO: stderr: ""
Aug 14 22:40:01.603: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:40:01.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6988" for this suite.
Aug 14 22:40:07.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:08.028: INFO: namespace kubectl-6988 deletion completed in 6.408651706s

• [SLOW TEST:9.964 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:40:08.029: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-209d2d7a-c753-44c6-9a2d-9e92029bfb8e
STEP: Creating a pod to test consume configMaps
Aug 14 22:40:08.279: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1" in namespace "projected-9880" to be "success or failure"
Aug 14 22:40:08.294: INFO: Pod "pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.324638ms
Aug 14 22:40:10.307: INFO: Pod "pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028269394s
STEP: Saw pod success
Aug 14 22:40:10.307: INFO: Pod "pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1" satisfied condition "success or failure"
Aug 14 22:40:10.319: INFO: Trying to get logs from node 10.195.18.146 pod pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:40:10.382: INFO: Waiting for pod pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1 to disappear
Aug 14 22:40:10.396: INFO: Pod pod-projected-configmaps-3f5c91a2-1bad-45c3-b82b-a542093badc1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:40:10.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9880" for this suite.
Aug 14 22:40:16.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:16.845: INFO: namespace projected-9880 deletion completed in 6.432954593s

• [SLOW TEST:8.816 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:40:16.846: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1518
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c16ae51c-42c3-44ed-91fe-86c9babfa83b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c16ae51c-42c3-44ed-91fe-86c9babfa83b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:40:21.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1518" for this suite.
Aug 14 22:40:45.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:45.680: INFO: namespace projected-1518 deletion completed in 24.432171362s

• [SLOW TEST:28.834 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:40:45.683: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8606
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 14 22:40:45.890: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-037535427 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:40:46.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8606" for this suite.
Aug 14 22:40:52.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:52.451: INFO: namespace kubectl-8606 deletion completed in 6.415695322s

• [SLOW TEST:6.768 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:40:52.452: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-m9zr
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 22:40:52.705: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-m9zr" in namespace "subpath-5206" to be "success or failure"
Aug 14 22:40:52.721: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.005691ms
Aug 14 22:40:54.733: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 2.028361214s
Aug 14 22:40:56.746: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 4.04109875s
Aug 14 22:40:58.759: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 6.053998797s
Aug 14 22:41:00.772: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 8.066956501s
Aug 14 22:41:02.795: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 10.090078487s
Aug 14 22:41:04.808: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 12.102523792s
Aug 14 22:41:06.821: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 14.116094064s
Aug 14 22:41:08.834: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 16.129047217s
Aug 14 22:41:10.847: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 18.142389164s
Aug 14 22:41:12.862: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Running", Reason="", readiness=true. Elapsed: 20.156418325s
Aug 14 22:41:14.873: INFO: Pod "pod-subpath-test-configmap-m9zr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.168149166s
STEP: Saw pod success
Aug 14 22:41:14.873: INFO: Pod "pod-subpath-test-configmap-m9zr" satisfied condition "success or failure"
Aug 14 22:41:14.893: INFO: Trying to get logs from node 10.195.18.184 pod pod-subpath-test-configmap-m9zr container test-container-subpath-configmap-m9zr: <nil>
STEP: delete the pod
Aug 14 22:41:14.968: INFO: Waiting for pod pod-subpath-test-configmap-m9zr to disappear
Aug 14 22:41:14.981: INFO: Pod pod-subpath-test-configmap-m9zr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-m9zr
Aug 14 22:41:14.981: INFO: Deleting pod "pod-subpath-test-configmap-m9zr" in namespace "subpath-5206"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:41:14.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5206" for this suite.
Aug 14 22:41:21.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:41:21.492: INFO: namespace subpath-5206 deletion completed in 6.48190585s

• [SLOW TEST:29.040 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:41:21.492: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:41:21.701: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 14 22:41:22.794: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:41:22.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7726" for this suite.
Aug 14 22:41:30.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:41:31.243: INFO: namespace replication-controller-7726 deletion completed in 8.409701011s

• [SLOW TEST:9.751 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:41:31.243: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8531
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8531
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8531
Aug 14 22:41:31.483: INFO: Found 0 stateful pods, waiting for 1
Aug 14 22:41:41.497: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 14 22:41:41.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:41:41.993: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:41:41.993: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:41:41.993: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:41:42.006: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 22:41:52.021: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:41:52.021: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:41:52.066: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:41:52.066: INFO: ss-0  10.195.18.184  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:41:52.066: INFO: ss-1                 Pending         []
Aug 14 22:41:52.066: INFO: 
Aug 14 22:41:52.066: INFO: StatefulSet ss has not reached scale 3, at 2
Aug 14 22:41:53.080: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987805298s
Aug 14 22:41:54.093: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973833766s
Aug 14 22:41:55.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960528342s
Aug 14 22:41:56.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.947287012s
Aug 14 22:41:57.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.920745194s
Aug 14 22:41:58.159: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.907045576s
Aug 14 22:41:59.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.894071399s
Aug 14 22:42:00.188: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.880771073s
Aug 14 22:42:01.201: INFO: Verifying statefulset ss doesn't scale past 3 for another 865.722633ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8531
Aug 14 22:42:02.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:42:02.676: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 22:42:02.677: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:42:02.677: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:42:02.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:42:03.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 14 22:42:03.165: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:42:03.165: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:42:03.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:42:03.632: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 14 22:42:03.632: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:42:03.632: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:42:03.646: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:42:03.646: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:42:03.646: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 14 22:42:03.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:42:04.091: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:42:04.091: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:42:04.091: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:42:04.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:42:04.534: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:42:04.534: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:42:04.534: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:42:04.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec --namespace=statefulset-8531 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:42:04.979: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 22:42:04.979: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:42:04.979: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:42:04.979: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:42:04.990: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 14 22:42:15.016: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:42:15.016: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:42:15.016: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:42:15.053: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:15.053: INFO: ss-0  10.195.18.184  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:15.053: INFO: ss-1  10.195.18.146  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:15.053: INFO: ss-2  10.195.18.148  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:15.053: INFO: 
Aug 14 22:42:15.053: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 22:42:16.066: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:16.066: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:16.066: INFO: ss-1  10.195.18.146  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:16.066: INFO: ss-2  10.195.18.148  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:16.066: INFO: 
Aug 14 22:42:16.066: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 22:42:17.093: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:17.093: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:17.093: INFO: ss-1  10.195.18.146  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:17.093: INFO: ss-2  10.195.18.148  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:17.093: INFO: 
Aug 14 22:42:17.093: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 22:42:18.106: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:18.106: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:18.106: INFO: ss-2  10.195.18.148  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:18.106: INFO: 
Aug 14 22:42:18.106: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 14 22:42:19.120: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:19.120: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:19.120: INFO: ss-2  10.195.18.148  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:19.120: INFO: 
Aug 14 22:42:19.120: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 14 22:42:20.133: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:20.133: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:20.133: INFO: ss-2  10.195.18.148  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:52 +0000 UTC  }]
Aug 14 22:42:20.133: INFO: 
Aug 14 22:42:20.133: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 14 22:42:21.146: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:21.146: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:21.146: INFO: 
Aug 14 22:42:21.146: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 14 22:42:22.159: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:22.159: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:22.159: INFO: 
Aug 14 22:42:22.159: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 14 22:42:23.172: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:42:23.172: INFO: ss-0  10.195.18.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:41:31 +0000 UTC  }]
Aug 14 22:42:23.172: INFO: 
Aug 14 22:42:23.172: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 14 22:42:24.185: INFO: Verifying statefulset ss doesn't scale past 0 for another 865.840123ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8531
Aug 14 22:42:25.198: INFO: Scaling statefulset ss to 0
Aug 14 22:42:25.231: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 22:42:25.243: INFO: Deleting all statefulset in ns statefulset-8531
Aug 14 22:42:25.253: INFO: Scaling statefulset ss to 0
Aug 14 22:42:25.286: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:42:25.296: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:42:25.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8531" for this suite.
Aug 14 22:42:31.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:42:31.766: INFO: namespace statefulset-8531 deletion completed in 6.40901042s

• [SLOW TEST:60.523 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:42:31.767: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-39
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:42:31.998: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 14 22:42:37.011: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 22:42:37.011: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 22:42:41.106: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-39,SelfLink:/apis/apps/v1/namespaces/deployment-39/deployments/test-cleanup-deployment,UID:475ab8f2-6bad-435b-8b4e-85f08e150464,ResourceVersion:36045,Generation:1,CreationTimestamp:2019-08-14 22:42:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 22:42:37 +0000 UTC 2019-08-14 22:42:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 22:42:39 +0000 UTC 2019-08-14 22:42:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 22:42:41.116: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-39,SelfLink:/apis/apps/v1/namespaces/deployment-39/replicasets/test-cleanup-deployment-55bbcbc84c,UID:79c74bda-1b64-406b-a2aa-24872385867b,ResourceVersion:36035,Generation:1,CreationTimestamp:2019-08-14 22:42:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 475ab8f2-6bad-435b-8b4e-85f08e150464 0xc002a919f7 0xc002a919f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 22:42:41.129: INFO: Pod "test-cleanup-deployment-55bbcbc84c-4q72w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-4q72w,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-39,SelfLink:/api/v1/namespaces/deployment-39/pods/test-cleanup-deployment-55bbcbc84c-4q72w,UID:69cfaeae-3084-4c42-80f9-f2574a4ae02c,ResourceVersion:36034,Generation:0,CreationTimestamp:2019-08-14 22:42:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 79c74bda-1b64-406b-a2aa-24872385867b 0xc002ee8447 0xc002ee8448}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-f7jm4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-f7jm4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-f7jm4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.146,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ee84c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ee84e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:42:37 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.146,PodIP:172.30.168.84,StartTime:2019-08-14 22:42:37 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 22:42:38 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://ab04cfe1d1f17f99150f19089beed887c9e526b3e4c9b4953c685fcd8eb23aa2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:42:41.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-39" for this suite.
Aug 14 22:42:47.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:42:47.610: INFO: namespace deployment-39 deletion completed in 6.45325086s

• [SLOW TEST:15.843 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:42:47.610: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9517
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-a215c85a-f1a7-4769-80e9-2161288d8721
STEP: Creating configMap with name cm-test-opt-upd-f78a0a40-0627-45de-8020-4c251b3595d2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a215c85a-f1a7-4769-80e9-2161288d8721
STEP: Updating configmap cm-test-opt-upd-f78a0a40-0627-45de-8020-4c251b3595d2
STEP: Creating configMap with name cm-test-opt-create-464153bd-fb96-46f6-ab5e-8d4387cd2356
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:44:03.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9517" for this suite.
Aug 14 22:44:27.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:44:27.871: INFO: namespace projected-9517 deletion completed in 24.417766012s

• [SLOW TEST:100.261 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:44:27.871: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-491a9129-851b-4b68-836e-5aaa49748fb6
STEP: Creating a pod to test consume secrets
Aug 14 22:44:28.116: INFO: Waiting up to 5m0s for pod "pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9" in namespace "secrets-2109" to be "success or failure"
Aug 14 22:44:28.131: INFO: Pod "pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.167531ms
Aug 14 22:44:30.144: INFO: Pod "pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027347527s
STEP: Saw pod success
Aug 14 22:44:30.144: INFO: Pod "pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9" satisfied condition "success or failure"
Aug 14 22:44:30.156: INFO: Trying to get logs from node 10.195.18.184 pod pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9 container secret-env-test: <nil>
STEP: delete the pod
Aug 14 22:44:30.293: INFO: Waiting for pod pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9 to disappear
Aug 14 22:44:30.308: INFO: Pod pod-secrets-b2f6df8a-5190-468f-88e0-e536018a9ec9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:44:30.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2109" for this suite.
Aug 14 22:44:36.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:44:36.798: INFO: namespace secrets-2109 deletion completed in 6.474123403s

• [SLOW TEST:8.927 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:44:36.799: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 22:44:37.024: INFO: Waiting up to 5m0s for pod "pod-58148f62-9fa7-411b-9629-b82a3b6c69f9" in namespace "emptydir-8860" to be "success or failure"
Aug 14 22:44:37.040: INFO: Pod "pod-58148f62-9fa7-411b-9629-b82a3b6c69f9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.372593ms
Aug 14 22:44:39.055: INFO: Pod "pod-58148f62-9fa7-411b-9629-b82a3b6c69f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031031607s
STEP: Saw pod success
Aug 14 22:44:39.056: INFO: Pod "pod-58148f62-9fa7-411b-9629-b82a3b6c69f9" satisfied condition "success or failure"
Aug 14 22:44:39.084: INFO: Trying to get logs from node 10.195.18.146 pod pod-58148f62-9fa7-411b-9629-b82a3b6c69f9 container test-container: <nil>
STEP: delete the pod
Aug 14 22:44:39.152: INFO: Waiting for pod pod-58148f62-9fa7-411b-9629-b82a3b6c69f9 to disappear
Aug 14 22:44:39.167: INFO: Pod pod-58148f62-9fa7-411b-9629-b82a3b6c69f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:44:39.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8860" for this suite.
Aug 14 22:44:45.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:44:45.610: INFO: namespace emptydir-8860 deletion completed in 6.426455996s

• [SLOW TEST:8.811 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:44:45.616: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9393
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-98ae408c-f719-490d-8853-0d9a799a6c92
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:44:49.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9393" for this suite.
Aug 14 22:45:06.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:06.437: INFO: namespace configmap-9393 deletion completed in 16.444555503s

• [SLOW TEST:20.822 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:45:06.438: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-a259c861-b25a-498a-8039-656f25c98128
STEP: Creating a pod to test consume secrets
Aug 14 22:45:06.684: INFO: Waiting up to 5m0s for pod "pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420" in namespace "secrets-4486" to be "success or failure"
Aug 14 22:45:06.699: INFO: Pod "pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420": Phase="Pending", Reason="", readiness=false. Elapsed: 14.954944ms
Aug 14 22:45:08.713: INFO: Pod "pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420": Phase="Running", Reason="", readiness=true. Elapsed: 2.028610421s
Aug 14 22:45:10.726: INFO: Pod "pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041595737s
STEP: Saw pod success
Aug 14 22:45:10.726: INFO: Pod "pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420" satisfied condition "success or failure"
Aug 14 22:45:10.744: INFO: Trying to get logs from node 10.195.18.184 pod pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:45:10.809: INFO: Waiting for pod pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420 to disappear
Aug 14 22:45:10.822: INFO: Pod pod-secrets-81f95d83-2c81-4877-9957-3c3fa1fb5420 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:45:10.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4486" for this suite.
Aug 14 22:45:16.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:17.255: INFO: namespace secrets-4486 deletion completed in 6.416666389s

• [SLOW TEST:10.817 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:45:17.255: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:45:17.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7578'
Aug 14 22:45:17.676: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:45:17.676: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug 14 22:45:19.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7578'
Aug 14 22:45:19.858: INFO: stderr: ""
Aug 14 22:45:19.858: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:45:19.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7578" for this suite.
Aug 14 22:45:25.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:26.316: INFO: namespace kubectl-7578 deletion completed in 6.427586884s

• [SLOW TEST:9.061 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:45:26.319: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7391
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-d5afb393-393c-409a-a6f4-30fe1fa2f176
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d5afb393-393c-409a-a6f4-30fe1fa2f176
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:45:30.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7391" for this suite.
Aug 14 22:45:54.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:55.264: INFO: namespace configmap-7391 deletion completed in 24.530732226s

• [SLOW TEST:28.945 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:45:55.265: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:45:55.474: INFO: Creating ReplicaSet my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36
Aug 14 22:45:55.498: INFO: Pod name my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36: Found 0 pods out of 1
Aug 14 22:46:00.512: INFO: Pod name my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36: Found 1 pods out of 1
Aug 14 22:46:00.512: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36" is running
Aug 14 22:46:00.524: INFO: Pod "my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36-zmrlp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:45:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:45:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:45:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:45:55 +0000 UTC Reason: Message:}])
Aug 14 22:46:00.524: INFO: Trying to dial the pod
Aug 14 22:46:05.598: INFO: Controller my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36: Got expected result from replica 1 [my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36-zmrlp]: "my-hostname-basic-db72e170-aead-4b47-9fdb-fed2d6b5ef36-zmrlp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:46:05.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6991" for this suite.
Aug 14 22:46:11.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:46:12.023: INFO: namespace replicaset-6991 deletion completed in 6.408416414s

• [SLOW TEST:16.758 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:46:12.024: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 14 22:46:12.254: INFO: Waiting up to 5m0s for pod "var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea" in namespace "var-expansion-3878" to be "success or failure"
Aug 14 22:46:12.268: INFO: Pod "var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea": Phase="Pending", Reason="", readiness=false. Elapsed: 14.410483ms
Aug 14 22:46:14.281: INFO: Pod "var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea": Phase="Running", Reason="", readiness=true. Elapsed: 2.027512254s
Aug 14 22:46:16.296: INFO: Pod "var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041718995s
STEP: Saw pod success
Aug 14 22:46:16.296: INFO: Pod "var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea" satisfied condition "success or failure"
Aug 14 22:46:16.308: INFO: Trying to get logs from node 10.195.18.146 pod var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:46:16.375: INFO: Waiting for pod var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea to disappear
Aug 14 22:46:16.404: INFO: Pod var-expansion-dd9edaa2-2775-4b91-ad8f-d55dbabd7cea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:46:16.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3878" for this suite.
Aug 14 22:46:22.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:46:22.870: INFO: namespace var-expansion-3878 deletion completed in 6.448878696s

• [SLOW TEST:10.847 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:46:22.870: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8869
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 22:46:23.102: INFO: Waiting up to 5m0s for pod "downward-api-11992627-da84-4956-bff3-8247a7288eb3" in namespace "downward-api-8869" to be "success or failure"
Aug 14 22:46:23.118: INFO: Pod "downward-api-11992627-da84-4956-bff3-8247a7288eb3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.35136ms
Aug 14 22:46:25.131: INFO: Pod "downward-api-11992627-da84-4956-bff3-8247a7288eb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028560722s
STEP: Saw pod success
Aug 14 22:46:25.131: INFO: Pod "downward-api-11992627-da84-4956-bff3-8247a7288eb3" satisfied condition "success or failure"
Aug 14 22:46:25.143: INFO: Trying to get logs from node 10.195.18.148 pod downward-api-11992627-da84-4956-bff3-8247a7288eb3 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:46:25.218: INFO: Waiting for pod downward-api-11992627-da84-4956-bff3-8247a7288eb3 to disappear
Aug 14 22:46:25.232: INFO: Pod downward-api-11992627-da84-4956-bff3-8247a7288eb3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:46:25.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8869" for this suite.
Aug 14 22:46:31.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:46:31.669: INFO: namespace downward-api-8869 deletion completed in 6.420149064s

• [SLOW TEST:8.799 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:46:31.670: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-mt5l
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 22:46:31.919: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mt5l" in namespace "subpath-8822" to be "success or failure"
Aug 14 22:46:31.934: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Pending", Reason="", readiness=false. Elapsed: 14.952143ms
Aug 14 22:46:33.947: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 2.027557051s
Aug 14 22:46:35.960: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 4.040502655s
Aug 14 22:46:37.973: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 6.054312214s
Aug 14 22:46:39.986: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 8.06694614s
Aug 14 22:46:41.999: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 10.080100177s
Aug 14 22:46:44.012: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 12.093021256s
Aug 14 22:46:46.025: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 14.105880925s
Aug 14 22:46:48.038: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 16.118664355s
Aug 14 22:46:50.051: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 18.13153435s
Aug 14 22:46:52.069: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 20.150301363s
Aug 14 22:46:54.082: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Running", Reason="", readiness=true. Elapsed: 22.16305869s
Aug 14 22:46:56.095: INFO: Pod "pod-subpath-test-configmap-mt5l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.176153616s
STEP: Saw pod success
Aug 14 22:46:56.095: INFO: Pod "pod-subpath-test-configmap-mt5l" satisfied condition "success or failure"
Aug 14 22:46:56.108: INFO: Trying to get logs from node 10.195.18.184 pod pod-subpath-test-configmap-mt5l container test-container-subpath-configmap-mt5l: <nil>
STEP: delete the pod
Aug 14 22:46:56.178: INFO: Waiting for pod pod-subpath-test-configmap-mt5l to disappear
Aug 14 22:46:56.190: INFO: Pod pod-subpath-test-configmap-mt5l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mt5l
Aug 14 22:46:56.190: INFO: Deleting pod "pod-subpath-test-configmap-mt5l" in namespace "subpath-8822"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:46:56.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8822" for this suite.
Aug 14 22:47:02.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:47:02.699: INFO: namespace subpath-8822 deletion completed in 6.481292743s

• [SLOW TEST:31.029 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:47:02.701: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 22:47:11.066: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:11.079: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:13.079: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:13.093: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:15.080: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:15.092: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:17.079: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:17.092: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:19.080: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:19.093: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:21.079: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:21.093: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:23.080: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:23.093: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:25.079: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:25.092: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:27.080: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:27.092: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:29.080: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:29.093: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 22:47:31.079: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 22:47:31.104: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:47:31.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1884" for this suite.
Aug 14 22:47:55.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:47:55.567: INFO: namespace container-lifecycle-hook-1884 deletion completed in 24.414943739s

• [SLOW TEST:52.866 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:47:55.567: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-86557357-054b-487f-afe3-6a7180af7632
STEP: Creating a pod to test consume configMaps
Aug 14 22:47:55.806: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64" in namespace "projected-6551" to be "success or failure"
Aug 14 22:47:55.821: INFO: Pod "pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64": Phase="Pending", Reason="", readiness=false. Elapsed: 14.651197ms
Aug 14 22:47:57.834: INFO: Pod "pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027599103s
STEP: Saw pod success
Aug 14 22:47:57.834: INFO: Pod "pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64" satisfied condition "success or failure"
Aug 14 22:47:57.846: INFO: Trying to get logs from node 10.195.18.184 pod pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:47:57.930: INFO: Waiting for pod pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64 to disappear
Aug 14 22:47:57.942: INFO: Pod pod-projected-configmaps-b7e32a2e-6a28-43ff-91e2-3720f8b76e64 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:47:57.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6551" for this suite.
Aug 14 22:48:03.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:48:04.370: INFO: namespace projected-6551 deletion completed in 6.411859112s

• [SLOW TEST:8.803 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:48:04.371: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9149
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 22:48:04.578: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 22:48:34.887: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.76.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9149 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:48:34.887: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:48:36.184: INFO: Found all expected endpoints: [netserver-0]
Aug 14 22:48:36.198: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.32.220 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9149 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:48:36.198: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:48:37.527: INFO: Found all expected endpoints: [netserver-1]
Aug 14 22:48:37.540: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.168.81 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9149 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:48:37.540: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:48:38.887: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:48:38.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9149" for this suite.
Aug 14 22:49:02.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:03.338: INFO: namespace pod-network-test-9149 deletion completed in 24.434085305s

• [SLOW TEST:58.967 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:49:03.338: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9376
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug 14 22:49:33.677: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 22:49:33.677455      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:49:33.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9376" for this suite.
Aug 14 22:49:41.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:42.114: INFO: namespace gc-9376 deletion completed in 8.422794203s

• [SLOW TEST:38.776 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:49:42.115: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2537
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:49:42.354: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1" in namespace "projected-2537" to be "success or failure"
Aug 14 22:49:42.369: INFO: Pod "downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.471403ms
Aug 14 22:49:44.383: INFO: Pod "downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028272508s
STEP: Saw pod success
Aug 14 22:49:44.383: INFO: Pod "downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1" satisfied condition "success or failure"
Aug 14 22:49:44.394: INFO: Trying to get logs from node 10.195.18.146 pod downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1 container client-container: <nil>
STEP: delete the pod
Aug 14 22:49:44.477: INFO: Waiting for pod downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1 to disappear
Aug 14 22:49:44.488: INFO: Pod downwardapi-volume-c0275b79-06a5-4f5e-9932-81cc25c51af1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:49:44.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2537" for this suite.
Aug 14 22:49:50.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:50.915: INFO: namespace projected-2537 deletion completed in 6.41172391s

• [SLOW TEST:8.801 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:49:50.918: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:49:56.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9976" for this suite.
Aug 14 22:50:02.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:50:03.107: INFO: namespace watch-9976 deletion completed in 6.521852658s

• [SLOW TEST:12.189 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:50:03.107: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-174
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 22:50:03.312: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 22:50:25.592: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.76.127:8080/dial?request=hostName&protocol=udp&host=172.30.76.76&port=8081&tries=1'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:50:25.592: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:50:25.935: INFO: Waiting for endpoints: map[]
Aug 14 22:50:25.947: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.76.127:8080/dial?request=hostName&protocol=udp&host=172.30.168.86&port=8081&tries=1'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:50:25.947: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:50:26.260: INFO: Waiting for endpoints: map[]
Aug 14 22:50:26.273: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.76.127:8080/dial?request=hostName&protocol=udp&host=172.30.32.221&port=8081&tries=1'] Namespace:pod-network-test-174 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:50:26.273: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:50:26.624: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:50:26.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-174" for this suite.
Aug 14 22:50:50.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:50:51.106: INFO: namespace pod-network-test-174 deletion completed in 24.464042311s

• [SLOW TEST:47.998 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:50:51.106: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 14 22:50:51.334: INFO: Waiting up to 5m0s for pod "client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d" in namespace "containers-5631" to be "success or failure"
Aug 14 22:50:51.349: INFO: Pod "client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.007012ms
Aug 14 22:50:53.364: INFO: Pod "client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030568944s
STEP: Saw pod success
Aug 14 22:50:53.364: INFO: Pod "client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d" satisfied condition "success or failure"
Aug 14 22:50:53.383: INFO: Trying to get logs from node 10.195.18.146 pod client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d container test-container: <nil>
STEP: delete the pod
Aug 14 22:50:53.444: INFO: Waiting for pod client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d to disappear
Aug 14 22:50:53.456: INFO: Pod client-containers-1d87befa-62d4-476f-8c70-7f2d9525478d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:50:53.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5631" for this suite.
Aug 14 22:50:59.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:50:59.922: INFO: namespace containers-5631 deletion completed in 6.449699909s

• [SLOW TEST:8.816 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:50:59.923: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 22:51:00.127: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 22:51:00.151: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 22:51:00.161: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.146 before test
Aug 14 22:51:00.202: INFO: ibm-master-proxy-static-10.195.18.146 from kube-system started at 2019-08-14 20:03:15 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container pause ready: true, restart count 0
Aug 14 22:51:00.202: INFO: ibm-keepalived-watcher-jkfrs from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:51:00.202: INFO: ibm-storage-watcher-59d4b77767-6bw8v from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 22:51:00.202: INFO: ibm-kube-fluentd-f4cz6 from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:51:00.202: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-ccxfv from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:51:00.202: INFO: calico-kube-controllers-8b68f5487-qch22 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 22:51:00.202: INFO: metrics-server-754f4b484d-wjtqj from kube-system started at 2019-08-14 20:03:51 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 22:51:00.202: INFO: coredns-64f45bf67-kk44n from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:51:00.202: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-shsbw from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:51:00.202: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:51:00.202: INFO: sonobuoy-e2e-job-a75c763ea9894b1d from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container e2e ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 22:51:00.202: INFO: calico-node-fpcf6 from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:51:00.202: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-lqjjx from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.202: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 22:51:00.202: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.148 before test
Aug 14 22:51:00.241: INFO: ibm-master-proxy-static-10.195.18.148 from kube-system started at 2019-08-14 20:12:10 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 22:51:00.241: INFO: 	Container pause ready: true, restart count 0
Aug 14 22:51:00.241: INFO: ibm-keepalived-watcher-5hfbl from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:51:00.241: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 20:15:26 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 22:51:00.241: INFO: vpn-75d8697c68-bh22v from kube-system started at 2019-08-14 20:21:26 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container vpn ready: true, restart count 0
Aug 14 22:51:00.241: INFO: ibm-kube-fluentd-qfb85 from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:51:00.241: INFO: calico-node-dtftv from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:51:00.241: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-vt4jz from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:51:00.241: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:51:00.241: INFO: coredns-64f45bf67-clbcf from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:51:00.241: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:39:46 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.241: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 22:51:00.241: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.184 before test
Aug 14 22:51:00.278: INFO: calico-node-zh8s4 from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:51:00.279: INFO: kubernetes-dashboard-596f947ff4-zk8kr from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 22:51:00.279: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-8q9np from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 22:51:00.279: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-fjqdk from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:51:00.279: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:51:00.279: INFO: ibm-master-proxy-static-10.195.18.184 from kube-system started at 2019-08-14 20:03:13 +0000 UTC (2 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 22:51:00.279: INFO: 	Container pause ready: true, restart count 0
Aug 14 22:51:00.279: INFO: ibm-kube-fluentd-9nqvp from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:51:00.279: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-998s4 from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:51:00.279: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:51:00.279: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:51:00.279: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:51:00.279: INFO: ibm-file-plugin-869b6f5676-6b5x2 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 22:51:00.279: INFO: ibm-keepalived-watcher-jp68n from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:51:00.279: INFO: coredns-autoscaler-74cb66766b-2b7jq from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:51:00.279: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1e4f41d9-745d-4568-b093-72c5a59820a5 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1e4f41d9-745d-4568-b093-72c5a59820a5 off the node 10.195.18.184
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1e4f41d9-745d-4568-b093-72c5a59820a5
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:51:04.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5320" for this suite.
Aug 14 22:51:12.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:12.957: INFO: namespace sched-pred-5320 deletion completed in 8.41478977s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:13.034 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:51:12.957: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 14 22:51:13.223: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38041,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:51:13.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38042,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 22:51:13.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38043,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 14 22:51:23.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38062,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:51:23.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38063,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 14 22:51:23.315: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3811,SelfLink:/api/v1/namespaces/watch-3811/configmaps/e2e-watch-test-label-changed,UID:19cb4b41-c6f9-4db6-8086-01bc9a5a4825,ResourceVersion:38064,Generation:0,CreationTimestamp:2019-08-14 22:51:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:51:23.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3811" for this suite.
Aug 14 22:51:29.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:29.758: INFO: namespace watch-3811 deletion completed in 6.425861156s

• [SLOW TEST:16.801 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:51:29.759: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 14 22:51:30.004: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38091,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:51:30.004: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38091,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 14 22:51:40.027: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38108,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 22:51:40.028: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38108,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 14 22:51:50.052: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38126,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:51:50.052: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38126,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 14 22:52:00.076: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38144,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:52:00.077: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-a,UID:74955b5e-9ed6-429d-b4cf-823fdb7fb156,ResourceVersion:38144,Generation:0,CreationTimestamp:2019-08-14 22:51:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 14 22:52:10.113: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-b,UID:e6ccdc93-bc7f-4073-9d3c-b25cd2a8f5da,ResourceVersion:38161,Generation:0,CreationTimestamp:2019-08-14 22:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:52:10.113: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-b,UID:e6ccdc93-bc7f-4073-9d3c-b25cd2a8f5da,ResourceVersion:38161,Generation:0,CreationTimestamp:2019-08-14 22:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 14 22:52:20.138: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-b,UID:e6ccdc93-bc7f-4073-9d3c-b25cd2a8f5da,ResourceVersion:38179,Generation:0,CreationTimestamp:2019-08-14 22:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:52:20.138: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7216,SelfLink:/api/v1/namespaces/watch-7216/configmaps/e2e-watch-test-configmap-b,UID:e6ccdc93-bc7f-4073-9d3c-b25cd2a8f5da,ResourceVersion:38179,Generation:0,CreationTimestamp:2019-08-14 22:52:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:52:30.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7216" for this suite.
Aug 14 22:52:36.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:52:36.562: INFO: namespace watch-7216 deletion completed in 6.406478913s

• [SLOW TEST:66.803 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:52:36.562: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-0a457e44-9aa9-4279-958c-2dfe45173976
STEP: Creating a pod to test consume configMaps
Aug 14 22:52:36.805: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96" in namespace "projected-5754" to be "success or failure"
Aug 14 22:52:36.821: INFO: Pod "pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96": Phase="Pending", Reason="", readiness=false. Elapsed: 15.58002ms
Aug 14 22:52:38.834: INFO: Pod "pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96": Phase="Running", Reason="", readiness=true. Elapsed: 2.028782371s
Aug 14 22:52:40.848: INFO: Pod "pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042829726s
STEP: Saw pod success
Aug 14 22:52:40.848: INFO: Pod "pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96" satisfied condition "success or failure"
Aug 14 22:52:40.860: INFO: Trying to get logs from node 10.195.18.148 pod pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:52:40.926: INFO: Waiting for pod pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96 to disappear
Aug 14 22:52:40.942: INFO: Pod pod-projected-configmaps-402cec9b-a9d2-49e2-a948-c8ec4cfc1a96 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:52:40.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5754" for this suite.
Aug 14 22:52:47.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:52:47.395: INFO: namespace projected-5754 deletion completed in 6.437405148s

• [SLOW TEST:10.833 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:52:47.396: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1230
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 22:52:47.606: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 22:53:13.920: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.32.223:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1230 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:53:13.920: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:53:14.258: INFO: Found all expected endpoints: [netserver-0]
Aug 14 22:53:14.410: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.168.88:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1230 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:53:14.410: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:53:14.729: INFO: Found all expected endpoints: [netserver-1]
Aug 14 22:53:14.742: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.76.79:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1230 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:53:14.742: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 22:53:15.059: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:53:15.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1230" for this suite.
Aug 14 22:53:39.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:53:39.503: INFO: namespace pod-network-test-1230 deletion completed in 24.426840197s

• [SLOW TEST:52.107 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:53:39.503: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 22:53:39.978: INFO: Create a RollingUpdate DaemonSet
Aug 14 22:53:39.990: INFO: Check that daemon pods launch on every node of the cluster
Aug 14 22:53:40.012: INFO: Number of nodes with available pods: 0
Aug 14 22:53:40.012: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:53:41.046: INFO: Number of nodes with available pods: 0
Aug 14 22:53:41.046: INFO: Node 10.195.18.146 is running more than one daemon pod
Aug 14 22:53:42.042: INFO: Number of nodes with available pods: 1
Aug 14 22:53:42.042: INFO: Node 10.195.18.148 is running more than one daemon pod
Aug 14 22:53:43.043: INFO: Number of nodes with available pods: 3
Aug 14 22:53:43.043: INFO: Number of running nodes: 3, number of available pods: 3
Aug 14 22:53:43.043: INFO: Update the DaemonSet to trigger a rollout
Aug 14 22:53:43.066: INFO: Updating DaemonSet daemon-set
Aug 14 22:53:46.121: INFO: Roll back the DaemonSet before rollout is complete
Aug 14 22:53:46.142: INFO: Updating DaemonSet daemon-set
Aug 14 22:53:46.142: INFO: Make sure DaemonSet rollback is complete
Aug 14 22:53:46.154: INFO: Wrong image for pod: daemon-set-rjdt8. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 14 22:53:46.154: INFO: Pod daemon-set-rjdt8 is not available
Aug 14 22:53:47.180: INFO: Wrong image for pod: daemon-set-rjdt8. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 14 22:53:47.180: INFO: Pod daemon-set-rjdt8 is not available
Aug 14 22:53:48.179: INFO: Pod daemon-set-dftgk is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2786, will wait for the garbage collector to delete the pods
Aug 14 22:53:48.302: INFO: Deleting DaemonSet.extensions daemon-set took: 22.455622ms
Aug 14 22:53:48.402: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.263824ms
Aug 14 22:53:55.315: INFO: Number of nodes with available pods: 0
Aug 14 22:53:55.315: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:53:55.325: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2786/daemonsets","resourceVersion":"38611"},"items":null}

Aug 14 22:53:55.338: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2786/pods","resourceVersion":"38611"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:53:55.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2786" for this suite.
Aug 14 22:54:03.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:54:03.867: INFO: namespace daemonsets-2786 deletion completed in 8.461915377s

• [SLOW TEST:24.364 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:54:03.868: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-fec42626-3f29-42de-8420-e318dcc112f5 in namespace container-probe-9549
Aug 14 22:54:14.134: INFO: Started pod liveness-fec42626-3f29-42de-8420-e318dcc112f5 in namespace container-probe-9549
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:54:14.146: INFO: Initial restart count of pod liveness-fec42626-3f29-42de-8420-e318dcc112f5 is 0
Aug 14 22:54:28.251: INFO: Restart count of pod container-probe-9549/liveness-fec42626-3f29-42de-8420-e318dcc112f5 is now 1 (14.10550843s elapsed)
Aug 14 22:54:48.385: INFO: Restart count of pod container-probe-9549/liveness-fec42626-3f29-42de-8420-e318dcc112f5 is now 2 (34.239246589s elapsed)
Aug 14 22:55:08.533: INFO: Restart count of pod container-probe-9549/liveness-fec42626-3f29-42de-8420-e318dcc112f5 is now 3 (54.386763488s elapsed)
Aug 14 22:55:28.767: INFO: Restart count of pod container-probe-9549/liveness-fec42626-3f29-42de-8420-e318dcc112f5 is now 4 (1m14.620924464s elapsed)
Aug 14 22:56:39.524: INFO: Restart count of pod container-probe-9549/liveness-fec42626-3f29-42de-8420-e318dcc112f5 is now 5 (2m25.377726996s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 22:56:39.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9549" for this suite.
Aug 14 22:56:45.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:56:46.034: INFO: namespace container-probe-9549 deletion completed in 6.445116699s

• [SLOW TEST:162.166 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 22:56:46.035: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-b3d17290-3367-46b9-8136-6b4e5007408f in namespace container-probe-7361
Aug 14 22:56:48.290: INFO: Started pod busybox-b3d17290-3367-46b9-8136-6b4e5007408f in namespace container-probe-7361
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:56:48.303: INFO: Initial restart count of pod busybox-b3d17290-3367-46b9-8136-6b4e5007408f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:00:50.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7361" for this suite.
Aug 14 23:00:56.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:00:56.769: INFO: namespace container-probe-7361 deletion completed in 6.453838709s

• [SLOW TEST:250.734 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:00:56.769: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7024
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:00:57.014: INFO: (0) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.443089ms)
Aug 14 23:00:57.032: INFO: (1) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.117954ms)
Aug 14 23:00:57.050: INFO: (2) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.677914ms)
Aug 14 23:00:57.067: INFO: (3) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.996374ms)
Aug 14 23:00:57.090: INFO: (4) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.307478ms)
Aug 14 23:00:57.107: INFO: (5) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.878762ms)
Aug 14 23:00:57.124: INFO: (6) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.076521ms)
Aug 14 23:00:57.141: INFO: (7) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.019566ms)
Aug 14 23:00:57.158: INFO: (8) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.791338ms)
Aug 14 23:00:57.176: INFO: (9) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.591044ms)
Aug 14 23:00:57.193: INFO: (10) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.332849ms)
Aug 14 23:00:57.213: INFO: (11) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.095246ms)
Aug 14 23:00:57.231: INFO: (12) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.357789ms)
Aug 14 23:00:57.249: INFO: (13) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.652407ms)
Aug 14 23:00:57.267: INFO: (14) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.642074ms)
Aug 14 23:00:57.284: INFO: (15) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.691344ms)
Aug 14 23:00:57.302: INFO: (16) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.423262ms)
Aug 14 23:00:57.318: INFO: (17) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.326439ms)
Aug 14 23:00:57.335: INFO: (18) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.316643ms)
Aug 14 23:00:57.351: INFO: (19) /api/v1/nodes/10.195.18.146/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.5238ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:00:57.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7024" for this suite.
Aug 14 23:01:03.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:01:03.840: INFO: namespace proxy-7024 deletion completed in 6.477072079s

• [SLOW TEST:7.071 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:01:03.841: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 23:01:04.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8" in namespace "projected-8351" to be "success or failure"
Aug 14 23:01:04.096: INFO: Pod "downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.469433ms
Aug 14 23:01:06.372: INFO: Pod "downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.29636797s
Aug 14 23:01:08.389: INFO: Pod "downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.313292114s
STEP: Saw pod success
Aug 14 23:01:08.389: INFO: Pod "downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8" satisfied condition "success or failure"
Aug 14 23:01:08.405: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8 container client-container: <nil>
STEP: delete the pod
Aug 14 23:01:08.478: INFO: Waiting for pod downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8 to disappear
Aug 14 23:01:08.489: INFO: Pod downwardapi-volume-71b2b27d-3f39-4207-809a-0b83b1f2beb8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:01:08.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8351" for this suite.
Aug 14 23:01:14.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:01:14.932: INFO: namespace projected-8351 deletion completed in 6.426571838s

• [SLOW TEST:11.091 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:01:14.933: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 23:01:15.142: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 23:01:15.171: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 23:01:15.183: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.146 before test
Aug 14 23:01:15.252: INFO: ibm-kube-fluentd-f4cz6 from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 23:01:15.252: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-ccxfv from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 23:01:15.252: INFO: calico-kube-controllers-8b68f5487-qch22 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 23:01:15.252: INFO: metrics-server-754f4b484d-wjtqj from kube-system started at 2019-08-14 20:03:51 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 23:01:15.252: INFO: coredns-64f45bf67-kk44n from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container coredns ready: true, restart count 0
Aug 14 23:01:15.252: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-shsbw from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 23:01:15.252: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 23:01:15.252: INFO: sonobuoy-e2e-job-a75c763ea9894b1d from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container e2e ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 23:01:15.252: INFO: calico-node-fpcf6 from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 23:01:15.252: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-lqjjx from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 23:01:15.252: INFO: ibm-master-proxy-static-10.195.18.146 from kube-system started at 2019-08-14 20:03:15 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 	Container pause ready: true, restart count 0
Aug 14 23:01:15.252: INFO: ibm-keepalived-watcher-jkfrs from kube-system started at 2019-08-14 20:03:16 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 23:01:15.252: INFO: ibm-storage-watcher-59d4b77767-6bw8v from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.252: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 23:01:15.252: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.148 before test
Aug 14 23:01:15.286: INFO: coredns-64f45bf67-clbcf from kube-system started at 2019-08-14 20:21:49 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.286: INFO: 	Container coredns ready: true, restart count 0
Aug 14 23:01:15.286: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:39:46 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.286: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 23:01:15.286: INFO: ibm-master-proxy-static-10.195.18.148 from kube-system started at 2019-08-14 20:12:10 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.286: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 23:01:15.286: INFO: 	Container pause ready: true, restart count 0
Aug 14 23:01:15.286: INFO: ibm-keepalived-watcher-5hfbl from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 23:01:15.287: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 20:15:26 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 23:01:15.287: INFO: vpn-75d8697c68-bh22v from kube-system started at 2019-08-14 20:21:26 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container vpn ready: true, restart count 0
Aug 14 23:01:15.287: INFO: ibm-kube-fluentd-qfb85 from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 23:01:15.287: INFO: calico-node-dtftv from kube-system started at 2019-08-14 20:12:16 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 23:01:15.287: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-vt4jz from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.287: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 23:01:15.287: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 23:01:15.288: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.184 before test
Aug 14 23:01:15.342: INFO: ibm-keepalived-watcher-jp68n from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 23:01:15.343: INFO: coredns-autoscaler-74cb66766b-2b7jq from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container autoscaler ready: true, restart count 0
Aug 14 23:01:15.343: INFO: ibm-file-plugin-869b6f5676-6b5x2 from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 23:01:15.343: INFO: kubernetes-dashboard-596f947ff4-zk8kr from kube-system started at 2019-08-14 20:03:34 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 23:01:15.343: INFO: ibm-cloud-provider-ip-135-90-87-142-6cb5647d5d-8q9np from ibm-system started at 2019-08-14 20:06:24 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container ibm-cloud-provider-ip-135-90-87-142 ready: true, restart count 0
Aug 14 23:01:15.343: INFO: calico-node-zh8s4 from kube-system started at 2019-08-14 20:03:20 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 23:01:15.343: INFO: sonobuoy-systemd-logs-daemon-set-026562c801934442-fjqdk from heptio-sonobuoy started at 2019-08-14 21:39:56 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.343: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 23:01:15.343: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 23:01:15.343: INFO: ibm-kube-fluentd-9nqvp from kube-system started at 2019-08-14 20:03:47 +0000 UTC (1 container statuses recorded)
Aug 14 23:01:15.344: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 23:01:15.344: INFO: public-crbla66o8s0gv1rqqkhfrg-alb1-585b9446d5-998s4 from kube-system started at 2019-08-14 20:11:51 +0000 UTC (4 container statuses recorded)
Aug 14 23:01:15.344: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 23:01:15.344: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 23:01:15.344: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 23:01:15.344: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 23:01:15.344: INFO: ibm-master-proxy-static-10.195.18.184 from kube-system started at 2019-08-14 20:03:13 +0000 UTC (2 container statuses recorded)
Aug 14 23:01:15.344: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Aug 14 23:01:15.344: INFO: 	Container pause ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15baec56317e18fc], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:01:16.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7965" for this suite.
Aug 14 23:01:22.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:01:22.867: INFO: namespace sched-pred-7965 deletion completed in 6.429335102s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.934 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:01:22.868: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9406
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:01:46.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9406" for this suite.
Aug 14 23:01:52.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:01:53.244: INFO: namespace container-runtime-9406 deletion completed in 6.428915933s

• [SLOW TEST:30.376 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:01:53.246: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 14 23:01:53.499: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6152,SelfLink:/api/v1/namespaces/watch-6152/configmaps/e2e-watch-test-watch-closed,UID:411d3fc2-41a3-473f-9480-696b0e562d81,ResourceVersion:39718,Generation:0,CreationTimestamp:2019-08-14 23:01:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 23:01:53.499: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6152,SelfLink:/api/v1/namespaces/watch-6152/configmaps/e2e-watch-test-watch-closed,UID:411d3fc2-41a3-473f-9480-696b0e562d81,ResourceVersion:39719,Generation:0,CreationTimestamp:2019-08-14 23:01:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 14 23:01:53.548: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6152,SelfLink:/api/v1/namespaces/watch-6152/configmaps/e2e-watch-test-watch-closed,UID:411d3fc2-41a3-473f-9480-696b0e562d81,ResourceVersion:39720,Generation:0,CreationTimestamp:2019-08-14 23:01:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 23:01:53.548: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6152,SelfLink:/api/v1/namespaces/watch-6152/configmaps/e2e-watch-test-watch-closed,UID:411d3fc2-41a3-473f-9480-696b0e562d81,ResourceVersion:39721,Generation:0,CreationTimestamp:2019-08-14 23:01:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:01:53.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6152" for this suite.
Aug 14 23:01:59.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:00.331: INFO: namespace watch-6152 deletion completed in 6.769830486s

• [SLOW TEST:7.085 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:00.332: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2813.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2813.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 23:02:04.786: INFO: DNS probes using dns-2813/dns-test-4747520c-5dc7-4d27-bbaa-681271a66265 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:04.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2813" for this suite.
Aug 14 23:02:10.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:11.286: INFO: namespace dns-2813 deletion completed in 6.448490865s

• [SLOW TEST:10.954 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:11.286: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 23:02:11.515: INFO: Waiting up to 5m0s for pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1" in namespace "emptydir-5751" to be "success or failure"
Aug 14 23:02:11.533: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.158246ms
Aug 14 23:02:13.545: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029874254s
Aug 14 23:02:15.558: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042714863s
Aug 14 23:02:17.572: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056042152s
Aug 14 23:02:19.585: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069300609s
STEP: Saw pod success
Aug 14 23:02:19.585: INFO: Pod "pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1" satisfied condition "success or failure"
Aug 14 23:02:19.597: INFO: Trying to get logs from node 10.195.18.148 pod pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1 container test-container: <nil>
STEP: delete the pod
Aug 14 23:02:19.657: INFO: Waiting for pod pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1 to disappear
Aug 14 23:02:19.669: INFO: Pod pod-0cd712c1-41f9-4249-9e8a-9856b9a1ead1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:19.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5751" for this suite.
Aug 14 23:02:25.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:26.106: INFO: namespace emptydir-5751 deletion completed in 6.420824623s

• [SLOW TEST:14.820 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:26.107: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-445ae237-8161-412e-a175-404f6ccfa35d
STEP: Creating a pod to test consume configMaps
Aug 14 23:02:26.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1" in namespace "projected-5818" to be "success or failure"
Aug 14 23:02:26.360: INFO: Pod "pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.886194ms
Aug 14 23:02:28.373: INFO: Pod "pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027384438s
STEP: Saw pod success
Aug 14 23:02:28.373: INFO: Pod "pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1" satisfied condition "success or failure"
Aug 14 23:02:28.386: INFO: Trying to get logs from node 10.195.18.184 pod pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 23:02:28.444: INFO: Waiting for pod pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1 to disappear
Aug 14 23:02:28.475: INFO: Pod pod-projected-configmaps-33d0ab3f-5410-4304-890e-ed12a30dcdd1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:28.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5818" for this suite.
Aug 14 23:02:34.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:34.925: INFO: namespace projected-5818 deletion completed in 6.432950597s

• [SLOW TEST:8.818 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:34.926: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9132
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 23:02:35.162: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b" in namespace "projected-9132" to be "success or failure"
Aug 14 23:02:35.177: INFO: Pod "downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.727547ms
Aug 14 23:02:37.189: INFO: Pod "downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027049686s
Aug 14 23:02:39.202: INFO: Pod "downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04005139s
STEP: Saw pod success
Aug 14 23:02:39.202: INFO: Pod "downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b" satisfied condition "success or failure"
Aug 14 23:02:39.214: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b container client-container: <nil>
STEP: delete the pod
Aug 14 23:02:39.278: INFO: Waiting for pod downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b to disappear
Aug 14 23:02:39.289: INFO: Pod downwardapi-volume-4f00dbb5-d0ff-4aa0-9978-debce833284b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:39.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9132" for this suite.
Aug 14 23:02:45.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:45.745: INFO: namespace projected-9132 deletion completed in 6.439827127s

• [SLOW TEST:10.820 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:45.746: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 23:02:45.976: INFO: Waiting up to 5m0s for pod "pod-56b313af-a654-4605-83c0-d3bc298699f2" in namespace "emptydir-9105" to be "success or failure"
Aug 14 23:02:45.990: INFO: Pod "pod-56b313af-a654-4605-83c0-d3bc298699f2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.523978ms
Aug 14 23:02:48.002: INFO: Pod "pod-56b313af-a654-4605-83c0-d3bc298699f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025995889s
STEP: Saw pod success
Aug 14 23:02:48.003: INFO: Pod "pod-56b313af-a654-4605-83c0-d3bc298699f2" satisfied condition "success or failure"
Aug 14 23:02:48.014: INFO: Trying to get logs from node 10.195.18.146 pod pod-56b313af-a654-4605-83c0-d3bc298699f2 container test-container: <nil>
STEP: delete the pod
Aug 14 23:02:48.072: INFO: Waiting for pod pod-56b313af-a654-4605-83c0-d3bc298699f2 to disappear
Aug 14 23:02:48.088: INFO: Pod pod-56b313af-a654-4605-83c0-d3bc298699f2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:48.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9105" for this suite.
Aug 14 23:02:54.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:02:54.538: INFO: namespace emptydir-9105 deletion completed in 6.433383081s

• [SLOW TEST:8.792 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:02:54.539: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:02:54.789: INFO: (0) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.436308ms)
Aug 14 23:02:54.810: INFO: (1) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.428482ms)
Aug 14 23:02:54.827: INFO: (2) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.440611ms)
Aug 14 23:02:54.846: INFO: (3) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.967854ms)
Aug 14 23:02:54.864: INFO: (4) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.614412ms)
Aug 14 23:02:54.881: INFO: (5) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.392134ms)
Aug 14 23:02:54.899: INFO: (6) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.254455ms)
Aug 14 23:02:54.919: INFO: (7) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.178722ms)
Aug 14 23:02:54.936: INFO: (8) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.298944ms)
Aug 14 23:02:54.955: INFO: (9) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.68755ms)
Aug 14 23:02:54.973: INFO: (10) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.938218ms)
Aug 14 23:02:54.990: INFO: (11) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.861866ms)
Aug 14 23:02:55.026: INFO: (12) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 35.625696ms)
Aug 14 23:02:55.042: INFO: (13) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.752407ms)
Aug 14 23:02:55.059: INFO: (14) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.638988ms)
Aug 14 23:02:55.077: INFO: (15) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.43578ms)
Aug 14 23:02:55.094: INFO: (16) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.652247ms)
Aug 14 23:02:55.111: INFO: (17) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.154104ms)
Aug 14 23:02:55.130: INFO: (18) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.777503ms)
Aug 14 23:02:55.148: INFO: (19) /api/v1/nodes/10.195.18.146:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.209509ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:02:55.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-723" for this suite.
Aug 14 23:03:01.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:03:01.591: INFO: namespace proxy-723 deletion completed in 6.430922572s

• [SLOW TEST:7.052 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:03:01.591: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7336
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:03:01.842: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 14 23:03:06.855: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 23:03:06.855: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 14 23:03:08.866: INFO: Creating deployment "test-rollover-deployment"
Aug 14 23:03:08.893: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 14 23:03:10.917: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 14 23:03:10.944: INFO: Ensure that both replica sets have 1 created replica
Aug 14 23:03:10.964: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 14 23:03:10.988: INFO: Updating deployment test-rollover-deployment
Aug 14 23:03:10.988: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 14 23:03:13.012: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 14 23:03:13.035: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 14 23:03:13.058: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 23:03:13.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420592, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 23:03:15.081: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 23:03:15.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420592, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 23:03:17.081: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 23:03:17.082: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420592, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 23:03:19.085: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 23:03:19.086: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420592, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 23:03:21.081: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 23:03:21.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420592, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420588, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 23:03:23.081: INFO: 
Aug 14 23:03:23.082: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 23:03:23.118: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7336,SelfLink:/apis/apps/v1/namespaces/deployment-7336/deployments/test-rollover-deployment,UID:1a7dec6b-0f23-47a6-a226-b42be2b4b205,ResourceVersion:40170,Generation:2,CreationTimestamp:2019-08-14 23:03:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 23:03:08 +0000 UTC 2019-08-14 23:03:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 23:03:22 +0000 UTC 2019-08-14 23:03:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 23:03:23.129: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-7336,SelfLink:/apis/apps/v1/namespaces/deployment-7336/replicasets/test-rollover-deployment-854595fc44,UID:46a62fe7-8524-42ab-9e3f-8ac946c40fca,ResourceVersion:40160,Generation:2,CreationTimestamp:2019-08-14 23:03:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a7dec6b-0f23-47a6-a226-b42be2b4b205 0xc002d93b07 0xc002d93b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 23:03:23.129: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 14 23:03:23.129: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7336,SelfLink:/apis/apps/v1/namespaces/deployment-7336/replicasets/test-rollover-controller,UID:aa225dc5-81e0-4d35-96b7-3638511ee502,ResourceVersion:40169,Generation:2,CreationTimestamp:2019-08-14 23:03:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a7dec6b-0f23-47a6-a226-b42be2b4b205 0xc002d93a37 0xc002d93a38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 23:03:23.129: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-7336,SelfLink:/apis/apps/v1/namespaces/deployment-7336/replicasets/test-rollover-deployment-9b8b997cf,UID:14ee0f6b-a07d-4a3e-be57-2159dde9c6a5,ResourceVersion:40125,Generation:2,CreationTimestamp:2019-08-14 23:03:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1a7dec6b-0f23-47a6-a226-b42be2b4b205 0xc002d93bd0 0xc002d93bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 23:03:23.142: INFO: Pod "test-rollover-deployment-854595fc44-824fb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-824fb,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-7336,SelfLink:/api/v1/namespaces/deployment-7336/pods/test-rollover-deployment-854595fc44-824fb,UID:39cc8528-5795-4ee3-8cde-27ee0f59453d,ResourceVersion:40140,Generation:0,CreationTimestamp:2019-08-14 23:03:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 46a62fe7-8524-42ab-9e3f-8ac946c40fca 0xc0035e67a7 0xc0035e67a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-l5p65 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l5p65,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-l5p65 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.148,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0035e6820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0035e6840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 23:03:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 23:03:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 23:03:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 23:03:11 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.148,PodIP:172.30.32.234,StartTime:2019-08-14 23:03:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 23:03:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://3abbfb1ec89731830c16bffaa12d6c97dd4edb398c49736456645cdf292562b7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:03:23.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7336" for this suite.
Aug 14 23:03:29.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:03:29.580: INFO: namespace deployment-7336 deletion completed in 6.406752223s

• [SLOW TEST:27.989 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:03:29.581: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 14 23:03:35.921: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:35.921: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:36.254: INFO: Exec stderr: ""
Aug 14 23:03:36.255: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:36.255: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:36.584: INFO: Exec stderr: ""
Aug 14 23:03:36.584: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:36.584: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:36.887: INFO: Exec stderr: ""
Aug 14 23:03:36.887: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:36.887: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:37.257: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 14 23:03:37.257: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:37.257: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:37.579: INFO: Exec stderr: ""
Aug 14 23:03:37.579: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:37.579: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:37.999: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 14 23:03:37.999: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:37.999: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:38.316: INFO: Exec stderr: ""
Aug 14 23:03:38.316: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:38.316: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:38.651: INFO: Exec stderr: ""
Aug 14 23:03:38.651: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:38.651: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:38.938: INFO: Exec stderr: ""
Aug 14 23:03:38.938: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8877 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:03:38.938: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:03:39.277: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:03:39.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8877" for this suite.
Aug 14 23:04:25.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:04:25.733: INFO: namespace e2e-kubelet-etc-hosts-8877 deletion completed in 46.420206683s

• [SLOW TEST:56.152 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:04:25.735: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 23:04:25.966: INFO: Waiting up to 5m0s for pod "pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824" in namespace "emptydir-1648" to be "success or failure"
Aug 14 23:04:25.978: INFO: Pod "pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824": Phase="Pending", Reason="", readiness=false. Elapsed: 11.853413ms
Aug 14 23:04:27.991: INFO: Pod "pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024801972s
STEP: Saw pod success
Aug 14 23:04:27.991: INFO: Pod "pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824" satisfied condition "success or failure"
Aug 14 23:04:28.003: INFO: Trying to get logs from node 10.195.18.148 pod pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824 container test-container: <nil>
STEP: delete the pod
Aug 14 23:04:28.063: INFO: Waiting for pod pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824 to disappear
Aug 14 23:04:28.080: INFO: Pod pod-9e9a1613-aec8-4cba-8cd2-df8e8b230824 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:04:28.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1648" for this suite.
Aug 14 23:04:34.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:04:34.530: INFO: namespace emptydir-1648 deletion completed in 6.433273954s

• [SLOW TEST:8.795 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:04:34.530: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1493
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-183587bc-51b4-4f44-9a4d-13d34f6d07d0
STEP: Creating a pod to test consume configMaps
Aug 14 23:04:34.768: INFO: Waiting up to 5m0s for pod "pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c" in namespace "configmap-1493" to be "success or failure"
Aug 14 23:04:34.784: INFO: Pod "pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.600449ms
Aug 14 23:04:36.797: INFO: Pod "pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029107032s
STEP: Saw pod success
Aug 14 23:04:36.797: INFO: Pod "pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c" satisfied condition "success or failure"
Aug 14 23:04:36.809: INFO: Trying to get logs from node 10.195.18.184 pod pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 23:04:36.870: INFO: Waiting for pod pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c to disappear
Aug 14 23:04:36.888: INFO: Pod pod-configmaps-a39394f8-126e-4215-95a3-6bed23b2dc0c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:04:36.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1493" for this suite.
Aug 14 23:04:42.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:04:43.355: INFO: namespace configmap-1493 deletion completed in 6.449828673s

• [SLOW TEST:8.825 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:04:43.355: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 14 23:04:44.131: INFO: created pod pod-service-account-defaultsa
Aug 14 23:04:44.131: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 14 23:04:44.145: INFO: created pod pod-service-account-mountsa
Aug 14 23:04:44.145: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 14 23:04:44.159: INFO: created pod pod-service-account-nomountsa
Aug 14 23:04:44.159: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 14 23:04:44.173: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 14 23:04:44.173: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 14 23:04:44.187: INFO: created pod pod-service-account-mountsa-mountspec
Aug 14 23:04:44.187: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 14 23:04:44.204: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 14 23:04:44.204: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 14 23:04:44.251: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 14 23:04:44.251: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 14 23:04:44.265: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 14 23:04:44.266: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 14 23:04:44.279: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 14 23:04:44.279: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:04:44.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5606" for this suite.
Aug 14 23:04:52.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:04:52.712: INFO: namespace svcaccounts-5606 deletion completed in 8.415054222s

• [SLOW TEST:9.357 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:04:52.713: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-62482bea-7525-4dfa-a4df-7b8f7890a016
STEP: Creating a pod to test consume secrets
Aug 14 23:04:52.945: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4" in namespace "projected-6668" to be "success or failure"
Aug 14 23:04:52.958: INFO: Pod "pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.746572ms
Aug 14 23:04:54.971: INFO: Pod "pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025663749s
STEP: Saw pod success
Aug 14 23:04:54.971: INFO: Pod "pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4" satisfied condition "success or failure"
Aug 14 23:04:54.982: INFO: Trying to get logs from node 10.195.18.146 pod pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 23:04:55.046: INFO: Waiting for pod pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4 to disappear
Aug 14 23:04:55.057: INFO: Pod pod-projected-secrets-a3b1a665-8973-476a-a2ca-26e9f3a9d0b4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:04:55.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6668" for this suite.
Aug 14 23:05:01.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:01.515: INFO: namespace projected-6668 deletion completed in 6.442355927s

• [SLOW TEST:8.802 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:01.516: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-eab6e3a9-da8f-4fab-983e-8e35747c2775
STEP: Creating a pod to test consume secrets
Aug 14 23:05:01.757: INFO: Waiting up to 5m0s for pod "pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4" in namespace "secrets-1844" to be "success or failure"
Aug 14 23:05:01.778: INFO: Pod "pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.306992ms
Aug 14 23:05:03.792: INFO: Pod "pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034881574s
Aug 14 23:05:05.805: INFO: Pod "pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047815552s
STEP: Saw pod success
Aug 14 23:05:05.805: INFO: Pod "pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4" satisfied condition "success or failure"
Aug 14 23:05:05.817: INFO: Trying to get logs from node 10.195.18.146 pod pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 23:05:05.876: INFO: Waiting for pod pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4 to disappear
Aug 14 23:05:05.888: INFO: Pod pod-secrets-84e3c532-aef3-490d-9fbb-fae7be9a89f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:05:05.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1844" for this suite.
Aug 14 23:05:11.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:12.318: INFO: namespace secrets-1844 deletion completed in 6.41376723s

• [SLOW TEST:10.801 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:12.318: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 23:05:12.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e" in namespace "projected-8091" to be "success or failure"
Aug 14 23:05:12.562: INFO: Pod "downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.743719ms
Aug 14 23:05:14.575: INFO: Pod "downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026121272s
Aug 14 23:05:16.587: INFO: Pod "downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038631504s
STEP: Saw pod success
Aug 14 23:05:16.587: INFO: Pod "downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e" satisfied condition "success or failure"
Aug 14 23:05:16.598: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e container client-container: <nil>
STEP: delete the pod
Aug 14 23:05:16.658: INFO: Waiting for pod downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e to disappear
Aug 14 23:05:16.674: INFO: Pod downwardapi-volume-99c24b6b-8683-45d0-b089-f42fd513c39e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:05:16.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8091" for this suite.
Aug 14 23:05:22.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:23.306: INFO: namespace projected-8091 deletion completed in 6.611810421s

• [SLOW TEST:10.989 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:23.307: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-4cd95e15-c226-47d2-83cd-f44d076d5632
STEP: Creating a pod to test consume configMaps
Aug 14 23:05:23.546: INFO: Waiting up to 5m0s for pod "pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4" in namespace "configmap-265" to be "success or failure"
Aug 14 23:05:23.560: INFO: Pod "pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.599467ms
Aug 14 23:05:25.573: INFO: Pod "pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026379482s
Aug 14 23:05:27.584: INFO: Pod "pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038339672s
STEP: Saw pod success
Aug 14 23:05:27.585: INFO: Pod "pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4" satisfied condition "success or failure"
Aug 14 23:05:27.604: INFO: Trying to get logs from node 10.195.18.148 pod pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 23:05:27.677: INFO: Waiting for pod pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4 to disappear
Aug 14 23:05:27.709: INFO: Pod pod-configmaps-00e18c61-d75e-420b-a426-308a4d2101c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:05:27.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-265" for this suite.
Aug 14 23:05:33.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:34.139: INFO: namespace configmap-265 deletion completed in 6.413385747s

• [SLOW TEST:10.832 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:34.140: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 23:05:34.370: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5" in namespace "downward-api-7628" to be "success or failure"
Aug 14 23:05:34.384: INFO: Pod "downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.849785ms
Aug 14 23:05:36.397: INFO: Pod "downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.026447147s
Aug 14 23:05:38.413: INFO: Pod "downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042514906s
STEP: Saw pod success
Aug 14 23:05:38.413: INFO: Pod "downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5" satisfied condition "success or failure"
Aug 14 23:05:38.428: INFO: Trying to get logs from node 10.195.18.148 pod downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5 container client-container: <nil>
STEP: delete the pod
Aug 14 23:05:38.491: INFO: Waiting for pod downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5 to disappear
Aug 14 23:05:38.503: INFO: Pod downwardapi-volume-35c9fb0d-aba4-41da-82d8-50f4e49cc9f5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:05:38.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7628" for this suite.
Aug 14 23:05:44.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:44.955: INFO: namespace downward-api-7628 deletion completed in 6.435566189s

• [SLOW TEST:10.815 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:44.955: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3719
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:05:45.157: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:05:46.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3719" for this suite.
Aug 14 23:05:52.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:05:52.897: INFO: namespace custom-resource-definition-3719 deletion completed in 6.402195139s

• [SLOW TEST:7.942 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:05:52.898: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-98
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-98
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-98
STEP: Creating statefulset with conflicting port in namespace statefulset-98
STEP: Waiting until pod test-pod will start running in namespace statefulset-98
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-98
Aug 14 23:05:55.193: INFO: Observed stateful pod in namespace: statefulset-98, name: ss-0, uid: bb237918-cc9e-4214-93da-abc30a3a5a69, status phase: Pending. Waiting for statefulset controller to delete.
Aug 14 23:05:55.198: INFO: Observed stateful pod in namespace: statefulset-98, name: ss-0, uid: bb237918-cc9e-4214-93da-abc30a3a5a69, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 23:05:55.217: INFO: Observed stateful pod in namespace: statefulset-98, name: ss-0, uid: bb237918-cc9e-4214-93da-abc30a3a5a69, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 23:05:55.233: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-98
STEP: Removing pod with conflicting port in namespace statefulset-98
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-98 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 23:05:57.294: INFO: Deleting all statefulset in ns statefulset-98
Aug 14 23:05:57.304: INFO: Scaling statefulset ss to 0
Aug 14 23:06:07.366: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 23:06:07.378: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:06:07.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-98" for this suite.
Aug 14 23:06:13.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:06:13.855: INFO: namespace statefulset-98 deletion completed in 6.404243251s

• [SLOW TEST:20.957 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:06:13.856: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:06:16.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-499" for this suite.
Aug 14 23:07:06.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:07:06.588: INFO: namespace kubelet-test-499 deletion completed in 50.417420673s

• [SLOW TEST:52.732 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:07:06.592: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 23:07:06.817: INFO: Waiting up to 5m0s for pod "downward-api-78225a72-e00b-438e-ac2f-6b30c1480589" in namespace "downward-api-7456" to be "success or failure"
Aug 14 23:07:06.833: INFO: Pod "downward-api-78225a72-e00b-438e-ac2f-6b30c1480589": Phase="Pending", Reason="", readiness=false. Elapsed: 15.924046ms
Aug 14 23:07:08.846: INFO: Pod "downward-api-78225a72-e00b-438e-ac2f-6b30c1480589": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029029482s
Aug 14 23:07:10.858: INFO: Pod "downward-api-78225a72-e00b-438e-ac2f-6b30c1480589": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041690962s
STEP: Saw pod success
Aug 14 23:07:10.858: INFO: Pod "downward-api-78225a72-e00b-438e-ac2f-6b30c1480589" satisfied condition "success or failure"
Aug 14 23:07:10.870: INFO: Trying to get logs from node 10.195.18.148 pod downward-api-78225a72-e00b-438e-ac2f-6b30c1480589 container dapi-container: <nil>
STEP: delete the pod
Aug 14 23:07:10.951: INFO: Waiting for pod downward-api-78225a72-e00b-438e-ac2f-6b30c1480589 to disappear
Aug 14 23:07:10.968: INFO: Pod downward-api-78225a72-e00b-438e-ac2f-6b30c1480589 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:07:10.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7456" for this suite.
Aug 14 23:07:17.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:07:17.410: INFO: namespace downward-api-7456 deletion completed in 6.42564885s

• [SLOW TEST:10.818 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:07:17.410: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-f28cacb2-3309-4acd-9b83-4985befbe9b5
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:07:17.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7704" for this suite.
Aug 14 23:07:23.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:07:24.053: INFO: namespace configmap-7704 deletion completed in 6.411843134s

• [SLOW TEST:6.643 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:07:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 23:07:24.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7327'
Aug 14 23:07:24.470: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 23:07:24.470: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 14 23:07:24.495: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-nmdjz]
Aug 14 23:07:24.495: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-nmdjz" in namespace "kubectl-7327" to be "running and ready"
Aug 14 23:07:24.507: INFO: Pod "e2e-test-nginx-rc-nmdjz": Phase="Pending", Reason="", readiness=false. Elapsed: 11.409903ms
Aug 14 23:07:26.520: INFO: Pod "e2e-test-nginx-rc-nmdjz": Phase="Running", Reason="", readiness=true. Elapsed: 2.025136096s
Aug 14 23:07:26.520: INFO: Pod "e2e-test-nginx-rc-nmdjz" satisfied condition "running and ready"
Aug 14 23:07:26.520: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-nmdjz]
Aug 14 23:07:26.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 logs rc/e2e-test-nginx-rc --namespace=kubectl-7327'
Aug 14 23:07:26.962: INFO: stderr: ""
Aug 14 23:07:26.962: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug 14 23:07:26.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete rc e2e-test-nginx-rc --namespace=kubectl-7327'
Aug 14 23:07:27.101: INFO: stderr: ""
Aug 14 23:07:27.101: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:07:27.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7327" for this suite.
Aug 14 23:07:51.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:07:51.752: INFO: namespace kubectl-7327 deletion completed in 24.634414144s

• [SLOW TEST:27.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:07:51.753: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3395/configmap-test-1b4c5305-2fea-463a-9630-45c636db78f2
STEP: Creating a pod to test consume configMaps
Aug 14 23:07:52.010: INFO: Waiting up to 5m0s for pod "pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44" in namespace "configmap-3395" to be "success or failure"
Aug 14 23:07:52.026: INFO: Pod "pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44": Phase="Pending", Reason="", readiness=false. Elapsed: 15.37436ms
Aug 14 23:07:54.038: INFO: Pod "pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027972414s
STEP: Saw pod success
Aug 14 23:07:54.038: INFO: Pod "pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44" satisfied condition "success or failure"
Aug 14 23:07:54.064: INFO: Trying to get logs from node 10.195.18.148 pod pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44 container env-test: <nil>
STEP: delete the pod
Aug 14 23:07:54.128: INFO: Waiting for pod pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44 to disappear
Aug 14 23:07:54.144: INFO: Pod pod-configmaps-08fe6217-73f6-49a0-abc3-caa1052f5d44 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:07:54.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3395" for this suite.
Aug 14 23:08:00.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:08:00.705: INFO: namespace configmap-3395 deletion completed in 6.543815103s

• [SLOW TEST:8.952 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:08:00.706: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-4698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-4698
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4698
STEP: Deleting pre-stop pod
Aug 14 23:08:18.097: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:08:18.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4698" for this suite.
Aug 14 23:08:58.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:08:58.887: INFO: namespace prestop-4698 deletion completed in 40.737793793s

• [SLOW TEST:58.181 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:08:58.888: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 14 23:09:01.177: INFO: Pod pod-hostip-1f4e9d89-913e-4c9a-bce1-a5572d2f2fb3 has hostIP: 10.195.18.184
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:09:01.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-334" for this suite.
Aug 14 23:09:25.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:09:25.645: INFO: namespace pods-334 deletion completed in 24.451434632s

• [SLOW TEST:26.758 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:09:25.646: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 14 23:09:25.860: INFO: namespace kubectl-8817
Aug 14 23:09:25.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-8817'
Aug 14 23:09:26.151: INFO: stderr: ""
Aug 14 23:09:26.151: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 23:09:27.165: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:09:27.165: INFO: Found 0 / 1
Aug 14 23:09:28.164: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:09:28.164: INFO: Found 0 / 1
Aug 14 23:09:29.164: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:09:29.164: INFO: Found 1 / 1
Aug 14 23:09:29.164: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 23:09:29.176: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:09:29.176: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 23:09:29.176: INFO: wait on redis-master startup in kubectl-8817 
Aug 14 23:09:29.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 logs redis-master-9qz7x redis-master --namespace=kubectl-8817'
Aug 14 23:09:29.324: INFO: stderr: ""
Aug 14 23:09:29.324: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 23:09:27.503 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 23:09:27.503 # Server started, Redis version 3.2.12\n1:M 14 Aug 23:09:27.503 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 23:09:27.503 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 14 23:09:29.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8817'
Aug 14 23:09:29.497: INFO: stderr: ""
Aug 14 23:09:29.497: INFO: stdout: "service/rm2 exposed\n"
Aug 14 23:09:29.507: INFO: Service rm2 in namespace kubectl-8817 found.
STEP: exposing service
Aug 14 23:09:31.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8817'
Aug 14 23:09:31.687: INFO: stderr: ""
Aug 14 23:09:31.687: INFO: stdout: "service/rm3 exposed\n"
Aug 14 23:09:31.696: INFO: Service rm3 in namespace kubectl-8817 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:09:33.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8817" for this suite.
Aug 14 23:09:57.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:09:58.137: INFO: namespace kubectl-8817 deletion completed in 24.403292653s

• [SLOW TEST:32.491 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:09:58.137: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-bfff69e5-8423-4550-8044-3087bc39fb66
STEP: Creating a pod to test consume secrets
Aug 14 23:09:58.395: INFO: Waiting up to 5m0s for pod "pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601" in namespace "secrets-2551" to be "success or failure"
Aug 14 23:09:58.411: INFO: Pod "pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601": Phase="Pending", Reason="", readiness=false. Elapsed: 16.200578ms
Aug 14 23:10:00.425: INFO: Pod "pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030553022s
STEP: Saw pod success
Aug 14 23:10:00.425: INFO: Pod "pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601" satisfied condition "success or failure"
Aug 14 23:10:00.438: INFO: Trying to get logs from node 10.195.18.148 pod pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 23:10:00.504: INFO: Waiting for pod pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601 to disappear
Aug 14 23:10:00.520: INFO: Pod pod-secrets-81643edc-6e9b-48ff-9ca4-c1ae5ed61601 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:10:00.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2551" for this suite.
Aug 14 23:10:06.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:10:06.948: INFO: namespace secrets-2551 deletion completed in 6.408995282s

• [SLOW TEST:8.811 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:10:06.949: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 23:10:09.232: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:10:09.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5117" for this suite.
Aug 14 23:10:15.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:10:15.728: INFO: namespace container-runtime-5117 deletion completed in 6.433277912s

• [SLOW TEST:8.779 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:10:15.729: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9729
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 14 23:10:21.046: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:10:21.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9729" for this suite.
Aug 14 23:10:45.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:10:45.835: INFO: namespace replicaset-9729 deletion completed in 24.726312234s

• [SLOW TEST:30.106 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:10:45.836: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2168
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 14 23:10:46.081: INFO: Found 0 stateful pods, waiting for 3
Aug 14 23:10:56.102: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 23:10:56.102: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 23:10:56.102: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 23:10:56.173: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 14 23:11:06.255: INFO: Updating stateful set ss2
Aug 14 23:11:06.277: INFO: Waiting for Pod statefulset-2168/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 14 23:11:16.404: INFO: Found 2 stateful pods, waiting for 3
Aug 14 23:11:26.418: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 23:11:26.418: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 23:11:26.418: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 14 23:11:26.480: INFO: Updating stateful set ss2
Aug 14 23:11:26.514: INFO: Waiting for Pod statefulset-2168/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 23:11:36.587: INFO: Updating stateful set ss2
Aug 14 23:11:36.614: INFO: Waiting for StatefulSet statefulset-2168/ss2 to complete update
Aug 14 23:11:36.614: INFO: Waiting for Pod statefulset-2168/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 23:11:46.638: INFO: Deleting all statefulset in ns statefulset-2168
Aug 14 23:11:46.648: INFO: Scaling statefulset ss2 to 0
Aug 14 23:12:16.701: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 23:12:16.711: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:12:16.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2168" for this suite.
Aug 14 23:12:24.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:12:25.197: INFO: namespace statefulset-2168 deletion completed in 8.420465102s

• [SLOW TEST:99.361 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:12:25.198: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 23:12:25.422: INFO: Waiting up to 5m0s for pod "pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43" in namespace "emptydir-716" to be "success or failure"
Aug 14 23:12:25.444: INFO: Pod "pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43": Phase="Pending", Reason="", readiness=false. Elapsed: 21.278671ms
Aug 14 23:12:27.458: INFO: Pod "pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035729044s
Aug 14 23:12:29.470: INFO: Pod "pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04793664s
STEP: Saw pod success
Aug 14 23:12:29.471: INFO: Pod "pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43" satisfied condition "success or failure"
Aug 14 23:12:29.483: INFO: Trying to get logs from node 10.195.18.148 pod pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43 container test-container: <nil>
STEP: delete the pod
Aug 14 23:12:29.549: INFO: Waiting for pod pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43 to disappear
Aug 14 23:12:29.566: INFO: Pod pod-8dcb2c73-0c57-4f62-b82d-ee262a9c0c43 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:12:29.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-716" for this suite.
Aug 14 23:12:35.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:12:36.042: INFO: namespace emptydir-716 deletion completed in 6.460485204s

• [SLOW TEST:10.845 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:12:36.045: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 23:12:38.330: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:12:38.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8589" for this suite.
Aug 14 23:12:44.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:12:44.802: INFO: namespace container-runtime-8589 deletion completed in 6.404798763s

• [SLOW TEST:8.757 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:12:44.803: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 23:12:45.041: INFO: Waiting up to 5m0s for pod "pod-58059e90-89d8-42a9-9e26-12e185413168" in namespace "emptydir-2740" to be "success or failure"
Aug 14 23:12:45.056: INFO: Pod "pod-58059e90-89d8-42a9-9e26-12e185413168": Phase="Pending", Reason="", readiness=false. Elapsed: 14.503462ms
Aug 14 23:12:47.069: INFO: Pod "pod-58059e90-89d8-42a9-9e26-12e185413168": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02767875s
STEP: Saw pod success
Aug 14 23:12:47.069: INFO: Pod "pod-58059e90-89d8-42a9-9e26-12e185413168" satisfied condition "success or failure"
Aug 14 23:12:47.081: INFO: Trying to get logs from node 10.195.18.146 pod pod-58059e90-89d8-42a9-9e26-12e185413168 container test-container: <nil>
STEP: delete the pod
Aug 14 23:12:47.144: INFO: Waiting for pod pod-58059e90-89d8-42a9-9e26-12e185413168 to disappear
Aug 14 23:12:47.160: INFO: Pod pod-58059e90-89d8-42a9-9e26-12e185413168 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:12:47.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2740" for this suite.
Aug 14 23:12:53.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:12:53.606: INFO: namespace emptydir-2740 deletion completed in 6.429684436s

• [SLOW TEST:8.803 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:12:53.606: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 23:12:53.837: INFO: Waiting up to 5m0s for pod "downward-api-09b55102-7885-42b0-b589-de5f21a16374" in namespace "downward-api-8746" to be "success or failure"
Aug 14 23:12:53.851: INFO: Pod "downward-api-09b55102-7885-42b0-b589-de5f21a16374": Phase="Pending", Reason="", readiness=false. Elapsed: 14.867109ms
Aug 14 23:12:55.865: INFO: Pod "downward-api-09b55102-7885-42b0-b589-de5f21a16374": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028218585s
STEP: Saw pod success
Aug 14 23:12:55.865: INFO: Pod "downward-api-09b55102-7885-42b0-b589-de5f21a16374" satisfied condition "success or failure"
Aug 14 23:12:55.877: INFO: Trying to get logs from node 10.195.18.148 pod downward-api-09b55102-7885-42b0-b589-de5f21a16374 container dapi-container: <nil>
STEP: delete the pod
Aug 14 23:12:55.952: INFO: Waiting for pod downward-api-09b55102-7885-42b0-b589-de5f21a16374 to disappear
Aug 14 23:12:55.968: INFO: Pod downward-api-09b55102-7885-42b0-b589-de5f21a16374 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:12:55.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8746" for this suite.
Aug 14 23:13:02.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:13:02.416: INFO: namespace downward-api-8746 deletion completed in 6.431253891s

• [SLOW TEST:8.810 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:13:02.418: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-cadf2bd4-0287-4471-ad06-2903770245a5 in namespace container-probe-7810
Aug 14 23:13:10.680: INFO: Started pod liveness-cadf2bd4-0287-4471-ad06-2903770245a5 in namespace container-probe-7810
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 23:13:10.692: INFO: Initial restart count of pod liveness-cadf2bd4-0287-4471-ad06-2903770245a5 is 0
Aug 14 23:13:28.824: INFO: Restart count of pod container-probe-7810/liveness-cadf2bd4-0287-4471-ad06-2903770245a5 is now 1 (18.132361928s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:13:28.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7810" for this suite.
Aug 14 23:13:34.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:13:35.351: INFO: namespace container-probe-7810 deletion completed in 6.474704848s

• [SLOW TEST:32.933 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:13:35.352: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 14 23:13:35.580: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:13:50.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-282" for this suite.
Aug 14 23:13:56.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:13:56.854: INFO: namespace pods-282 deletion completed in 6.410175278s

• [SLOW TEST:21.502 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:13:56.854: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1206
I0814 23:13:57.070443      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1206, replica count: 1
I0814 23:13:58.120823      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 23:13:59.121023      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 23:13:59.245: INFO: Created: latency-svc-xwh24
Aug 14 23:13:59.254: INFO: Got endpoints: latency-svc-xwh24 [32.787971ms]
Aug 14 23:13:59.278: INFO: Created: latency-svc-kw6zx
Aug 14 23:13:59.284: INFO: Got endpoints: latency-svc-kw6zx [29.845187ms]
Aug 14 23:13:59.288: INFO: Created: latency-svc-brj4m
Aug 14 23:13:59.296: INFO: Got endpoints: latency-svc-brj4m [41.533269ms]
Aug 14 23:13:59.299: INFO: Created: latency-svc-mr7wp
Aug 14 23:13:59.306: INFO: Got endpoints: latency-svc-mr7wp [51.965323ms]
Aug 14 23:13:59.311: INFO: Created: latency-svc-9m4c8
Aug 14 23:13:59.320: INFO: Got endpoints: latency-svc-9m4c8 [66.312029ms]
Aug 14 23:13:59.337: INFO: Created: latency-svc-v9tb7
Aug 14 23:13:59.337: INFO: Created: latency-svc-x9c9n
Aug 14 23:13:59.337: INFO: Got endpoints: latency-svc-x9c9n [82.922006ms]
Aug 14 23:13:59.373: INFO: Created: latency-svc-xvwsd
Aug 14 23:13:59.373: INFO: Created: latency-svc-57s6m
Aug 14 23:13:59.373: INFO: Created: latency-svc-rdjk5
Aug 14 23:13:59.373: INFO: Got endpoints: latency-svc-rdjk5 [119.316016ms]
Aug 14 23:13:59.373: INFO: Got endpoints: latency-svc-57s6m [119.217339ms]
Aug 14 23:13:59.373: INFO: Got endpoints: latency-svc-v9tb7 [119.171849ms]
Aug 14 23:13:59.377: INFO: Got endpoints: latency-svc-xvwsd [123.181865ms]
Aug 14 23:13:59.381: INFO: Created: latency-svc-gcstg
Aug 14 23:13:59.389: INFO: Got endpoints: latency-svc-gcstg [134.290487ms]
Aug 14 23:13:59.394: INFO: Created: latency-svc-jns8x
Aug 14 23:13:59.401: INFO: Got endpoints: latency-svc-jns8x [146.263329ms]
Aug 14 23:13:59.407: INFO: Created: latency-svc-r8g22
Aug 14 23:13:59.414: INFO: Got endpoints: latency-svc-r8g22 [160.111333ms]
Aug 14 23:13:59.418: INFO: Created: latency-svc-j5z4k
Aug 14 23:13:59.426: INFO: Got endpoints: latency-svc-j5z4k [171.435799ms]
Aug 14 23:13:59.430: INFO: Created: latency-svc-76wnp
Aug 14 23:13:59.437: INFO: Got endpoints: latency-svc-76wnp [182.535806ms]
Aug 14 23:13:59.442: INFO: Created: latency-svc-9h5hn
Aug 14 23:13:59.449: INFO: Got endpoints: latency-svc-9h5hn [194.393473ms]
Aug 14 23:13:59.454: INFO: Created: latency-svc-xb6jb
Aug 14 23:13:59.461: INFO: Got endpoints: latency-svc-xb6jb [177.562272ms]
Aug 14 23:13:59.465: INFO: Created: latency-svc-nn4zd
Aug 14 23:13:59.472: INFO: Got endpoints: latency-svc-nn4zd [176.396454ms]
Aug 14 23:13:59.476: INFO: Created: latency-svc-zfpvv
Aug 14 23:13:59.483: INFO: Got endpoints: latency-svc-zfpvv [176.870707ms]
Aug 14 23:13:59.488: INFO: Created: latency-svc-k82k5
Aug 14 23:13:59.495: INFO: Got endpoints: latency-svc-k82k5 [174.375922ms]
Aug 14 23:13:59.499: INFO: Created: latency-svc-gs9kk
Aug 14 23:13:59.506: INFO: Got endpoints: latency-svc-gs9kk [168.724188ms]
Aug 14 23:13:59.511: INFO: Created: latency-svc-vbzcz
Aug 14 23:13:59.518: INFO: Got endpoints: latency-svc-vbzcz [144.909595ms]
Aug 14 23:13:59.523: INFO: Created: latency-svc-9z4cx
Aug 14 23:13:59.530: INFO: Got endpoints: latency-svc-9z4cx [156.702044ms]
Aug 14 23:13:59.534: INFO: Created: latency-svc-8zfgm
Aug 14 23:13:59.542: INFO: Got endpoints: latency-svc-8zfgm [168.167865ms]
Aug 14 23:13:59.545: INFO: Created: latency-svc-sv2zb
Aug 14 23:13:59.553: INFO: Got endpoints: latency-svc-sv2zb [175.908722ms]
Aug 14 23:13:59.556: INFO: Created: latency-svc-qbkgn
Aug 14 23:13:59.565: INFO: Got endpoints: latency-svc-qbkgn [175.961957ms]
Aug 14 23:13:59.567: INFO: Created: latency-svc-bh6vc
Aug 14 23:13:59.573: INFO: Got endpoints: latency-svc-bh6vc [172.627071ms]
Aug 14 23:13:59.578: INFO: Created: latency-svc-h4b8v
Aug 14 23:13:59.586: INFO: Got endpoints: latency-svc-h4b8v [171.116537ms]
Aug 14 23:13:59.590: INFO: Created: latency-svc-82sw4
Aug 14 23:13:59.597: INFO: Got endpoints: latency-svc-82sw4 [171.631106ms]
Aug 14 23:13:59.602: INFO: Created: latency-svc-ds257
Aug 14 23:13:59.609: INFO: Got endpoints: latency-svc-ds257 [171.944436ms]
Aug 14 23:13:59.614: INFO: Created: latency-svc-d8xnt
Aug 14 23:13:59.621: INFO: Got endpoints: latency-svc-d8xnt [172.766738ms]
Aug 14 23:13:59.626: INFO: Created: latency-svc-bcc5f
Aug 14 23:13:59.633: INFO: Got endpoints: latency-svc-bcc5f [172.183488ms]
Aug 14 23:13:59.637: INFO: Created: latency-svc-7qrlp
Aug 14 23:13:59.647: INFO: Got endpoints: latency-svc-7qrlp [174.540382ms]
Aug 14 23:13:59.649: INFO: Created: latency-svc-h28ww
Aug 14 23:13:59.657: INFO: Got endpoints: latency-svc-h28ww [174.467342ms]
Aug 14 23:13:59.661: INFO: Created: latency-svc-snzn8
Aug 14 23:13:59.668: INFO: Got endpoints: latency-svc-snzn8 [173.420159ms]
Aug 14 23:13:59.673: INFO: Created: latency-svc-tgmmj
Aug 14 23:13:59.680: INFO: Got endpoints: latency-svc-tgmmj [174.239461ms]
Aug 14 23:13:59.684: INFO: Created: latency-svc-sssbp
Aug 14 23:13:59.691: INFO: Got endpoints: latency-svc-sssbp [172.882253ms]
Aug 14 23:13:59.697: INFO: Created: latency-svc-dbdvv
Aug 14 23:13:59.705: INFO: Got endpoints: latency-svc-dbdvv [175.140266ms]
Aug 14 23:13:59.709: INFO: Created: latency-svc-9lq2b
Aug 14 23:13:59.716: INFO: Got endpoints: latency-svc-9lq2b [174.028076ms]
Aug 14 23:13:59.720: INFO: Created: latency-svc-w8spv
Aug 14 23:13:59.727: INFO: Got endpoints: latency-svc-w8spv [174.052569ms]
Aug 14 23:13:59.732: INFO: Created: latency-svc-47rfl
Aug 14 23:13:59.739: INFO: Got endpoints: latency-svc-47rfl [174.825176ms]
Aug 14 23:13:59.744: INFO: Created: latency-svc-wp64b
Aug 14 23:13:59.750: INFO: Got endpoints: latency-svc-wp64b [176.910104ms]
Aug 14 23:13:59.755: INFO: Created: latency-svc-jjbvg
Aug 14 23:13:59.762: INFO: Got endpoints: latency-svc-jjbvg [175.988264ms]
Aug 14 23:13:59.767: INFO: Created: latency-svc-t8njz
Aug 14 23:13:59.776: INFO: Got endpoints: latency-svc-t8njz [178.700448ms]
Aug 14 23:13:59.778: INFO: Created: latency-svc-z9sx2
Aug 14 23:13:59.785: INFO: Got endpoints: latency-svc-z9sx2 [176.121157ms]
Aug 14 23:13:59.790: INFO: Created: latency-svc-dhhlq
Aug 14 23:13:59.796: INFO: Got endpoints: latency-svc-dhhlq [174.831517ms]
Aug 14 23:13:59.800: INFO: Created: latency-svc-mqtc7
Aug 14 23:13:59.808: INFO: Got endpoints: latency-svc-mqtc7 [174.246833ms]
Aug 14 23:13:59.813: INFO: Created: latency-svc-lcvz5
Aug 14 23:13:59.821: INFO: Got endpoints: latency-svc-lcvz5 [174.291799ms]
Aug 14 23:13:59.823: INFO: Created: latency-svc-w9tzc
Aug 14 23:13:59.830: INFO: Got endpoints: latency-svc-w9tzc [172.439858ms]
Aug 14 23:13:59.835: INFO: Created: latency-svc-7v4dn
Aug 14 23:13:59.842: INFO: Got endpoints: latency-svc-7v4dn [173.693042ms]
Aug 14 23:13:59.846: INFO: Created: latency-svc-6td8q
Aug 14 23:13:59.853: INFO: Got endpoints: latency-svc-6td8q [173.002622ms]
Aug 14 23:13:59.858: INFO: Created: latency-svc-dxpjr
Aug 14 23:13:59.865: INFO: Got endpoints: latency-svc-dxpjr [173.931332ms]
Aug 14 23:13:59.870: INFO: Created: latency-svc-ghshq
Aug 14 23:13:59.877: INFO: Got endpoints: latency-svc-ghshq [171.399239ms]
Aug 14 23:13:59.881: INFO: Created: latency-svc-qcfh4
Aug 14 23:13:59.888: INFO: Got endpoints: latency-svc-qcfh4 [172.243142ms]
Aug 14 23:13:59.892: INFO: Created: latency-svc-qddcx
Aug 14 23:13:59.899: INFO: Got endpoints: latency-svc-qddcx [171.100566ms]
Aug 14 23:13:59.903: INFO: Created: latency-svc-52r54
Aug 14 23:13:59.910: INFO: Got endpoints: latency-svc-52r54 [170.381126ms]
Aug 14 23:13:59.914: INFO: Created: latency-svc-7pbr4
Aug 14 23:13:59.921: INFO: Got endpoints: latency-svc-7pbr4 [170.366049ms]
Aug 14 23:13:59.926: INFO: Created: latency-svc-rgpqg
Aug 14 23:13:59.932: INFO: Got endpoints: latency-svc-rgpqg [170.363345ms]
Aug 14 23:13:59.937: INFO: Created: latency-svc-kjvdn
Aug 14 23:13:59.944: INFO: Got endpoints: latency-svc-kjvdn [168.056533ms]
Aug 14 23:13:59.950: INFO: Created: latency-svc-7lwjn
Aug 14 23:13:59.957: INFO: Got endpoints: latency-svc-7lwjn [172.077335ms]
Aug 14 23:13:59.962: INFO: Created: latency-svc-cmmc6
Aug 14 23:13:59.969: INFO: Got endpoints: latency-svc-cmmc6 [172.788425ms]
Aug 14 23:13:59.974: INFO: Created: latency-svc-gp7vx
Aug 14 23:13:59.982: INFO: Got endpoints: latency-svc-gp7vx [174.160163ms]
Aug 14 23:13:59.986: INFO: Created: latency-svc-n7vxk
Aug 14 23:13:59.993: INFO: Got endpoints: latency-svc-n7vxk [171.518065ms]
Aug 14 23:13:59.997: INFO: Created: latency-svc-vpqqw
Aug 14 23:14:00.005: INFO: Got endpoints: latency-svc-vpqqw [174.944786ms]
Aug 14 23:14:00.009: INFO: Created: latency-svc-rn5x5
Aug 14 23:14:00.016: INFO: Got endpoints: latency-svc-rn5x5 [173.579492ms]
Aug 14 23:14:00.020: INFO: Created: latency-svc-58kjz
Aug 14 23:14:00.027: INFO: Got endpoints: latency-svc-58kjz [173.852937ms]
Aug 14 23:14:00.050: INFO: Created: latency-svc-mfb4h
Aug 14 23:14:00.050: INFO: Created: latency-svc-bnd59
Aug 14 23:14:00.051: INFO: Got endpoints: latency-svc-bnd59 [185.232352ms]
Aug 14 23:14:00.058: INFO: Created: latency-svc-wq84x
Aug 14 23:14:00.077: INFO: Created: latency-svc-4jj8j
Aug 14 23:14:00.077: INFO: Got endpoints: latency-svc-wq84x [188.798318ms]
Aug 14 23:14:00.077: INFO: Got endpoints: latency-svc-mfb4h [199.972693ms]
Aug 14 23:14:00.080: INFO: Got endpoints: latency-svc-4jj8j [181.341116ms]
Aug 14 23:14:00.085: INFO: Created: latency-svc-4sxhz
Aug 14 23:14:00.091: INFO: Got endpoints: latency-svc-4sxhz [181.127178ms]
Aug 14 23:14:00.098: INFO: Created: latency-svc-r7spl
Aug 14 23:14:00.107: INFO: Got endpoints: latency-svc-r7spl [186.172726ms]
Aug 14 23:14:00.108: INFO: Created: latency-svc-vp4h5
Aug 14 23:14:00.116: INFO: Got endpoints: latency-svc-vp4h5 [183.582856ms]
Aug 14 23:14:00.119: INFO: Created: latency-svc-8bf9l
Aug 14 23:14:00.127: INFO: Got endpoints: latency-svc-8bf9l [182.349532ms]
Aug 14 23:14:00.133: INFO: Created: latency-svc-9m4zl
Aug 14 23:14:00.139: INFO: Got endpoints: latency-svc-9m4zl [182.028167ms]
Aug 14 23:14:00.144: INFO: Created: latency-svc-87vd4
Aug 14 23:14:00.154: INFO: Got endpoints: latency-svc-87vd4 [184.929567ms]
Aug 14 23:14:00.167: INFO: Created: latency-svc-7hlqk
Aug 14 23:14:00.167: INFO: Got endpoints: latency-svc-7hlqk [184.6797ms]
Aug 14 23:14:00.168: INFO: Created: latency-svc-p5grv
Aug 14 23:14:00.176: INFO: Got endpoints: latency-svc-p5grv [183.029078ms]
Aug 14 23:14:00.178: INFO: Created: latency-svc-8mcwq
Aug 14 23:14:00.188: INFO: Got endpoints: latency-svc-8mcwq [182.695923ms]
Aug 14 23:14:00.190: INFO: Created: latency-svc-z6wsj
Aug 14 23:14:00.198: INFO: Got endpoints: latency-svc-z6wsj [182.499596ms]
Aug 14 23:14:00.202: INFO: Created: latency-svc-2vczw
Aug 14 23:14:00.210: INFO: Got endpoints: latency-svc-2vczw [182.634991ms]
Aug 14 23:14:00.214: INFO: Created: latency-svc-g9n28
Aug 14 23:14:00.225: INFO: Got endpoints: latency-svc-g9n28 [174.12604ms]
Aug 14 23:14:00.225: INFO: Created: latency-svc-9dmmq
Aug 14 23:14:00.233: INFO: Got endpoints: latency-svc-9dmmq [155.646119ms]
Aug 14 23:14:00.237: INFO: Created: latency-svc-7gw84
Aug 14 23:14:00.246: INFO: Got endpoints: latency-svc-7gw84 [168.844654ms]
Aug 14 23:14:00.248: INFO: Created: latency-svc-5hlhg
Aug 14 23:14:00.255: INFO: Got endpoints: latency-svc-5hlhg [174.840261ms]
Aug 14 23:14:00.259: INFO: Created: latency-svc-zf2mr
Aug 14 23:14:00.266: INFO: Got endpoints: latency-svc-zf2mr [174.531855ms]
Aug 14 23:14:00.271: INFO: Created: latency-svc-x7n45
Aug 14 23:14:00.280: INFO: Got endpoints: latency-svc-x7n45 [172.634609ms]
Aug 14 23:14:00.282: INFO: Created: latency-svc-c7j8d
Aug 14 23:14:00.290: INFO: Got endpoints: latency-svc-c7j8d [174.430353ms]
Aug 14 23:14:00.293: INFO: Created: latency-svc-7bwjr
Aug 14 23:14:00.300: INFO: Got endpoints: latency-svc-7bwjr [173.810139ms]
Aug 14 23:14:00.306: INFO: Created: latency-svc-jrwsz
Aug 14 23:14:00.318: INFO: Created: latency-svc-8d582
Aug 14 23:14:00.318: INFO: Got endpoints: latency-svc-jrwsz [178.878961ms]
Aug 14 23:14:00.325: INFO: Got endpoints: latency-svc-8d582 [170.977834ms]
Aug 14 23:14:00.329: INFO: Created: latency-svc-jr4qk
Aug 14 23:14:00.336: INFO: Got endpoints: latency-svc-jr4qk [169.544002ms]
Aug 14 23:14:00.341: INFO: Created: latency-svc-q2kt5
Aug 14 23:14:00.351: INFO: Got endpoints: latency-svc-q2kt5 [174.890616ms]
Aug 14 23:14:00.352: INFO: Created: latency-svc-qnllg
Aug 14 23:14:00.359: INFO: Got endpoints: latency-svc-qnllg [171.19564ms]
Aug 14 23:14:00.364: INFO: Created: latency-svc-b4f7p
Aug 14 23:14:00.371: INFO: Got endpoints: latency-svc-b4f7p [172.948731ms]
Aug 14 23:14:00.375: INFO: Created: latency-svc-22pct
Aug 14 23:14:00.383: INFO: Got endpoints: latency-svc-22pct [173.571321ms]
Aug 14 23:14:00.387: INFO: Created: latency-svc-dsz8n
Aug 14 23:14:00.395: INFO: Got endpoints: latency-svc-dsz8n [169.892754ms]
Aug 14 23:14:00.399: INFO: Created: latency-svc-plh4f
Aug 14 23:14:00.406: INFO: Got endpoints: latency-svc-plh4f [173.293515ms]
Aug 14 23:14:00.411: INFO: Created: latency-svc-f42s4
Aug 14 23:14:00.419: INFO: Got endpoints: latency-svc-f42s4 [172.931454ms]
Aug 14 23:14:00.423: INFO: Created: latency-svc-wsnnp
Aug 14 23:14:00.430: INFO: Got endpoints: latency-svc-wsnnp [175.293993ms]
Aug 14 23:14:00.435: INFO: Created: latency-svc-hpg47
Aug 14 23:14:00.442: INFO: Got endpoints: latency-svc-hpg47 [176.518265ms]
Aug 14 23:14:00.447: INFO: Created: latency-svc-zqc4r
Aug 14 23:14:00.454: INFO: Got endpoints: latency-svc-zqc4r [173.804395ms]
Aug 14 23:14:00.463: INFO: Created: latency-svc-rh26p
Aug 14 23:14:00.466: INFO: Got endpoints: latency-svc-rh26p [176.025441ms]
Aug 14 23:14:00.470: INFO: Created: latency-svc-w8gxv
Aug 14 23:14:00.483: INFO: Got endpoints: latency-svc-w8gxv [182.213214ms]
Aug 14 23:14:00.483: INFO: Created: latency-svc-tshgj
Aug 14 23:14:00.490: INFO: Got endpoints: latency-svc-tshgj [171.262352ms]
Aug 14 23:14:00.499: INFO: Created: latency-svc-wt6xw
Aug 14 23:14:00.502: INFO: Got endpoints: latency-svc-wt6xw [176.362362ms]
Aug 14 23:14:00.509: INFO: Created: latency-svc-qh2sb
Aug 14 23:14:00.515: INFO: Got endpoints: latency-svc-qh2sb [179.072833ms]
Aug 14 23:14:00.527: INFO: Created: latency-svc-6dk49
Aug 14 23:14:00.528: INFO: Got endpoints: latency-svc-6dk49 [177.037254ms]
Aug 14 23:14:00.532: INFO: Created: latency-svc-5bcpv
Aug 14 23:14:00.540: INFO: Got endpoints: latency-svc-5bcpv [180.957718ms]
Aug 14 23:14:00.543: INFO: Created: latency-svc-x555l
Aug 14 23:14:00.557: INFO: Created: latency-svc-rnxbc
Aug 14 23:14:00.557: INFO: Got endpoints: latency-svc-x555l [186.013671ms]
Aug 14 23:14:00.564: INFO: Got endpoints: latency-svc-rnxbc [179.748887ms]
Aug 14 23:14:00.567: INFO: Created: latency-svc-xnvqw
Aug 14 23:14:00.575: INFO: Got endpoints: latency-svc-xnvqw [179.595726ms]
Aug 14 23:14:00.580: INFO: Created: latency-svc-bxwbd
Aug 14 23:14:00.588: INFO: Got endpoints: latency-svc-bxwbd [182.18013ms]
Aug 14 23:14:00.591: INFO: Created: latency-svc-dwh2c
Aug 14 23:14:00.602: INFO: Got endpoints: latency-svc-dwh2c [183.56012ms]
Aug 14 23:14:00.603: INFO: Created: latency-svc-j52fg
Aug 14 23:14:00.610: INFO: Got endpoints: latency-svc-j52fg [179.804875ms]
Aug 14 23:14:00.614: INFO: Created: latency-svc-m2rj9
Aug 14 23:14:00.622: INFO: Got endpoints: latency-svc-m2rj9 [180.246192ms]
Aug 14 23:14:00.627: INFO: Created: latency-svc-bsjb6
Aug 14 23:14:00.634: INFO: Got endpoints: latency-svc-bsjb6 [180.856431ms]
Aug 14 23:14:00.638: INFO: Created: latency-svc-h7sjl
Aug 14 23:14:00.645: INFO: Got endpoints: latency-svc-h7sjl [179.031001ms]
Aug 14 23:14:00.649: INFO: Created: latency-svc-nknn2
Aug 14 23:14:00.657: INFO: Got endpoints: latency-svc-nknn2 [173.701302ms]
Aug 14 23:14:00.662: INFO: Created: latency-svc-j49p7
Aug 14 23:14:00.669: INFO: Got endpoints: latency-svc-j49p7 [179.143333ms]
Aug 14 23:14:00.674: INFO: Created: latency-svc-2j5xm
Aug 14 23:14:00.696: INFO: Created: latency-svc-zq7rk
Aug 14 23:14:00.696: INFO: Got endpoints: latency-svc-zq7rk [180.2885ms]
Aug 14 23:14:00.696: INFO: Got endpoints: latency-svc-2j5xm [194.366001ms]
Aug 14 23:14:00.697: INFO: Created: latency-svc-267lb
Aug 14 23:14:00.704: INFO: Got endpoints: latency-svc-267lb [175.759446ms]
Aug 14 23:14:00.709: INFO: Created: latency-svc-txbb7
Aug 14 23:14:00.716: INFO: Got endpoints: latency-svc-txbb7 [175.825684ms]
Aug 14 23:14:00.721: INFO: Created: latency-svc-ztg8v
Aug 14 23:14:00.728: INFO: Got endpoints: latency-svc-ztg8v [170.862919ms]
Aug 14 23:14:00.733: INFO: Created: latency-svc-j97p5
Aug 14 23:14:00.740: INFO: Got endpoints: latency-svc-j97p5 [176.623305ms]
Aug 14 23:14:00.744: INFO: Created: latency-svc-cwnrt
Aug 14 23:14:00.761: INFO: Created: latency-svc-45rwh
Aug 14 23:14:00.761: INFO: Got endpoints: latency-svc-cwnrt [186.212045ms]
Aug 14 23:14:00.765: INFO: Got endpoints: latency-svc-45rwh [176.7545ms]
Aug 14 23:14:00.769: INFO: Created: latency-svc-fqbkq
Aug 14 23:14:00.776: INFO: Got endpoints: latency-svc-fqbkq [173.916015ms]
Aug 14 23:14:00.780: INFO: Created: latency-svc-689wz
Aug 14 23:14:00.788: INFO: Got endpoints: latency-svc-689wz [177.370259ms]
Aug 14 23:14:00.793: INFO: Created: latency-svc-928n5
Aug 14 23:14:00.800: INFO: Got endpoints: latency-svc-928n5 [177.119147ms]
Aug 14 23:14:00.804: INFO: Created: latency-svc-dxjv6
Aug 14 23:14:00.811: INFO: Got endpoints: latency-svc-dxjv6 [176.477365ms]
Aug 14 23:14:00.815: INFO: Created: latency-svc-tn29w
Aug 14 23:14:00.824: INFO: Got endpoints: latency-svc-tn29w [178.49399ms]
Aug 14 23:14:00.827: INFO: Created: latency-svc-f24qq
Aug 14 23:14:00.834: INFO: Got endpoints: latency-svc-f24qq [177.169388ms]
Aug 14 23:14:00.838: INFO: Created: latency-svc-8dwqx
Aug 14 23:14:00.846: INFO: Got endpoints: latency-svc-8dwqx [176.472707ms]
Aug 14 23:14:00.851: INFO: Created: latency-svc-llbwd
Aug 14 23:14:00.859: INFO: Got endpoints: latency-svc-llbwd [163.273109ms]
Aug 14 23:14:00.862: INFO: Created: latency-svc-9xcgk
Aug 14 23:14:00.871: INFO: Got endpoints: latency-svc-9xcgk [174.428224ms]
Aug 14 23:14:00.875: INFO: Created: latency-svc-zmh67
Aug 14 23:14:00.882: INFO: Got endpoints: latency-svc-zmh67 [178.67545ms]
Aug 14 23:14:00.886: INFO: Created: latency-svc-vdsj8
Aug 14 23:14:00.893: INFO: Got endpoints: latency-svc-vdsj8 [177.651136ms]
Aug 14 23:14:00.898: INFO: Created: latency-svc-h89xg
Aug 14 23:14:00.907: INFO: Got endpoints: latency-svc-h89xg [178.98273ms]
Aug 14 23:14:00.910: INFO: Created: latency-svc-t86mf
Aug 14 23:14:00.918: INFO: Got endpoints: latency-svc-t86mf [177.898899ms]
Aug 14 23:14:00.922: INFO: Created: latency-svc-nrfkt
Aug 14 23:14:00.929: INFO: Got endpoints: latency-svc-nrfkt [168.387875ms]
Aug 14 23:14:00.933: INFO: Created: latency-svc-9xhhc
Aug 14 23:14:00.941: INFO: Got endpoints: latency-svc-9xhhc [176.350933ms]
Aug 14 23:14:00.945: INFO: Created: latency-svc-cr7gq
Aug 14 23:14:00.952: INFO: Got endpoints: latency-svc-cr7gq [175.79798ms]
Aug 14 23:14:00.956: INFO: Created: latency-svc-khvhb
Aug 14 23:14:00.964: INFO: Got endpoints: latency-svc-khvhb [176.723882ms]
Aug 14 23:14:00.968: INFO: Created: latency-svc-hq7vc
Aug 14 23:14:00.975: INFO: Got endpoints: latency-svc-hq7vc [175.803017ms]
Aug 14 23:14:00.980: INFO: Created: latency-svc-pf7wg
Aug 14 23:14:00.988: INFO: Got endpoints: latency-svc-pf7wg [176.538439ms]
Aug 14 23:14:00.992: INFO: Created: latency-svc-8fc95
Aug 14 23:14:01.000: INFO: Got endpoints: latency-svc-8fc95 [175.630052ms]
Aug 14 23:14:01.003: INFO: Created: latency-svc-zs7ng
Aug 14 23:14:01.010: INFO: Got endpoints: latency-svc-zs7ng [176.490564ms]
Aug 14 23:14:01.015: INFO: Created: latency-svc-44gfb
Aug 14 23:14:01.022: INFO: Got endpoints: latency-svc-44gfb [176.265165ms]
Aug 14 23:14:01.027: INFO: Created: latency-svc-l8n58
Aug 14 23:14:01.033: INFO: Got endpoints: latency-svc-l8n58 [174.070745ms]
Aug 14 23:14:01.038: INFO: Created: latency-svc-56zt6
Aug 14 23:14:01.047: INFO: Got endpoints: latency-svc-56zt6 [175.815731ms]
Aug 14 23:14:01.050: INFO: Created: latency-svc-jdclj
Aug 14 23:14:01.057: INFO: Got endpoints: latency-svc-jdclj [174.454766ms]
Aug 14 23:14:01.063: INFO: Created: latency-svc-d9qbl
Aug 14 23:14:01.069: INFO: Got endpoints: latency-svc-d9qbl [175.374013ms]
Aug 14 23:14:01.073: INFO: Created: latency-svc-rhvm8
Aug 14 23:14:01.081: INFO: Got endpoints: latency-svc-rhvm8 [174.292533ms]
Aug 14 23:14:01.085: INFO: Created: latency-svc-6tvht
Aug 14 23:14:01.093: INFO: Got endpoints: latency-svc-6tvht [174.357151ms]
Aug 14 23:14:01.097: INFO: Created: latency-svc-l49gj
Aug 14 23:14:01.104: INFO: Got endpoints: latency-svc-l49gj [174.849919ms]
Aug 14 23:14:01.109: INFO: Created: latency-svc-k429f
Aug 14 23:14:01.117: INFO: Got endpoints: latency-svc-k429f [175.472278ms]
Aug 14 23:14:01.122: INFO: Created: latency-svc-h7kkm
Aug 14 23:14:01.129: INFO: Got endpoints: latency-svc-h7kkm [176.502022ms]
Aug 14 23:14:01.133: INFO: Created: latency-svc-tg9pv
Aug 14 23:14:01.141: INFO: Got endpoints: latency-svc-tg9pv [176.525118ms]
Aug 14 23:14:01.145: INFO: Created: latency-svc-9xckj
Aug 14 23:14:01.152: INFO: Got endpoints: latency-svc-9xckj [176.876352ms]
Aug 14 23:14:01.158: INFO: Created: latency-svc-kh4lz
Aug 14 23:14:01.167: INFO: Got endpoints: latency-svc-kh4lz [179.040303ms]
Aug 14 23:14:01.169: INFO: Created: latency-svc-2d7t6
Aug 14 23:14:01.177: INFO: Got endpoints: latency-svc-2d7t6 [176.782257ms]
Aug 14 23:14:01.181: INFO: Created: latency-svc-pxk6x
Aug 14 23:14:01.188: INFO: Got endpoints: latency-svc-pxk6x [177.691541ms]
Aug 14 23:14:01.193: INFO: Created: latency-svc-q7474
Aug 14 23:14:01.200: INFO: Got endpoints: latency-svc-q7474 [178.072438ms]
Aug 14 23:14:01.206: INFO: Created: latency-svc-r5h7c
Aug 14 23:14:01.215: INFO: Got endpoints: latency-svc-r5h7c [181.373849ms]
Aug 14 23:14:01.218: INFO: Created: latency-svc-8gtcz
Aug 14 23:14:01.227: INFO: Got endpoints: latency-svc-8gtcz [180.872981ms]
Aug 14 23:14:01.230: INFO: Created: latency-svc-tkp46
Aug 14 23:14:01.238: INFO: Got endpoints: latency-svc-tkp46 [181.036575ms]
Aug 14 23:14:01.246: INFO: Created: latency-svc-bn2cl
Aug 14 23:14:01.255: INFO: Got endpoints: latency-svc-bn2cl [185.633055ms]
Aug 14 23:14:01.257: INFO: Created: latency-svc-mx4jx
Aug 14 23:14:01.263: INFO: Got endpoints: latency-svc-mx4jx [181.434971ms]
Aug 14 23:14:01.266: INFO: Created: latency-svc-h8wxk
Aug 14 23:14:01.274: INFO: Got endpoints: latency-svc-h8wxk [181.048177ms]
Aug 14 23:14:01.277: INFO: Created: latency-svc-9hpk2
Aug 14 23:14:01.285: INFO: Got endpoints: latency-svc-9hpk2 [180.828543ms]
Aug 14 23:14:01.290: INFO: Created: latency-svc-hsmk2
Aug 14 23:14:01.297: INFO: Got endpoints: latency-svc-hsmk2 [179.673512ms]
Aug 14 23:14:01.301: INFO: Created: latency-svc-77q2l
Aug 14 23:14:01.308: INFO: Got endpoints: latency-svc-77q2l [179.337339ms]
Aug 14 23:14:01.313: INFO: Created: latency-svc-nscmb
Aug 14 23:14:01.322: INFO: Got endpoints: latency-svc-nscmb [180.537103ms]
Aug 14 23:14:01.326: INFO: Created: latency-svc-tnkbq
Aug 14 23:14:01.336: INFO: Got endpoints: latency-svc-tnkbq [183.135546ms]
Aug 14 23:14:01.338: INFO: Created: latency-svc-vb7z6
Aug 14 23:14:01.345: INFO: Got endpoints: latency-svc-vb7z6 [178.043114ms]
Aug 14 23:14:01.353: INFO: Created: latency-svc-vqmsq
Aug 14 23:14:01.356: INFO: Got endpoints: latency-svc-vqmsq [179.679516ms]
Aug 14 23:14:01.360: INFO: Created: latency-svc-bgbfb
Aug 14 23:14:01.367: INFO: Got endpoints: latency-svc-bgbfb [179.106822ms]
Aug 14 23:14:01.373: INFO: Created: latency-svc-p2gkr
Aug 14 23:14:01.381: INFO: Got endpoints: latency-svc-p2gkr [180.907492ms]
Aug 14 23:14:01.386: INFO: Created: latency-svc-v4xhl
Aug 14 23:14:01.392: INFO: Got endpoints: latency-svc-v4xhl [177.056323ms]
Aug 14 23:14:01.396: INFO: Created: latency-svc-55t9n
Aug 14 23:14:01.406: INFO: Got endpoints: latency-svc-55t9n [178.245125ms]
Aug 14 23:14:01.407: INFO: Created: latency-svc-zxb7p
Aug 14 23:14:01.416: INFO: Got endpoints: latency-svc-zxb7p [177.590359ms]
Aug 14 23:14:01.419: INFO: Created: latency-svc-8lgjt
Aug 14 23:14:01.427: INFO: Got endpoints: latency-svc-8lgjt [172.144054ms]
Aug 14 23:14:01.432: INFO: Created: latency-svc-grgcx
Aug 14 23:14:01.441: INFO: Got endpoints: latency-svc-grgcx [177.671138ms]
Aug 14 23:14:01.445: INFO: Created: latency-svc-zfjj9
Aug 14 23:14:01.453: INFO: Got endpoints: latency-svc-zfjj9 [178.872856ms]
Aug 14 23:14:01.458: INFO: Created: latency-svc-jcmpn
Aug 14 23:14:01.466: INFO: Got endpoints: latency-svc-jcmpn [180.285195ms]
Aug 14 23:14:01.470: INFO: Created: latency-svc-rvsvz
Aug 14 23:14:01.478: INFO: Got endpoints: latency-svc-rvsvz [181.455285ms]
Aug 14 23:14:01.483: INFO: Created: latency-svc-2hcns
Aug 14 23:14:01.491: INFO: Got endpoints: latency-svc-2hcns [182.275804ms]
Aug 14 23:14:01.494: INFO: Created: latency-svc-bq4pg
Aug 14 23:14:01.502: INFO: Got endpoints: latency-svc-bq4pg [180.715299ms]
Aug 14 23:14:01.506: INFO: Created: latency-svc-qhlxs
Aug 14 23:14:01.513: INFO: Got endpoints: latency-svc-qhlxs [177.793389ms]
Aug 14 23:14:01.518: INFO: Created: latency-svc-tg7w2
Aug 14 23:14:01.527: INFO: Got endpoints: latency-svc-tg7w2 [181.372409ms]
Aug 14 23:14:01.531: INFO: Created: latency-svc-j6kdr
Aug 14 23:14:01.540: INFO: Got endpoints: latency-svc-j6kdr [183.900549ms]
Aug 14 23:14:01.544: INFO: Created: latency-svc-6qzp8
Aug 14 23:14:01.552: INFO: Got endpoints: latency-svc-6qzp8 [184.198423ms]
Aug 14 23:14:01.555: INFO: Created: latency-svc-fbd4x
Aug 14 23:14:01.563: INFO: Got endpoints: latency-svc-fbd4x [182.044368ms]
Aug 14 23:14:01.568: INFO: Created: latency-svc-9cp6h
Aug 14 23:14:01.575: INFO: Got endpoints: latency-svc-9cp6h [183.633824ms]
Aug 14 23:14:01.579: INFO: Created: latency-svc-6ccgd
Aug 14 23:14:01.588: INFO: Got endpoints: latency-svc-6ccgd [182.1224ms]
Aug 14 23:14:01.591: INFO: Created: latency-svc-lmrzl
Aug 14 23:14:01.599: INFO: Got endpoints: latency-svc-lmrzl [183.155376ms]
Aug 14 23:14:01.603: INFO: Created: latency-svc-4m85f
Aug 14 23:14:01.610: INFO: Got endpoints: latency-svc-4m85f [183.423367ms]
Aug 14 23:14:01.614: INFO: Created: latency-svc-xh7dr
Aug 14 23:14:01.622: INFO: Got endpoints: latency-svc-xh7dr [181.16546ms]
Aug 14 23:14:01.626: INFO: Created: latency-svc-w9m8g
Aug 14 23:14:01.634: INFO: Got endpoints: latency-svc-w9m8g [180.875067ms]
Aug 14 23:14:01.634: INFO: Latencies: [29.845187ms 41.533269ms 51.965323ms 66.312029ms 82.922006ms 119.171849ms 119.217339ms 119.316016ms 123.181865ms 134.290487ms 144.909595ms 146.263329ms 155.646119ms 156.702044ms 160.111333ms 163.273109ms 168.056533ms 168.167865ms 168.387875ms 168.724188ms 168.844654ms 169.544002ms 169.892754ms 170.363345ms 170.366049ms 170.381126ms 170.862919ms 170.977834ms 171.100566ms 171.116537ms 171.19564ms 171.262352ms 171.399239ms 171.435799ms 171.518065ms 171.631106ms 171.944436ms 172.077335ms 172.144054ms 172.183488ms 172.243142ms 172.439858ms 172.627071ms 172.634609ms 172.766738ms 172.788425ms 172.882253ms 172.931454ms 172.948731ms 173.002622ms 173.293515ms 173.420159ms 173.571321ms 173.579492ms 173.693042ms 173.701302ms 173.804395ms 173.810139ms 173.852937ms 173.916015ms 173.931332ms 174.028076ms 174.052569ms 174.070745ms 174.12604ms 174.160163ms 174.239461ms 174.246833ms 174.291799ms 174.292533ms 174.357151ms 174.375922ms 174.428224ms 174.430353ms 174.454766ms 174.467342ms 174.531855ms 174.540382ms 174.825176ms 174.831517ms 174.840261ms 174.849919ms 174.890616ms 174.944786ms 175.140266ms 175.293993ms 175.374013ms 175.472278ms 175.630052ms 175.759446ms 175.79798ms 175.803017ms 175.815731ms 175.825684ms 175.908722ms 175.961957ms 175.988264ms 176.025441ms 176.121157ms 176.265165ms 176.350933ms 176.362362ms 176.396454ms 176.472707ms 176.477365ms 176.490564ms 176.502022ms 176.518265ms 176.525118ms 176.538439ms 176.623305ms 176.723882ms 176.7545ms 176.782257ms 176.870707ms 176.876352ms 176.910104ms 177.037254ms 177.056323ms 177.119147ms 177.169388ms 177.370259ms 177.562272ms 177.590359ms 177.651136ms 177.671138ms 177.691541ms 177.793389ms 177.898899ms 178.043114ms 178.072438ms 178.245125ms 178.49399ms 178.67545ms 178.700448ms 178.872856ms 178.878961ms 178.98273ms 179.031001ms 179.040303ms 179.072833ms 179.106822ms 179.143333ms 179.337339ms 179.595726ms 179.673512ms 179.679516ms 179.748887ms 179.804875ms 180.246192ms 180.285195ms 180.2885ms 180.537103ms 180.715299ms 180.828543ms 180.856431ms 180.872981ms 180.875067ms 180.907492ms 180.957718ms 181.036575ms 181.048177ms 181.127178ms 181.16546ms 181.341116ms 181.372409ms 181.373849ms 181.434971ms 181.455285ms 182.028167ms 182.044368ms 182.1224ms 182.18013ms 182.213214ms 182.275804ms 182.349532ms 182.499596ms 182.535806ms 182.634991ms 182.695923ms 183.029078ms 183.135546ms 183.155376ms 183.423367ms 183.56012ms 183.582856ms 183.633824ms 183.900549ms 184.198423ms 184.6797ms 184.929567ms 185.232352ms 185.633055ms 186.013671ms 186.172726ms 186.212045ms 188.798318ms 194.366001ms 194.393473ms 199.972693ms]
Aug 14 23:14:01.634: INFO: 50 %ile: 176.350933ms
Aug 14 23:14:01.634: INFO: 90 %ile: 183.029078ms
Aug 14 23:14:01.634: INFO: 99 %ile: 194.393473ms
Aug 14 23:14:01.634: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:14:01.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1206" for this suite.
Aug 14 23:14:17.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:14:18.080: INFO: namespace svc-latency-1206 deletion completed in 16.429715675s

• [SLOW TEST:21.227 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:14:18.081: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 23:14:18.323: INFO: Waiting up to 5m0s for pod "pod-19db395a-c1ee-4bce-ab09-0dac082d880d" in namespace "emptydir-1187" to be "success or failure"
Aug 14 23:14:18.338: INFO: Pod "pod-19db395a-c1ee-4bce-ab09-0dac082d880d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.287242ms
Aug 14 23:14:20.351: INFO: Pod "pod-19db395a-c1ee-4bce-ab09-0dac082d880d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0282973s
Aug 14 23:14:22.364: INFO: Pod "pod-19db395a-c1ee-4bce-ab09-0dac082d880d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040888262s
STEP: Saw pod success
Aug 14 23:14:22.364: INFO: Pod "pod-19db395a-c1ee-4bce-ab09-0dac082d880d" satisfied condition "success or failure"
Aug 14 23:14:22.376: INFO: Trying to get logs from node 10.195.18.184 pod pod-19db395a-c1ee-4bce-ab09-0dac082d880d container test-container: <nil>
STEP: delete the pod
Aug 14 23:14:22.459: INFO: Waiting for pod pod-19db395a-c1ee-4bce-ab09-0dac082d880d to disappear
Aug 14 23:14:22.471: INFO: Pod pod-19db395a-c1ee-4bce-ab09-0dac082d880d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:14:22.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1187" for this suite.
Aug 14 23:14:28.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:14:28.899: INFO: namespace emptydir-1187 deletion completed in 6.41227234s

• [SLOW TEST:10.819 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:14:28.900: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:15:29.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1461" for this suite.
Aug 14 23:15:53.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:15:53.581: INFO: namespace container-probe-1461 deletion completed in 24.418962028s

• [SLOW TEST:84.681 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:15:53.581: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3568
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 14 23:15:53.808: INFO: Waiting up to 5m0s for pod "pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b" in namespace "emptydir-3568" to be "success or failure"
Aug 14 23:15:53.823: INFO: Pod "pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.145585ms
Aug 14 23:15:55.836: INFO: Pod "pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027175305s
Aug 14 23:15:57.848: INFO: Pod "pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039766454s
STEP: Saw pod success
Aug 14 23:15:57.849: INFO: Pod "pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b" satisfied condition "success or failure"
Aug 14 23:15:57.861: INFO: Trying to get logs from node 10.195.18.148 pod pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b container test-container: <nil>
STEP: delete the pod
Aug 14 23:15:57.941: INFO: Waiting for pod pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b to disappear
Aug 14 23:15:57.957: INFO: Pod pod-23961f14-d0cd-4d1d-8645-a54e5e054d5b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:15:57.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3568" for this suite.
Aug 14 23:16:04.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:16:04.397: INFO: namespace emptydir-3568 deletion completed in 6.424165815s

• [SLOW TEST:10.816 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:16:04.397: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 14 23:16:04.687: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8392,SelfLink:/api/v1/namespaces/watch-8392/configmaps/e2e-watch-test-resource-version,UID:900359c3-454c-4b93-9566-ce449edd941e,ResourceVersion:44431,Generation:0,CreationTimestamp:2019-08-14 23:16:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 23:16:04.687: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8392,SelfLink:/api/v1/namespaces/watch-8392/configmaps/e2e-watch-test-resource-version,UID:900359c3-454c-4b93-9566-ce449edd941e,ResourceVersion:44432,Generation:0,CreationTimestamp:2019-08-14 23:16:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:16:04.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8392" for this suite.
Aug 14 23:16:10.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:16:11.139: INFO: namespace watch-8392 deletion completed in 6.434993808s

• [SLOW TEST:6.741 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:16:11.139: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 23:16:11.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6721'
Aug 14 23:16:11.475: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 23:16:11.475: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug 14 23:16:13.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6721'
Aug 14 23:16:13.639: INFO: stderr: ""
Aug 14 23:16:13.639: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:16:13.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6721" for this suite.
Aug 14 23:16:37.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:16:38.077: INFO: namespace kubectl-6721 deletion completed in 24.422077549s

• [SLOW TEST:26.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:16:38.078: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-598
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 14 23:16:42.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 exec pod-sharedvolume-c7bd2278-dd48-4496-9907-facddc28f60f -c busybox-main-container --namespace=emptydir-598 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 14 23:16:42.814: INFO: stderr: ""
Aug 14 23:16:42.814: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:16:42.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-598" for this suite.
Aug 14 23:16:48.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:16:49.255: INFO: namespace emptydir-598 deletion completed in 6.424808864s

• [SLOW TEST:11.178 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:16:49.256: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-5693
STEP: Creating secret with name secret-test-bccfdbb2-d861-4578-8ff6-400eb105e380
STEP: Creating a pod to test consume secrets
Aug 14 23:16:49.711: INFO: Waiting up to 5m0s for pod "pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441" in namespace "secrets-6789" to be "success or failure"
Aug 14 23:16:49.729: INFO: Pod "pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441": Phase="Pending", Reason="", readiness=false. Elapsed: 17.37767ms
Aug 14 23:16:51.741: INFO: Pod "pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029483925s
Aug 14 23:16:53.753: INFO: Pod "pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042162535s
STEP: Saw pod success
Aug 14 23:16:53.753: INFO: Pod "pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441" satisfied condition "success or failure"
Aug 14 23:16:53.766: INFO: Trying to get logs from node 10.195.18.148 pod pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 23:16:53.828: INFO: Waiting for pod pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441 to disappear
Aug 14 23:16:53.842: INFO: Pod pod-secrets-fa7d988c-a02a-48f6-afea-b8baac06d441 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:16:53.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6789" for this suite.
Aug 14 23:16:59.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:17:00.307: INFO: namespace secrets-6789 deletion completed in 6.448877646s
STEP: Destroying namespace "secret-namespace-5693" for this suite.
Aug 14 23:17:06.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:17:06.708: INFO: namespace secret-namespace-5693 deletion completed in 6.400840346s

• [SLOW TEST:17.452 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:17:06.708: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:17:09.014: INFO: Waiting up to 5m0s for pod "client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2" in namespace "pods-2505" to be "success or failure"
Aug 14 23:17:09.026: INFO: Pod "client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385364ms
Aug 14 23:17:11.039: INFO: Pod "client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025894528s
Aug 14 23:17:13.053: INFO: Pod "client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039623459s
STEP: Saw pod success
Aug 14 23:17:13.053: INFO: Pod "client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2" satisfied condition "success or failure"
Aug 14 23:17:13.065: INFO: Trying to get logs from node 10.195.18.148 pod client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2 container env3cont: <nil>
STEP: delete the pod
Aug 14 23:17:13.135: INFO: Waiting for pod client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2 to disappear
Aug 14 23:17:13.147: INFO: Pod client-envvars-1f8ba444-8350-4af4-a053-d834c98b3fc2 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:17:13.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2505" for this suite.
Aug 14 23:17:55.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:17:55.670: INFO: namespace pods-2505 deletion completed in 42.506207333s

• [SLOW TEST:48.962 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:17:55.670: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 23:18:02.023: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 23:18:02.036: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 23:18:04.036: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 23:18:04.052: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 23:18:06.036: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 23:18:06.053: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:18:06.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2978" for this suite.
Aug 14 23:18:30.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:18:30.582: INFO: namespace container-lifecycle-hook-2978 deletion completed in 24.480748871s

• [SLOW TEST:34.912 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:18:30.582: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1437
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:18:30.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1437" for this suite.
Aug 14 23:18:54.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:18:55.283: INFO: namespace kubelet-test-1437 deletion completed in 24.422771437s

• [SLOW TEST:24.700 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:18:55.283: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2727, will wait for the garbage collector to delete the pods
Aug 14 23:18:59.608: INFO: Deleting Job.batch foo took: 26.13434ms
Aug 14 23:18:59.710: INFO: Terminating Job.batch foo pods took: 101.803258ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:19:32.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2727" for this suite.
Aug 14 23:19:38.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:19:38.585: INFO: namespace job-2727 deletion completed in 6.433259411s

• [SLOW TEST:43.302 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:19:38.585: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5821
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-22d3f7fa-7ece-4f2c-8760-62eeb2a3f555
STEP: Creating a pod to test consume secrets
Aug 14 23:19:38.827: INFO: Waiting up to 5m0s for pod "pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0" in namespace "secrets-5821" to be "success or failure"
Aug 14 23:19:38.842: INFO: Pod "pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.926826ms
Aug 14 23:19:40.855: INFO: Pod "pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027589992s
STEP: Saw pod success
Aug 14 23:19:40.855: INFO: Pod "pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0" satisfied condition "success or failure"
Aug 14 23:19:40.877: INFO: Trying to get logs from node 10.195.18.146 pod pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 23:19:40.947: INFO: Waiting for pod pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0 to disappear
Aug 14 23:19:40.964: INFO: Pod pod-secrets-dd203acb-3642-4acc-ad65-de33074f08c0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:19:40.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5821" for this suite.
Aug 14 23:19:47.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:19:47.409: INFO: namespace secrets-5821 deletion completed in 6.428597095s

• [SLOW TEST:8.824 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:19:47.410: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-x8ft
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 23:19:47.678: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-x8ft" in namespace "subpath-3373" to be "success or failure"
Aug 14 23:19:47.693: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Pending", Reason="", readiness=false. Elapsed: 15.846071ms
Aug 14 23:19:49.706: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 2.028150636s
Aug 14 23:19:51.718: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 4.040656457s
Aug 14 23:19:53.732: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 6.054390073s
Aug 14 23:19:55.744: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 8.066842302s
Aug 14 23:19:57.758: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 10.080795244s
Aug 14 23:19:59.771: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 12.093722181s
Aug 14 23:20:01.785: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 14.107373538s
Aug 14 23:20:03.801: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 16.123017501s
Aug 14 23:20:05.814: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 18.136227317s
Aug 14 23:20:07.827: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Running", Reason="", readiness=true. Elapsed: 20.149097581s
Aug 14 23:20:09.840: INFO: Pod "pod-subpath-test-secret-x8ft": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.161988847s
STEP: Saw pod success
Aug 14 23:20:09.840: INFO: Pod "pod-subpath-test-secret-x8ft" satisfied condition "success or failure"
Aug 14 23:20:09.861: INFO: Trying to get logs from node 10.195.18.146 pod pod-subpath-test-secret-x8ft container test-container-subpath-secret-x8ft: <nil>
STEP: delete the pod
Aug 14 23:20:09.922: INFO: Waiting for pod pod-subpath-test-secret-x8ft to disappear
Aug 14 23:20:09.938: INFO: Pod pod-subpath-test-secret-x8ft no longer exists
STEP: Deleting pod pod-subpath-test-secret-x8ft
Aug 14 23:20:09.938: INFO: Deleting pod "pod-subpath-test-secret-x8ft" in namespace "subpath-3373"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:20:09.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3373" for this suite.
Aug 14 23:20:16.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:20:16.440: INFO: namespace subpath-3373 deletion completed in 6.471383947s

• [SLOW TEST:29.030 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:20:16.441: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 23:20:16.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 version'
Aug 14 23:20:16.767: INFO: stderr: ""
Aug 14 23:20:16.767: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2+IKS\", GitCommit:\"9ed1f87be54287b97e312ccce3920f309ba81616\", GitTreeState:\"clean\", BuildDate:\"2019-08-07T12:17:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:20:16.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1428" for this suite.
Aug 14 23:20:22.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:20:23.213: INFO: namespace kubectl-1428 deletion completed in 6.428409333s

• [SLOW TEST:6.772 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:20:23.214: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug 14 23:20:24.227: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 23:20:24.227778      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:20:24.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2559" for this suite.
Aug 14 23:20:30.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:20:30.668: INFO: namespace gc-2559 deletion completed in 6.425312421s

• [SLOW TEST:7.455 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:20:30.668: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 14 23:20:30.884: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-037535427 proxy --unix-socket=/tmp/kubectl-proxy-unix082289114/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:20:30.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3843" for this suite.
Aug 14 23:20:37.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:20:37.375: INFO: namespace kubectl-3843 deletion completed in 6.402043326s

• [SLOW TEST:6.706 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:20:37.375: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-277
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 23:20:37.585: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 23:20:59.903: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.32.203:8080/dial?request=hostName&protocol=http&host=172.30.32.249&port=8080&tries=1'] Namespace:pod-network-test-277 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:20:59.903: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:21:00.240: INFO: Waiting for endpoints: map[]
Aug 14 23:21:00.252: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.32.203:8080/dial?request=hostName&protocol=http&host=172.30.168.108&port=8080&tries=1'] Namespace:pod-network-test-277 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:21:00.252: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:21:00.617: INFO: Waiting for endpoints: map[]
Aug 14 23:21:00.635: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.32.203:8080/dial?request=hostName&protocol=http&host=172.30.76.100&port=8080&tries=1'] Namespace:pod-network-test-277 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 23:21:00.635: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
Aug 14 23:21:00.953: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:21:00.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-277" for this suite.
Aug 14 23:21:25.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:21:25.449: INFO: namespace pod-network-test-277 deletion completed in 24.478290091s

• [SLOW TEST:48.074 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 23:21:25.449: INFO: >>> kubeConfig: /tmp/kubeconfig-037535427
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug 14 23:21:25.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 create -f - --namespace=kubectl-8139'
Aug 14 23:21:25.967: INFO: stderr: ""
Aug 14 23:21:25.967: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 14 23:21:26.981: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:21:26.981: INFO: Found 0 / 1
Aug 14 23:21:27.980: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:21:27.980: INFO: Found 1 / 1
Aug 14 23:21:27.980: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 23:21:27.992: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 23:21:27.992: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 14 23:21:27.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 logs redis-master-tdx27 redis-master --namespace=kubectl-8139'
Aug 14 23:21:28.169: INFO: stderr: ""
Aug 14 23:21:28.169: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 23:21:27.329 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 23:21:27.329 # Server started, Redis version 3.2.12\n1:M 14 Aug 23:21:27.329 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 23:21:27.329 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 14 23:21:28.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 log redis-master-tdx27 redis-master --namespace=kubectl-8139 --tail=1'
Aug 14 23:21:28.314: INFO: stderr: ""
Aug 14 23:21:28.314: INFO: stdout: "1:M 14 Aug 23:21:27.329 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 14 23:21:28.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 log redis-master-tdx27 redis-master --namespace=kubectl-8139 --limit-bytes=1'
Aug 14 23:21:28.489: INFO: stderr: ""
Aug 14 23:21:28.489: INFO: stdout: " "
STEP: exposing timestamps
Aug 14 23:21:28.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 log redis-master-tdx27 redis-master --namespace=kubectl-8139 --tail=1 --timestamps'
Aug 14 23:21:28.634: INFO: stderr: ""
Aug 14 23:21:28.634: INFO: stdout: "2019-08-14T23:21:27.329772999Z 1:M 14 Aug 23:21:27.329 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 14 23:21:31.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 log redis-master-tdx27 redis-master --namespace=kubectl-8139 --since=1s'
Aug 14 23:21:31.282: INFO: stderr: ""
Aug 14 23:21:31.282: INFO: stdout: ""
Aug 14 23:21:31.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 log redis-master-tdx27 redis-master --namespace=kubectl-8139 --since=24h'
Aug 14 23:21:31.426: INFO: stderr: ""
Aug 14 23:21:31.426: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 23:21:27.329 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 23:21:27.329 # Server started, Redis version 3.2.12\n1:M 14 Aug 23:21:27.329 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 23:21:27.329 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug 14 23:21:31.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 delete --grace-period=0 --force -f - --namespace=kubectl-8139'
Aug 14 23:21:31.580: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 23:21:31.580: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 14 23:21:31.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get rc,svc -l name=nginx --no-headers --namespace=kubectl-8139'
Aug 14 23:21:31.707: INFO: stderr: "No resources found.\n"
Aug 14 23:21:31.707: INFO: stdout: ""
Aug 14 23:21:31.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-037535427 get pods -l name=nginx --namespace=kubectl-8139 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 23:21:31.832: INFO: stderr: ""
Aug 14 23:21:31.832: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 23:21:31.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8139" for this suite.
Aug 14 23:21:55.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 23:21:56.301: INFO: namespace kubectl-8139 deletion completed in 24.451321149s

• [SLOW TEST:30.852 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSAug 14 23:21:56.301: INFO: Running AfterSuite actions on all nodes
Aug 14 23:21:56.301: INFO: Running AfterSuite actions on node 1
Aug 14 23:21:56.301: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6085.623 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h41m27.109894054s
Test Suite Passed
