I0526 15:34:36.747141      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-131493333
I0526 15:34:36.747324      16 e2e.go:243] Starting e2e run "f315a9d6-cd36-43db-982d-be002eec603a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1590507275 - Will randomize all specs
Will run 215 of 4413 specs

May 26 15:34:36.981: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 15:34:36.984: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 26 15:34:37.040: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 26 15:34:37.122: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 26 15:34:37.122: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
May 26 15:34:37.122: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 26 15:34:37.165: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May 26 15:34:37.165: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
May 26 15:34:37.165: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
May 26 15:34:37.165: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
May 26 15:34:37.165: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
May 26 15:34:37.165: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
May 26 15:34:37.165: INFO: e2e test version: v1.15.12
May 26 15:34:37.170: INFO: kube-apiserver version: v1.15.12+IKS
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:34:37.170: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
May 26 15:34:37.308: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 26 15:34:37.364: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-cd0f1382-aaf1-45a6-8497-3a6f45ab16db
STEP: Creating a pod to test consume secrets
May 26 15:34:37.584: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22" in namespace "projected-8032" to be "success or failure"
May 26 15:34:37.601: INFO: Pod "pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22": Phase="Pending", Reason="", readiness=false. Elapsed: 17.031547ms
May 26 15:34:39.613: INFO: Pod "pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029231412s
May 26 15:34:41.624: INFO: Pod "pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040325879s
STEP: Saw pod success
May 26 15:34:41.624: INFO: Pod "pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22" satisfied condition "success or failure"
May 26 15:34:41.640: INFO: Trying to get logs from node 10.113.231.185 pod pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 26 15:34:41.728: INFO: Waiting for pod pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22 to disappear
May 26 15:34:41.747: INFO: Pod pod-projected-secrets-f436ce7f-0fc9-4017-b383-110d59a3fd22 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:34:41.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8032" for this suite.
May 26 15:34:49.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:34:50.317: INFO: namespace projected-8032 deletion completed in 8.545283017s

• [SLOW TEST:13.147 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:34:50.320: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:34:55.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4404" for this suite.
May 26 15:35:19.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:35:20.353: INFO: namespace replication-controller-4404 deletion completed in 24.587565297s

• [SLOW TEST:30.033 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:35:20.354: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 26 15:35:27.716: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:35:28.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5260" for this suite.
May 26 15:35:52.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:35:53.331: INFO: namespace replicaset-5260 deletion completed in 24.549202303s

• [SLOW TEST:32.977 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:35:53.331: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 26 15:35:53.585: INFO: Waiting up to 5m0s for pod "pod-44ba4139-a0ad-46e0-95b1-4c868c675c90" in namespace "emptydir-1849" to be "success or failure"
May 26 15:35:53.596: INFO: Pod "pod-44ba4139-a0ad-46e0-95b1-4c868c675c90": Phase="Pending", Reason="", readiness=false. Elapsed: 11.125425ms
May 26 15:35:55.608: INFO: Pod "pod-44ba4139-a0ad-46e0-95b1-4c868c675c90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023121037s
May 26 15:35:57.620: INFO: Pod "pod-44ba4139-a0ad-46e0-95b1-4c868c675c90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034890886s
STEP: Saw pod success
May 26 15:35:57.620: INFO: Pod "pod-44ba4139-a0ad-46e0-95b1-4c868c675c90" satisfied condition "success or failure"
May 26 15:35:57.631: INFO: Trying to get logs from node 10.113.231.133 pod pod-44ba4139-a0ad-46e0-95b1-4c868c675c90 container test-container: <nil>
STEP: delete the pod
May 26 15:35:57.740: INFO: Waiting for pod pod-44ba4139-a0ad-46e0-95b1-4c868c675c90 to disappear
May 26 15:35:57.753: INFO: Pod pod-44ba4139-a0ad-46e0-95b1-4c868c675c90 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:35:57.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1849" for this suite.
May 26 15:36:05.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:36:06.440: INFO: namespace emptydir-1849 deletion completed in 8.606701438s

• [SLOW TEST:13.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:36:06.440: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-18
STEP: Creating secret with name secret-test-6987c862-4d95-40a8-ac75-aff1ebcf8830
STEP: Creating a pod to test consume secrets
May 26 15:36:06.997: INFO: Waiting up to 5m0s for pod "pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99" in namespace "secrets-3488" to be "success or failure"
May 26 15:36:07.007: INFO: Pod "pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.183498ms
May 26 15:36:09.018: INFO: Pod "pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020813772s
May 26 15:36:11.030: INFO: Pod "pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032935569s
STEP: Saw pod success
May 26 15:36:11.030: INFO: Pod "pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99" satisfied condition "success or failure"
May 26 15:36:11.042: INFO: Trying to get logs from node 10.113.231.185 pod pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99 container secret-volume-test: <nil>
STEP: delete the pod
May 26 15:36:11.113: INFO: Waiting for pod pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99 to disappear
May 26 15:36:11.125: INFO: Pod pod-secrets-ed439e9c-1b95-444c-a0ac-fa25b71ced99 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:36:11.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3488" for this suite.
May 26 15:36:19.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:36:19.639: INFO: namespace secrets-3488 deletion completed in 8.496508683s
STEP: Destroying namespace "secret-namespace-18" for this suite.
May 26 15:36:27.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:36:28.132: INFO: namespace secret-namespace-18 deletion completed in 8.493613124s

• [SLOW TEST:21.693 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:36:28.136: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:36:33.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8446" for this suite.
May 26 15:36:42.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:36:42.609: INFO: namespace watch-8446 deletion completed in 8.640170301s

• [SLOW TEST:14.474 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:36:42.614: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
May 26 15:36:42.856: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 26 15:36:42.886: INFO: Waiting for terminating namespaces to be deleted...
May 26 15:36:42.901: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.133 before test
May 26 15:36:42.990: INFO: sonobuoy from sonobuoy started at 2020-05-26 15:33:56 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 26 15:36:42.991: INFO: ibm-keepalived-watcher-p8dn5 from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 15:36:42.991: INFO: calico-node-qw94x from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container calico-node ready: true, restart count 0
May 26 15:36:42.991: INFO: coredns-c6797c986-wbcgx from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container coredns ready: true, restart count 0
May 26 15:36:42.991: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-97kmg from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 15:36:42.991: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 15:36:42.991: INFO: vpn-bd4d5cff7-mtlkg from kube-system started at 2020-05-26 14:15:51 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container vpn ready: true, restart count 0
May 26 15:36:42.991: INFO: ibm-master-proxy-static-10.113.231.133 from kube-system started at 2020-05-26 13:52:25 +0000 UTC (2 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 15:36:42.991: INFO: 	Container pause ready: true, restart count 0
May 26 15:36:42.991: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-05-26 13:55:18 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 26 15:36:42.991: INFO: ibm-file-plugin-5bcd9c888c-s8l25 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 26 15:36:42.991: INFO: metrics-server-875894b87-5gbms from kube-system started at 2020-05-26 13:52:56 +0000 UTC (2 container statuses recorded)
May 26 15:36:42.991: INFO: 	Container metrics-server ready: true, restart count 0
May 26 15:36:42.991: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 26 15:36:42.991: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.144 before test
May 26 15:36:43.049: INFO: ibm-master-proxy-static-10.113.231.144 from kube-system started at 2020-05-26 13:52:21 +0000 UTC (2 container statuses recorded)
May 26 15:36:43.050: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 15:36:43.050: INFO: 	Container pause ready: true, restart count 0
May 26 15:36:43.050: INFO: ibm-keepalived-watcher-wvnv5 from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.050: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 15:36:43.050: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-5s4gm from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 15:36:43.050: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 15:36:43.050: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 15:36:43.050: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 15:36:43.050: INFO: 	Container nginx-ingress ready: true, restart count 0
May 26 15:36:43.050: INFO: ibm-storage-watcher-7d98f4ccfc-kkghg from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.050: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 26 15:36:43.050: INFO: kubernetes-dashboard-656d9457bf-xnzp4 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.050: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 26 15:36:43.050: INFO: calico-kube-controllers-b449456b9-8m86m from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.051: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 26 15:36:43.051: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-w7w2z from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.051: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 15:36:43.051: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-zssmt from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 15:36:43.051: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 15:36:43.051: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 15:36:43.051: INFO: calico-node-lz98l from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.051: INFO: 	Container calico-node ready: true, restart count 0
May 26 15:36:43.051: INFO: sonobuoy-e2e-job-317cc8361edf4b82 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 15:36:43.051: INFO: 	Container e2e ready: true, restart count 0
May 26 15:36:43.051: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 15:36:43.051: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.185 before test
May 26 15:36:43.163: INFO: ibm-keepalived-watcher-fgt8t from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 15:36:43.163: INFO: coredns-autoscaler-65bc7cb8b5-28zmr from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container autoscaler ready: true, restart count 0
May 26 15:36:43.163: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-l9676 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 15:36:43.163: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 15:36:43.163: INFO: ibm-master-proxy-static-10.113.231.185 from kube-system started at 2020-05-26 13:52:12 +0000 UTC (2 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 15:36:43.163: INFO: 	Container pause ready: true, restart count 0
May 26 15:36:43.163: INFO: coredns-c6797c986-4rh25 from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container coredns ready: true, restart count 0
May 26 15:36:43.163: INFO: calico-node-5pk9b from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container calico-node ready: true, restart count 0
May 26 15:36:43.163: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-rmth7 from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 15:36:43.163: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-jzhkr from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 15:36:43.163: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 15:36:43.163: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 15:36:43.163: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 15:36:43.163: INFO: 	Container nginx-ingress ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.113.231.133
STEP: verifying the node has the label node 10.113.231.144
STEP: verifying the node has the label node 10.113.231.185
May 26 15:36:43.326: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod ibm-cloud-provider-ip-159-8-185-125-5df5868f74-rmth7 requesting resource cpu=5m on Node 10.113.231.185
May 26 15:36:43.326: INFO: Pod ibm-cloud-provider-ip-159-8-185-125-5df5868f74-w7w2z requesting resource cpu=5m on Node 10.113.231.144
May 26 15:36:43.326: INFO: Pod calico-kube-controllers-b449456b9-8m86m requesting resource cpu=10m on Node 10.113.231.144
May 26 15:36:43.326: INFO: Pod calico-node-5pk9b requesting resource cpu=250m on Node 10.113.231.185
May 26 15:36:43.326: INFO: Pod calico-node-lz98l requesting resource cpu=250m on Node 10.113.231.144
May 26 15:36:43.326: INFO: Pod calico-node-qw94x requesting resource cpu=250m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod coredns-autoscaler-65bc7cb8b5-28zmr requesting resource cpu=20m on Node 10.113.231.185
May 26 15:36:43.326: INFO: Pod coredns-c6797c986-4rh25 requesting resource cpu=100m on Node 10.113.231.185
May 26 15:36:43.326: INFO: Pod coredns-c6797c986-wbcgx requesting resource cpu=100m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod ibm-file-plugin-5bcd9c888c-s8l25 requesting resource cpu=50m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod ibm-keepalived-watcher-fgt8t requesting resource cpu=5m on Node 10.113.231.185
May 26 15:36:43.326: INFO: Pod ibm-keepalived-watcher-p8dn5 requesting resource cpu=5m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod ibm-keepalived-watcher-wvnv5 requesting resource cpu=5m on Node 10.113.231.144
May 26 15:36:43.326: INFO: Pod ibm-master-proxy-static-10.113.231.133 requesting resource cpu=25m on Node 10.113.231.133
May 26 15:36:43.326: INFO: Pod ibm-master-proxy-static-10.113.231.144 requesting resource cpu=25m on Node 10.113.231.144
May 26 15:36:43.326: INFO: Pod ibm-master-proxy-static-10.113.231.185 requesting resource cpu=25m on Node 10.113.231.185
May 26 15:36:43.327: INFO: Pod ibm-storage-watcher-7d98f4ccfc-kkghg requesting resource cpu=50m on Node 10.113.231.144
May 26 15:36:43.327: INFO: Pod kubernetes-dashboard-656d9457bf-xnzp4 requesting resource cpu=50m on Node 10.113.231.144
May 26 15:36:43.327: INFO: Pod metrics-server-875894b87-5gbms requesting resource cpu=121m on Node 10.113.231.133
May 26 15:36:43.327: INFO: Pod public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-5s4gm requesting resource cpu=10m on Node 10.113.231.144
May 26 15:36:43.327: INFO: Pod public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-jzhkr requesting resource cpu=10m on Node 10.113.231.185
May 26 15:36:43.327: INFO: Pod vpn-bd4d5cff7-mtlkg requesting resource cpu=5m on Node 10.113.231.133
May 26 15:36:43.327: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.113.231.133
May 26 15:36:43.327: INFO: Pod sonobuoy-e2e-job-317cc8361edf4b82 requesting resource cpu=0m on Node 10.113.231.144
May 26 15:36:43.327: INFO: Pod sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-97kmg requesting resource cpu=0m on Node 10.113.231.133
May 26 15:36:43.327: INFO: Pod sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-l9676 requesting resource cpu=0m on Node 10.113.231.185
May 26 15:36:43.327: INFO: Pod sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-zssmt requesting resource cpu=0m on Node 10.113.231.144
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd.16129e0e791f7a75], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9951/filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd to 10.113.231.144]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd.16129e0eb839389c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd.16129e0ebb64b2c9], Reason = [Created], Message = [Created container filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd.16129e0ec37ce06a], Reason = [Started], Message = [Started container filler-pod-90a2691b-89f0-4b5d-b5f3-992355016cfd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985.16129e0e769d6d53], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9951/filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985 to 10.113.231.185]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985.16129e0ebc09e85a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985.16129e0ec0c2d71f], Reason = [Created], Message = [Created container filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985.16129e0ecb646942], Reason = [Started], Message = [Started container filler-pod-98f771d4-0b0f-4fe4-a868-99b2a6236985]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323.16129e0e77e344fc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9951/filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323 to 10.113.231.133]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323.16129e0eba513b28], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323.16129e0ebe3fc0bd], Reason = [Created], Message = [Created container filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323.16129e0ec7538d77], Reason = [Started], Message = [Started container filler-pod-e6966be1-f576-4daa-b4d7-b9cd7473a323]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16129e0f6d712281], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.113.231.133
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.113.231.144
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.113.231.185
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:36:48.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9951" for this suite.
May 26 15:36:56.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:36:57.500: INFO: namespace sched-pred-9951 deletion completed in 8.796305064s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:14.886 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:36:57.501: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
May 26 15:37:02.962: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1336 pod-service-account-522fe601-0829-4ae1-a4f3-cdb8aa8e9d4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 26 15:37:03.534: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1336 pod-service-account-522fe601-0829-4ae1-a4f3-cdb8aa8e9d4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 26 15:37:03.921: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1336 pod-service-account-522fe601-0829-4ae1-a4f3-cdb8aa8e9d4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:37:04.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1336" for this suite.
May 26 15:37:12.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:37:12.898: INFO: namespace svcaccounts-1336 deletion completed in 8.52650903s

• [SLOW TEST:15.398 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:37:12.899: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9785
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e6802093-3c07-445b-ab3d-1d3c13bfd192
STEP: Creating a pod to test consume configMaps
May 26 15:37:13.183: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942" in namespace "projected-9785" to be "success or failure"
May 26 15:37:13.193: INFO: Pod "pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942": Phase="Pending", Reason="", readiness=false. Elapsed: 9.584843ms
May 26 15:37:15.204: INFO: Pod "pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020550245s
May 26 15:37:17.219: INFO: Pod "pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03556847s
STEP: Saw pod success
May 26 15:37:17.219: INFO: Pod "pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942" satisfied condition "success or failure"
May 26 15:37:17.230: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 15:37:17.306: INFO: Waiting for pod pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942 to disappear
May 26 15:37:17.315: INFO: Pod pod-projected-configmaps-d4abcbbc-7bca-4170-8d57-1e9e947dc942 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:37:17.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9785" for this suite.
May 26 15:37:25.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:37:25.842: INFO: namespace projected-9785 deletion completed in 8.511368851s

• [SLOW TEST:12.943 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:37:25.843: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-a1038f0e-02d9-42e9-be79-ab6ceb8618e3
STEP: Creating a pod to test consume configMaps
May 26 15:37:26.121: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187" in namespace "configmap-2066" to be "success or failure"
May 26 15:37:26.131: INFO: Pod "pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187": Phase="Pending", Reason="", readiness=false. Elapsed: 10.05829ms
May 26 15:37:28.145: INFO: Pod "pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02417327s
May 26 15:37:30.158: INFO: Pod "pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037076725s
STEP: Saw pod success
May 26 15:37:30.158: INFO: Pod "pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187" satisfied condition "success or failure"
May 26 15:37:30.171: INFO: Trying to get logs from node 10.113.231.144 pod pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 15:37:30.243: INFO: Waiting for pod pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187 to disappear
May 26 15:37:30.257: INFO: Pod pod-configmaps-ae3cf40b-05f0-4eb7-8c85-37c759b85187 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:37:30.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2066" for this suite.
May 26 15:37:38.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:37:38.789: INFO: namespace configmap-2066 deletion completed in 8.5086595s

• [SLOW TEST:12.946 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:37:38.790: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7935
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-61263a5c-3e90-43dc-9b5c-a0bd14fcb774
STEP: Creating a pod to test consume configMaps
May 26 15:37:39.077: INFO: Waiting up to 5m0s for pod "pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a" in namespace "configmap-7935" to be "success or failure"
May 26 15:37:39.087: INFO: Pod "pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.196298ms
May 26 15:37:41.099: INFO: Pod "pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021648706s
May 26 15:37:43.110: INFO: Pod "pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032970587s
STEP: Saw pod success
May 26 15:37:43.110: INFO: Pod "pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a" satisfied condition "success or failure"
May 26 15:37:43.123: INFO: Trying to get logs from node 10.113.231.185 pod pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a container configmap-volume-test: <nil>
STEP: delete the pod
May 26 15:37:43.204: INFO: Waiting for pod pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a to disappear
May 26 15:37:43.215: INFO: Pod pod-configmaps-e2aeb125-e5cf-4374-8e4a-1f42cb66779a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:37:43.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7935" for this suite.
May 26 15:37:51.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:37:51.798: INFO: namespace configmap-7935 deletion completed in 8.557825065s

• [SLOW TEST:13.009 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:37:51.799: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6606
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
May 26 15:37:52.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-6606'
May 26 15:37:52.440: INFO: stderr: ""
May 26 15:37:52.440: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 15:37:52.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6606'
May 26 15:37:52.614: INFO: stderr: ""
May 26 15:37:52.614: INFO: stdout: "update-demo-nautilus-g4kkk update-demo-nautilus-x9mhv "
May 26 15:37:52.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-g4kkk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6606'
May 26 15:37:52.759: INFO: stderr: ""
May 26 15:37:52.759: INFO: stdout: ""
May 26 15:37:52.759: INFO: update-demo-nautilus-g4kkk is created but not running
May 26 15:37:57.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6606'
May 26 15:37:57.902: INFO: stderr: ""
May 26 15:37:57.902: INFO: stdout: "update-demo-nautilus-g4kkk update-demo-nautilus-x9mhv "
May 26 15:37:57.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-g4kkk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6606'
May 26 15:37:58.030: INFO: stderr: ""
May 26 15:37:58.030: INFO: stdout: "true"
May 26 15:37:58.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-g4kkk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6606'
May 26 15:37:58.164: INFO: stderr: ""
May 26 15:37:58.164: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 15:37:58.164: INFO: validating pod update-demo-nautilus-g4kkk
May 26 15:37:58.193: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 15:37:58.193: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 15:37:58.193: INFO: update-demo-nautilus-g4kkk is verified up and running
May 26 15:37:58.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-x9mhv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6606'
May 26 15:37:58.722: INFO: stderr: ""
May 26 15:37:58.722: INFO: stdout: "true"
May 26 15:37:58.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-x9mhv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6606'
May 26 15:37:58.869: INFO: stderr: ""
May 26 15:37:58.869: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 15:37:58.869: INFO: validating pod update-demo-nautilus-x9mhv
May 26 15:37:58.900: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 15:37:58.900: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 15:37:58.900: INFO: update-demo-nautilus-x9mhv is verified up and running
STEP: using delete to clean up resources
May 26 15:37:58.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-6606'
May 26 15:37:59.075: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 15:37:59.075: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 26 15:37:59.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6606'
May 26 15:37:59.263: INFO: stderr: "No resources found.\n"
May 26 15:37:59.263: INFO: stdout: ""
May 26 15:37:59.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -l name=update-demo --namespace=kubectl-6606 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 26 15:37:59.406: INFO: stderr: ""
May 26 15:37:59.406: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:37:59.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6606" for this suite.
May 26 15:38:07.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:38:07.934: INFO: namespace kubectl-6606 deletion completed in 8.50799186s

• [SLOW TEST:16.135 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:38:07.935: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
May 26 15:38:08.211: INFO: Waiting up to 5m0s for pod "var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b" in namespace "var-expansion-2302" to be "success or failure"
May 26 15:38:08.229: INFO: Pod "var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.505164ms
May 26 15:38:10.245: INFO: Pod "var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033297756s
May 26 15:38:12.262: INFO: Pod "var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050739349s
STEP: Saw pod success
May 26 15:38:12.262: INFO: Pod "var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b" satisfied condition "success or failure"
May 26 15:38:12.274: INFO: Trying to get logs from node 10.113.231.185 pod var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b container dapi-container: <nil>
STEP: delete the pod
May 26 15:38:12.353: INFO: Waiting for pod var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b to disappear
May 26 15:38:12.368: INFO: Pod var-expansion-0c3922f9-dfe5-45ac-bbe7-69b642cf3e6b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:38:12.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2302" for this suite.
May 26 15:38:20.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:38:20.885: INFO: namespace var-expansion-2302 deletion completed in 8.500558095s

• [SLOW TEST:12.950 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:38:20.886: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9162
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 26 15:38:21.146: INFO: Waiting up to 5m0s for pod "pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19" in namespace "emptydir-9162" to be "success or failure"
May 26 15:38:21.156: INFO: Pod "pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19": Phase="Pending", Reason="", readiness=false. Elapsed: 10.519305ms
May 26 15:38:23.170: INFO: Pod "pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023929953s
STEP: Saw pod success
May 26 15:38:23.170: INFO: Pod "pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19" satisfied condition "success or failure"
May 26 15:38:23.180: INFO: Trying to get logs from node 10.113.231.133 pod pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19 container test-container: <nil>
STEP: delete the pod
May 26 15:38:23.266: INFO: Waiting for pod pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19 to disappear
May 26 15:38:23.277: INFO: Pod pod-248e01fa-b5a9-4d12-8ab5-6786b488ec19 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:38:23.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9162" for this suite.
May 26 15:38:29.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:38:29.837: INFO: namespace emptydir-9162 deletion completed in 6.541067851s

• [SLOW TEST:8.951 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:38:29.838: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2689
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
May 26 15:38:30.122: INFO: Waiting up to 5m0s for pod "pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d" in namespace "emptydir-2689" to be "success or failure"
May 26 15:38:30.133: INFO: Pod "pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.976135ms
May 26 15:38:32.144: INFO: Pod "pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021779625s
May 26 15:38:34.155: INFO: Pod "pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033559277s
STEP: Saw pod success
May 26 15:38:34.155: INFO: Pod "pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d" satisfied condition "success or failure"
May 26 15:38:34.166: INFO: Trying to get logs from node 10.113.231.144 pod pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d container test-container: <nil>
STEP: delete the pod
May 26 15:38:34.249: INFO: Waiting for pod pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d to disappear
May 26 15:38:34.262: INFO: Pod pod-cc40e43e-52c8-496a-bd17-bf2c52cc4c5d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:38:34.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2689" for this suite.
May 26 15:38:42.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:38:42.857: INFO: namespace emptydir-2689 deletion completed in 8.575921008s

• [SLOW TEST:13.019 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:38:42.858: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-mhrg
STEP: Creating a pod to test atomic-volume-subpath
May 26 15:38:43.210: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mhrg" in namespace "subpath-8497" to be "success or failure"
May 26 15:38:43.222: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Pending", Reason="", readiness=false. Elapsed: 11.313389ms
May 26 15:38:45.235: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024851798s
May 26 15:38:47.247: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 4.03634318s
May 26 15:38:49.260: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 6.049738828s
May 26 15:38:51.273: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 8.062624728s
May 26 15:38:53.287: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 10.076139267s
May 26 15:38:55.298: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 12.08775365s
May 26 15:38:57.310: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 14.099294584s
May 26 15:38:59.321: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 16.110405557s
May 26 15:39:01.339: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 18.128908777s
May 26 15:39:03.351: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 20.140461818s
May 26 15:39:05.371: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Running", Reason="", readiness=true. Elapsed: 22.160650781s
May 26 15:39:07.385: INFO: Pod "pod-subpath-test-downwardapi-mhrg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.174863376s
STEP: Saw pod success
May 26 15:39:07.385: INFO: Pod "pod-subpath-test-downwardapi-mhrg" satisfied condition "success or failure"
May 26 15:39:07.397: INFO: Trying to get logs from node 10.113.231.185 pod pod-subpath-test-downwardapi-mhrg container test-container-subpath-downwardapi-mhrg: <nil>
STEP: delete the pod
May 26 15:39:07.472: INFO: Waiting for pod pod-subpath-test-downwardapi-mhrg to disappear
May 26 15:39:07.483: INFO: Pod pod-subpath-test-downwardapi-mhrg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mhrg
May 26 15:39:07.483: INFO: Deleting pod "pod-subpath-test-downwardapi-mhrg" in namespace "subpath-8497"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:39:07.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8497" for this suite.
May 26 15:39:15.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:39:16.013: INFO: namespace subpath-8497 deletion completed in 8.502395431s

• [SLOW TEST:33.155 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:39:16.014: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
May 26 15:39:16.283: INFO: Waiting up to 5m0s for pod "downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b" in namespace "downward-api-3331" to be "success or failure"
May 26 15:39:16.295: INFO: Pod "downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.702903ms
May 26 15:39:18.308: INFO: Pod "downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024875182s
May 26 15:39:20.321: INFO: Pod "downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037436061s
STEP: Saw pod success
May 26 15:39:20.321: INFO: Pod "downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b" satisfied condition "success or failure"
May 26 15:39:20.336: INFO: Trying to get logs from node 10.113.231.133 pod downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b container dapi-container: <nil>
STEP: delete the pod
May 26 15:39:20.407: INFO: Waiting for pod downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b to disappear
May 26 15:39:20.420: INFO: Pod downward-api-223bb3c8-7c57-4dcd-9549-be21335d139b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:39:20.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3331" for this suite.
May 26 15:39:28.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:39:28.977: INFO: namespace downward-api-3331 deletion completed in 8.538357177s

• [SLOW TEST:12.963 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:39:28.977: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-17cd1543-e6ce-41cc-bb81-cf88b843ccc7
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:39:29.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5607" for this suite.
May 26 15:39:35.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:39:36.027: INFO: namespace secrets-5607 deletion completed in 6.526212359s

• [SLOW TEST:7.050 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:39:36.028: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1c7cd682-ba99-46ac-885f-9f6c39421977
STEP: Creating a pod to test consume secrets
May 26 15:39:36.334: INFO: Waiting up to 5m0s for pod "pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346" in namespace "secrets-5819" to be "success or failure"
May 26 15:39:36.346: INFO: Pod "pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346": Phase="Pending", Reason="", readiness=false. Elapsed: 12.048809ms
May 26 15:39:38.358: INFO: Pod "pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024633718s
May 26 15:39:40.373: INFO: Pod "pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03894774s
STEP: Saw pod success
May 26 15:39:40.373: INFO: Pod "pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346" satisfied condition "success or failure"
May 26 15:39:40.391: INFO: Trying to get logs from node 10.113.231.144 pod pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346 container secret-volume-test: <nil>
STEP: delete the pod
May 26 15:39:40.494: INFO: Waiting for pod pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346 to disappear
May 26 15:39:40.506: INFO: Pod pod-secrets-320a8b02-0762-4efc-8b96-631cbcee7346 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:39:40.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5819" for this suite.
May 26 15:39:48.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:39:49.036: INFO: namespace secrets-5819 deletion completed in 8.512625395s

• [SLOW TEST:13.008 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:39:49.044: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-327affe2-37b2-4a4c-8337-d90a04217695 in namespace container-probe-426
May 26 15:39:53.334: INFO: Started pod test-webserver-327affe2-37b2-4a4c-8337-d90a04217695 in namespace container-probe-426
STEP: checking the pod's current state and verifying that restartCount is present
May 26 15:39:53.348: INFO: Initial restart count of pod test-webserver-327affe2-37b2-4a4c-8337-d90a04217695 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:43:53.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-426" for this suite.
May 26 15:43:59.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:43:59.907: INFO: namespace container-probe-426 deletion completed in 6.497893294s

• [SLOW TEST:250.863 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:43:59.908: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 26 15:44:03.248: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:44:03.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2995" for this suite.
May 26 15:44:11.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:44:11.860: INFO: namespace container-runtime-2995 deletion completed in 8.527916016s

• [SLOW TEST:11.952 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:44:11.860: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 26 15:44:16.217: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:44:16.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6197" for this suite.
May 26 15:44:24.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:44:24.841: INFO: namespace container-runtime-6197 deletion completed in 8.547123479s

• [SLOW TEST:12.981 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:44:24.843: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 15:44:25.111: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 26 15:44:30.125: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 26 15:44:30.125: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
May 26 15:44:30.197: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4836,SelfLink:/apis/apps/v1/namespaces/deployment-4836/deployments/test-cleanup-deployment,UID:e892dcc7-609c-49a6-9e1d-d5f9a6dfe679,ResourceVersion:22514,Generation:1,CreationTimestamp:2020-05-26 15:44:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 26 15:44:30.209: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-4836,SelfLink:/apis/apps/v1/namespaces/deployment-4836/replicasets/test-cleanup-deployment-55bbcbc84c,UID:bf6d158c-cd41-41d0-8662-cd4dc4c3b882,ResourceVersion:22516,Generation:1,CreationTimestamp:2020-05-26 15:44:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e892dcc7-609c-49a6-9e1d-d5f9a6dfe679 0xc002e5dad7 0xc002e5dad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 15:44:30.209: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 26 15:44:30.209: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-4836,SelfLink:/apis/apps/v1/namespaces/deployment-4836/replicasets/test-cleanup-controller,UID:fef1a8be-ed97-40ed-86f9-8ed2a6c2bf7c,ResourceVersion:22515,Generation:1,CreationTimestamp:2020-05-26 15:44:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e892dcc7-609c-49a6-9e1d-d5f9a6dfe679 0xc002e5da07 0xc002e5da08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 26 15:44:30.223: INFO: Pod "test-cleanup-controller-8hnzf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-8hnzf,GenerateName:test-cleanup-controller-,Namespace:deployment-4836,SelfLink:/api/v1/namespaces/deployment-4836/pods/test-cleanup-controller-8hnzf,UID:37a25694-3d51-4bd2-9df4-0c96544e00c4,ResourceVersion:22508,Generation:0,CreationTimestamp:2020-05-26 15:44:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller fef1a8be-ed97-40ed-86f9-8ed2a6c2bf7c 0xc002eb4527 0xc002eb4528}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7lxsj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7lxsj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7lxsj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eb45a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eb45c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 15:44:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 15:44:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 15:44:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 15:44:25 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.210,StartTime:2020-05-26 15:44:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 15:44:26 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://5357bf8a4412b735dee608c54c3832ab3f7aefc459059fd3bd7b572ecddbd9c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 15:44:30.223: INFO: Pod "test-cleanup-deployment-55bbcbc84c-g7npj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-g7npj,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-4836,SelfLink:/api/v1/namespaces/deployment-4836/pods/test-cleanup-deployment-55bbcbc84c-g7npj,UID:0e89b54d-d21d-4fd0-b4ef-391ad576d20e,ResourceVersion:22517,Generation:0,CreationTimestamp:2020-05-26 15:44:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c bf6d158c-cd41-41d0-8662-cd4dc4c3b882 0xc002eb46a7 0xc002eb46a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-7lxsj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7lxsj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7lxsj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eb4710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eb4730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:44:30.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4836" for this suite.
May 26 15:44:38.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:44:38.788: INFO: namespace deployment-4836 deletion completed in 8.548905758s

• [SLOW TEST:13.945 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:44:38.790: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
May 26 15:44:43.667: INFO: Successfully updated pod "labelsupdate8850b92d-0e82-4133-9338-410683e075bb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:44:45.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3709" for this suite.
May 26 15:45:09.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:45:10.334: INFO: namespace projected-3709 deletion completed in 24.582120118s

• [SLOW TEST:31.544 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:45:10.335: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
May 26 15:45:10.599: INFO: Waiting up to 5m0s for pod "client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5" in namespace "containers-3484" to be "success or failure"
May 26 15:45:10.612: INFO: Pod "client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.716386ms
May 26 15:45:12.624: INFO: Pod "client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024974475s
May 26 15:45:14.635: INFO: Pod "client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035989287s
STEP: Saw pod success
May 26 15:45:14.635: INFO: Pod "client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5" satisfied condition "success or failure"
May 26 15:45:14.648: INFO: Trying to get logs from node 10.113.231.185 pod client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5 container test-container: <nil>
STEP: delete the pod
May 26 15:45:14.736: INFO: Waiting for pod client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5 to disappear
May 26 15:45:14.747: INFO: Pod client-containers-5504abdd-1143-40bf-8733-5dae5e57ced5 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:45:14.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3484" for this suite.
May 26 15:45:22.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:45:23.317: INFO: namespace containers-3484 deletion completed in 8.550947235s

• [SLOW TEST:12.982 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:45:23.317: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-66031493-1bed-4712-8815-28e0470fed6e
STEP: Creating a pod to test consume secrets
May 26 15:45:23.610: INFO: Waiting up to 5m0s for pod "pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd" in namespace "secrets-9776" to be "success or failure"
May 26 15:45:23.629: INFO: Pod "pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd": Phase="Pending", Reason="", readiness=false. Elapsed: 19.437003ms
May 26 15:45:25.644: INFO: Pod "pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034322942s
May 26 15:45:27.657: INFO: Pod "pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046793457s
STEP: Saw pod success
May 26 15:45:27.657: INFO: Pod "pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd" satisfied condition "success or failure"
May 26 15:45:27.670: INFO: Trying to get logs from node 10.113.231.133 pod pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd container secret-env-test: <nil>
STEP: delete the pod
May 26 15:45:27.757: INFO: Waiting for pod pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd to disappear
May 26 15:45:27.768: INFO: Pod pod-secrets-74f4afde-a196-4a0e-84b5-50f959274acd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:45:27.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9776" for this suite.
May 26 15:45:33.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:45:34.312: INFO: namespace secrets-9776 deletion completed in 6.526742885s

• [SLOW TEST:10.994 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:45:34.312: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7551
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-t2kp4 in namespace proxy-7551
I0526 15:45:34.610035      16 runners.go:180] Created replication controller with name: proxy-service-t2kp4, namespace: proxy-7551, replica count: 1
I0526 15:45:35.662141      16 runners.go:180] proxy-service-t2kp4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0526 15:45:36.662405      16 runners.go:180] proxy-service-t2kp4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0526 15:45:37.662711      16 runners.go:180] proxy-service-t2kp4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0526 15:45:38.662987      16 runners.go:180] proxy-service-t2kp4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 26 15:45:38.684: INFO: setup took 4.134056409s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 26 15:45:38.710: INFO: (0) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 25.791917ms)
May 26 15:45:38.718: INFO: (0) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 33.701895ms)
May 26 15:45:38.720: INFO: (0) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 35.268034ms)
May 26 15:45:38.720: INFO: (0) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 35.875364ms)
May 26 15:45:38.729: INFO: (0) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 44.60249ms)
May 26 15:45:38.729: INFO: (0) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 43.926035ms)
May 26 15:45:38.729: INFO: (0) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 44.360442ms)
May 26 15:45:38.731: INFO: (0) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 46.7019ms)
May 26 15:45:38.731: INFO: (0) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 46.540147ms)
May 26 15:45:38.731: INFO: (0) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 46.466924ms)
May 26 15:45:38.740: INFO: (0) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 55.1214ms)
May 26 15:45:38.748: INFO: (0) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 62.964819ms)
May 26 15:45:38.749: INFO: (0) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 64.027949ms)
May 26 15:45:38.754: INFO: (0) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 69.522043ms)
May 26 15:45:38.761: INFO: (0) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 77.41494ms)
May 26 15:45:38.763: INFO: (0) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 78.809093ms)
May 26 15:45:38.781: INFO: (1) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 18.057697ms)
May 26 15:45:38.793: INFO: (1) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 29.758286ms)
May 26 15:45:38.797: INFO: (1) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 33.409584ms)
May 26 15:45:38.797: INFO: (1) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 33.399268ms)
May 26 15:45:38.797: INFO: (1) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 33.738826ms)
May 26 15:45:38.797: INFO: (1) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 33.734857ms)
May 26 15:45:38.798: INFO: (1) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 34.762946ms)
May 26 15:45:38.799: INFO: (1) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 35.014851ms)
May 26 15:45:38.799: INFO: (1) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 35.150529ms)
May 26 15:45:38.803: INFO: (1) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 39.973388ms)
May 26 15:45:38.804: INFO: (1) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 39.926491ms)
May 26 15:45:38.813: INFO: (1) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 49.100704ms)
May 26 15:45:38.813: INFO: (1) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 50.010262ms)
May 26 15:45:38.825: INFO: (1) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 61.476535ms)
May 26 15:45:38.827: INFO: (1) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 62.835279ms)
May 26 15:45:38.828: INFO: (1) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 64.461809ms)
May 26 15:45:38.850: INFO: (2) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 21.987217ms)
May 26 15:45:38.855: INFO: (2) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 26.998608ms)
May 26 15:45:38.855: INFO: (2) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 27.275138ms)
May 26 15:45:38.856: INFO: (2) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 27.442052ms)
May 26 15:45:38.856: INFO: (2) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 28.082279ms)
May 26 15:45:38.856: INFO: (2) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 28.027179ms)
May 26 15:45:38.856: INFO: (2) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 28.070814ms)
May 26 15:45:38.857: INFO: (2) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 28.51171ms)
May 26 15:45:38.857: INFO: (2) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 29.054227ms)
May 26 15:45:38.857: INFO: (2) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 29.123292ms)
May 26 15:45:38.868: INFO: (2) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 40.138556ms)
May 26 15:45:38.870: INFO: (2) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 42.017425ms)
May 26 15:45:38.876: INFO: (2) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 48.009578ms)
May 26 15:45:38.876: INFO: (2) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 48.387691ms)
May 26 15:45:38.876: INFO: (2) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 48.347175ms)
May 26 15:45:38.876: INFO: (2) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 48.303317ms)
May 26 15:45:38.899: INFO: (3) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 22.683176ms)
May 26 15:45:38.919: INFO: (3) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 42.435579ms)
May 26 15:45:38.919: INFO: (3) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 42.067911ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 44.681557ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 44.805872ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 44.558357ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 45.393645ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 44.990585ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 45.457053ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 44.981766ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 45.583081ms)
May 26 15:45:38.922: INFO: (3) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 45.880481ms)
May 26 15:45:38.927: INFO: (3) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 50.339151ms)
May 26 15:45:38.929: INFO: (3) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 51.71792ms)
May 26 15:45:38.929: INFO: (3) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 52.274385ms)
May 26 15:45:38.930: INFO: (3) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 53.018879ms)
May 26 15:45:38.954: INFO: (4) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 23.087445ms)
May 26 15:45:38.964: INFO: (4) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 33.66779ms)
May 26 15:45:38.964: INFO: (4) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 33.635327ms)
May 26 15:45:38.965: INFO: (4) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 34.507285ms)
May 26 15:45:38.965: INFO: (4) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 34.565829ms)
May 26 15:45:38.965: INFO: (4) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 35.029552ms)
May 26 15:45:38.966: INFO: (4) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 35.251389ms)
May 26 15:45:38.966: INFO: (4) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 36.281233ms)
May 26 15:45:38.966: INFO: (4) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 35.960936ms)
May 26 15:45:38.966: INFO: (4) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 36.010145ms)
May 26 15:45:38.971: INFO: (4) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 40.810398ms)
May 26 15:45:38.977: INFO: (4) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 46.594833ms)
May 26 15:45:38.980: INFO: (4) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 49.48467ms)
May 26 15:45:38.980: INFO: (4) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 49.77906ms)
May 26 15:45:38.982: INFO: (4) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 52.387952ms)
May 26 15:45:38.983: INFO: (4) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 52.275273ms)
May 26 15:45:39.010: INFO: (5) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 26.987277ms)
May 26 15:45:39.010: INFO: (5) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 27.002219ms)
May 26 15:45:39.011: INFO: (5) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 27.83764ms)
May 26 15:45:39.011: INFO: (5) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 27.768526ms)
May 26 15:45:39.013: INFO: (5) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 29.811439ms)
May 26 15:45:39.014: INFO: (5) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 30.924714ms)
May 26 15:45:39.014: INFO: (5) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 31.092595ms)
May 26 15:45:39.014: INFO: (5) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 30.928199ms)
May 26 15:45:39.015: INFO: (5) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 31.483356ms)
May 26 15:45:39.016: INFO: (5) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 32.579663ms)
May 26 15:45:39.016: INFO: (5) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 32.812327ms)
May 26 15:45:39.032: INFO: (5) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 49.117857ms)
May 26 15:45:39.035: INFO: (5) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 51.333536ms)
May 26 15:45:39.040: INFO: (5) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 56.866889ms)
May 26 15:45:39.041: INFO: (5) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 57.793375ms)
May 26 15:45:39.042: INFO: (5) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 58.014322ms)
May 26 15:45:39.064: INFO: (6) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 22.268284ms)
May 26 15:45:39.069: INFO: (6) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 26.761917ms)
May 26 15:45:39.070: INFO: (6) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 28.000192ms)
May 26 15:45:39.074: INFO: (6) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 31.165822ms)
May 26 15:45:39.074: INFO: (6) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 32.551299ms)
May 26 15:45:39.075: INFO: (6) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 32.433044ms)
May 26 15:45:39.075: INFO: (6) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 32.853642ms)
May 26 15:45:39.076: INFO: (6) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 33.411144ms)
May 26 15:45:39.076: INFO: (6) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 33.987132ms)
May 26 15:45:39.076: INFO: (6) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 33.801301ms)
May 26 15:45:39.081: INFO: (6) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 39.321016ms)
May 26 15:45:39.086: INFO: (6) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 44.049871ms)
May 26 15:45:39.086: INFO: (6) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 44.204645ms)
May 26 15:45:39.087: INFO: (6) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 44.680398ms)
May 26 15:45:39.088: INFO: (6) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 45.753703ms)
May 26 15:45:39.109: INFO: (6) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 66.934907ms)
May 26 15:45:39.135: INFO: (7) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 25.13662ms)
May 26 15:45:39.139: INFO: (7) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 28.288677ms)
May 26 15:45:39.139: INFO: (7) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 29.6524ms)
May 26 15:45:39.139: INFO: (7) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 29.391135ms)
May 26 15:45:39.140: INFO: (7) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 29.629929ms)
May 26 15:45:39.140: INFO: (7) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 29.185189ms)
May 26 15:45:39.140: INFO: (7) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 30.664653ms)
May 26 15:45:39.140: INFO: (7) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 30.306147ms)
May 26 15:45:39.140: INFO: (7) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 30.971139ms)
May 26 15:45:39.141: INFO: (7) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 30.235088ms)
May 26 15:45:39.143: INFO: (7) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 33.157222ms)
May 26 15:45:39.151: INFO: (7) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 40.638388ms)
May 26 15:45:39.184: INFO: (7) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 73.460834ms)
May 26 15:45:39.184: INFO: (7) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 73.208669ms)
May 26 15:45:39.184: INFO: (7) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 73.057271ms)
May 26 15:45:39.184: INFO: (7) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 74.357849ms)
May 26 15:45:39.205: INFO: (8) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 19.972396ms)
May 26 15:45:39.210: INFO: (8) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 24.505397ms)
May 26 15:45:39.210: INFO: (8) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 25.010134ms)
May 26 15:45:39.210: INFO: (8) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 25.087059ms)
May 26 15:45:39.210: INFO: (8) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 25.22978ms)
May 26 15:45:39.210: INFO: (8) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 25.249413ms)
May 26 15:45:39.211: INFO: (8) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 26.438203ms)
May 26 15:45:39.211: INFO: (8) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 26.363991ms)
May 26 15:45:39.211: INFO: (8) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 26.072967ms)
May 26 15:45:39.213: INFO: (8) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 27.952393ms)
May 26 15:45:39.216: INFO: (8) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 31.514014ms)
May 26 15:45:39.218: INFO: (8) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 32.4582ms)
May 26 15:45:39.222: INFO: (8) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 36.351449ms)
May 26 15:45:39.225: INFO: (8) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 39.589588ms)
May 26 15:45:39.225: INFO: (8) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 40.039821ms)
May 26 15:45:39.225: INFO: (8) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 40.225002ms)
May 26 15:45:39.250: INFO: (9) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 24.649715ms)
May 26 15:45:39.253: INFO: (9) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 27.025586ms)
May 26 15:45:39.259: INFO: (9) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 33.463125ms)
May 26 15:45:39.259: INFO: (9) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 33.925ms)
May 26 15:45:39.260: INFO: (9) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 34.21912ms)
May 26 15:45:39.262: INFO: (9) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 36.109131ms)
May 26 15:45:39.262: INFO: (9) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 36.706589ms)
May 26 15:45:39.263: INFO: (9) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 37.484834ms)
May 26 15:45:39.263: INFO: (9) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 37.837566ms)
May 26 15:45:39.264: INFO: (9) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 37.89325ms)
May 26 15:45:39.264: INFO: (9) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 38.17923ms)
May 26 15:45:39.265: INFO: (9) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 39.486878ms)
May 26 15:45:39.268: INFO: (9) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 42.894755ms)
May 26 15:45:39.269: INFO: (9) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 43.286879ms)
May 26 15:45:39.271: INFO: (9) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 45.728379ms)
May 26 15:45:39.272: INFO: (9) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 46.780648ms)
May 26 15:45:39.294: INFO: (10) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 21.531128ms)
May 26 15:45:39.297: INFO: (10) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 24.264659ms)
May 26 15:45:39.303: INFO: (10) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 30.825728ms)
May 26 15:45:39.304: INFO: (10) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 31.41911ms)
May 26 15:45:39.304: INFO: (10) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 31.679849ms)
May 26 15:45:39.304: INFO: (10) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 31.36474ms)
May 26 15:45:39.305: INFO: (10) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 32.46978ms)
May 26 15:45:39.306: INFO: (10) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 33.350552ms)
May 26 15:45:39.306: INFO: (10) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 34.326976ms)
May 26 15:45:39.306: INFO: (10) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 33.769151ms)
May 26 15:45:39.314: INFO: (10) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 41.957523ms)
May 26 15:45:39.314: INFO: (10) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 41.698984ms)
May 26 15:45:39.319: INFO: (10) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 46.716799ms)
May 26 15:45:39.321: INFO: (10) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 48.389874ms)
May 26 15:45:39.321: INFO: (10) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 48.121665ms)
May 26 15:45:39.321: INFO: (10) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 48.825012ms)
May 26 15:45:39.345: INFO: (11) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 24.213647ms)
May 26 15:45:39.347: INFO: (11) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 25.281246ms)
May 26 15:45:39.353: INFO: (11) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 31.95599ms)
May 26 15:45:39.360: INFO: (11) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 38.44504ms)
May 26 15:45:39.360: INFO: (11) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 38.912463ms)
May 26 15:45:39.360: INFO: (11) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 38.727816ms)
May 26 15:45:39.360: INFO: (11) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 39.034422ms)
May 26 15:45:39.360: INFO: (11) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 38.546173ms)
May 26 15:45:39.361: INFO: (11) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 39.256561ms)
May 26 15:45:39.361: INFO: (11) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 39.63039ms)
May 26 15:45:39.361: INFO: (11) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 39.548405ms)
May 26 15:45:39.362: INFO: (11) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 40.632019ms)
May 26 15:45:39.365: INFO: (11) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 44.006964ms)
May 26 15:45:39.371: INFO: (11) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 49.943085ms)
May 26 15:45:39.371: INFO: (11) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 49.827599ms)
May 26 15:45:39.371: INFO: (11) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 49.997941ms)
May 26 15:45:39.393: INFO: (12) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 21.174212ms)
May 26 15:45:39.394: INFO: (12) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 22.45352ms)
May 26 15:45:39.395: INFO: (12) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 22.995029ms)
May 26 15:45:39.395: INFO: (12) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 23.188147ms)
May 26 15:45:39.396: INFO: (12) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 23.907222ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 35.763915ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 35.749018ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 36.284063ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 36.650537ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 36.437117ms)
May 26 15:45:39.408: INFO: (12) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 36.341838ms)
May 26 15:45:39.419: INFO: (12) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 47.187012ms)
May 26 15:45:39.420: INFO: (12) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 47.79867ms)
May 26 15:45:39.420: INFO: (12) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 48.108886ms)
May 26 15:45:39.420: INFO: (12) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 48.266971ms)
May 26 15:45:39.422: INFO: (12) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 49.824306ms)
May 26 15:45:39.447: INFO: (13) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 25.049944ms)
May 26 15:45:39.453: INFO: (13) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 30.343402ms)
May 26 15:45:39.454: INFO: (13) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 31.619016ms)
May 26 15:45:39.454: INFO: (13) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 31.845447ms)
May 26 15:45:39.455: INFO: (13) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 33.260289ms)
May 26 15:45:39.456: INFO: (13) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 33.618842ms)
May 26 15:45:39.456: INFO: (13) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 34.154612ms)
May 26 15:45:39.456: INFO: (13) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 34.191026ms)
May 26 15:45:39.457: INFO: (13) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 34.458062ms)
May 26 15:45:39.457: INFO: (13) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 34.77527ms)
May 26 15:45:39.467: INFO: (13) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 45.426628ms)
May 26 15:45:39.468: INFO: (13) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 45.86725ms)
May 26 15:45:39.468: INFO: (13) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 45.651206ms)
May 26 15:45:39.468: INFO: (13) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 45.976484ms)
May 26 15:45:39.468: INFO: (13) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 45.589441ms)
May 26 15:45:39.468: INFO: (13) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 45.48902ms)
May 26 15:45:39.488: INFO: (14) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 19.784288ms)
May 26 15:45:39.501: INFO: (14) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 32.766927ms)
May 26 15:45:39.503: INFO: (14) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 34.469172ms)
May 26 15:45:39.503: INFO: (14) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 34.761557ms)
May 26 15:45:39.503: INFO: (14) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 35.010256ms)
May 26 15:45:39.504: INFO: (14) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 34.881835ms)
May 26 15:45:39.504: INFO: (14) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 34.935833ms)
May 26 15:45:39.504: INFO: (14) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 35.205163ms)
May 26 15:45:39.504: INFO: (14) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 35.498405ms)
May 26 15:45:39.510: INFO: (14) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 41.93407ms)
May 26 15:45:39.515: INFO: (14) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 47.013181ms)
May 26 15:45:39.515: INFO: (14) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 47.197484ms)
May 26 15:45:39.516: INFO: (14) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 48.131055ms)
May 26 15:45:39.517: INFO: (14) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 47.969861ms)
May 26 15:45:39.517: INFO: (14) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 48.247361ms)
May 26 15:45:39.517: INFO: (14) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 48.458599ms)
May 26 15:45:39.544: INFO: (15) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 26.537886ms)
May 26 15:45:39.550: INFO: (15) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 32.386134ms)
May 26 15:45:39.550: INFO: (15) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 32.688544ms)
May 26 15:45:39.550: INFO: (15) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 32.580201ms)
May 26 15:45:39.551: INFO: (15) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 33.593024ms)
May 26 15:45:39.555: INFO: (15) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 36.985202ms)
May 26 15:45:39.555: INFO: (15) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 37.345031ms)
May 26 15:45:39.561: INFO: (15) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 43.356075ms)
May 26 15:45:39.561: INFO: (15) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 43.227735ms)
May 26 15:45:39.561: INFO: (15) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 43.292575ms)
May 26 15:45:39.561: INFO: (15) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 43.67482ms)
May 26 15:45:39.561: INFO: (15) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 43.904312ms)
May 26 15:45:39.568: INFO: (15) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 50.652514ms)
May 26 15:45:39.569: INFO: (15) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 51.300529ms)
May 26 15:45:39.570: INFO: (15) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 52.82335ms)
May 26 15:45:39.570: INFO: (15) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 52.499112ms)
May 26 15:45:39.604: INFO: (16) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 33.786137ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 34.605739ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 34.47173ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 34.696767ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 34.443868ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 34.412135ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 34.516577ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 34.426883ms)
May 26 15:45:39.605: INFO: (16) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 35.170172ms)
May 26 15:45:39.632: INFO: (16) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 61.569679ms)
May 26 15:45:39.632: INFO: (16) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 61.660015ms)
May 26 15:45:39.640: INFO: (16) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 69.468825ms)
May 26 15:45:39.641: INFO: (16) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 70.5159ms)
May 26 15:45:39.641: INFO: (16) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 70.530171ms)
May 26 15:45:39.641: INFO: (16) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 71.121876ms)
May 26 15:45:39.648: INFO: (16) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 77.936333ms)
May 26 15:45:39.676: INFO: (17) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 27.333623ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 41.032176ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 41.121095ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 41.20879ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 41.133444ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 41.200656ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 41.514143ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 41.532299ms)
May 26 15:45:39.690: INFO: (17) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 41.27455ms)
May 26 15:45:39.694: INFO: (17) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 44.794661ms)
May 26 15:45:39.694: INFO: (17) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 44.882981ms)
May 26 15:45:39.694: INFO: (17) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 45.044136ms)
May 26 15:45:39.699: INFO: (17) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 50.048856ms)
May 26 15:45:39.702: INFO: (17) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 52.799668ms)
May 26 15:45:39.702: INFO: (17) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 52.728088ms)
May 26 15:45:39.704: INFO: (17) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 55.537757ms)
May 26 15:45:39.726: INFO: (18) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 21.439724ms)
May 26 15:45:39.734: INFO: (18) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 28.62888ms)
May 26 15:45:39.734: INFO: (18) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 28.775049ms)
May 26 15:45:39.734: INFO: (18) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 28.582293ms)
May 26 15:45:39.734: INFO: (18) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 28.122523ms)
May 26 15:45:39.734: INFO: (18) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 28.127378ms)
May 26 15:45:39.744: INFO: (18) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 38.042293ms)
May 26 15:45:39.744: INFO: (18) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 39.153008ms)
May 26 15:45:39.744: INFO: (18) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 38.849556ms)
May 26 15:45:39.744: INFO: (18) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 38.784452ms)
May 26 15:45:39.751: INFO: (18) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 44.864388ms)
May 26 15:45:39.751: INFO: (18) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 45.347276ms)
May 26 15:45:39.752: INFO: (18) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 47.438533ms)
May 26 15:45:39.752: INFO: (18) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 45.910799ms)
May 26 15:45:39.760: INFO: (18) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 54.072926ms)
May 26 15:45:39.760: INFO: (18) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 54.173275ms)
May 26 15:45:39.782: INFO: (19) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">test<... (200; 21.501871ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 30.14107ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f/proxy/rewriteme">test</a> (200; 29.83184ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 29.79871ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:160/proxy/: foo (200; 30.007528ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:443/proxy/tlsrewritem... (200; 30.184095ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:462/proxy/: tls qux (200; 29.764263ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/: <a href="/api/v1/namespaces/proxy-7551/pods/http:proxy-service-t2kp4-lfz5f:1080/proxy/rewriteme">... (200; 30.587191ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/https:proxy-service-t2kp4-lfz5f:460/proxy/: tls baz (200; 29.908096ms)
May 26 15:45:39.790: INFO: (19) /api/v1/namespaces/proxy-7551/pods/proxy-service-t2kp4-lfz5f:162/proxy/: bar (200; 29.873269ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname1/proxy/: tls baz (200; 44.555907ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/https:proxy-service-t2kp4:tlsportname2/proxy/: tls qux (200; 44.573779ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname2/proxy/: bar (200; 44.907377ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/http:proxy-service-t2kp4:portname1/proxy/: foo (200; 44.991207ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname1/proxy/: foo (200; 45.324365ms)
May 26 15:45:39.805: INFO: (19) /api/v1/namespaces/proxy-7551/services/proxy-service-t2kp4:portname2/proxy/: bar (200; 44.969331ms)
STEP: deleting ReplicationController proxy-service-t2kp4 in namespace proxy-7551, will wait for the garbage collector to delete the pods
May 26 15:45:39.905: INFO: Deleting ReplicationController proxy-service-t2kp4 took: 35.575016ms
May 26 15:45:40.106: INFO: Terminating ReplicationController proxy-service-t2kp4 pods took: 200.548619ms
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:45:51.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7551" for this suite.
May 26 15:45:59.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:45:59.834: INFO: namespace proxy-7551 deletion completed in 8.504234271s

• [SLOW TEST:25.522 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:45:59.834: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6507
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 26 15:46:00.195: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6507,SelfLink:/api/v1/namespaces/watch-6507/configmaps/e2e-watch-test-resource-version,UID:5d9b776c-5130-4af2-bf8d-2fbb1cadc9e5,ResourceVersion:22899,Generation:0,CreationTimestamp:2020-05-26 15:46:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 26 15:46:00.195: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6507,SelfLink:/api/v1/namespaces/watch-6507/configmaps/e2e-watch-test-resource-version,UID:5d9b776c-5130-4af2-bf8d-2fbb1cadc9e5,ResourceVersion:22900,Generation:0,CreationTimestamp:2020-05-26 15:46:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:46:00.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6507" for this suite.
May 26 15:46:06.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:46:06.734: INFO: namespace watch-6507 deletion completed in 6.523811368s

• [SLOW TEST:6.900 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:46:06.735: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
May 26 15:46:06.990: INFO: namespace kubectl-1198
May 26 15:46:06.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1198'
May 26 15:46:07.438: INFO: stderr: ""
May 26 15:46:07.438: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 26 15:46:08.453: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:08.453: INFO: Found 0 / 1
May 26 15:46:09.450: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:09.450: INFO: Found 0 / 1
May 26 15:46:10.449: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:10.449: INFO: Found 0 / 1
May 26 15:46:11.450: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:11.450: INFO: Found 0 / 1
May 26 15:46:12.454: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:12.454: INFO: Found 1 / 1
May 26 15:46:12.454: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 26 15:46:12.466: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:12.466: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 26 15:46:12.466: INFO: wait on redis-master startup in kubectl-1198 
May 26 15:46:12.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-8hwls redis-master --namespace=kubectl-1198'
May 26 15:46:12.652: INFO: stderr: ""
May 26 15:46:12.652: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 May 15:46:10.667 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 May 15:46:10.667 # Server started, Redis version 3.2.12\n1:M 26 May 15:46:10.668 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 May 15:46:10.668 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 26 15:46:12.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1198'
May 26 15:46:12.896: INFO: stderr: ""
May 26 15:46:12.896: INFO: stdout: "service/rm2 exposed\n"
May 26 15:46:12.910: INFO: Service rm2 in namespace kubectl-1198 found.
STEP: exposing service
May 26 15:46:14.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1198'
May 26 15:46:15.108: INFO: stderr: ""
May 26 15:46:15.108: INFO: stdout: "service/rm3 exposed\n"
May 26 15:46:15.120: INFO: Service rm3 in namespace kubectl-1198 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:46:17.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1198" for this suite.
May 26 15:46:41.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:46:41.667: INFO: namespace kubectl-1198 deletion completed in 24.503838788s

• [SLOW TEST:34.932 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:46:41.667: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7069
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
May 26 15:46:41.929: INFO: Waiting up to 5m0s for pod "downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e" in namespace "downward-api-7069" to be "success or failure"
May 26 15:46:41.941: INFO: Pod "downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.656475ms
May 26 15:46:43.956: INFO: Pod "downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026406383s
STEP: Saw pod success
May 26 15:46:43.956: INFO: Pod "downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e" satisfied condition "success or failure"
May 26 15:46:43.972: INFO: Trying to get logs from node 10.113.231.144 pod downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e container dapi-container: <nil>
STEP: delete the pod
May 26 15:46:44.061: INFO: Waiting for pod downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e to disappear
May 26 15:46:44.077: INFO: Pod downward-api-6e2cf55a-c700-4df0-88e1-282f971f832e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:46:44.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7069" for this suite.
May 26 15:46:52.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:46:52.676: INFO: namespace downward-api-7069 deletion completed in 8.574191501s

• [SLOW TEST:11.009 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:46:52.678: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
May 26 15:46:52.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-4063'
May 26 15:46:53.199: INFO: stderr: ""
May 26 15:46:53.199: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 26 15:46:54.220: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:54.220: INFO: Found 0 / 1
May 26 15:46:55.214: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:55.214: INFO: Found 0 / 1
May 26 15:46:56.212: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:56.212: INFO: Found 1 / 1
May 26 15:46:56.212: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 26 15:46:56.223: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:56.223: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 26 15:46:56.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 patch pod redis-master-fcf78 --namespace=kubectl-4063 -p {"metadata":{"annotations":{"x":"y"}}}'
May 26 15:46:56.398: INFO: stderr: ""
May 26 15:46:56.398: INFO: stdout: "pod/redis-master-fcf78 patched\n"
STEP: checking annotations
May 26 15:46:56.411: INFO: Selector matched 1 pods for map[app:redis]
May 26 15:46:56.411: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:46:56.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4063" for this suite.
May 26 15:47:20.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:47:20.951: INFO: namespace kubectl-4063 deletion completed in 24.519810618s

• [SLOW TEST:28.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:47:20.951: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2782
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:47:23.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2782" for this suite.
May 26 15:48:03.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:48:03.819: INFO: namespace kubelet-test-2782 deletion completed in 40.518932504s

• [SLOW TEST:42.868 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:48:03.822: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-rglh
STEP: Creating a pod to test atomic-volume-subpath
May 26 15:48:04.188: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rglh" in namespace "subpath-1514" to be "success or failure"
May 26 15:48:04.203: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Pending", Reason="", readiness=false. Elapsed: 15.37583ms
May 26 15:48:06.217: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 2.029028886s
May 26 15:48:08.229: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 4.041239049s
May 26 15:48:10.241: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 6.053238423s
May 26 15:48:12.257: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 8.069268297s
May 26 15:48:14.269: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 10.081493988s
May 26 15:48:16.286: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 12.098655247s
May 26 15:48:18.301: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 14.113603158s
May 26 15:48:20.312: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 16.12454082s
May 26 15:48:22.325: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 18.136865841s
May 26 15:48:24.336: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Running", Reason="", readiness=true. Elapsed: 20.148193831s
May 26 15:48:26.350: INFO: Pod "pod-subpath-test-configmap-rglh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.162489016s
STEP: Saw pod success
May 26 15:48:26.350: INFO: Pod "pod-subpath-test-configmap-rglh" satisfied condition "success or failure"
May 26 15:48:26.363: INFO: Trying to get logs from node 10.113.231.133 pod pod-subpath-test-configmap-rglh container test-container-subpath-configmap-rglh: <nil>
STEP: delete the pod
May 26 15:48:26.438: INFO: Waiting for pod pod-subpath-test-configmap-rglh to disappear
May 26 15:48:26.449: INFO: Pod pod-subpath-test-configmap-rglh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rglh
May 26 15:48:26.450: INFO: Deleting pod "pod-subpath-test-configmap-rglh" in namespace "subpath-1514"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:48:26.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1514" for this suite.
May 26 15:48:32.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:48:33.029: INFO: namespace subpath-1514 deletion completed in 6.547545187s

• [SLOW TEST:29.207 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:48:33.030: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4621
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 15:48:33.323: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977" in namespace "downward-api-4621" to be "success or failure"
May 26 15:48:33.333: INFO: Pod "downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977": Phase="Pending", Reason="", readiness=false. Elapsed: 9.755574ms
May 26 15:48:35.347: INFO: Pod "downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023685987s
STEP: Saw pod success
May 26 15:48:35.347: INFO: Pod "downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977" satisfied condition "success or failure"
May 26 15:48:35.357: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977 container client-container: <nil>
STEP: delete the pod
May 26 15:48:35.445: INFO: Waiting for pod downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977 to disappear
May 26 15:48:35.456: INFO: Pod downwardapi-volume-40cca6c3-7815-4025-91c1-9f124af16977 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:48:35.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4621" for this suite.
May 26 15:48:41.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:48:42.010: INFO: namespace downward-api-4621 deletion completed in 6.530000432s

• [SLOW TEST:8.979 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:48:42.013: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-6b0e0bba-7e6e-443e-828a-d58bdec455a6
STEP: Creating a pod to test consume secrets
May 26 15:48:42.335: INFO: Waiting up to 5m0s for pod "pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75" in namespace "secrets-6527" to be "success or failure"
May 26 15:48:42.345: INFO: Pod "pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75": Phase="Pending", Reason="", readiness=false. Elapsed: 10.127371ms
May 26 15:48:44.361: INFO: Pod "pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025975352s
STEP: Saw pod success
May 26 15:48:44.361: INFO: Pod "pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75" satisfied condition "success or failure"
May 26 15:48:44.377: INFO: Trying to get logs from node 10.113.231.185 pod pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75 container secret-volume-test: <nil>
STEP: delete the pod
May 26 15:48:44.457: INFO: Waiting for pod pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75 to disappear
May 26 15:48:44.470: INFO: Pod pod-secrets-8d878543-ebcb-4ee2-8062-92cf55fe9f75 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:48:44.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6527" for this suite.
May 26 15:48:52.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:48:53.028: INFO: namespace secrets-6527 deletion completed in 8.533556522s

• [SLOW TEST:11.015 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:48:53.030: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-91df07a3-887d-44bb-9cfb-f21bdd910d76
STEP: Creating a pod to test consume secrets
May 26 15:48:53.331: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b" in namespace "projected-5388" to be "success or failure"
May 26 15:48:53.342: INFO: Pod "pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.911773ms
May 26 15:48:55.354: INFO: Pod "pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023606029s
STEP: Saw pod success
May 26 15:48:55.354: INFO: Pod "pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b" satisfied condition "success or failure"
May 26 15:48:55.366: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 26 15:48:55.438: INFO: Waiting for pod pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b to disappear
May 26 15:48:55.449: INFO: Pod pod-projected-secrets-5e6f789b-a14b-4e8e-bae4-a45ea2cefa2b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:48:55.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5388" for this suite.
May 26 15:49:03.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:49:03.977: INFO: namespace projected-5388 deletion completed in 8.508215627s

• [SLOW TEST:10.948 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:49:03.978: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 15:49:24.293: INFO: Container started at 2020-05-26 15:49:07 +0000 UTC, pod became ready at 2020-05-26 15:49:23 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:49:24.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3442" for this suite.
May 26 15:49:40.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:49:40.810: INFO: namespace container-probe-3442 deletion completed in 16.493375829s

• [SLOW TEST:36.832 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:49:40.811: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
May 26 15:49:43.697: INFO: Successfully updated pod "labelsupdate01ecbab0-e000-426c-8a87-f752f6cf49d2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:49:45.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4637" for this suite.
May 26 15:50:09.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:50:10.374: INFO: namespace downward-api-4637 deletion completed in 24.594620757s

• [SLOW TEST:29.564 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:50:10.382: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6086
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-77fc6c2d-8b12-4b95-af66-3371c5898d9c
STEP: Creating a pod to test consume configMaps
May 26 15:50:10.673: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a" in namespace "projected-6086" to be "success or failure"
May 26 15:50:10.683: INFO: Pod "pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.483219ms
May 26 15:50:12.697: INFO: Pod "pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023760494s
STEP: Saw pod success
May 26 15:50:12.697: INFO: Pod "pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a" satisfied condition "success or failure"
May 26 15:50:12.710: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 15:50:12.783: INFO: Waiting for pod pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a to disappear
May 26 15:50:12.795: INFO: Pod pod-projected-configmaps-690a7c48-86a4-41ca-8846-2dbb84119d1a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:50:12.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6086" for this suite.
May 26 15:50:20.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:50:21.370: INFO: namespace projected-6086 deletion completed in 8.553461823s

• [SLOW TEST:10.988 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:50:21.370: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
May 26 15:50:21.646: INFO: Waiting up to 5m0s for pod "var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f" in namespace "var-expansion-899" to be "success or failure"
May 26 15:50:21.660: INFO: Pod "var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.660331ms
May 26 15:50:23.674: INFO: Pod "var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028556801s
May 26 15:50:25.686: INFO: Pod "var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039947243s
STEP: Saw pod success
May 26 15:50:25.686: INFO: Pod "var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f" satisfied condition "success or failure"
May 26 15:50:25.698: INFO: Trying to get logs from node 10.113.231.144 pod var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f container dapi-container: <nil>
STEP: delete the pod
May 26 15:50:25.769: INFO: Waiting for pod var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f to disappear
May 26 15:50:25.781: INFO: Pod var-expansion-7dd7837e-241a-4ee3-a65a-5beacf0d923f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:50:25.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-899" for this suite.
May 26 15:50:31.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:50:32.316: INFO: namespace var-expansion-899 deletion completed in 6.516786948s

• [SLOW TEST:10.946 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:50:32.316: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
May 26 15:50:32.558: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:50:36.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8227" for this suite.
May 26 15:50:44.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:50:44.745: INFO: namespace init-container-8227 deletion completed in 8.562428584s

• [SLOW TEST:12.429 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:50:44.746: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4694
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
May 26 15:50:45.030: INFO: Found 0 stateful pods, waiting for 3
May 26 15:50:55.043: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:50:55.043: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:50:55.043: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 26 15:50:55.132: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 26 15:51:05.235: INFO: Updating stateful set ss2
May 26 15:51:05.265: INFO: Waiting for Pod statefulset-4694/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
May 26 15:51:15.395: INFO: Found 2 stateful pods, waiting for 3
May 26 15:51:25.428: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:51:25.428: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:51:25.428: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 26 15:51:25.504: INFO: Updating stateful set ss2
May 26 15:51:25.537: INFO: Waiting for Pod statefulset-4694/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
May 26 15:51:35.616: INFO: Updating stateful set ss2
May 26 15:51:35.657: INFO: Waiting for StatefulSet statefulset-4694/ss2 to complete update
May 26 15:51:35.657: INFO: Waiting for Pod statefulset-4694/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
May 26 15:51:45.686: INFO: Waiting for StatefulSet statefulset-4694/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
May 26 15:51:55.868: INFO: Deleting all statefulset in ns statefulset-4694
May 26 15:51:55.882: INFO: Scaling statefulset ss2 to 0
May 26 15:52:15.947: INFO: Waiting for statefulset status.replicas updated to 0
May 26 15:52:15.962: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:52:16.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4694" for this suite.
May 26 15:52:24.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:52:24.596: INFO: namespace statefulset-4694 deletion completed in 8.550681988s

• [SLOW TEST:99.850 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:52:24.596: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 15:52:24.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-3703'
May 26 15:52:25.107: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 26 15:52:25.107: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
May 26 15:52:29.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3703'
May 26 15:52:29.333: INFO: stderr: ""
May 26 15:52:29.333: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:52:29.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3703" for this suite.
May 26 15:52:53.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:52:53.852: INFO: namespace kubectl-3703 deletion completed in 24.501514782s

• [SLOW TEST:29.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:52:53.853: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 15:52:54.123: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e" in namespace "downward-api-7460" to be "success or failure"
May 26 15:52:54.136: INFO: Pod "downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.729449ms
May 26 15:52:56.150: INFO: Pod "downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027443189s
STEP: Saw pod success
May 26 15:52:56.150: INFO: Pod "downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e" satisfied condition "success or failure"
May 26 15:52:56.164: INFO: Trying to get logs from node 10.113.231.133 pod downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e container client-container: <nil>
STEP: delete the pod
May 26 15:52:56.246: INFO: Waiting for pod downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e to disappear
May 26 15:52:56.256: INFO: Pod downwardapi-volume-e188da1e-6b06-46ed-9dbe-c2e1d8ef277e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:52:56.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7460" for this suite.
May 26 15:53:04.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:53:04.807: INFO: namespace downward-api-7460 deletion completed in 8.533442241s

• [SLOW TEST:10.955 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:53:04.807: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6951
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
May 26 15:53:05.083: INFO: Waiting up to 5m0s for pod "pod-8b9cef1b-25f2-4787-a1cf-3678e752b766" in namespace "emptydir-6951" to be "success or failure"
May 26 15:53:05.094: INFO: Pod "pod-8b9cef1b-25f2-4787-a1cf-3678e752b766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.568239ms
May 26 15:53:07.107: INFO: Pod "pod-8b9cef1b-25f2-4787-a1cf-3678e752b766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024261348s
May 26 15:53:09.120: INFO: Pod "pod-8b9cef1b-25f2-4787-a1cf-3678e752b766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03649147s
STEP: Saw pod success
May 26 15:53:09.120: INFO: Pod "pod-8b9cef1b-25f2-4787-a1cf-3678e752b766" satisfied condition "success or failure"
May 26 15:53:09.130: INFO: Trying to get logs from node 10.113.231.144 pod pod-8b9cef1b-25f2-4787-a1cf-3678e752b766 container test-container: <nil>
STEP: delete the pod
May 26 15:53:09.217: INFO: Waiting for pod pod-8b9cef1b-25f2-4787-a1cf-3678e752b766 to disappear
May 26 15:53:09.228: INFO: Pod pod-8b9cef1b-25f2-4787-a1cf-3678e752b766 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:53:09.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6951" for this suite.
May 26 15:53:17.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:53:18.698: INFO: namespace emptydir-6951 deletion completed in 9.445621601s

• [SLOW TEST:13.890 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:53:18.699: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
May 26 15:53:18.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 --namespace=kubectl-9840 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 26 15:53:21.855: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 26 15:53:21.856: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:53:23.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9840" for this suite.
May 26 15:53:33.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:53:34.436: INFO: namespace kubectl-9840 deletion completed in 10.535444442s

• [SLOW TEST:15.737 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:53:34.437: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5545
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
May 26 15:53:34.731: INFO: Found 0 stateful pods, waiting for 3
May 26 15:53:44.746: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:53:44.746: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:53:44.746: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 26 15:53:44.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-5545 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 15:53:45.256: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 15:53:45.256: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 15:53:45.256: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 26 15:53:55.348: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 26 15:54:05.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-5545 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 15:54:05.813: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 15:54:05.813: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 15:54:05.813: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 15:54:25.900: INFO: Waiting for StatefulSet statefulset-5545/ss2 to complete update
May 26 15:54:25.900: INFO: Waiting for Pod statefulset-5545/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
May 26 15:54:35.933: INFO: Waiting for StatefulSet statefulset-5545/ss2 to complete update
STEP: Rolling back to a previous revision
May 26 15:54:45.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-5545 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 15:54:46.819: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 15:54:46.819: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 15:54:46.819: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 15:54:56.924: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 26 15:55:07.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-5545 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 15:55:07.435: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 15:55:07.435: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 15:55:07.435: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 15:55:27.517: INFO: Waiting for StatefulSet statefulset-5545/ss2 to complete update
May 26 15:55:27.517: INFO: Waiting for Pod statefulset-5545/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
May 26 15:55:37.547: INFO: Waiting for StatefulSet statefulset-5545/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
May 26 15:55:47.554: INFO: Deleting all statefulset in ns statefulset-5545
May 26 15:55:47.569: INFO: Scaling statefulset ss2 to 0
May 26 15:56:17.626: INFO: Waiting for statefulset status.replicas updated to 0
May 26 15:56:17.642: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:56:17.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5545" for this suite.
May 26 15:56:25.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:56:26.228: INFO: namespace statefulset-5545 deletion completed in 8.507365748s

• [SLOW TEST:171.791 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:56:26.231: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 15:56:26.568: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 26 15:56:26.621: INFO: Number of nodes with available pods: 0
May 26 15:56:26.621: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 15:56:27.666: INFO: Number of nodes with available pods: 0
May 26 15:56:27.666: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 15:56:28.655: INFO: Number of nodes with available pods: 1
May 26 15:56:28.655: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 15:56:29.659: INFO: Number of nodes with available pods: 3
May 26 15:56:29.659: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 26 15:56:29.762: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:29.762: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:29.762: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:30.793: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:30.793: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:30.793: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.442: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.443: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.443: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.794: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.794: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:32.794: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:32.794: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:33.792: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:33.792: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:33.792: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:33.792: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:34.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:34.791: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:34.791: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:34.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:35.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:35.791: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:35.791: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:35.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:36.792: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:36.792: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:36.792: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:36.792: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:37.800: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:37.800: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:37.800: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:37.800: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:38.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:38.792: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:38.792: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:38.792: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:39.796: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:39.796: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:39.796: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:39.796: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:40.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:40.791: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:40.791: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:40.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:41.792: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:41.792: INFO: Wrong image for pod: daemon-set-cgnsk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:41.793: INFO: Pod daemon-set-cgnsk is not available
May 26 15:56:41.793: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:42.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:42.791: INFO: Pod daemon-set-c49mb is not available
May 26 15:56:42.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:43.790: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:43.790: INFO: Pod daemon-set-c49mb is not available
May 26 15:56:43.790: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:44.796: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:44.796: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:45.795: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:45.795: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:45.795: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:46.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:46.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:46.791: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:47.790: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:47.790: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:47.790: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:48.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:48.792: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:48.792: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:49.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:49.791: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:49.791: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:50.796: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:50.796: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:50.796: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:51.790: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:51.790: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:51.790: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:52.790: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:52.790: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:52.790: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:53.793: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:53.793: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:53.793: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:54.792: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:54.793: INFO: Wrong image for pod: daemon-set-mpjg4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:54.793: INFO: Pod daemon-set-mpjg4 is not available
May 26 15:56:55.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:55.791: INFO: Pod daemon-set-svjjx is not available
May 26 15:56:56.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:56.791: INFO: Pod daemon-set-svjjx is not available
May 26 15:56:57.790: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:58.793: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:59.791: INFO: Wrong image for pod: daemon-set-9psmt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 26 15:56:59.791: INFO: Pod daemon-set-9psmt is not available
May 26 15:57:00.792: INFO: Pod daemon-set-h5vnq is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 26 15:57:00.850: INFO: Number of nodes with available pods: 2
May 26 15:57:00.850: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 15:57:01.883: INFO: Number of nodes with available pods: 2
May 26 15:57:01.883: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 15:57:02.882: INFO: Number of nodes with available pods: 2
May 26 15:57:02.882: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 15:57:03.883: INFO: Number of nodes with available pods: 2
May 26 15:57:03.883: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 15:57:04.879: INFO: Number of nodes with available pods: 3
May 26 15:57:04.879: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9583, will wait for the garbage collector to delete the pods
May 26 15:57:05.057: INFO: Deleting DaemonSet.extensions daemon-set took: 39.420149ms
May 26 15:57:05.258: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.448829ms
May 26 15:57:12.069: INFO: Number of nodes with available pods: 0
May 26 15:57:12.069: INFO: Number of running nodes: 0, number of available pods: 0
May 26 15:57:12.084: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9583/daemonsets","resourceVersion":"25584"},"items":null}

May 26 15:57:12.096: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9583/pods","resourceVersion":"25584"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:57:12.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9583" for this suite.
May 26 15:57:20.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:57:20.710: INFO: namespace daemonsets-9583 deletion completed in 8.536696289s

• [SLOW TEST:54.479 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:57:20.710: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6758
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 26 15:57:27.110: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:27.120: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:29.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:29.132: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:31.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:31.131: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:33.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:33.132: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:35.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:35.134: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:37.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:37.133: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:39.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:39.137: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:41.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:41.132: INFO: Pod pod-with-poststart-http-hook still exists
May 26 15:57:43.120: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 26 15:57:43.131: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:57:43.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6758" for this suite.
May 26 15:58:07.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:58:07.680: INFO: namespace container-lifecycle-hook-6758 deletion completed in 24.530722763s

• [SLOW TEST:46.970 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:58:07.682: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
May 26 15:58:07.987: INFO: Waiting up to 5m0s for pod "pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa" in namespace "emptydir-5638" to be "success or failure"
May 26 15:58:08.006: INFO: Pod "pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa": Phase="Pending", Reason="", readiness=false. Elapsed: 18.165926ms
May 26 15:58:10.019: INFO: Pod "pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031130297s
May 26 15:58:12.031: INFO: Pod "pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043483968s
STEP: Saw pod success
May 26 15:58:12.031: INFO: Pod "pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa" satisfied condition "success or failure"
May 26 15:58:12.047: INFO: Trying to get logs from node 10.113.231.144 pod pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa container test-container: <nil>
STEP: delete the pod
May 26 15:58:12.122: INFO: Waiting for pod pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa to disappear
May 26 15:58:12.140: INFO: Pod pod-fbedcbad-94a3-4664-8a6b-f80fac545ffa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:58:12.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5638" for this suite.
May 26 15:58:20.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:58:20.676: INFO: namespace emptydir-5638 deletion completed in 8.51256548s

• [SLOW TEST:12.995 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:58:20.677: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3813
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 26 15:58:20.921: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 26 15:58:45.205: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.21.207 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3813 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 15:58:45.205: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 15:58:46.425: INFO: Found all expected endpoints: [netserver-0]
May 26 15:58:46.436: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.125.180 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3813 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 15:58:46.436: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 15:58:47.694: INFO: Found all expected endpoints: [netserver-1]
May 26 15:58:47.710: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.57.228 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3813 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 15:58:47.710: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 15:58:48.965: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:58:48.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3813" for this suite.
May 26 15:59:13.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:59:14.584: INFO: namespace pod-network-test-3813 deletion completed in 24.940581583s

• [SLOW TEST:53.907 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:59:14.585: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
May 26 15:59:14.855: INFO: Waiting up to 5m0s for pod "pod-738c16d0-ab51-4a68-86ca-91f8ef02224b" in namespace "emptydir-4706" to be "success or failure"
May 26 15:59:14.868: INFO: Pod "pod-738c16d0-ab51-4a68-86ca-91f8ef02224b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.619061ms
May 26 15:59:16.879: INFO: Pod "pod-738c16d0-ab51-4a68-86ca-91f8ef02224b": Phase="Running", Reason="", readiness=true. Elapsed: 2.024087073s
May 26 15:59:18.891: INFO: Pod "pod-738c16d0-ab51-4a68-86ca-91f8ef02224b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035468076s
STEP: Saw pod success
May 26 15:59:18.891: INFO: Pod "pod-738c16d0-ab51-4a68-86ca-91f8ef02224b" satisfied condition "success or failure"
May 26 15:59:18.906: INFO: Trying to get logs from node 10.113.231.144 pod pod-738c16d0-ab51-4a68-86ca-91f8ef02224b container test-container: <nil>
STEP: delete the pod
May 26 15:59:18.979: INFO: Waiting for pod pod-738c16d0-ab51-4a68-86ca-91f8ef02224b to disappear
May 26 15:59:19.004: INFO: Pod pod-738c16d0-ab51-4a68-86ca-91f8ef02224b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:59:19.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4706" for this suite.
May 26 15:59:27.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:59:27.584: INFO: namespace emptydir-4706 deletion completed in 8.562788374s

• [SLOW TEST:13.000 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:59:27.585: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a
May 26 15:59:27.848: INFO: Pod name my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a: Found 0 pods out of 1
May 26 15:59:32.864: INFO: Pod name my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a: Found 1 pods out of 1
May 26 15:59:32.864: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a" are running
May 26 15:59:32.877: INFO: Pod "my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a-p75bh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 15:59:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 15:59:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 15:59:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 15:59:27 +0000 UTC Reason: Message:}])
May 26 15:59:32.877: INFO: Trying to dial the pod
May 26 15:59:37.931: INFO: Controller my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a: Got expected result from replica 1 [my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a-p75bh]: "my-hostname-basic-4e29c75d-967f-44b3-9a1d-503bd1617f5a-p75bh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:59:37.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5884" for this suite.
May 26 15:59:46.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 15:59:46.534: INFO: namespace replication-controller-5884 deletion completed in 8.580741141s

• [SLOW TEST:18.949 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 15:59:46.538: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 15:59:46.851: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d5e9aa5b-4a33-4b22-807c-945dfeef5f09", Controller:(*bool)(0xc002ac25d6), BlockOwnerDeletion:(*bool)(0xc002ac25d7)}}
May 26 15:59:46.869: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"542e5bc1-641d-4298-89c5-9948258569c3", Controller:(*bool)(0xc00320ad26), BlockOwnerDeletion:(*bool)(0xc00320ad27)}}
May 26 15:59:46.895: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"da8bef71-4e14-4699-8047-02c706faf0d9", Controller:(*bool)(0xc002d76186), BlockOwnerDeletion:(*bool)(0xc002d76187)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 15:59:51.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-160" for this suite.
May 26 15:59:59.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:00:00.501: INFO: namespace gc-160 deletion completed in 8.557742947s

• [SLOW TEST:13.963 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:00:00.501: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:00:00.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7" in namespace "projected-5014" to be "success or failure"
May 26 16:00:00.804: INFO: Pod "downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.128473ms
May 26 16:00:02.817: INFO: Pod "downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028181016s
STEP: Saw pod success
May 26 16:00:02.817: INFO: Pod "downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7" satisfied condition "success or failure"
May 26 16:00:02.831: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7 container client-container: <nil>
STEP: delete the pod
May 26 16:00:02.906: INFO: Waiting for pod downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7 to disappear
May 26 16:00:02.924: INFO: Pod downwardapi-volume-c3c367c0-8ca7-4255-bddb-cd660d9147c7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:00:02.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5014" for this suite.
May 26 16:00:11.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:00:11.592: INFO: namespace projected-5014 deletion completed in 8.647988397s

• [SLOW TEST:11.091 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:00:11.592: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5530
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-6eb3c810-288f-4d0d-b3e6-d86179a3d3a4
STEP: Creating secret with name s-test-opt-upd-4700cacd-dd32-4da5-9c20-d2637fefcc42
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6eb3c810-288f-4d0d-b3e6-d86179a3d3a4
STEP: Updating secret s-test-opt-upd-4700cacd-dd32-4da5-9c20-d2637fefcc42
STEP: Creating secret with name s-test-opt-create-911bc117-d72d-4cbe-b7ec-880ec11a736e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:01:20.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5530" for this suite.
May 26 16:01:44.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:01:45.016: INFO: namespace secrets-5530 deletion completed in 24.512290493s

• [SLOW TEST:93.424 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:01:45.020: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5164
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-3c9b54ef-0f47-4877-a51c-1bca2d4a1f8e
STEP: Creating a pod to test consume configMaps
May 26 16:01:45.300: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583" in namespace "projected-5164" to be "success or failure"
May 26 16:01:45.316: INFO: Pod "pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583": Phase="Pending", Reason="", readiness=false. Elapsed: 15.618116ms
May 26 16:01:47.331: INFO: Pod "pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030563739s
STEP: Saw pod success
May 26 16:01:47.331: INFO: Pod "pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583" satisfied condition "success or failure"
May 26 16:01:47.346: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:01:47.416: INFO: Waiting for pod pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583 to disappear
May 26 16:01:47.425: INFO: Pod pod-projected-configmaps-81f9058e-936c-44a4-a7cc-542c7c8f0583 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:01:47.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5164" for this suite.
May 26 16:01:55.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:01:55.933: INFO: namespace projected-5164 deletion completed in 8.489400017s

• [SLOW TEST:10.913 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:01:55.934: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5030
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-b744002a-72dc-4869-b4f5-6d8dffc70ef6
STEP: Creating secret with name s-test-opt-upd-ae5297c2-9e4f-4cff-836c-ee59e15e8971
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b744002a-72dc-4869-b4f5-6d8dffc70ef6
STEP: Updating secret s-test-opt-upd-ae5297c2-9e4f-4cff-836c-ee59e15e8971
STEP: Creating secret with name s-test-opt-create-839896aa-3f31-43b2-af4f-ece5b9855732
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:03:26.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5030" for this suite.
May 26 16:03:50.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:03:51.199: INFO: namespace projected-5030 deletion completed in 24.508825714s

• [SLOW TEST:115.265 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:03:51.199: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:03:51.444: INFO: Creating ReplicaSet my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a
May 26 16:03:51.468: INFO: Pod name my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a: Found 0 pods out of 1
May 26 16:03:56.480: INFO: Pod name my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a: Found 1 pods out of 1
May 26 16:03:56.480: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a" is running
May 26 16:03:56.493: INFO: Pod "my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a-dlqzz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 16:03:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 16:03:54 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 16:03:54 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-26 16:03:51 +0000 UTC Reason: Message:}])
May 26 16:03:56.493: INFO: Trying to dial the pod
May 26 16:04:01.566: INFO: Controller my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a: Got expected result from replica 1 [my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a-dlqzz]: "my-hostname-basic-e7bdbdbd-c774-4744-a8fe-c60daf0cae6a-dlqzz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:01.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9421" for this suite.
May 26 16:04:09.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:04:10.136: INFO: namespace replicaset-9421 deletion completed in 8.545158164s

• [SLOW TEST:18.936 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:04:10.139: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8764
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-e73119f0-edd9-4915-8cc3-87eb4bb7c63f
STEP: Creating a pod to test consume configMaps
May 26 16:04:10.421: INFO: Waiting up to 5m0s for pod "pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187" in namespace "configmap-8764" to be "success or failure"
May 26 16:04:10.431: INFO: Pod "pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187": Phase="Pending", Reason="", readiness=false. Elapsed: 10.139336ms
May 26 16:04:12.443: INFO: Pod "pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022334565s
STEP: Saw pod success
May 26 16:04:12.443: INFO: Pod "pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187" satisfied condition "success or failure"
May 26 16:04:12.456: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:04:12.556: INFO: Waiting for pod pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187 to disappear
May 26 16:04:12.570: INFO: Pod pod-configmaps-cacd6225-675d-4d93-a217-a77415c62187 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:12.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8764" for this suite.
May 26 16:04:18.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:04:19.110: INFO: namespace configmap-8764 deletion completed in 6.520851509s

• [SLOW TEST:8.971 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:04:19.111: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2953
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May 26 16:04:25.936: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0526 16:04:25.936195      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:25.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2953" for this suite.
May 26 16:04:34.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:04:34.520: INFO: namespace gc-2953 deletion completed in 8.559950071s

• [SLOW TEST:15.410 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:04:34.521: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 16:04:34.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4823'
May 26 16:04:35.052: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 26 16:04:35.052: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 26 16:04:35.084: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-w4f85]
May 26 16:04:35.084: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-w4f85" in namespace "kubectl-4823" to be "running and ready"
May 26 16:04:35.097: INFO: Pod "e2e-test-nginx-rc-w4f85": Phase="Pending", Reason="", readiness=false. Elapsed: 12.746109ms
May 26 16:04:37.107: INFO: Pod "e2e-test-nginx-rc-w4f85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023179564s
May 26 16:04:39.134: INFO: Pod "e2e-test-nginx-rc-w4f85": Phase="Running", Reason="", readiness=true. Elapsed: 4.049691211s
May 26 16:04:39.134: INFO: Pod "e2e-test-nginx-rc-w4f85" satisfied condition "running and ready"
May 26 16:04:39.134: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-w4f85]
May 26 16:04:39.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs rc/e2e-test-nginx-rc --namespace=kubectl-4823'
May 26 16:04:39.370: INFO: stderr: ""
May 26 16:04:39.370: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
May 26 16:04:39.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete rc e2e-test-nginx-rc --namespace=kubectl-4823'
May 26 16:04:39.552: INFO: stderr: ""
May 26 16:04:39.552: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:39.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4823" for this suite.
May 26 16:04:45.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:04:46.269: INFO: namespace kubectl-4823 deletion completed in 6.699600257s

• [SLOW TEST:11.749 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:04:46.270: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
May 26 16:04:46.508: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-131493333 proxy --unix-socket=/tmp/kubectl-proxy-unix794645808/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:46.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9414" for this suite.
May 26 16:04:52.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:04:53.120: INFO: namespace kubectl-9414 deletion completed in 6.518403681s

• [SLOW TEST:6.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:04:53.122: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:04:53.395: INFO: (0) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.056819ms)
May 26 16:04:53.417: INFO: (1) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.778086ms)
May 26 16:04:53.440: INFO: (2) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.848684ms)
May 26 16:04:53.474: INFO: (3) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.827769ms)
May 26 16:04:53.499: INFO: (4) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 24.745864ms)
May 26 16:04:53.521: INFO: (5) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.685902ms)
May 26 16:04:53.547: INFO: (6) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 25.854657ms)
May 26 16:04:53.572: INFO: (7) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 24.686619ms)
May 26 16:04:53.608: INFO: (8) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 35.88902ms)
May 26 16:04:53.628: INFO: (9) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.457339ms)
May 26 16:04:53.657: INFO: (10) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 28.805563ms)
May 26 16:04:53.688: INFO: (11) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 30.778504ms)
May 26 16:04:53.708: INFO: (12) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.480162ms)
May 26 16:04:53.730: INFO: (13) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.763918ms)
May 26 16:04:53.751: INFO: (14) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.373104ms)
May 26 16:04:53.791: INFO: (15) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 40.636208ms)
May 26 16:04:53.822: INFO: (16) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 30.080585ms)
May 26 16:04:53.855: INFO: (17) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.668743ms)
May 26 16:04:53.878: INFO: (18) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.398347ms)
May 26 16:04:53.899: INFO: (19) /api/v1/nodes/10.113.231.133/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.273386ms)
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:04:53.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6237" for this suite.
May 26 16:05:01.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:05:02.526: INFO: namespace proxy-6237 deletion completed in 8.610773197s

• [SLOW TEST:9.404 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:05:02.528: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:05:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8708" for this suite.
May 26 16:05:15.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:05:15.482: INFO: namespace emptydir-wrapper-8708 deletion completed in 8.486829435s

• [SLOW TEST:12.954 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:05:15.485: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 26 16:05:18.812: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:05:18.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7637" for this suite.
May 26 16:05:26.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:05:27.434: INFO: namespace container-runtime-7637 deletion completed in 8.54824657s

• [SLOW TEST:11.949 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:05:27.434: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
May 26 16:05:27.678: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 26 16:05:27.706: INFO: Waiting for terminating namespaces to be deleted...
May 26 16:05:27.727: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.133 before test
May 26 16:05:27.838: INFO: ibm-keepalived-watcher-p8dn5 from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 16:05:27.838: INFO: calico-node-qw94x from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:05:27.838: INFO: coredns-c6797c986-wbcgx from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container coredns ready: true, restart count 0
May 26 16:05:27.838: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-97kmg from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:05:27.838: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 16:05:27.838: INFO: vpn-bd4d5cff7-mtlkg from kube-system started at 2020-05-26 14:15:51 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container vpn ready: true, restart count 0
May 26 16:05:27.838: INFO: ibm-master-proxy-static-10.113.231.133 from kube-system started at 2020-05-26 13:52:25 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:05:27.838: INFO: 	Container pause ready: true, restart count 0
May 26 16:05:27.838: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-05-26 13:55:18 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 26 16:05:27.838: INFO: ibm-file-plugin-5bcd9c888c-s8l25 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 26 16:05:27.838: INFO: metrics-server-875894b87-5gbms from kube-system started at 2020-05-26 13:52:56 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container metrics-server ready: true, restart count 0
May 26 16:05:27.838: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 26 16:05:27.838: INFO: sonobuoy from sonobuoy started at 2020-05-26 15:33:56 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.838: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 26 16:05:27.838: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.144 before test
May 26 16:05:27.890: INFO: kubernetes-dashboard-656d9457bf-xnzp4 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.890: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 26 16:05:27.890: INFO: calico-kube-controllers-b449456b9-8m86m from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.890: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 26 16:05:27.891: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-w7w2z from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.891: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 16:05:27.891: INFO: ibm-storage-watcher-7d98f4ccfc-kkghg from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.891: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 26 16:05:27.891: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-zssmt from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.892: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:05:27.892: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 16:05:27.892: INFO: sonobuoy-e2e-job-317cc8361edf4b82 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.892: INFO: 	Container e2e ready: true, restart count 0
May 26 16:05:27.892: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:05:27.893: INFO: calico-node-lz98l from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.893: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:05:27.893: INFO: ibm-keepalived-watcher-wvnv5 from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.893: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 16:05:27.893: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-5s4gm from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 16:05:27.893: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 16:05:27.894: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 16:05:27.894: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 16:05:27.894: INFO: 	Container nginx-ingress ready: true, restart count 0
May 26 16:05:27.894: INFO: ibm-master-proxy-static-10.113.231.144 from kube-system started at 2020-05-26 13:52:21 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.894: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:05:27.895: INFO: 	Container pause ready: true, restart count 0
May 26 16:05:27.895: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.185 before test
May 26 16:05:27.989: INFO: ibm-master-proxy-static-10.113.231.185 from kube-system started at 2020-05-26 13:52:12 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:05:27.989: INFO: 	Container pause ready: true, restart count 0
May 26 16:05:27.989: INFO: coredns-c6797c986-4rh25 from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container coredns ready: true, restart count 0
May 26 16:05:27.989: INFO: calico-node-5pk9b from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:05:27.989: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-rmth7 from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 16:05:27.989: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-jzhkr from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 16:05:27.989: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 16:05:27.989: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 16:05:27.989: INFO: 	Container nginx-ingress ready: true, restart count 0
May 26 16:05:27.989: INFO: ibm-keepalived-watcher-fgt8t from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 16:05:27.989: INFO: coredns-autoscaler-65bc7cb8b5-28zmr from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container autoscaler ready: true, restart count 0
May 26 16:05:27.989: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-l9676 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:05:27.989: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:05:27.989: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16129fa006247636], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:05:29.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1347" for this suite.
May 26 16:05:35.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:05:35.620: INFO: namespace sched-pred-1347 deletion completed in 6.513229453s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:8.186 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:05:35.621: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 26 16:05:36.822: INFO: Pod name wrapped-volume-race-bc522b29-5eba-45e3-b523-590e48469284: Found 0 pods out of 5
May 26 16:05:41.841: INFO: Pod name wrapped-volume-race-bc522b29-5eba-45e3-b523-590e48469284: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bc522b29-5eba-45e3-b523-590e48469284 in namespace emptydir-wrapper-9738, will wait for the garbage collector to delete the pods
May 26 16:05:42.009: INFO: Deleting ReplicationController wrapped-volume-race-bc522b29-5eba-45e3-b523-590e48469284 took: 37.982306ms
May 26 16:05:42.210: INFO: Terminating ReplicationController wrapped-volume-race-bc522b29-5eba-45e3-b523-590e48469284 pods took: 200.343707ms
STEP: Creating RC which spawns configmap-volume pods
May 26 16:06:25.468: INFO: Pod name wrapped-volume-race-0359c0be-14e7-4ad4-aa82-db49683635ca: Found 0 pods out of 5
May 26 16:06:30.489: INFO: Pod name wrapped-volume-race-0359c0be-14e7-4ad4-aa82-db49683635ca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0359c0be-14e7-4ad4-aa82-db49683635ca in namespace emptydir-wrapper-9738, will wait for the garbage collector to delete the pods
May 26 16:06:30.653: INFO: Deleting ReplicationController wrapped-volume-race-0359c0be-14e7-4ad4-aa82-db49683635ca took: 38.633554ms
May 26 16:06:30.854: INFO: Terminating ReplicationController wrapped-volume-race-0359c0be-14e7-4ad4-aa82-db49683635ca pods took: 200.295166ms
STEP: Creating RC which spawns configmap-volume pods
May 26 16:07:15.426: INFO: Pod name wrapped-volume-race-25515ef2-77b4-4073-800b-fc8065e9a68f: Found 0 pods out of 5
May 26 16:07:20.444: INFO: Pod name wrapped-volume-race-25515ef2-77b4-4073-800b-fc8065e9a68f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-25515ef2-77b4-4073-800b-fc8065e9a68f in namespace emptydir-wrapper-9738, will wait for the garbage collector to delete the pods
May 26 16:07:20.605: INFO: Deleting ReplicationController wrapped-volume-race-25515ef2-77b4-4073-800b-fc8065e9a68f took: 34.790298ms
May 26 16:07:20.805: INFO: Terminating ReplicationController wrapped-volume-race-25515ef2-77b4-4073-800b-fc8065e9a68f pods took: 200.343136ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:08:07.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9738" for this suite.
May 26 16:08:17.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:08:17.843: INFO: namespace emptydir-wrapper-9738 deletion completed in 10.751651592s

• [SLOW TEST:162.223 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:08:17.848: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
May 26 16:08:18.090: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 26 16:08:18.124: INFO: Waiting for terminating namespaces to be deleted...
May 26 16:08:18.137: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.133 before test
May 26 16:08:18.193: INFO: ibm-keepalived-watcher-p8dn5 from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.194: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 16:08:18.194: INFO: calico-node-qw94x from kube-system started at 2020-05-26 13:52:26 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.194: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:08:18.194: INFO: coredns-c6797c986-wbcgx from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.194: INFO: 	Container coredns ready: true, restart count 0
May 26 16:08:18.194: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-97kmg from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.194: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:08:18.195: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 16:08:18.195: INFO: vpn-bd4d5cff7-mtlkg from kube-system started at 2020-05-26 14:15:51 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.195: INFO: 	Container vpn ready: true, restart count 0
May 26 16:08:18.195: INFO: ibm-master-proxy-static-10.113.231.133 from kube-system started at 2020-05-26 13:52:25 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.195: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:08:18.195: INFO: 	Container pause ready: true, restart count 0
May 26 16:08:18.195: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-05-26 13:55:18 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.195: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 26 16:08:18.196: INFO: ibm-file-plugin-5bcd9c888c-s8l25 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.196: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 26 16:08:18.196: INFO: metrics-server-875894b87-5gbms from kube-system started at 2020-05-26 13:52:56 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.196: INFO: 	Container metrics-server ready: true, restart count 0
May 26 16:08:18.196: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 26 16:08:18.196: INFO: sonobuoy from sonobuoy started at 2020-05-26 15:33:56 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.196: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 26 16:08:18.196: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.144 before test
May 26 16:08:18.269: INFO: ibm-master-proxy-static-10.113.231.144 from kube-system started at 2020-05-26 13:52:21 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.269: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:08:18.269: INFO: 	Container pause ready: true, restart count 0
May 26 16:08:18.269: INFO: ibm-keepalived-watcher-wvnv5 from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.269: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 26 16:08:18.270: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-5s4gm from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 16:08:18.270: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 16:08:18.270: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 16:08:18.270: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 16:08:18.270: INFO: 	Container nginx-ingress ready: true, restart count 0
May 26 16:08:18.270: INFO: ibm-storage-watcher-7d98f4ccfc-kkghg from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.271: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 26 16:08:18.271: INFO: kubernetes-dashboard-656d9457bf-xnzp4 from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.271: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 26 16:08:18.271: INFO: calico-kube-controllers-b449456b9-8m86m from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.271: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 26 16:08:18.271: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-w7w2z from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.271: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 16:08:18.272: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-zssmt from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.272: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:08:18.272: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 16:08:18.272: INFO: calico-node-lz98l from kube-system started at 2020-05-26 13:52:27 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.272: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:08:18.272: INFO: sonobuoy-e2e-job-317cc8361edf4b82 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.272: INFO: 	Container e2e ready: true, restart count 0
May 26 16:08:18.273: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:08:18.273: INFO: 
Logging pods the kubelet thinks is on node 10.113.231.185 before test
May 26 16:08:18.331: INFO: coredns-autoscaler-65bc7cb8b5-28zmr from kube-system started at 2020-05-26 13:52:47 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.331: INFO: 	Container autoscaler ready: true, restart count 0
May 26 16:08:18.331: INFO: sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-l9676 from sonobuoy started at 2020-05-26 15:34:02 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.332: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 26 16:08:18.332: INFO: 	Container systemd-logs ready: true, restart count 0
May 26 16:08:18.332: INFO: ibm-master-proxy-static-10.113.231.185 from kube-system started at 2020-05-26 13:52:12 +0000 UTC (2 container statuses recorded)
May 26 16:08:18.332: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
May 26 16:08:18.332: INFO: 	Container pause ready: true, restart count 0
May 26 16:08:18.332: INFO: coredns-c6797c986-4rh25 from kube-system started at 2020-05-26 14:16:14 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.333: INFO: 	Container coredns ready: true, restart count 0
May 26 16:08:18.333: INFO: calico-node-5pk9b from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.333: INFO: 	Container calico-node ready: true, restart count 0
May 26 16:08:18.333: INFO: ibm-cloud-provider-ip-159-8-185-125-5df5868f74-rmth7 from ibm-system started at 2020-05-26 13:53:40 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.333: INFO: 	Container ibm-cloud-provider-ip-159-8-185-125 ready: true, restart count 0
May 26 16:08:18.333: INFO: public-crbr6hn8ql0obpu0v8me50-alb1-58bd4b8d8c-jzhkr from kube-system started at 2020-05-26 13:56:23 +0000 UTC (4 container statuses recorded)
May 26 16:08:18.334: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 26 16:08:18.334: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 26 16:08:18.334: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 26 16:08:18.334: INFO: 	Container nginx-ingress ready: true, restart count 0
May 26 16:08:18.334: INFO: ibm-keepalived-watcher-fgt8t from kube-system started at 2020-05-26 13:52:18 +0000 UTC (1 container statuses recorded)
May 26 16:08:18.334: INFO: 	Container keepalived-watcher ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-63069d93-a4b9-4482-a94d-a96277b596c9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-63069d93-a4b9-4482-a94d-a96277b596c9 off the node 10.113.231.144
STEP: verifying the node doesn't have the label kubernetes.io/e2e-63069d93-a4b9-4482-a94d-a96277b596c9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:08:26.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2770" for this suite.
May 26 16:08:42.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:08:43.123: INFO: namespace sched-pred-2770 deletion completed in 16.514989089s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:25.275 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:08:43.128: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 16:08:43.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7051'
May 26 16:08:43.528: INFO: stderr: ""
May 26 16:08:43.528: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
May 26 16:08:43.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete pods e2e-test-nginx-pod --namespace=kubectl-7051'
May 26 16:08:55.107: INFO: stderr: ""
May 26 16:08:55.107: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:08:55.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7051" for this suite.
May 26 16:09:03.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:09:03.689: INFO: namespace kubectl-7051 deletion completed in 8.564399227s

• [SLOW TEST:20.561 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:09:03.689: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3617
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0526 16:09:14.079902      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 26 16:09:14.080: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:09:14.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3617" for this suite.
May 26 16:09:22.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:09:22.609: INFO: namespace gc-3617 deletion completed in 8.516872893s

• [SLOW TEST:18.920 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:09:22.612: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1221
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7253
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2961
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:09:30.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1221" for this suite.
May 26 16:09:36.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:09:36.994: INFO: namespace namespaces-1221 deletion completed in 6.52936808s
STEP: Destroying namespace "nsdeletetest-7253" for this suite.
May 26 16:09:37.008: INFO: Namespace nsdeletetest-7253 was already deleted
STEP: Destroying namespace "nsdeletetest-2961" for this suite.
May 26 16:09:43.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:09:43.535: INFO: namespace nsdeletetest-2961 deletion completed in 6.52639764s

• [SLOW TEST:20.923 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:09:43.535: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:10:43.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5184" for this suite.
May 26 16:11:07.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:11:08.478: INFO: namespace container-probe-5184 deletion completed in 24.538991445s

• [SLOW TEST:84.943 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:11:08.479: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2111
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:11:08.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8" in namespace "projected-2111" to be "success or failure"
May 26 16:11:08.770: INFO: Pod "downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8": Phase="Pending", Reason="", readiness=false. Elapsed: 17.040888ms
May 26 16:11:10.784: INFO: Pod "downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030989867s
May 26 16:11:12.797: INFO: Pod "downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043592595s
STEP: Saw pod success
May 26 16:11:12.797: INFO: Pod "downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8" satisfied condition "success or failure"
May 26 16:11:12.808: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8 container client-container: <nil>
STEP: delete the pod
May 26 16:11:12.875: INFO: Waiting for pod downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8 to disappear
May 26 16:11:12.889: INFO: Pod downwardapi-volume-b94e867c-1c76-4e0d-bc52-111cc70d85b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:11:12.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2111" for this suite.
May 26 16:11:20.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:11:21.435: INFO: namespace projected-2111 deletion completed in 8.529593379s

• [SLOW TEST:12.957 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:11:21.442: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
May 26 16:11:21.730: INFO: Waiting up to 5m0s for pod "downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f" in namespace "downward-api-6108" to be "success or failure"
May 26 16:11:21.746: INFO: Pod "downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054507ms
May 26 16:11:23.763: INFO: Pod "downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032272763s
May 26 16:11:25.775: INFO: Pod "downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044357848s
STEP: Saw pod success
May 26 16:11:25.775: INFO: Pod "downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f" satisfied condition "success or failure"
May 26 16:11:25.788: INFO: Trying to get logs from node 10.113.231.185 pod downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f container dapi-container: <nil>
STEP: delete the pod
May 26 16:11:25.874: INFO: Waiting for pod downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f to disappear
May 26 16:11:25.885: INFO: Pod downward-api-0370d184-bb58-492e-b7b6-02e7d479bd9f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:11:25.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6108" for this suite.
May 26 16:11:31.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:11:32.424: INFO: namespace downward-api-6108 deletion completed in 6.509909043s

• [SLOW TEST:10.982 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:11:32.424: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:11:32.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc" in namespace "projected-1498" to be "success or failure"
May 26 16:11:32.714: INFO: Pod "downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.101455ms
May 26 16:11:34.725: INFO: Pod "downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021443337s
STEP: Saw pod success
May 26 16:11:34.725: INFO: Pod "downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc" satisfied condition "success or failure"
May 26 16:11:34.736: INFO: Trying to get logs from node 10.113.231.133 pod downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc container client-container: <nil>
STEP: delete the pod
May 26 16:11:34.821: INFO: Waiting for pod downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc to disappear
May 26 16:11:34.834: INFO: Pod downwardapi-volume-0de6dde3-6c5f-406a-abaa-6926538950cc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:11:34.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1498" for this suite.
May 26 16:11:42.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:11:43.374: INFO: namespace projected-1498 deletion completed in 8.522827146s

• [SLOW TEST:10.950 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:11:43.374: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-a2aba477-2d4c-481e-a047-e145e2b520f4 in namespace container-probe-8295
May 26 16:11:47.674: INFO: Started pod busybox-a2aba477-2d4c-481e-a047-e145e2b520f4 in namespace container-probe-8295
STEP: checking the pod's current state and verifying that restartCount is present
May 26 16:11:47.686: INFO: Initial restart count of pod busybox-a2aba477-2d4c-481e-a047-e145e2b520f4 is 0
May 26 16:12:37.184: INFO: Restart count of pod container-probe-8295/busybox-a2aba477-2d4c-481e-a047-e145e2b520f4 is now 1 (49.49753669s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:12:37.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8295" for this suite.
May 26 16:12:45.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:12:45.947: INFO: namespace container-probe-8295 deletion completed in 8.702975815s

• [SLOW TEST:62.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:12:45.947: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8947
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
May 26 16:12:48.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec pod-sharedvolume-3c2a184a-8f8e-4db4-a541-3ee8ca5a16ba -c busybox-main-container --namespace=emptydir-8947 -- cat /usr/share/volumeshare/shareddata.txt'
May 26 16:12:48.693: INFO: stderr: ""
May 26 16:12:48.693: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:12:48.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8947" for this suite.
May 26 16:12:56.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:12:57.219: INFO: namespace emptydir-8947 deletion completed in 8.508782947s

• [SLOW TEST:11.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:12:57.220: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:13:26.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2566" for this suite.
May 26 16:13:34.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:13:34.877: INFO: namespace container-runtime-2566 deletion completed in 8.529122129s

• [SLOW TEST:37.657 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:13:34.878: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4481
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-22de7749-ee87-4f8e-92f3-2106f6745a52
STEP: Creating configMap with name cm-test-opt-upd-70295ab2-7079-45a0-97d2-cddca5113f67
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-22de7749-ee87-4f8e-92f3-2106f6745a52
STEP: Updating configmap cm-test-opt-upd-70295ab2-7079-45a0-97d2-cddca5113f67
STEP: Creating configMap with name cm-test-opt-create-107122b0-bdc1-46ea-8fff-9202a4a55994
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:13:43.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4481" for this suite.
May 26 16:14:07.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:14:08.121: INFO: namespace configmap-4481 deletion completed in 24.526626227s

• [SLOW TEST:33.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:14:08.121: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
May 26 16:14:08.387: INFO: Waiting up to 5m0s for pod "pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4" in namespace "emptydir-7578" to be "success or failure"
May 26 16:14:08.400: INFO: Pod "pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.601535ms
May 26 16:14:10.417: INFO: Pod "pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030149714s
STEP: Saw pod success
May 26 16:14:10.417: INFO: Pod "pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4" satisfied condition "success or failure"
May 26 16:14:10.427: INFO: Trying to get logs from node 10.113.231.144 pod pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4 container test-container: <nil>
STEP: delete the pod
May 26 16:14:10.797: INFO: Waiting for pod pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4 to disappear
May 26 16:14:10.813: INFO: Pod pod-d4ffd2f2-1392-4676-9bd7-9bfebd19c2c4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:14:10.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7578" for this suite.
May 26 16:14:16.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:14:17.513: INFO: namespace emptydir-7578 deletion completed in 6.679736729s

• [SLOW TEST:9.392 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:14:17.513: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
May 26 16:14:17.750: INFO: PodSpec: initContainers in spec.initContainers
May 26 16:15:02.554: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e0896919-c9b1-4f70-9338-f13e360c11a7", GenerateName:"", Namespace:"init-container-8236", SelfLink:"/api/v1/namespaces/init-container-8236/pods/pod-init-e0896919-c9b1-4f70-9338-f13e360c11a7", UID:"70496cfb-f48e-47ca-8593-7bfb4284bc7a", ResourceVersion:"29683", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63726106457, loc:(*time.Location)(0x7edea20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"750757836"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2lbhf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0016e8440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lbhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lbhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lbhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002c0c4c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.113.231.185", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d402a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c0c700)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002c0c720)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002c0c728), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002c0c72c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106457, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106457, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106457, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106457, loc:(*time.Location)(0x7edea20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.113.231.185", PodIP:"172.30.57.239", StartTime:(*v1.Time)(0xc002d0a200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b68150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002b681c0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://43f2ca367084208127c4352103520e163d2d95741778cdff1e4d4bd26e2247dc"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002d0a240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002d0a220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:15:02.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8236" for this suite.
May 26 16:15:26.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:15:27.114: INFO: namespace init-container-8236 deletion completed in 24.539710942s

• [SLOW TEST:69.601 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:15:27.114: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:15:27.383: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4" in namespace "projected-4609" to be "success or failure"
May 26 16:15:27.395: INFO: Pod "downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.970238ms
May 26 16:15:29.407: INFO: Pod "downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023877522s
STEP: Saw pod success
May 26 16:15:29.407: INFO: Pod "downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4" satisfied condition "success or failure"
May 26 16:15:29.418: INFO: Trying to get logs from node 10.113.231.133 pod downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4 container client-container: <nil>
STEP: delete the pod
May 26 16:15:29.500: INFO: Waiting for pod downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4 to disappear
May 26 16:15:29.511: INFO: Pod downwardapi-volume-3e5d21af-51f3-4eaf-8745-95dc65e0f2b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:15:29.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4609" for this suite.
May 26 16:15:37.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:15:38.149: INFO: namespace projected-4609 deletion completed in 8.618295817s

• [SLOW TEST:11.035 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:15:38.150: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9765
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
May 26 16:15:38.408: INFO: Waiting up to 5m0s for pod "client-containers-f756e919-75c6-48ef-a344-74bce02b946b" in namespace "containers-9765" to be "success or failure"
May 26 16:15:38.421: INFO: Pod "client-containers-f756e919-75c6-48ef-a344-74bce02b946b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.306937ms
May 26 16:15:40.433: INFO: Pod "client-containers-f756e919-75c6-48ef-a344-74bce02b946b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024649178s
May 26 16:15:42.446: INFO: Pod "client-containers-f756e919-75c6-48ef-a344-74bce02b946b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03774012s
STEP: Saw pod success
May 26 16:15:42.446: INFO: Pod "client-containers-f756e919-75c6-48ef-a344-74bce02b946b" satisfied condition "success or failure"
May 26 16:15:42.458: INFO: Trying to get logs from node 10.113.231.144 pod client-containers-f756e919-75c6-48ef-a344-74bce02b946b container test-container: <nil>
STEP: delete the pod
May 26 16:15:42.520: INFO: Waiting for pod client-containers-f756e919-75c6-48ef-a344-74bce02b946b to disappear
May 26 16:15:42.530: INFO: Pod client-containers-f756e919-75c6-48ef-a344-74bce02b946b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:15:42.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9765" for this suite.
May 26 16:15:50.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:15:51.043: INFO: namespace containers-9765 deletion completed in 8.495922226s

• [SLOW TEST:12.893 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:15:51.043: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:15:51.306: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589" in namespace "downward-api-4008" to be "success or failure"
May 26 16:15:51.316: INFO: Pod "downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589": Phase="Pending", Reason="", readiness=false. Elapsed: 10.54402ms
May 26 16:15:53.327: INFO: Pod "downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021606682s
May 26 16:15:55.339: INFO: Pod "downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03343319s
STEP: Saw pod success
May 26 16:15:55.339: INFO: Pod "downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589" satisfied condition "success or failure"
May 26 16:15:55.350: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589 container client-container: <nil>
STEP: delete the pod
May 26 16:15:55.444: INFO: Waiting for pod downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589 to disappear
May 26 16:15:55.456: INFO: Pod downwardapi-volume-9bce28ea-9050-42b8-a83a-2dacb3631589 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:15:55.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4008" for this suite.
May 26 16:16:03.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:16:04.024: INFO: namespace downward-api-4008 deletion completed in 8.544159822s

• [SLOW TEST:12.981 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:16:04.027: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2203
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2203
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2203
May 26 16:16:04.338: INFO: Found 0 stateful pods, waiting for 1
May 26 16:16:14.352: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 26 16:16:14.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:16:14.929: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:16:14.929: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:16:14.929: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:16:14.944: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 26 16:16:24.956: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:16:24.956: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:16:25.023: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999997816s
May 26 16:16:26.037: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.986703682s
May 26 16:16:27.049: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.97194567s
May 26 16:16:28.062: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.959991494s
May 26 16:16:29.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.947248839s
May 26 16:16:30.086: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.93595335s
May 26 16:16:31.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.922862556s
May 26 16:16:32.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.910069043s
May 26 16:16:33.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.898057583s
May 26 16:16:34.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 886.331519ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2203
May 26 16:16:35.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:16:35.529: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 16:16:35.529: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:16:35.529: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:16:35.541: INFO: Found 1 stateful pods, waiting for 3
May 26 16:16:45.558: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 26 16:16:45.558: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 26 16:16:45.558: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 26 16:16:45.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:16:46.030: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:16:46.030: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:16:46.030: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:16:46.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:16:46.489: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:16:46.489: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:16:46.489: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:16:46.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:16:46.943: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:16:46.943: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:16:46.943: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:16:46.943: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:16:46.958: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 26 16:16:56.985: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:16:56.985: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:16:56.985: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:16:57.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997936s
May 26 16:16:58.044: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985487104s
May 26 16:16:59.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972789393s
May 26 16:17:00.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960171396s
May 26 16:17:01.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.945297309s
May 26 16:17:02.099: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.93171708s
May 26 16:17:03.111: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.918594416s
May 26 16:17:04.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.90590196s
May 26 16:17:05.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.889915912s
May 26 16:17:06.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 877.572022ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2203
May 26 16:17:07.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:17:07.616: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 16:17:07.616: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:17:07.616: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:17:07.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:17:08.019: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 16:17:08.019: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:17:08.019: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:17:08.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-2203 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:17:08.393: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 16:17:08.393: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:17:08.393: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:17:08.393: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
May 26 16:17:48.460: INFO: Deleting all statefulset in ns statefulset-2203
May 26 16:17:48.476: INFO: Scaling statefulset ss to 0
May 26 16:17:48.520: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:17:48.533: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:17:48.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2203" for this suite.
May 26 16:17:56.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:17:57.128: INFO: namespace statefulset-2203 deletion completed in 8.510814168s

• [SLOW TEST:113.101 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:17:57.130: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
May 26 16:17:57.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-6786'
May 26 16:17:57.732: INFO: stderr: ""
May 26 16:17:57.732: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 16:17:57.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:17:57.896: INFO: stderr: ""
May 26 16:17:57.896: INFO: stdout: "update-demo-nautilus-5x8xv update-demo-nautilus-g8rvp "
May 26 16:17:57.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:17:58.060: INFO: stderr: ""
May 26 16:17:58.060: INFO: stdout: ""
May 26 16:17:58.060: INFO: update-demo-nautilus-5x8xv is created but not running
May 26 16:18:03.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:18:03.240: INFO: stderr: ""
May 26 16:18:03.240: INFO: stdout: "update-demo-nautilus-5x8xv update-demo-nautilus-g8rvp "
May 26 16:18:03.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:03.396: INFO: stderr: ""
May 26 16:18:03.396: INFO: stdout: "true"
May 26 16:18:03.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:03.546: INFO: stderr: ""
May 26 16:18:03.546: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:18:03.546: INFO: validating pod update-demo-nautilus-5x8xv
May 26 16:18:03.583: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:18:03.583: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:18:03.583: INFO: update-demo-nautilus-5x8xv is verified up and running
May 26 16:18:03.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-g8rvp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:03.738: INFO: stderr: ""
May 26 16:18:03.738: INFO: stdout: "true"
May 26 16:18:03.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-g8rvp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:03.876: INFO: stderr: ""
May 26 16:18:03.876: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:18:03.876: INFO: validating pod update-demo-nautilus-g8rvp
May 26 16:18:03.915: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:18:03.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:18:03.915: INFO: update-demo-nautilus-g8rvp is verified up and running
STEP: scaling down the replication controller
May 26 16:18:03.917: INFO: scanned /root for discovery docs: <nil>
May 26 16:18:03.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6786'
May 26 16:18:05.146: INFO: stderr: ""
May 26 16:18:05.146: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 16:18:05.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:18:05.298: INFO: stderr: ""
May 26 16:18:05.298: INFO: stdout: "update-demo-nautilus-5x8xv update-demo-nautilus-g8rvp "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 26 16:18:10.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:18:10.446: INFO: stderr: ""
May 26 16:18:10.446: INFO: stdout: "update-demo-nautilus-5x8xv "
May 26 16:18:10.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:10.615: INFO: stderr: ""
May 26 16:18:10.615: INFO: stdout: "true"
May 26 16:18:10.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:10.759: INFO: stderr: ""
May 26 16:18:10.759: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:18:10.759: INFO: validating pod update-demo-nautilus-5x8xv
May 26 16:18:10.782: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:18:10.782: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:18:10.782: INFO: update-demo-nautilus-5x8xv is verified up and running
STEP: scaling up the replication controller
May 26 16:18:10.784: INFO: scanned /root for discovery docs: <nil>
May 26 16:18:10.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6786'
May 26 16:18:11.997: INFO: stderr: ""
May 26 16:18:11.997: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 16:18:11.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:18:12.184: INFO: stderr: ""
May 26 16:18:12.184: INFO: stdout: "update-demo-nautilus-2ptnb update-demo-nautilus-5x8xv "
May 26 16:18:12.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-2ptnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:12.339: INFO: stderr: ""
May 26 16:18:12.339: INFO: stdout: ""
May 26 16:18:12.339: INFO: update-demo-nautilus-2ptnb is created but not running
May 26 16:18:17.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6786'
May 26 16:18:17.488: INFO: stderr: ""
May 26 16:18:17.488: INFO: stdout: "update-demo-nautilus-2ptnb update-demo-nautilus-5x8xv "
May 26 16:18:17.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-2ptnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:17.664: INFO: stderr: ""
May 26 16:18:17.664: INFO: stdout: "true"
May 26 16:18:17.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-2ptnb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:17.816: INFO: stderr: ""
May 26 16:18:17.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:18:17.816: INFO: validating pod update-demo-nautilus-2ptnb
May 26 16:18:17.846: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:18:17.846: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:18:17.846: INFO: update-demo-nautilus-2ptnb is verified up and running
May 26 16:18:17.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:17.995: INFO: stderr: ""
May 26 16:18:17.995: INFO: stdout: "true"
May 26 16:18:17.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-5x8xv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6786'
May 26 16:18:18.173: INFO: stderr: ""
May 26 16:18:18.173: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:18:18.173: INFO: validating pod update-demo-nautilus-5x8xv
May 26 16:18:18.205: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:18:18.206: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:18:18.206: INFO: update-demo-nautilus-5x8xv is verified up and running
STEP: using delete to clean up resources
May 26 16:18:18.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-6786'
May 26 16:18:18.418: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:18:18.418: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 26 16:18:18.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6786'
May 26 16:18:18.599: INFO: stderr: "No resources found.\n"
May 26 16:18:18.599: INFO: stdout: ""
May 26 16:18:18.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -l name=update-demo --namespace=kubectl-6786 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 26 16:18:18.783: INFO: stderr: ""
May 26 16:18:18.783: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:18:18.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6786" for this suite.
May 26 16:18:42.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:18:43.331: INFO: namespace kubectl-6786 deletion completed in 24.531251855s

• [SLOW TEST:46.201 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:18:43.332: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8131
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-8131
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8131 to expose endpoints map[]
May 26 16:18:43.629: INFO: successfully validated that service endpoint-test2 in namespace services-8131 exposes endpoints map[] (15.976991ms elapsed)
STEP: Creating pod pod1 in namespace services-8131
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8131 to expose endpoints map[pod1:[80]]
May 26 16:18:45.746: INFO: successfully validated that service endpoint-test2 in namespace services-8131 exposes endpoints map[pod1:[80]] (2.08823578s elapsed)
STEP: Creating pod pod2 in namespace services-8131
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8131 to expose endpoints map[pod1:[80] pod2:[80]]
May 26 16:18:48.961: INFO: successfully validated that service endpoint-test2 in namespace services-8131 exposes endpoints map[pod1:[80] pod2:[80]] (3.200703332s elapsed)
STEP: Deleting pod pod1 in namespace services-8131
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8131 to expose endpoints map[pod2:[80]]
May 26 16:18:50.043: INFO: successfully validated that service endpoint-test2 in namespace services-8131 exposes endpoints map[pod2:[80]] (1.061635669s elapsed)
STEP: Deleting pod pod2 in namespace services-8131
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8131 to expose endpoints map[]
May 26 16:18:50.085: INFO: successfully validated that service endpoint-test2 in namespace services-8131 exposes endpoints map[] (15.666038ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:18:50.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8131" for this suite.
May 26 16:18:58.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:18:58.727: INFO: namespace services-8131 deletion completed in 8.518298011s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:15.396 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:18:58.728: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
May 26 16:18:58.980: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2866" to be "success or failure"
May 26 16:18:58.993: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.223757ms
May 26 16:19:01.005: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024518879s
May 26 16:19:03.018: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037271574s
STEP: Saw pod success
May 26 16:19:03.018: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 26 16:19:03.028: INFO: Trying to get logs from node 10.113.231.185 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 26 16:19:03.129: INFO: Waiting for pod pod-host-path-test to disappear
May 26 16:19:03.141: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:19:03.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2866" for this suite.
May 26 16:19:11.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:19:11.675: INFO: namespace hostpath-2866 deletion completed in 8.515363807s

• [SLOW TEST:12.947 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:19:11.676: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 26 16:19:11.944: INFO: Waiting up to 5m0s for pod "pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2" in namespace "emptydir-7585" to be "success or failure"
May 26 16:19:11.956: INFO: Pod "pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.202716ms
May 26 16:19:13.968: INFO: Pod "pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023911733s
STEP: Saw pod success
May 26 16:19:13.968: INFO: Pod "pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2" satisfied condition "success or failure"
May 26 16:19:13.982: INFO: Trying to get logs from node 10.113.231.133 pod pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2 container test-container: <nil>
STEP: delete the pod
May 26 16:19:14.058: INFO: Waiting for pod pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2 to disappear
May 26 16:19:14.070: INFO: Pod pod-4f77d2ae-cc41-4d6c-9868-d2d4c5d9ead2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:19:14.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7585" for this suite.
May 26 16:19:20.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:19:20.639: INFO: namespace emptydir-7585 deletion completed in 6.549351817s

• [SLOW TEST:8.963 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:19:20.640: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
May 26 16:19:20.889: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-131493333 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:19:21.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7604" for this suite.
May 26 16:19:27.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:19:27.537: INFO: namespace kubectl-7604 deletion completed in 6.507471123s

• [SLOW TEST:6.897 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:19:27.537: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8327
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-caccda03-eacc-432e-bf1e-2adeecde63ea
STEP: Creating configMap with name cm-test-opt-upd-c2f5b3e5-6318-459f-8d64-7bdcdec89c9c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-caccda03-eacc-432e-bf1e-2adeecde63ea
STEP: Updating configmap cm-test-opt-upd-c2f5b3e5-6318-459f-8d64-7bdcdec89c9c
STEP: Creating configMap with name cm-test-opt-create-84b77686-bb6c-4380-89b5-745f3a8571d0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:20:47.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8327" for this suite.
May 26 16:21:12.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:21:12.507: INFO: namespace projected-8327 deletion completed in 24.525701146s

• [SLOW TEST:104.969 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:21:12.508: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:21:12.853: INFO: Creating deployment "test-recreate-deployment"
May 26 16:21:12.869: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 26 16:21:12.899: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 26 16:21:14.929: INFO: Waiting deployment "test-recreate-deployment" to complete
May 26 16:21:14.941: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106872, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106872, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106872, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106872, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:21:16.956: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 26 16:21:16.989: INFO: Updating deployment test-recreate-deployment
May 26 16:21:16.989: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
May 26 16:21:17.166: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2447,SelfLink:/apis/apps/v1/namespaces/deployment-2447/deployments/test-recreate-deployment,UID:85e0049f-89ba-435d-b503-95370470c2e2,ResourceVersion:31018,Generation:2,CreationTimestamp:2020-05-26 16:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-05-26 16:21:17 +0000 UTC 2020-05-26 16:21:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-05-26 16:21:17 +0000 UTC 2020-05-26 16:21:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 26 16:21:17.186: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-2447,SelfLink:/apis/apps/v1/namespaces/deployment-2447/replicasets/test-recreate-deployment-5c8c9cc69d,UID:c7133522-b772-4d14-9f49-967c53550d6f,ResourceVersion:31015,Generation:1,CreationTimestamp:2020-05-26 16:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 85e0049f-89ba-435d-b503-95370470c2e2 0xc000017d77 0xc000017d78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:21:17.186: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 26 16:21:17.187: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-2447,SelfLink:/apis/apps/v1/namespaces/deployment-2447/replicasets/test-recreate-deployment-6df85df6b9,UID:a5638c3f-6a67-4f96-8a5f-5967c2cc86db,ResourceVersion:31007,Generation:2,CreationTimestamp:2020-05-26 16:21:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 85e0049f-89ba-435d-b503-95370470c2e2 0xc000017e47 0xc000017e48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:21:17.202: INFO: Pod "test-recreate-deployment-5c8c9cc69d-68n47" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-68n47,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-2447,SelfLink:/api/v1/namespaces/deployment-2447/pods/test-recreate-deployment-5c8c9cc69d-68n47,UID:0799ae88-d0c3-4bff-be07-6d476c6a1e97,ResourceVersion:31019,Generation:0,CreationTimestamp:2020-05-26 16:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d c7133522-b772-4d14-9f49-967c53550d6f 0xc002eb4977 0xc002eb4978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gzljt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gzljt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gzljt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002eb49f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002eb4a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:21:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:21:17.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2447" for this suite.
May 26 16:21:25.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:21:25.705: INFO: namespace deployment-2447 deletion completed in 8.485417437s

• [SLOW TEST:13.197 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:21:25.706: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:21:25.947: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 26 16:21:25.973: INFO: Pod name sample-pod: Found 0 pods out of 1
May 26 16:21:30.985: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 26 16:21:30.985: INFO: Creating deployment "test-rolling-update-deployment"
May 26 16:21:31.002: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 26 16:21:31.031: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 26 16:21:33.057: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 26 16:21:33.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106891, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106891, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106891, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726106891, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:21:35.090: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
May 26 16:21:35.129: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1304,SelfLink:/apis/apps/v1/namespaces/deployment-1304/deployments/test-rolling-update-deployment,UID:f2c06106-104b-410d-a4b3-18a1cbf588bf,ResourceVersion:31138,Generation:1,CreationTimestamp:2020-05-26 16:21:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-05-26 16:21:31 +0000 UTC 2020-05-26 16:21:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-05-26 16:21:33 +0000 UTC 2020-05-26 16:21:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 26 16:21:35.149: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-1304,SelfLink:/apis/apps/v1/namespaces/deployment-1304/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:37cc0263-1365-48a4-a735-dd1a2e81e5a2,ResourceVersion:31127,Generation:1,CreationTimestamp:2020-05-26 16:21:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f2c06106-104b-410d-a4b3-18a1cbf588bf 0xc000f0c8d7 0xc000f0c8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 26 16:21:35.149: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 26 16:21:35.149: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1304,SelfLink:/apis/apps/v1/namespaces/deployment-1304/replicasets/test-rolling-update-controller,UID:c6eae9ea-8a46-4ac9-b987-83a64a7db282,ResourceVersion:31137,Generation:2,CreationTimestamp:2020-05-26 16:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f2c06106-104b-410d-a4b3-18a1cbf588bf 0xc000f0c807 0xc000f0c808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:21:35.163: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-mqrcr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-mqrcr,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-1304,SelfLink:/api/v1/namespaces/deployment-1304/pods/test-rolling-update-deployment-79f6b9d75c-mqrcr,UID:47a03857-16f3-4f01-bdbc-94ad09502d7d,ResourceVersion:31126,Generation:0,CreationTimestamp:2020-05-26 16:21:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 37cc0263-1365-48a4-a735-dd1a2e81e5a2 0xc00351cce7 0xc00351cce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9286d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9286d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9286d true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00351cd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00351cd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:21:31 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.245,StartTime:2020-05-26 16:21:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-05-26 16:21:32 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://be9ea2a6df796643db8e5daf6074af0578ed776e8298a8a3149e3e2af27e78fe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:21:35.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1304" for this suite.
May 26 16:21:43.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:21:43.663: INFO: namespace deployment-1304 deletion completed in 8.483150296s

• [SLOW TEST:17.957 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:21:43.666: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f6c2352c-0069-43f9-94d3-3733813e797f
STEP: Creating a pod to test consume configMaps
May 26 16:21:43.944: INFO: Waiting up to 5m0s for pod "pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9" in namespace "configmap-8906" to be "success or failure"
May 26 16:21:43.954: INFO: Pod "pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.490923ms
May 26 16:21:45.966: INFO: Pod "pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022623172s
May 26 16:21:47.982: INFO: Pod "pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037986119s
STEP: Saw pod success
May 26 16:21:47.982: INFO: Pod "pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9" satisfied condition "success or failure"
May 26 16:21:47.994: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:21:48.076: INFO: Waiting for pod pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9 to disappear
May 26 16:21:48.090: INFO: Pod pod-configmaps-c576e41f-3034-4dfc-a3f6-84a8a88b90b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:21:48.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8906" for this suite.
May 26 16:21:54.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:21:54.680: INFO: namespace configmap-8906 deletion completed in 6.571706568s

• [SLOW TEST:11.014 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:21:54.680: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-60cc8d82-79af-4083-a883-d57123323345
STEP: Creating a pod to test consume secrets
May 26 16:21:54.981: INFO: Waiting up to 5m0s for pod "pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065" in namespace "secrets-4559" to be "success or failure"
May 26 16:21:54.999: INFO: Pod "pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065": Phase="Pending", Reason="", readiness=false. Elapsed: 18.160274ms
May 26 16:21:57.011: INFO: Pod "pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029528878s
STEP: Saw pod success
May 26 16:21:57.011: INFO: Pod "pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065" satisfied condition "success or failure"
May 26 16:21:57.033: INFO: Trying to get logs from node 10.113.231.185 pod pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065 container secret-volume-test: <nil>
STEP: delete the pod
May 26 16:21:57.115: INFO: Waiting for pod pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065 to disappear
May 26 16:21:57.126: INFO: Pod pod-secrets-c5a85670-f881-4d8f-a60f-80c4e4ccf065 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:21:57.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4559" for this suite.
May 26 16:22:03.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:22:03.705: INFO: namespace secrets-4559 deletion completed in 6.560171789s

• [SLOW TEST:9.025 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:22:03.705: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 26 16:22:10.079: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:10.320: INFO: Exec stderr: ""
May 26 16:22:10.320: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:10.321: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:10.524: INFO: Exec stderr: ""
May 26 16:22:10.524: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:10.524: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:10.794: INFO: Exec stderr: ""
May 26 16:22:10.795: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:10.795: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:11.089: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 26 16:22:11.089: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:11.089: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:11.318: INFO: Exec stderr: ""
May 26 16:22:11.318: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:11.560: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 26 16:22:11.560: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:11.560: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:11.776: INFO: Exec stderr: ""
May 26 16:22:11.776: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:11.776: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:12.008: INFO: Exec stderr: ""
May 26 16:22:12.008: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:12.008: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:12.285: INFO: Exec stderr: ""
May 26 16:22:12.285: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6006 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:22:12.285: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:22:12.560: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:22:12.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6006" for this suite.
May 26 16:23:04.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:23:05.258: INFO: namespace e2e-kubelet-etc-hosts-6006 deletion completed in 52.676748672s

• [SLOW TEST:61.553 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:23:05.259: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7291.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7291.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 16:23:19.765: INFO: DNS probes using dns-7291/dns-test-e1f03ca9-ab89-4be7-b195-78997891aec5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:23:19.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7291" for this suite.
May 26 16:23:27.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:23:28.329: INFO: namespace dns-7291 deletion completed in 8.506544373s

• [SLOW TEST:23.070 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:23:28.329: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 16:23:30.741: INFO: DNS probes using dns-test-f46dbb3c-329c-424f-96ca-c24b5810e354 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 16:23:42.921: INFO: File wheezy_udp@dns-test-service-3.dns-4890.svc.cluster.local from pod  dns-4890/dns-test-502ff986-8e2e-4349-b19b-346ad3f9ea5f contains 'foo.example.com.
' instead of 'bar.example.com.'
May 26 16:23:42.941: INFO: Lookups using dns-4890/dns-test-502ff986-8e2e-4349-b19b-346ad3f9ea5f failed for: [wheezy_udp@dns-test-service-3.dns-4890.svc.cluster.local]

May 26 16:23:47.990: INFO: DNS probes using dns-test-502ff986-8e2e-4349-b19b-346ad3f9ea5f succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4890.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4890.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 16:23:52.213: INFO: DNS probes using dns-test-5d224c82-327c-43ce-a71c-ead6b1303a8e succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:23:52.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4890" for this suite.
May 26 16:24:00.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:24:00.962: INFO: namespace dns-4890 deletion completed in 8.580903167s

• [SLOW TEST:32.633 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:24:00.965: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:24:01.242: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24" in namespace "projected-4847" to be "success or failure"
May 26 16:24:01.261: INFO: Pod "downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24": Phase="Pending", Reason="", readiness=false. Elapsed: 18.124838ms
May 26 16:24:03.272: INFO: Pod "downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029600275s
STEP: Saw pod success
May 26 16:24:03.272: INFO: Pod "downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24" satisfied condition "success or failure"
May 26 16:24:03.285: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24 container client-container: <nil>
STEP: delete the pod
May 26 16:24:03.381: INFO: Waiting for pod downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24 to disappear
May 26 16:24:03.396: INFO: Pod downwardapi-volume-a346a141-aa61-45f5-bbf6-f7a9e2842a24 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:24:03.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4847" for this suite.
May 26 16:24:09.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:24:09.967: INFO: namespace projected-4847 deletion completed in 6.550906839s

• [SLOW TEST:9.002 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:24:09.971: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-efbee2e3-c681-47d7-9520-5f2636a87ef8
STEP: Creating a pod to test consume secrets
May 26 16:24:10.279: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051" in namespace "projected-4128" to be "success or failure"
May 26 16:24:10.294: INFO: Pod "pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051": Phase="Pending", Reason="", readiness=false. Elapsed: 14.982958ms
May 26 16:24:12.309: INFO: Pod "pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030209699s
STEP: Saw pod success
May 26 16:24:12.310: INFO: Pod "pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051" satisfied condition "success or failure"
May 26 16:24:12.329: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 26 16:24:12.460: INFO: Waiting for pod pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051 to disappear
May 26 16:24:12.479: INFO: Pod pod-projected-secrets-d5eb2796-27c9-4700-a8a2-340b29dc1051 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:24:12.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4128" for this suite.
May 26 16:24:20.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:24:21.065: INFO: namespace projected-4128 deletion completed in 8.563690774s

• [SLOW TEST:11.094 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:24:21.067: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:24:21.411: INFO: Create a RollingUpdate DaemonSet
May 26 16:24:21.426: INFO: Check that daemon pods launch on every node of the cluster
May 26 16:24:21.450: INFO: Number of nodes with available pods: 0
May 26 16:24:21.450: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:24:22.489: INFO: Number of nodes with available pods: 0
May 26 16:24:22.489: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:24:23.490: INFO: Number of nodes with available pods: 1
May 26 16:24:23.490: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:24:24.483: INFO: Number of nodes with available pods: 3
May 26 16:24:24.483: INFO: Number of running nodes: 3, number of available pods: 3
May 26 16:24:24.483: INFO: Update the DaemonSet to trigger a rollout
May 26 16:24:24.520: INFO: Updating DaemonSet daemon-set
May 26 16:24:32.587: INFO: Roll back the DaemonSet before rollout is complete
May 26 16:24:32.625: INFO: Updating DaemonSet daemon-set
May 26 16:24:32.625: INFO: Make sure DaemonSet rollback is complete
May 26 16:24:32.658: INFO: Wrong image for pod: daemon-set-wj2lg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 26 16:24:32.658: INFO: Pod daemon-set-wj2lg is not available
May 26 16:24:33.686: INFO: Wrong image for pod: daemon-set-wj2lg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 26 16:24:33.686: INFO: Pod daemon-set-wj2lg is not available
May 26 16:24:34.683: INFO: Wrong image for pod: daemon-set-wj2lg. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 26 16:24:34.683: INFO: Pod daemon-set-wj2lg is not available
May 26 16:24:35.685: INFO: Pod daemon-set-cq6hd is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7520, will wait for the garbage collector to delete the pods
May 26 16:24:35.832: INFO: Deleting DaemonSet.extensions daemon-set took: 35.586102ms
May 26 16:24:36.032: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.417996ms
May 26 16:24:45.146: INFO: Number of nodes with available pods: 0
May 26 16:24:45.146: INFO: Number of running nodes: 0, number of available pods: 0
May 26 16:24:45.159: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7520/daemonsets","resourceVersion":"32017"},"items":null}

May 26 16:24:45.172: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7520/pods","resourceVersion":"32017"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:24:45.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7520" for this suite.
May 26 16:24:53.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:24:53.783: INFO: namespace daemonsets-7520 deletion completed in 8.538928886s

• [SLOW TEST:32.716 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:24:53.784: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May 26 16:25:24.678: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:25:24.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0526 16:25:24.678836      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3940" for this suite.
May 26 16:25:32.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:25:33.229: INFO: namespace gc-3940 deletion completed in 8.531998945s

• [SLOW TEST:39.445 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:25:33.229: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:25:33.501: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 26 16:25:38.513: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 26 16:25:38.513: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 26 16:25:40.526: INFO: Creating deployment "test-rollover-deployment"
May 26 16:25:40.556: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 26 16:25:42.589: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 26 16:25:42.617: INFO: Ensure that both replica sets have 1 created replica
May 26 16:25:42.645: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 26 16:25:42.671: INFO: Updating deployment test-rollover-deployment
May 26 16:25:42.671: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 26 16:25:44.698: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 26 16:25:44.722: INFO: Make sure deployment "test-rollover-deployment" is complete
May 26 16:25:44.751: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:44.752: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107142, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:46.779: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:46.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107145, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:48.782: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:48.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107145, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:50.784: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:50.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107145, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:52.783: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:52.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107145, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:54.784: INFO: all replica sets need to contain the pod-template-hash label
May 26 16:25:54.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107145, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726107140, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 16:25:56.785: INFO: 
May 26 16:25:56.785: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
May 26 16:25:56.841: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3670,SelfLink:/apis/apps/v1/namespaces/deployment-3670/deployments/test-rollover-deployment,UID:46345b40-0e11-410b-b023-d5b9c4284627,ResourceVersion:32335,Generation:2,CreationTimestamp:2020-05-26 16:25:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-05-26 16:25:40 +0000 UTC 2020-05-26 16:25:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-05-26 16:25:55 +0000 UTC 2020-05-26 16:25:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 26 16:25:56.857: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-3670,SelfLink:/apis/apps/v1/namespaces/deployment-3670/replicasets/test-rollover-deployment-854595fc44,UID:fe27b76e-63af-4f83-b143-3e3bd9a11c6c,ResourceVersion:32324,Generation:2,CreationTimestamp:2020-05-26 16:25:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46345b40-0e11-410b-b023-d5b9c4284627 0xc002d77b87 0xc002d77b88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 26 16:25:56.857: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 26 16:25:56.857: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3670,SelfLink:/apis/apps/v1/namespaces/deployment-3670/replicasets/test-rollover-controller,UID:7ad2b821-cb22-40ae-b029-840219f5a110,ResourceVersion:32333,Generation:2,CreationTimestamp:2020-05-26 16:25:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46345b40-0e11-410b-b023-d5b9c4284627 0xc002d77ab7 0xc002d77ab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:25:56.858: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-3670,SelfLink:/apis/apps/v1/namespaces/deployment-3670/replicasets/test-rollover-deployment-9b8b997cf,UID:7534d91d-f103-4516-9abd-56ed6938df92,ResourceVersion:32286,Generation:2,CreationTimestamp:2020-05-26 16:25:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46345b40-0e11-410b-b023-d5b9c4284627 0xc002d77e10 0xc002d77e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:25:56.871: INFO: Pod "test-rollover-deployment-854595fc44-fhdxh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-fhdxh,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-3670,SelfLink:/api/v1/namespaces/deployment-3670/pods/test-rollover-deployment-854595fc44-fhdxh,UID:6e7dd024-9c73-44e2-891d-118b93b130cd,ResourceVersion:32304,Generation:0,CreationTimestamp:2020-05-26 16:25:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 fe27b76e-63af-4f83-b143-3e3bd9a11c6c 0xc0030363e7 0xc0030363e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-m7m4f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m7m4f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-m7m4f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003036460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003036480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:25:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:25:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:25:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:25:42 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.254,StartTime:2020-05-26 16:25:42 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-05-26 16:25:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://77f7498af75fd6e0385757018496e47a773d0e6f35210dbbb8f07db54b1474da}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:25:56.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3670" for this suite.
May 26 16:26:04.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:26:05.464: INFO: namespace deployment-3670 deletion completed in 8.570952022s

• [SLOW TEST:32.235 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:26:05.468: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6772
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7836
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:26:31.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9492" for this suite.
May 26 16:26:37.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:26:37.934: INFO: namespace namespaces-9492 deletion completed in 6.554568716s
STEP: Destroying namespace "nsdeletetest-6772" for this suite.
May 26 16:26:37.944: INFO: Namespace nsdeletetest-6772 was already deleted
STEP: Destroying namespace "nsdeletetest-7836" for this suite.
May 26 16:26:43.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:26:44.437: INFO: namespace nsdeletetest-7836 deletion completed in 6.492991811s

• [SLOW TEST:38.970 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:26:44.440: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6872
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:26:44.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b" in namespace "downward-api-6872" to be "success or failure"
May 26 16:26:44.726: INFO: Pod "downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.62526ms
May 26 16:26:46.738: INFO: Pod "downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023468655s
May 26 16:26:48.751: INFO: Pod "downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036728866s
STEP: Saw pod success
May 26 16:26:48.752: INFO: Pod "downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b" satisfied condition "success or failure"
May 26 16:26:48.763: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b container client-container: <nil>
STEP: delete the pod
May 26 16:26:48.839: INFO: Waiting for pod downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b to disappear
May 26 16:26:48.851: INFO: Pod downwardapi-volume-7b7df695-f42f-4e33-81f0-10d3e8ea941b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:26:48.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6872" for this suite.
May 26 16:26:56.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:26:57.402: INFO: namespace downward-api-6872 deletion completed in 8.52944601s

• [SLOW TEST:12.962 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:26:57.403: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0526 16:27:37.796844      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 26 16:27:37.797: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:27:37.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-342" for this suite.
May 26 16:27:45.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:27:46.401: INFO: namespace gc-342 deletion completed in 8.590649007s

• [SLOW TEST:48.998 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:27:46.401: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7327.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7327.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 205.121.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.121.205_udp@PTR;check="$$(dig +tcp +noall +answer +search 205.121.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.121.205_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7327.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7327.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 205.121.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.121.205_udp@PTR;check="$$(dig +tcp +noall +answer +search 205.121.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.121.205_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 16:27:50.801: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:50.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:50.850: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:50.869: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:51.016: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:51.035: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:51.055: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:51.075: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:51.207: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:27:56.227: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.251: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.271: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.294: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.502: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.529: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.550: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.573: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:27:56.704: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:28:01.233: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.253: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.273: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.293: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.468: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.492: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.519: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.541: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:01.680: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:28:06.318: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.338: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.363: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.382: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.602: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.627: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.658: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.682: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:06.973: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:28:11.235: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.254: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.298: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.322: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.473: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.493: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.517: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.541: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:11.665: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:28:16.241: INFO: Unable to read wheezy_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.262: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.281: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.301: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.484: INFO: Unable to read jessie_udp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.518: INFO: Unable to read jessie_tcp@dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.561: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.593: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local from pod dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb: the server could not find the requested resource (get pods dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb)
May 26 16:28:16.776: INFO: Lookups using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb failed for: [wheezy_udp@dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@dns-test-service.dns-7327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_udp@dns-test-service.dns-7327.svc.cluster.local jessie_tcp@dns-test-service.dns-7327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7327.svc.cluster.local]

May 26 16:28:21.633: INFO: DNS probes using dns-7327/dns-test-1ab655dc-3b81-4fff-9d77-5ca1620490bb succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:28:21.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7327" for this suite.
May 26 16:28:29.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:28:30.479: INFO: namespace dns-7327 deletion completed in 8.580372557s

• [SLOW TEST:44.078 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:28:30.480: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:28:30.731: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:28:34.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9471" for this suite.
May 26 16:29:22.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:29:23.437: INFO: namespace pods-9471 deletion completed in 48.542552983s

• [SLOW TEST:52.958 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:29:23.438: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:29:23.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4695008a-ca87-4425-998c-405247979582" in namespace "projected-9576" to be "success or failure"
May 26 16:29:23.749: INFO: Pod "downwardapi-volume-4695008a-ca87-4425-998c-405247979582": Phase="Pending", Reason="", readiness=false. Elapsed: 29.749957ms
May 26 16:29:25.764: INFO: Pod "downwardapi-volume-4695008a-ca87-4425-998c-405247979582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043838177s
STEP: Saw pod success
May 26 16:29:25.764: INFO: Pod "downwardapi-volume-4695008a-ca87-4425-998c-405247979582" satisfied condition "success or failure"
May 26 16:29:25.776: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-4695008a-ca87-4425-998c-405247979582 container client-container: <nil>
STEP: delete the pod
May 26 16:29:25.856: INFO: Waiting for pod downwardapi-volume-4695008a-ca87-4425-998c-405247979582 to disappear
May 26 16:29:25.868: INFO: Pod downwardapi-volume-4695008a-ca87-4425-998c-405247979582 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:29:25.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9576" for this suite.
May 26 16:29:33.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:29:34.475: INFO: namespace projected-9576 deletion completed in 8.58417317s

• [SLOW TEST:11.037 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:29:34.489: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-547f4919-0aba-47a1-9c9e-9fe7af44b1ca
STEP: Creating a pod to test consume configMaps
May 26 16:29:34.788: INFO: Waiting up to 5m0s for pod "pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0" in namespace "configmap-2163" to be "success or failure"
May 26 16:29:34.800: INFO: Pod "pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.689264ms
May 26 16:29:36.812: INFO: Pod "pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024041421s
May 26 16:29:38.825: INFO: Pod "pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036488938s
STEP: Saw pod success
May 26 16:29:38.825: INFO: Pod "pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0" satisfied condition "success or failure"
May 26 16:29:38.840: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:29:38.916: INFO: Waiting for pod pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0 to disappear
May 26 16:29:38.928: INFO: Pod pod-configmaps-85dbd57c-1aa1-4a26-ac6e-98211d5a73b0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:29:38.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2163" for this suite.
May 26 16:29:47.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:29:47.521: INFO: namespace configmap-2163 deletion completed in 8.555406382s

• [SLOW TEST:13.032 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:29:47.521: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:29:47.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7860086-f683-4961-a947-651a6680228a" in namespace "downward-api-2884" to be "success or failure"
May 26 16:29:47.814: INFO: Pod "downwardapi-volume-e7860086-f683-4961-a947-651a6680228a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.636203ms
May 26 16:29:49.832: INFO: Pod "downwardapi-volume-e7860086-f683-4961-a947-651a6680228a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029643485s
STEP: Saw pod success
May 26 16:29:49.832: INFO: Pod "downwardapi-volume-e7860086-f683-4961-a947-651a6680228a" satisfied condition "success or failure"
May 26 16:29:49.854: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-e7860086-f683-4961-a947-651a6680228a container client-container: <nil>
STEP: delete the pod
May 26 16:29:49.964: INFO: Waiting for pod downwardapi-volume-e7860086-f683-4961-a947-651a6680228a to disappear
May 26 16:29:49.979: INFO: Pod downwardapi-volume-e7860086-f683-4961-a947-651a6680228a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:29:49.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2884" for this suite.
May 26 16:29:56.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:29:56.519: INFO: namespace downward-api-2884 deletion completed in 6.520859798s

• [SLOW TEST:8.998 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:29:56.520: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-10b04e79-30a0-4bb6-bf75-10e3d505fe0f
STEP: Creating a pod to test consume secrets
May 26 16:29:56.820: INFO: Waiting up to 5m0s for pod "pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583" in namespace "secrets-6619" to be "success or failure"
May 26 16:29:56.831: INFO: Pod "pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583": Phase="Pending", Reason="", readiness=false. Elapsed: 11.35947ms
May 26 16:29:58.843: INFO: Pod "pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023125017s
STEP: Saw pod success
May 26 16:29:58.843: INFO: Pod "pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583" satisfied condition "success or failure"
May 26 16:29:58.855: INFO: Trying to get logs from node 10.113.231.185 pod pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583 container secret-volume-test: <nil>
STEP: delete the pod
May 26 16:29:58.929: INFO: Waiting for pod pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583 to disappear
May 26 16:29:58.938: INFO: Pod pod-secrets-ec920bc2-a868-4c1b-8778-a0101ae48583 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:29:58.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6619" for this suite.
May 26 16:30:07.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:30:07.522: INFO: namespace secrets-6619 deletion completed in 8.566217931s

• [SLOW TEST:11.002 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:30:07.522: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-2f68ee34-e77e-4680-957b-5e76e2f34d38
STEP: Creating secret with name secret-projected-all-test-volume-ea5f7a13-6bd2-46f0-9e1b-253411aac229
STEP: Creating a pod to test Check all projections for projected volume plugin
May 26 16:30:07.838: INFO: Waiting up to 5m0s for pod "projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726" in namespace "projected-9308" to be "success or failure"
May 26 16:30:07.867: INFO: Pod "projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726": Phase="Pending", Reason="", readiness=false. Elapsed: 28.544908ms
May 26 16:30:09.891: INFO: Pod "projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052717572s
May 26 16:30:11.903: INFO: Pod "projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065018256s
STEP: Saw pod success
May 26 16:30:11.903: INFO: Pod "projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726" satisfied condition "success or failure"
May 26 16:30:11.915: INFO: Trying to get logs from node 10.113.231.133 pod projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726 container projected-all-volume-test: <nil>
STEP: delete the pod
May 26 16:30:12.004: INFO: Waiting for pod projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726 to disappear
May 26 16:30:12.016: INFO: Pod projected-volume-1ee2dbd7-271f-423e-840b-9ebe8e866726 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:30:12.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9308" for this suite.
May 26 16:30:20.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:30:20.624: INFO: namespace projected-9308 deletion completed in 8.588913058s

• [SLOW TEST:13.101 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:30:20.624: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
May 26 16:30:20.890: INFO: Waiting up to 5m0s for pod "pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d" in namespace "emptydir-7508" to be "success or failure"
May 26 16:30:20.901: INFO: Pod "pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.300966ms
May 26 16:30:22.913: INFO: Pod "pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023021092s
STEP: Saw pod success
May 26 16:30:22.913: INFO: Pod "pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d" satisfied condition "success or failure"
May 26 16:30:22.928: INFO: Trying to get logs from node 10.113.231.144 pod pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d container test-container: <nil>
STEP: delete the pod
May 26 16:30:23.016: INFO: Waiting for pod pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d to disappear
May 26 16:30:23.030: INFO: Pod pod-5b05d065-ec3f-4b97-9013-0f8f5bfad03d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:30:23.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7508" for this suite.
May 26 16:30:31.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:30:31.571: INFO: namespace emptydir-7508 deletion completed in 8.521523047s

• [SLOW TEST:10.947 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:30:31.571: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-261
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 26 16:30:33.922: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:30:33.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-261" for this suite.
May 26 16:30:42.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:30:42.754: INFO: namespace container-runtime-261 deletion completed in 8.710644637s

• [SLOW TEST:11.183 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:30:42.754: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-1223/secret-test-3b4f8768-6d9d-46da-bc04-95705c297e40
STEP: Creating a pod to test consume secrets
May 26 16:30:43.060: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047" in namespace "secrets-1223" to be "success or failure"
May 26 16:30:43.071: INFO: Pod "pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047": Phase="Pending", Reason="", readiness=false. Elapsed: 11.064607ms
May 26 16:30:45.082: INFO: Pod "pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022593494s
May 26 16:30:47.094: INFO: Pod "pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034307291s
STEP: Saw pod success
May 26 16:30:47.094: INFO: Pod "pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047" satisfied condition "success or failure"
May 26 16:30:47.105: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047 container env-test: <nil>
STEP: delete the pod
May 26 16:30:47.187: INFO: Waiting for pod pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047 to disappear
May 26 16:30:47.206: INFO: Pod pod-configmaps-0e191c75-e237-40b7-8d8a-54295e5a0047 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:30:47.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1223" for this suite.
May 26 16:30:53.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:30:53.765: INFO: namespace secrets-1223 deletion completed in 6.540320554s

• [SLOW TEST:11.011 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:30:53.767: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
May 26 16:30:54.056: INFO: Waiting up to 5m0s for pod "client-containers-70c94858-674b-4b43-92ec-96994647a5e4" in namespace "containers-1666" to be "success or failure"
May 26 16:30:54.071: INFO: Pod "client-containers-70c94858-674b-4b43-92ec-96994647a5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.123178ms
May 26 16:30:56.086: INFO: Pod "client-containers-70c94858-674b-4b43-92ec-96994647a5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029840123s
May 26 16:30:58.099: INFO: Pod "client-containers-70c94858-674b-4b43-92ec-96994647a5e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042297266s
STEP: Saw pod success
May 26 16:30:58.099: INFO: Pod "client-containers-70c94858-674b-4b43-92ec-96994647a5e4" satisfied condition "success or failure"
May 26 16:30:58.111: INFO: Trying to get logs from node 10.113.231.144 pod client-containers-70c94858-674b-4b43-92ec-96994647a5e4 container test-container: <nil>
STEP: delete the pod
May 26 16:30:58.186: INFO: Waiting for pod client-containers-70c94858-674b-4b43-92ec-96994647a5e4 to disappear
May 26 16:30:58.199: INFO: Pod client-containers-70c94858-674b-4b43-92ec-96994647a5e4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:30:58.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1666" for this suite.
May 26 16:31:06.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:31:06.859: INFO: namespace containers-1666 deletion completed in 8.643052603s

• [SLOW TEST:13.093 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:31:06.865: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:31:07.225: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 26 16:31:07.259: INFO: Number of nodes with available pods: 0
May 26 16:31:07.259: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 26 16:31:07.326: INFO: Number of nodes with available pods: 0
May 26 16:31:07.326: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:08.339: INFO: Number of nodes with available pods: 0
May 26 16:31:08.339: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:09.339: INFO: Number of nodes with available pods: 1
May 26 16:31:09.339: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 26 16:31:09.406: INFO: Number of nodes with available pods: 1
May 26 16:31:09.406: INFO: Number of running nodes: 0, number of available pods: 1
May 26 16:31:10.419: INFO: Number of nodes with available pods: 0
May 26 16:31:10.419: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 26 16:31:10.454: INFO: Number of nodes with available pods: 0
May 26 16:31:10.454: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:11.468: INFO: Number of nodes with available pods: 0
May 26 16:31:11.468: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:12.466: INFO: Number of nodes with available pods: 0
May 26 16:31:12.466: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:13.465: INFO: Number of nodes with available pods: 0
May 26 16:31:13.465: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:14.466: INFO: Number of nodes with available pods: 0
May 26 16:31:14.466: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:15.468: INFO: Number of nodes with available pods: 1
May 26 16:31:15.468: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2699, will wait for the garbage collector to delete the pods
May 26 16:31:15.628: INFO: Deleting DaemonSet.extensions daemon-set took: 40.896668ms
May 26 16:31:15.828: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.317993ms
May 26 16:31:19.443: INFO: Number of nodes with available pods: 0
May 26 16:31:19.443: INFO: Number of running nodes: 0, number of available pods: 0
May 26 16:31:19.458: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2699/daemonsets","resourceVersion":"33767"},"items":null}

May 26 16:31:19.470: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2699/pods","resourceVersion":"33767"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:31:19.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2699" for this suite.
May 26 16:31:27.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:31:28.084: INFO: namespace daemonsets-2699 deletion completed in 8.515434155s

• [SLOW TEST:21.220 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:31:28.085: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:31:28.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1" in namespace "projected-3836" to be "success or failure"
May 26 16:31:28.450: INFO: Pod "downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.348723ms
May 26 16:31:30.463: INFO: Pod "downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023634186s
STEP: Saw pod success
May 26 16:31:30.463: INFO: Pod "downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1" satisfied condition "success or failure"
May 26 16:31:30.473: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1 container client-container: <nil>
STEP: delete the pod
May 26 16:31:30.549: INFO: Waiting for pod downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1 to disappear
May 26 16:31:30.560: INFO: Pod downwardapi-volume-2c740f8f-4e0c-4523-a756-7395236981a1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:31:30.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3836" for this suite.
May 26 16:31:38.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:31:39.105: INFO: namespace projected-3836 deletion completed in 8.524415529s

• [SLOW TEST:11.020 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:31:39.106: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 26 16:31:39.474: INFO: Number of nodes with available pods: 0
May 26 16:31:39.474: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:40.504: INFO: Number of nodes with available pods: 0
May 26 16:31:40.504: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:41.513: INFO: Number of nodes with available pods: 1
May 26 16:31:41.513: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:31:42.505: INFO: Number of nodes with available pods: 3
May 26 16:31:42.505: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 26 16:31:42.590: INFO: Number of nodes with available pods: 2
May 26 16:31:42.590: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:43.617: INFO: Number of nodes with available pods: 2
May 26 16:31:43.617: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:31:44.623: INFO: Number of nodes with available pods: 3
May 26 16:31:44.623: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8718, will wait for the garbage collector to delete the pods
May 26 16:31:44.757: INFO: Deleting DaemonSet.extensions daemon-set took: 34.41689ms
May 26 16:31:44.958: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.307043ms
May 26 16:31:55.178: INFO: Number of nodes with available pods: 0
May 26 16:31:55.178: INFO: Number of running nodes: 0, number of available pods: 0
May 26 16:31:55.193: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8718/daemonsets","resourceVersion":"33984"},"items":null}

May 26 16:31:55.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8718/pods","resourceVersion":"33984"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:31:55.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8718" for this suite.
May 26 16:32:03.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:32:03.790: INFO: namespace daemonsets-8718 deletion completed in 8.515234743s

• [SLOW TEST:24.684 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:32:03.791: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0526 16:32:04.848439      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 26 16:32:04.848: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:32:04.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9557" for this suite.
May 26 16:32:12.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:32:13.423: INFO: namespace gc-9557 deletion completed in 8.55659248s

• [SLOW TEST:9.632 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:32:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
May 26 16:32:17.789: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-131493333 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 26 16:32:33.008: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:32:33.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2590" for this suite.
May 26 16:32:39.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:32:39.538: INFO: namespace pods-2590 deletion completed in 6.502226749s

• [SLOW TEST:26.114 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:32:39.538: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5605
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-4rkw
STEP: Creating a pod to test atomic-volume-subpath
May 26 16:32:39.852: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4rkw" in namespace "subpath-5605" to be "success or failure"
May 26 16:32:39.872: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Pending", Reason="", readiness=false. Elapsed: 20.692494ms
May 26 16:32:41.884: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 2.032293298s
May 26 16:32:43.899: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 4.046969862s
May 26 16:32:45.914: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 6.062800263s
May 26 16:32:47.929: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 8.077712372s
May 26 16:32:49.944: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 10.092051352s
May 26 16:32:51.958: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 12.106501106s
May 26 16:32:53.971: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 14.11889853s
May 26 16:32:55.982: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 16.130009117s
May 26 16:32:57.994: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 18.142431963s
May 26 16:33:00.006: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Running", Reason="", readiness=true. Elapsed: 20.154702261s
May 26 16:33:02.020: INFO: Pod "pod-subpath-test-configmap-4rkw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.168301585s
STEP: Saw pod success
May 26 16:33:02.020: INFO: Pod "pod-subpath-test-configmap-4rkw" satisfied condition "success or failure"
May 26 16:33:02.034: INFO: Trying to get logs from node 10.113.231.133 pod pod-subpath-test-configmap-4rkw container test-container-subpath-configmap-4rkw: <nil>
STEP: delete the pod
May 26 16:33:02.342: INFO: Waiting for pod pod-subpath-test-configmap-4rkw to disappear
May 26 16:33:02.358: INFO: Pod pod-subpath-test-configmap-4rkw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4rkw
May 26 16:33:02.358: INFO: Deleting pod "pod-subpath-test-configmap-4rkw" in namespace "subpath-5605"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:33:02.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5605" for this suite.
May 26 16:33:10.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:33:11.049: INFO: namespace subpath-5605 deletion completed in 8.657068272s

• [SLOW TEST:31.511 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:33:11.049: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9931
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
May 26 16:33:11.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-9931'
May 26 16:33:12.041: INFO: stderr: ""
May 26 16:33:12.041: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 16:33:12.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9931'
May 26 16:33:12.208: INFO: stderr: ""
May 26 16:33:12.208: INFO: stdout: "update-demo-nautilus-7rn2w update-demo-nautilus-xtcxh "
May 26 16:33:12.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-7rn2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:12.356: INFO: stderr: ""
May 26 16:33:12.356: INFO: stdout: ""
May 26 16:33:12.356: INFO: update-demo-nautilus-7rn2w is created but not running
May 26 16:33:17.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9931'
May 26 16:33:17.519: INFO: stderr: ""
May 26 16:33:17.519: INFO: stdout: "update-demo-nautilus-7rn2w update-demo-nautilus-xtcxh "
May 26 16:33:17.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-7rn2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:17.667: INFO: stderr: ""
May 26 16:33:17.667: INFO: stdout: "true"
May 26 16:33:17.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-7rn2w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:17.812: INFO: stderr: ""
May 26 16:33:17.812: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:33:17.812: INFO: validating pod update-demo-nautilus-7rn2w
May 26 16:33:17.846: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:33:17.846: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:33:17.846: INFO: update-demo-nautilus-7rn2w is verified up and running
May 26 16:33:17.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-xtcxh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:18.004: INFO: stderr: ""
May 26 16:33:18.004: INFO: stdout: "true"
May 26 16:33:18.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-nautilus-xtcxh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:18.156: INFO: stderr: ""
May 26 16:33:18.156: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 26 16:33:18.156: INFO: validating pod update-demo-nautilus-xtcxh
May 26 16:33:18.182: INFO: got data: {
  "image": "nautilus.jpg"
}

May 26 16:33:18.182: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 26 16:33:18.182: INFO: update-demo-nautilus-xtcxh is verified up and running
STEP: rolling-update to new replication controller
May 26 16:33:18.184: INFO: scanned /root for discovery docs: <nil>
May 26 16:33:18.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9931'
May 26 16:33:41.289: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 26 16:33:41.289: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 26 16:33:41.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9931'
May 26 16:33:41.435: INFO: stderr: ""
May 26 16:33:41.435: INFO: stdout: "update-demo-kitten-2g9bv update-demo-kitten-q7pqp "
May 26 16:33:41.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-kitten-2g9bv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:41.572: INFO: stderr: ""
May 26 16:33:41.572: INFO: stdout: "true"
May 26 16:33:41.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-kitten-2g9bv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:41.733: INFO: stderr: ""
May 26 16:33:41.733: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 26 16:33:41.733: INFO: validating pod update-demo-kitten-2g9bv
May 26 16:33:41.764: INFO: got data: {
  "image": "kitten.jpg"
}

May 26 16:33:41.764: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 26 16:33:41.764: INFO: update-demo-kitten-2g9bv is verified up and running
May 26 16:33:41.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-kitten-q7pqp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:41.899: INFO: stderr: ""
May 26 16:33:41.899: INFO: stdout: "true"
May 26 16:33:41.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods update-demo-kitten-q7pqp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9931'
May 26 16:33:42.041: INFO: stderr: ""
May 26 16:33:42.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 26 16:33:42.041: INFO: validating pod update-demo-kitten-q7pqp
May 26 16:33:42.088: INFO: got data: {
  "image": "kitten.jpg"
}

May 26 16:33:42.088: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 26 16:33:42.088: INFO: update-demo-kitten-q7pqp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:33:42.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9931" for this suite.
May 26 16:34:06.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:34:06.670: INFO: namespace kubectl-9931 deletion completed in 24.565454015s

• [SLOW TEST:55.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:34:06.671: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:34:06.931: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:34:11.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5218" for this suite.
May 26 16:34:57.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:34:57.808: INFO: namespace pods-5218 deletion completed in 46.56239813s

• [SLOW TEST:51.138 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:34:57.809: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1359
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-4c0fff58-6c2f-49b7-b964-28dfd5e68c58
STEP: Creating a pod to test consume configMaps
May 26 16:34:58.108: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86" in namespace "projected-1359" to be "success or failure"
May 26 16:34:58.118: INFO: Pod "pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86": Phase="Pending", Reason="", readiness=false. Elapsed: 10.622436ms
May 26 16:35:00.138: INFO: Pod "pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030600214s
STEP: Saw pod success
May 26 16:35:00.138: INFO: Pod "pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86" satisfied condition "success or failure"
May 26 16:35:00.150: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:35:00.251: INFO: Waiting for pod pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86 to disappear
May 26 16:35:00.263: INFO: Pod pod-projected-configmaps-b4981fba-8330-43ad-9bf3-df0ecb816e86 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:35:00.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1359" for this suite.
May 26 16:35:08.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:35:08.902: INFO: namespace projected-1359 deletion completed in 8.620995457s

• [SLOW TEST:11.094 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:35:08.910: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:35:09.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-2988'
May 26 16:35:09.714: INFO: stderr: ""
May 26 16:35:09.714: INFO: stdout: "replicationcontroller/redis-master created\n"
May 26 16:35:09.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-2988'
May 26 16:35:09.997: INFO: stderr: ""
May 26 16:35:09.997: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 26 16:35:11.010: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:35:11.010: INFO: Found 0 / 1
May 26 16:35:12.013: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:35:12.013: INFO: Found 1 / 1
May 26 16:35:12.013: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 26 16:35:12.026: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:35:12.026: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 26 16:35:12.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 describe pod redis-master-k25jz --namespace=kubectl-2988'
May 26 16:35:12.196: INFO: stderr: ""
May 26 16:35:12.196: INFO: stdout: "Name:           redis-master-k25jz\nNamespace:      kubectl-2988\nPriority:       0\nNode:           10.113.231.185/10.113.231.185\nStart Time:     Tue, 26 May 2020 16:35:09 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.57.206\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://5af05111cb207fa422bcdd3154f9f4611ded734766c2ba11cdab6166d84396dd\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 26 May 2020 16:35:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-nmltz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-nmltz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-nmltz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned kubectl-2988/redis-master-k25jz to 10.113.231.185\n  Normal  Pulled     2s    kubelet, 10.113.231.185  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.113.231.185  Created container redis-master\n  Normal  Started    1s    kubelet, 10.113.231.185  Started container redis-master\n"
May 26 16:35:12.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 describe rc redis-master --namespace=kubectl-2988'
May 26 16:35:12.409: INFO: stderr: ""
May 26 16:35:12.409: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2988\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-k25jz\n"
May 26 16:35:12.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 describe service redis-master --namespace=kubectl-2988'
May 26 16:35:12.603: INFO: stderr: ""
May 26 16:35:12.603: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2988\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.236.252\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.57.206:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 26 16:35:12.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 describe node 10.113.231.133'
May 26 16:35:12.836: INFO: stderr: ""
May 26 16:35:12.836: INFO: stdout: "Name:               10.113.231.133\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-gb\n                    failure-domain.beta.kubernetes.io/zone=lon02\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=159.8.141.20\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.113.231.133\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=eu-gb\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-br6hn8ql0obpu0v8me50-kubee2epvgp-default-00000133\n                    ibm-cloud.kubernetes.io/worker-pool-id=br6hn8ql0obpu0v8me50-fc31757\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.11_1538\n                    ibm-cloud.kubernetes.io/zone=lon02\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.113.231.133\n                    kubernetes.io/os=linux\n                    privateVLAN=2747290\n                    publicVLAN=2747292\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 May 2020 13:52:26 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 26 May 2020 16:34:31 +0000   Tue, 26 May 2020 13:52:26 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 26 May 2020 16:34:31 +0000   Tue, 26 May 2020 13:52:26 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 26 May 2020 16:34:31 +0000   Tue, 26 May 2020 13:52:26 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 26 May 2020 16:34:31 +0000   Tue, 26 May 2020 13:52:36 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.113.231.133\n  ExternalIP:  159.8.141.20\n  Hostname:    10.113.231.133\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419684Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627236Ki\n pods:               110\nSystem Info:\n Machine ID:                 4a3db72740e0428eabc70e7df71819e9\n System UUID:                FE7BC20A-E43F-539D-DF8C-8CBAD68C6CF6\n Boot ID:                    73942067-415b-4d13-8faa-0c0f5eb025d1\n Kernel Version:             4.15.0-99-generic\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.13\n Kubelet Version:            v1.15.11+IKS\n Kube-Proxy Version:         v1.15.11+IKS\nProviderID:                  ibm://fee034388aa6435883a1f720010ab3a2///br6hn8ql0obpu0v8me50/kube-br6hn8ql0obpu0v8me50-kubee2epvgp-default-00000133\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         159m\n  kube-system                calico-node-qw94x                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         162m\n  kube-system                coredns-c6797c986-wbcgx                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     138m\n  kube-system                ibm-file-plugin-5bcd9c888c-s8l25                           50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         167m\n  kube-system                ibm-keepalived-watcher-p8dn5                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         162m\n  kube-system                ibm-master-proxy-static-10.113.231.133                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      162m\n  kube-system                metrics-server-875894b87-5gbms                             121m (3%)     216m (5%)   186Mi (1%)       436Mi (3%)     162m\n  kube-system                vpn-bd4d5cff7-mtlkg                                        5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         139m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-088c5a8cf8c74722-97kmg    0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                556m (14%)     716m (18%)\n  memory             493074Ki (3%)  1356064Ki (9%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
May 26 16:35:12.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 describe namespace kubectl-2988'
May 26 16:35:13.039: INFO: stderr: ""
May 26 16:35:13.040: INFO: stdout: "Name:         kubectl-2988\nLabels:       e2e-framework=kubectl\n              e2e-run=f315a9d6-cd36-43db-982d-be002eec603a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:35:13.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2988" for this suite.
May 26 16:35:37.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:35:37.642: INFO: namespace kubectl-2988 deletion completed in 24.577960564s

• [SLOW TEST:28.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:35:37.643: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9568
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-30ef69a6-8b30-4897-8523-f278e99e51c3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-30ef69a6-8b30-4897-8523-f278e99e51c3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:35:42.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9568" for this suite.
May 26 16:36:06.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:36:06.707: INFO: namespace projected-9568 deletion completed in 24.565594881s

• [SLOW TEST:29.064 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:36:06.708: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8240/configmap-test-c212159c-6fd5-4033-b0ad-295061eda8d0
STEP: Creating a pod to test consume configMaps
May 26 16:36:07.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88" in namespace "configmap-8240" to be "success or failure"
May 26 16:36:07.100: INFO: Pod "pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88": Phase="Pending", Reason="", readiness=false. Elapsed: 10.609767ms
May 26 16:36:09.113: INFO: Pod "pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022654238s
STEP: Saw pod success
May 26 16:36:09.113: INFO: Pod "pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88" satisfied condition "success or failure"
May 26 16:36:09.123: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88 container env-test: <nil>
STEP: delete the pod
May 26 16:36:09.221: INFO: Waiting for pod pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88 to disappear
May 26 16:36:09.233: INFO: Pod pod-configmaps-5da429e3-bb54-4cbf-8b42-a9d982effc88 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:36:09.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8240" for this suite.
May 26 16:36:17.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:36:17.784: INFO: namespace configmap-8240 deletion completed in 8.531602954s

• [SLOW TEST:11.076 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:36:17.785: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f in namespace container-probe-9541
May 26 16:36:22.067: INFO: Started pod liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f in namespace container-probe-9541
STEP: checking the pod's current state and verifying that restartCount is present
May 26 16:36:22.082: INFO: Initial restart count of pod liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is 0
May 26 16:36:38.202: INFO: Restart count of pod container-probe-9541/liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is now 1 (16.119648563s elapsed)
May 26 16:36:58.337: INFO: Restart count of pod container-probe-9541/liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is now 2 (36.254433867s elapsed)
May 26 16:37:18.478: INFO: Restart count of pod container-probe-9541/liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is now 3 (56.395328818s elapsed)
May 26 16:37:36.832: INFO: Restart count of pod container-probe-9541/liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is now 4 (1m14.750205888s elapsed)
May 26 16:38:37.252: INFO: Restart count of pod container-probe-9541/liveness-d75ee534-5d9c-44c0-8453-ed3948c8934f is now 5 (2m15.169994115s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:38:37.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9541" for this suite.
May 26 16:38:45.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:38:46.249: INFO: namespace container-probe-9541 deletion completed in 8.942800243s

• [SLOW TEST:148.464 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:38:46.249: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
May 26 16:38:46.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-5102'
May 26 16:38:46.861: INFO: stderr: ""
May 26 16:38:46.861: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
May 26 16:38:47.876: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:38:47.876: INFO: Found 0 / 1
May 26 16:38:49.211: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:38:49.211: INFO: Found 0 / 1
May 26 16:38:49.874: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:38:49.874: INFO: Found 1 / 1
May 26 16:38:49.874: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 26 16:38:49.884: INFO: Selector matched 1 pods for map[app:redis]
May 26 16:38:49.884: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 26 16:38:49.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102'
May 26 16:38:50.064: INFO: stderr: ""
May 26 16:38:50.064: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 May 16:38:48.235 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 May 16:38:48.235 # Server started, Redis version 3.2.12\n1:M 26 May 16:38:48.235 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 May 16:38:48.235 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 26 16:38:50.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102 --tail=1'
May 26 16:38:50.262: INFO: stderr: ""
May 26 16:38:50.262: INFO: stdout: "1:M 26 May 16:38:48.235 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 26 16:38:50.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102 --limit-bytes=1'
May 26 16:38:50.446: INFO: stderr: ""
May 26 16:38:50.446: INFO: stdout: " "
STEP: exposing timestamps
May 26 16:38:50.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102 --tail=1 --timestamps'
May 26 16:38:50.638: INFO: stderr: ""
May 26 16:38:50.638: INFO: stdout: "2020-05-26T16:38:48.235922767Z 1:M 26 May 16:38:48.235 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 26 16:38:53.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102 --since=1s'
May 26 16:38:53.341: INFO: stderr: ""
May 26 16:38:53.341: INFO: stdout: ""
May 26 16:38:53.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 logs redis-master-qxmcd redis-master --namespace=kubectl-5102 --since=24h'
May 26 16:38:54.282: INFO: stderr: ""
May 26 16:38:54.282: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 May 16:38:48.235 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 May 16:38:48.235 # Server started, Redis version 3.2.12\n1:M 26 May 16:38:48.235 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 May 16:38:48.235 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
May 26 16:38:54.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-5102'
May 26 16:38:54.463: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:38:54.463: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 26 16:38:54.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get rc,svc -l name=nginx --no-headers --namespace=kubectl-5102'
May 26 16:38:54.649: INFO: stderr: "No resources found.\n"
May 26 16:38:54.649: INFO: stdout: ""
May 26 16:38:54.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -l name=nginx --namespace=kubectl-5102 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 26 16:38:54.796: INFO: stderr: ""
May 26 16:38:54.796: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:38:54.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5102" for this suite.
May 26 16:39:18.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:39:19.475: INFO: namespace kubectl-5102 deletion completed in 24.659367983s

• [SLOW TEST:33.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:39:19.476: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
May 26 16:39:22.350: INFO: Successfully updated pod "annotationupdatea10789ad-e8bb-4715-b578-3d673f65a232"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:39:24.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3927" for this suite.
May 26 16:39:40.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:39:40.974: INFO: namespace projected-3927 deletion completed in 16.535505985s

• [SLOW TEST:21.498 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:39:40.975: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:39:41.278: INFO: (0) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.10662ms)
May 26 16:39:41.300: INFO: (1) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.745971ms)
May 26 16:39:41.326: INFO: (2) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.34547ms)
May 26 16:39:41.347: INFO: (3) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.446709ms)
May 26 16:39:41.369: INFO: (4) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.489347ms)
May 26 16:39:41.390: INFO: (5) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.028273ms)
May 26 16:39:41.413: INFO: (6) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.494923ms)
May 26 16:39:41.436: INFO: (7) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.036225ms)
May 26 16:39:41.459: INFO: (8) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.381571ms)
May 26 16:39:41.481: INFO: (9) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.511598ms)
May 26 16:39:41.502: INFO: (10) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.800962ms)
May 26 16:39:41.523: INFO: (11) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.531597ms)
May 26 16:39:41.549: INFO: (12) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 25.852657ms)
May 26 16:39:41.583: INFO: (13) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.155254ms)
May 26 16:39:41.606: INFO: (14) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.659677ms)
May 26 16:39:41.629: INFO: (15) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.084769ms)
May 26 16:39:41.650: INFO: (16) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.958019ms)
May 26 16:39:41.673: INFO: (17) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.755393ms)
May 26 16:39:41.708: INFO: (18) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 35.469203ms)
May 26 16:39:41.734: INFO: (19) /api/v1/nodes/10.113.231.133:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 25.188663ms)
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:39:41.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8216" for this suite.
May 26 16:39:47.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:39:48.282: INFO: namespace proxy-8216 deletion completed in 6.531293728s

• [SLOW TEST:7.307 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:39:48.283: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-6nwg
STEP: Creating a pod to test atomic-volume-subpath
May 26 16:39:48.583: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6nwg" in namespace "subpath-6201" to be "success or failure"
May 26 16:39:48.593: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085434ms
May 26 16:39:50.607: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024668825s
May 26 16:39:52.624: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 4.041678104s
May 26 16:39:54.636: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 6.053034938s
May 26 16:39:56.650: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 8.067435105s
May 26 16:39:58.668: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 10.085319116s
May 26 16:40:00.681: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 12.098709709s
May 26 16:40:02.697: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 14.11445347s
May 26 16:40:04.712: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 16.129579199s
May 26 16:40:06.724: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 18.141199815s
May 26 16:40:08.737: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 20.154278644s
May 26 16:40:10.749: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Running", Reason="", readiness=true. Elapsed: 22.166653282s
May 26 16:40:12.762: INFO: Pod "pod-subpath-test-secret-6nwg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.179506795s
STEP: Saw pod success
May 26 16:40:12.763: INFO: Pod "pod-subpath-test-secret-6nwg" satisfied condition "success or failure"
May 26 16:40:12.775: INFO: Trying to get logs from node 10.113.231.144 pod pod-subpath-test-secret-6nwg container test-container-subpath-secret-6nwg: <nil>
STEP: delete the pod
May 26 16:40:12.847: INFO: Waiting for pod pod-subpath-test-secret-6nwg to disappear
May 26 16:40:12.856: INFO: Pod pod-subpath-test-secret-6nwg no longer exists
STEP: Deleting pod pod-subpath-test-secret-6nwg
May 26 16:40:12.856: INFO: Deleting pod "pod-subpath-test-secret-6nwg" in namespace "subpath-6201"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:40:12.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6201" for this suite.
May 26 16:40:20.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:40:21.375: INFO: namespace subpath-6201 deletion completed in 8.490957269s

• [SLOW TEST:33.092 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:40:21.383: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 26 16:40:29.760: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:29.778: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:31.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:31.790: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:33.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:33.793: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:35.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:35.790: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:37.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:37.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:39.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:39.789: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:41.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:41.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:43.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:43.793: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:45.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:45.794: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:47.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:47.796: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:49.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:49.794: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:51.787: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:51.800: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:53.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:53.795: INFO: Pod pod-with-prestop-exec-hook still exists
May 26 16:40:55.778: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 26 16:40:55.789: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:40:55.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2842" for this suite.
May 26 16:41:19.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:41:20.449: INFO: namespace container-lifecycle-hook-2842 deletion completed in 24.538005766s

• [SLOW TEST:59.067 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:41:20.451: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:41:20.697: INFO: Creating deployment "nginx-deployment"
May 26 16:41:20.712: INFO: Waiting for observed generation 1
May 26 16:41:22.740: INFO: Waiting for all required pods to come up
May 26 16:41:22.756: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 26 16:41:24.794: INFO: Waiting for deployment "nginx-deployment" to complete
May 26 16:41:24.819: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 26 16:41:24.847: INFO: Updating deployment nginx-deployment
May 26 16:41:24.847: INFO: Waiting for observed generation 2
May 26 16:41:26.888: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 26 16:41:26.902: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 26 16:41:26.914: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 26 16:41:26.958: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 26 16:41:26.958: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 26 16:41:26.977: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 26 16:41:27.003: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 26 16:41:27.003: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 26 16:41:27.038: INFO: Updating deployment nginx-deployment
May 26 16:41:27.039: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 26 16:41:27.071: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 26 16:41:29.117: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
May 26 16:41:29.167: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1957,SelfLink:/apis/apps/v1/namespaces/deployment-1957/deployments/nginx-deployment,UID:85bcc24f-7b15-40dc-8ef4-c7e9f16588f5,ResourceVersion:36202,Generation:3,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[{Available False 2020-05-26 16:41:27 +0000 UTC 2020-05-26 16:41:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-05-26 16:41:29 +0000 UTC 2020-05-26 16:41:20 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:10,CollisionCount:nil,},}

May 26 16:41:29.187: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-1957,SelfLink:/apis/apps/v1/namespaces/deployment-1957/replicasets/nginx-deployment-55fb7cb77f,UID:c36a8494-4652-4cf0-93a1-d7a5fc4de785,ResourceVersion:36045,Generation:3,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 85bcc24f-7b15-40dc-8ef4-c7e9f16588f5 0xc00331c0a7 0xc00331c0a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 26 16:41:29.187: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 26 16:41:29.187: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-1957,SelfLink:/apis/apps/v1/namespaces/deployment-1957/replicasets/nginx-deployment-7b8c6f4498,UID:3ed00ad7-7209-4247-ad09-64bc6f0c15d1,ResourceVersion:36199,Generation:3,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 85bcc24f-7b15-40dc-8ef4-c7e9f16588f5 0xc00331c177 0xc00331c178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[],},}
May 26 16:41:29.208: INFO: Pod "nginx-deployment-55fb7cb77f-2tfvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2tfvp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-2tfvp,UID:3b5fd052-d232-4828-bbd7-cd7b17fd2ed4,ResourceVersion:36056,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331cb17 0xc00331cb18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331cb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331cbb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.209: INFO: Pod "nginx-deployment-55fb7cb77f-2xf5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2xf5g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-2xf5g,UID:ead2d87a-88e2-43ec-a59d-8dd75b12bf9d,ResourceVersion:36085,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331cc80 0xc00331cc81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331cd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331cd20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.210: INFO: Pod "nginx-deployment-55fb7cb77f-bmd5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bmd5d,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-bmd5d,UID:454b2d5b-eae9-4636-ab4a-49186bdb6ed0,ResourceVersion:36195,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331cdf0 0xc00331cdf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331ce70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331ce90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.254,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.211: INFO: Pod "nginx-deployment-55fb7cb77f-cz2r6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cz2r6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-cz2r6,UID:caf9c87f-78e9-4cc1-a6c2-8a00d14940e4,ResourceVersion:36095,Generation:0,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331cf80 0xc00331cf81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.213,StartTime:2020-05-26 16:41:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.212: INFO: Pod "nginx-deployment-55fb7cb77f-drm2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-drm2s,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-drm2s,UID:fceeb100-e030-40f5-b0a2-a147be03b97d,ResourceVersion:35979,Generation:0,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d110 0xc00331d111}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.253,StartTime:2020-05-26 16:41:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.213: INFO: Pod "nginx-deployment-55fb7cb77f-f75nr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-f75nr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-f75nr,UID:2e920c1e-f353-4290-bc07-47870789dd6f,ResourceVersion:36106,Generation:0,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d2a0 0xc00331d2a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.183,StartTime:2020-05-26 16:41:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.213: INFO: Pod "nginx-deployment-55fb7cb77f-fxn9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fxn9h,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-fxn9h,UID:b99d1a95-7035-45f8-8293-35bf8af48067,ResourceVersion:36090,Generation:0,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d430 0xc00331d431}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d4b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d4d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.214,StartTime:2020-05-26 16:41:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.213: INFO: Pod "nginx-deployment-55fb7cb77f-ggnrh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ggnrh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-ggnrh,UID:1c69899f-7eec-4334-9dd3-26afb600a73c,ResourceVersion:36082,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d5c0 0xc00331d5c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.213: INFO: Pod "nginx-deployment-55fb7cb77f-ghjq8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ghjq8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-ghjq8,UID:4c7e28ad-d513-4182-9dc8-57d3e7f92981,ResourceVersion:36102,Generation:0,CreationTimestamp:2020-05-26 16:41:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d730 0xc00331d731}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:24 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.184,StartTime:2020-05-26 16:41:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-55fb7cb77f-hqfrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hqfrz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-hqfrz,UID:cd139b96-cb24-4beb-8f75-45cdb903292f,ResourceVersion:36081,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331d8c0 0xc00331d8c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331d940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331d960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-55fb7cb77f-lcc69" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lcc69,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-lcc69,UID:9cf2f36d-4554-4b53-a792-d4bc26a50cba,ResourceVersion:36053,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331da30 0xc00331da31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331dab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331dad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-55fb7cb77f-m8mgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-m8mgn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-m8mgn,UID:74129aed-98a3-4512-942e-d76768ebe9db,ResourceVersion:36076,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331dbb0 0xc00331dbb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331dc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331dc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-55fb7cb77f-qx7md" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qx7md,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-55fb7cb77f-qx7md,UID:f5601281-3a5a-4b90-9837-711a9fb805d6,ResourceVersion:36073,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f c36a8494-4652-4cf0-93a1-d7a5fc4de785 0xc00331dd40 0xc00331dd41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331ddc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331dde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-7b8c6f4498-2tkjd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2tkjd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-2tkjd,UID:95ce353c-96ad-4c38-953d-6e0c73da3d53,ResourceVersion:36060,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00331deb0 0xc00331deb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00331df20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00331df40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-7b8c6f4498-4r4p2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4r4p2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-4r4p2,UID:840d27e1-fd65-45ea-9016-d73ac269d089,ResourceVersion:36078,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c017 0xc00244c018}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.214: INFO: Pod "nginx-deployment-7b8c6f4498-5hszq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5hszq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-5hszq,UID:b55120ec-14b8-4d09-bfcf-2e93f5f4a36b,ResourceVersion:35857,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c177 0xc00244c178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.180,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://d4031fd6ceca16c25a8057f536a194ddd7300333d5d0b8a22f2f31e4adb3a844}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-68t2p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-68t2p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-68t2p,UID:e291eb9b-90fe-4fba-9a08-6df90926a4f2,ResourceVersion:35853,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c2e7 0xc00244c2e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.182,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e9f2a569374d27cf9e93f2aeacfa9a19a4707f836465e7c12081b9f181b85654}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-99gwl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-99gwl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-99gwl,UID:d1f0d46c-823f-4a8e-9e62-793d32fe005e,ResourceVersion:36089,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c457 0xc00244c458}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c4e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-dgthj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dgthj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-dgthj,UID:ed25cc79-a24e-499b-9da0-cd922be8c77d,ResourceVersion:35833,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c5c7 0xc00244c5c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.209,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ff4aab09f68b0b7a919dfff0fc9e9e80e4c775d8cff79f40b58083cfcee18f34}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-f64zp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f64zp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-f64zp,UID:cc23cc55-58ef-46a2-99db-58dafb49fa87,ResourceVersion:35861,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c737 0xc00244c738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.181,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://682c5a3113a78f73eb42f4ae3446628f1d67e3c20e5d033e8b6f25923f94b3a4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-gn9gs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gn9gs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-gn9gs,UID:7b72af93-ca1d-4262-a366-304c890fa71b,ResourceVersion:36068,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244c8a7 0xc00244c8a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244c920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244c940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.215: INFO: Pod "nginx-deployment-7b8c6f4498-hl28l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hl28l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-hl28l,UID:248f4bac-062b-4328-b562-7f7db669fcdd,ResourceVersion:36067,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244ca07 0xc00244ca08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244ca80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244caa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.221: INFO: Pod "nginx-deployment-7b8c6f4498-kqwk2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kqwk2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-kqwk2,UID:cb2b620b-e16b-4c0d-8a08-5d05fc8dc8ed,ResourceVersion:35882,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244cb67 0xc00244cb68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244cbe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244cc00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.210,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://fdf1eda34ccc0fccd0082a04aa64984994ebe3c926fe66af3af6eafb68da2b5e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.222: INFO: Pod "nginx-deployment-7b8c6f4498-l4pbh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l4pbh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-l4pbh,UID:1eb5f60b-d7f2-4141-b262-63231aa6b3d4,ResourceVersion:35874,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244ccd7 0xc00244ccd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244cd50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244cd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.250,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://959ef053972465aa35ea810fe4a29d339c8a72319f473dbe16d623755c295ea3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.222: INFO: Pod "nginx-deployment-7b8c6f4498-mcr4d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mcr4d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-mcr4d,UID:3e1b3ed5-42c1-4814-ad2b-7303d805bf2c,ResourceVersion:36152,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244ce47 0xc00244ce48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244cec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244cee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:172.30.125.185,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:28 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ef9e5a555939b0f4f081eb1f36eef1eeeb45a9d1e4ce405fc836e207fd5e2b22}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.222: INFO: Pod "nginx-deployment-7b8c6f4498-mpdw9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mpdw9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-mpdw9,UID:3f713c25-1d0f-450e-8326-fe615b3e189e,ResourceVersion:36064,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244cfb7 0xc00244cfb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.222: INFO: Pod "nginx-deployment-7b8c6f4498-mrw77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mrw77,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-mrw77,UID:09d60486-1205-49e4-b607-9e568590af94,ResourceVersion:36021,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d127 0xc00244d128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.222: INFO: Pod "nginx-deployment-7b8c6f4498-pj5nl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pj5nl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-pj5nl,UID:52f2b9ec-5740-4dfd-bc35-b0c6d281ca31,ResourceVersion:36057,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d287 0xc00244d288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.223: INFO: Pod "nginx-deployment-7b8c6f4498-pkqhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pkqhg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-pkqhg,UID:82932f32-407f-4ba9-9bbf-4be8e13203fa,ResourceVersion:36044,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d3e7 0xc00244d3e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.223: INFO: Pod "nginx-deployment-7b8c6f4498-r8gmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r8gmc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-r8gmc,UID:d8e033ea-5aad-4b09-bfb6-df2483c6f5bd,ResourceVersion:36047,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d547 0xc00244d548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.133,PodIP:,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.223: INFO: Pod "nginx-deployment-7b8c6f4498-s8ht8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s8ht8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-s8ht8,UID:3320d335-683c-455d-a92a-f5aa457250d6,ResourceVersion:36198,Generation:0,CreationTimestamp:2020-05-26 16:41:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d6a7 0xc00244d6a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:27 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.255,StartTime:2020-05-26 16:41:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:28 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://1557269a074f1f3ad06f5ebad05b47dde572e108e4cde387b4d8127ee44762a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.223: INFO: Pod "nginx-deployment-7b8c6f4498-txwkr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-txwkr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-txwkr,UID:14ba3fe3-96a8-4340-860a-6612376e752d,ResourceVersion:35871,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d817 0xc00244d818}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.252,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f62fbf0c830a78f51172a5401280e8f90a5d933b618bd6b526aee4d115824556}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 26 16:41:29.224: INFO: Pod "nginx-deployment-7b8c6f4498-xb8js" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xb8js,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1957,SelfLink:/api/v1/namespaces/deployment-1957/pods/nginx-deployment-7b8c6f4498-xb8js,UID:c2f26079-b579-478a-bafb-2fd15ecbc013,ResourceVersion:35868,Generation:0,CreationTimestamp:2020-05-26 16:41:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 3ed00ad7-7209-4247-ad09-64bc6f0c15d1 0xc00244d987 0xc00244d988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdhlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdhlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdhlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244da00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244da20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:41:20 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.144,PodIP:172.30.21.251,StartTime:2020-05-26 16:41:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-05-26 16:41:22 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7e7546bfcd6d947b55ddadbb2f47dd69a8da06cca6c13af03ffb4f967ab477d1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:41:29.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1957" for this suite.
May 26 16:41:43.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:41:43.775: INFO: namespace deployment-1957 deletion completed in 14.523243733s

• [SLOW TEST:23.324 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:41:43.776: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3087
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3087, will wait for the garbage collector to delete the pods
May 26 16:41:48.287: INFO: Deleting Job.batch foo took: 29.123278ms
May 26 16:41:48.488: INFO: Terminating Job.batch foo pods took: 200.566781ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:42:31.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3087" for this suite.
May 26 16:42:39.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:42:39.819: INFO: namespace job-3087 deletion completed in 8.500362287s

• [SLOW TEST:56.043 seconds]
[sig-apps] Job
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:42:39.819: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:42:42.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2170" for this suite.
May 26 16:43:24.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:43:24.741: INFO: namespace kubelet-test-2170 deletion completed in 42.537238575s

• [SLOW TEST:44.921 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:43:24.744: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:43:24.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3061" for this suite.
May 26 16:43:31.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:43:31.778: INFO: namespace services-3061 deletion completed in 6.760247966s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:7.034 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:43:31.779: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3165
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-3165
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3165
May 26 16:43:32.067: INFO: Found 0 stateful pods, waiting for 1
May 26 16:43:42.080: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 26 16:43:42.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:43:42.629: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:43:42.629: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:43:42.629: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:43:42.674: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 26 16:43:52.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:43:52.688: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:43:52.742: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:43:52.742: INFO: ss-0  10.113.231.133  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  }]
May 26 16:43:52.742: INFO: 
May 26 16:43:52.742: INFO: StatefulSet ss has not reached scale 3, at 1
May 26 16:43:53.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988957758s
May 26 16:43:54.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977559699s
May 26 16:43:55.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965101352s
May 26 16:43:56.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.94998019s
May 26 16:43:57.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.936274248s
May 26 16:43:58.824: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.920961508s
May 26 16:43:59.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.907897823s
May 26 16:44:00.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.895869601s
May 26 16:44:01.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 879.841713ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3165
May 26 16:44:02.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:44:03.262: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 26 16:44:03.262: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:44:03.262: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:44:03.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:44:03.665: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 26 16:44:03.665: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:44:03.665: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:44:03.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 26 16:44:04.119: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 26 16:44:04.120: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 26 16:44:04.120: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 26 16:44:04.132: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 26 16:44:04.132: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 26 16:44:04.132: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 26 16:44:04.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:44:04.585: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:44:04.585: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:44:04.585: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:44:04.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:44:04.958: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:44:04.958: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:44:04.958: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:44:04.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 exec --namespace=statefulset-3165 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 26 16:44:05.350: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 26 16:44:05.350: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 26 16:44:05.350: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 26 16:44:05.350: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:44:05.373: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 26 16:44:15.399: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:44:15.399: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:44:15.399: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 26 16:44:15.459: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:15.459: INFO: ss-0  10.113.231.133  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  }]
May 26 16:44:15.459: INFO: ss-1  10.113.231.185  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:15.459: INFO: ss-2  10.113.231.144  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:15.459: INFO: 
May 26 16:44:15.459: INFO: StatefulSet ss has not reached scale 0, at 3
May 26 16:44:16.476: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:16.476: INFO: ss-0  10.113.231.133  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:32 +0000 UTC  }]
May 26 16:44:16.476: INFO: ss-1  10.113.231.185  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:16.476: INFO: ss-2  10.113.231.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:16.476: INFO: 
May 26 16:44:16.476: INFO: StatefulSet ss has not reached scale 0, at 3
May 26 16:44:17.492: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:17.492: INFO: ss-1  10.113.231.185  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:17.492: INFO: ss-2  10.113.231.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:17.492: INFO: 
May 26 16:44:17.492: INFO: StatefulSet ss has not reached scale 0, at 2
May 26 16:44:18.512: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:18.512: INFO: ss-1  10.113.231.185  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:18.512: INFO: 
May 26 16:44:18.512: INFO: StatefulSet ss has not reached scale 0, at 1
May 26 16:44:19.524: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:19.524: INFO: ss-1  10.113.231.185  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:19.524: INFO: 
May 26 16:44:19.524: INFO: StatefulSet ss has not reached scale 0, at 1
May 26 16:44:20.534: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:20.534: INFO: ss-1  10.113.231.185  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:20.534: INFO: 
May 26 16:44:20.534: INFO: StatefulSet ss has not reached scale 0, at 1
May 26 16:44:21.546: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 26 16:44:21.546: INFO: ss-1  10.113.231.185  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:44:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:43:52 +0000 UTC  }]
May 26 16:44:21.546: INFO: 
May 26 16:44:21.546: INFO: StatefulSet ss has not reached scale 0, at 1
May 26 16:44:22.571: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.891477955s
May 26 16:44:23.584: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.866470832s
May 26 16:44:24.597: INFO: Verifying statefulset ss doesn't scale past 0 for another 853.718028ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3165
May 26 16:44:25.617: INFO: Scaling statefulset ss to 0
May 26 16:44:25.672: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
May 26 16:44:25.687: INFO: Deleting all statefulset in ns statefulset-3165
May 26 16:44:25.703: INFO: Scaling statefulset ss to 0
May 26 16:44:25.751: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:44:25.765: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:44:25.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3165" for this suite.
May 26 16:44:33.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:44:34.507: INFO: namespace statefulset-3165 deletion completed in 8.655446948s

• [SLOW TEST:62.728 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:44:34.510: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 26 16:44:34.800: INFO: Waiting up to 5m0s for pod "pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce" in namespace "emptydir-2841" to be "success or failure"
May 26 16:44:34.813: INFO: Pod "pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce": Phase="Pending", Reason="", readiness=false. Elapsed: 12.425013ms
May 26 16:44:36.824: INFO: Pod "pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce": Phase="Running", Reason="", readiness=true. Elapsed: 2.024147329s
May 26 16:44:38.836: INFO: Pod "pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035359386s
STEP: Saw pod success
May 26 16:44:38.836: INFO: Pod "pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce" satisfied condition "success or failure"
May 26 16:44:38.847: INFO: Trying to get logs from node 10.113.231.133 pod pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce container test-container: <nil>
STEP: delete the pod
May 26 16:44:38.926: INFO: Waiting for pod pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce to disappear
May 26 16:44:38.937: INFO: Pod pod-6e0c583b-5f85-45b4-a36d-fe88b52d09ce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:44:38.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2841" for this suite.
May 26 16:44:47.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:44:47.498: INFO: namespace emptydir-2841 deletion completed in 8.542968028s

• [SLOW TEST:12.989 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:44:47.499: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9326
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-baab20b8-f43f-48fa-b173-fe5905f30483
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:44:49.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9326" for this suite.
May 26 16:45:14.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:45:14.672: INFO: namespace configmap-9326 deletion completed in 24.688202927s

• [SLOW TEST:27.174 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:45:14.674: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 16:45:14.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5512'
May 26 16:45:15.099: INFO: stderr: ""
May 26 16:45:15.099: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 26 16:45:20.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pod e2e-test-nginx-pod --namespace=kubectl-5512 -o json'
May 26 16:45:20.294: INFO: stderr: ""
May 26 16:45:20.294: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-05-26T16:45:15Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5512\",\n        \"resourceVersion\": \"37438\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5512/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3a75bfaa-450f-445f-801b-d081ad9ec71c\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-948g4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.113.231.185\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-948g4\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-948g4\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-26T16:45:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-26T16:45:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-26T16:45:16Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-26T16:45:15Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://3ccba08dfa5e15b6c4ef155018973b0f4d9c215aa9da64e04fac6bec13e4f47d\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-05-26T16:45:16Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.113.231.185\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.57.224\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-05-26T16:45:15Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 26 16:45:20.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 replace -f - --namespace=kubectl-5512'
May 26 16:45:20.686: INFO: stderr: ""
May 26 16:45:20.686: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
May 26 16:45:20.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete pods e2e-test-nginx-pod --namespace=kubectl-5512'
May 26 16:45:31.999: INFO: stderr: ""
May 26 16:45:31.999: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:45:31.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5512" for this suite.
May 26 16:45:40.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:45:40.542: INFO: namespace kubectl-5512 deletion completed in 8.523373008s

• [SLOW TEST:25.868 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:45:40.543: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7352
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 26 16:45:40.928: INFO: Number of nodes with available pods: 0
May 26 16:45:40.928: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:45:41.963: INFO: Number of nodes with available pods: 0
May 26 16:45:41.963: INFO: Node 10.113.231.133 is running more than one daemon pod
May 26 16:45:42.957: INFO: Number of nodes with available pods: 2
May 26 16:45:42.957: INFO: Node 10.113.231.185 is running more than one daemon pod
May 26 16:45:43.965: INFO: Number of nodes with available pods: 3
May 26 16:45:43.965: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 26 16:45:44.042: INFO: Number of nodes with available pods: 2
May 26 16:45:44.042: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:45.070: INFO: Number of nodes with available pods: 2
May 26 16:45:45.070: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:46.074: INFO: Number of nodes with available pods: 2
May 26 16:45:46.075: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:47.071: INFO: Number of nodes with available pods: 2
May 26 16:45:47.072: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:48.078: INFO: Number of nodes with available pods: 2
May 26 16:45:48.078: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:49.072: INFO: Number of nodes with available pods: 2
May 26 16:45:49.072: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:50.081: INFO: Number of nodes with available pods: 2
May 26 16:45:50.081: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:51.080: INFO: Number of nodes with available pods: 2
May 26 16:45:51.080: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:52.071: INFO: Number of nodes with available pods: 2
May 26 16:45:52.071: INFO: Node 10.113.231.144 is running more than one daemon pod
May 26 16:45:53.072: INFO: Number of nodes with available pods: 3
May 26 16:45:53.072: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7352, will wait for the garbage collector to delete the pods
May 26 16:45:53.194: INFO: Deleting DaemonSet.extensions daemon-set took: 44.039981ms
May 26 16:45:53.395: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.3434ms
May 26 16:46:02.110: INFO: Number of nodes with available pods: 0
May 26 16:46:02.110: INFO: Number of running nodes: 0, number of available pods: 0
May 26 16:46:02.127: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7352/daemonsets","resourceVersion":"37637"},"items":null}

May 26 16:46:02.140: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7352/pods","resourceVersion":"37637"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:02.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7352" for this suite.
May 26 16:46:10.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:46:10.764: INFO: namespace daemonsets-7352 deletion completed in 8.535768932s

• [SLOW TEST:30.221 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:46:10.765: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 26 16:46:11.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2298,SelfLink:/api/v1/namespaces/watch-2298/configmaps/e2e-watch-test-watch-closed,UID:6568d237-aab0-41e0-b6ff-9f8b4904fe04,ResourceVersion:37690,Generation:0,CreationTimestamp:2020-05-26 16:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 26 16:46:11.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2298,SelfLink:/api/v1/namespaces/watch-2298/configmaps/e2e-watch-test-watch-closed,UID:6568d237-aab0-41e0-b6ff-9f8b4904fe04,ResourceVersion:37691,Generation:0,CreationTimestamp:2020-05-26 16:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 26 16:46:11.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2298,SelfLink:/api/v1/namespaces/watch-2298/configmaps/e2e-watch-test-watch-closed,UID:6568d237-aab0-41e0-b6ff-9f8b4904fe04,ResourceVersion:37692,Generation:0,CreationTimestamp:2020-05-26 16:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 26 16:46:11.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-2298,SelfLink:/api/v1/namespaces/watch-2298/configmaps/e2e-watch-test-watch-closed,UID:6568d237-aab0-41e0-b6ff-9f8b4904fe04,ResourceVersion:37693,Generation:0,CreationTimestamp:2020-05-26 16:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:11.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2298" for this suite.
May 26 16:46:17.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:46:17.649: INFO: namespace watch-2298 deletion completed in 6.507826832s

• [SLOW TEST:6.884 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:46:17.653: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
May 26 16:46:17.942: INFO: Waiting up to 5m0s for pod "pod-56f1b2bc-4468-44e1-a549-bb4e56895581" in namespace "emptydir-7910" to be "success or failure"
May 26 16:46:17.959: INFO: Pod "pod-56f1b2bc-4468-44e1-a549-bb4e56895581": Phase="Pending", Reason="", readiness=false. Elapsed: 16.168544ms
May 26 16:46:19.972: INFO: Pod "pod-56f1b2bc-4468-44e1-a549-bb4e56895581": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029786176s
May 26 16:46:21.984: INFO: Pod "pod-56f1b2bc-4468-44e1-a549-bb4e56895581": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042076098s
STEP: Saw pod success
May 26 16:46:21.984: INFO: Pod "pod-56f1b2bc-4468-44e1-a549-bb4e56895581" satisfied condition "success or failure"
May 26 16:46:21.994: INFO: Trying to get logs from node 10.113.231.133 pod pod-56f1b2bc-4468-44e1-a549-bb4e56895581 container test-container: <nil>
STEP: delete the pod
May 26 16:46:22.083: INFO: Waiting for pod pod-56f1b2bc-4468-44e1-a549-bb4e56895581 to disappear
May 26 16:46:22.095: INFO: Pod pod-56f1b2bc-4468-44e1-a549-bb4e56895581 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:22.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7910" for this suite.
May 26 16:46:28.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:46:28.632: INFO: namespace emptydir-7910 deletion completed in 6.518882601s

• [SLOW TEST:10.980 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:46:28.633: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
May 26 16:46:28.898: INFO: Waiting up to 5m0s for pod "var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14" in namespace "var-expansion-8400" to be "success or failure"
May 26 16:46:28.911: INFO: Pod "var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14": Phase="Pending", Reason="", readiness=false. Elapsed: 12.299496ms
May 26 16:46:30.922: INFO: Pod "var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023223844s
STEP: Saw pod success
May 26 16:46:30.922: INFO: Pod "var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14" satisfied condition "success or failure"
May 26 16:46:30.936: INFO: Trying to get logs from node 10.113.231.144 pod var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14 container dapi-container: <nil>
STEP: delete the pod
May 26 16:46:31.009: INFO: Waiting for pod var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14 to disappear
May 26 16:46:31.019: INFO: Pod var-expansion-c2fded57-f28c-4600-bd79-80a8bcc74a14 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:31.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8400" for this suite.
May 26 16:46:39.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:46:39.570: INFO: namespace var-expansion-8400 deletion completed in 8.533755469s

• [SLOW TEST:10.937 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:46:39.571: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5080
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:39.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5080" for this suite.
May 26 16:46:47.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:46:48.438: INFO: namespace kubelet-test-5080 deletion completed in 8.525553193s

• [SLOW TEST:8.867 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:46:48.440: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-841
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
May 26 16:46:50.754: INFO: Pod pod-hostip-97cbdad2-02c6-49ed-bb6e-db51f3c38920 has hostIP: 10.113.231.133
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:46:50.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-841" for this suite.
May 26 16:47:14.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:47:15.282: INFO: namespace pods-841 deletion completed in 24.509258318s

• [SLOW TEST:26.842 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:47:15.288: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5a55bd21-8eb2-466a-8ea8-b79ce73dbd72
STEP: Creating a pod to test consume configMaps
May 26 16:47:15.581: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b" in namespace "projected-4535" to be "success or failure"
May 26 16:47:15.592: INFO: Pod "pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.719409ms
May 26 16:47:17.606: INFO: Pod "pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02516481s
STEP: Saw pod success
May 26 16:47:17.606: INFO: Pod "pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b" satisfied condition "success or failure"
May 26 16:47:17.618: INFO: Trying to get logs from node 10.113.231.185 pod pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 16:47:17.716: INFO: Waiting for pod pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b to disappear
May 26 16:47:17.732: INFO: Pod pod-projected-configmaps-034bf2c7-0321-457e-a3e2-3c4e3713458b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:47:17.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4535" for this suite.
May 26 16:47:23.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:47:24.299: INFO: namespace projected-4535 deletion completed in 6.547126687s

• [SLOW TEST:9.011 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:47:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:47:24.589: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8" in namespace "projected-818" to be "success or failure"
May 26 16:47:24.603: INFO: Pod "downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.204899ms
May 26 16:47:26.616: INFO: Pod "downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02641383s
STEP: Saw pod success
May 26 16:47:26.616: INFO: Pod "downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8" satisfied condition "success or failure"
May 26 16:47:26.630: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8 container client-container: <nil>
STEP: delete the pod
May 26 16:47:26.697: INFO: Waiting for pod downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8 to disappear
May 26 16:47:26.707: INFO: Pod downwardapi-volume-eb8668d3-c0d2-4530-84f5-dda7e6dbd0d8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:47:26.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-818" for this suite.
May 26 16:47:32.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:47:33.232: INFO: namespace projected-818 deletion completed in 6.508685833s

• [SLOW TEST:8.933 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:47:33.233: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
May 26 16:47:33.475: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 26 16:47:33.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:33.968: INFO: stderr: ""
May 26 16:47:33.968: INFO: stdout: "service/redis-slave created\n"
May 26 16:47:33.969: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 26 16:47:33.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:34.287: INFO: stderr: ""
May 26 16:47:34.287: INFO: stdout: "service/redis-master created\n"
May 26 16:47:34.287: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 26 16:47:34.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:34.587: INFO: stderr: ""
May 26 16:47:34.587: INFO: stdout: "service/frontend created\n"
May 26 16:47:34.587: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 26 16:47:34.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:34.967: INFO: stderr: ""
May 26 16:47:34.967: INFO: stdout: "deployment.apps/frontend created\n"
May 26 16:47:34.967: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 26 16:47:34.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:35.235: INFO: stderr: ""
May 26 16:47:35.235: INFO: stdout: "deployment.apps/redis-master created\n"
May 26 16:47:35.235: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 26 16:47:35.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-1705'
May 26 16:47:35.648: INFO: stderr: ""
May 26 16:47:35.648: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May 26 16:47:35.648: INFO: Waiting for all frontend pods to be Running.
May 26 16:47:55.699: INFO: Waiting for frontend to serve content.
May 26 16:47:55.770: INFO: Trying to add a new entry to the guestbook.
May 26 16:47:55.832: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 26 16:47:55.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:56.174: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:56.174: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 26 16:47:56.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:56.790: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:56.790: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 26 16:47:56.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:57.046: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:57.047: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 26 16:47:57.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:57.278: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:57.278: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 26 16:47:57.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:57.442: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:57.442: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 26 16:47:57.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-1705'
May 26 16:47:57.640: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 16:47:57.640: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:47:57.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1705" for this suite.
May 26 16:48:43.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:48:44.200: INFO: namespace kubectl-1705 deletion completed in 46.537187518s

• [SLOW TEST:70.967 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:48:44.201: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9208
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-1e707ffe-da3e-4372-8540-a012a61fb524
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1e707ffe-da3e-4372-8540-a012a61fb524
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:49:58.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9208" for this suite.
May 26 16:50:22.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:50:23.123: INFO: namespace configmap-9208 deletion completed in 24.53842014s

• [SLOW TEST:98.922 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:50:23.127: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4804
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
May 26 16:50:23.391: INFO: Waiting up to 5m0s for pod "pod-9014e961-72c4-411f-b855-98a39fc0565d" in namespace "emptydir-4804" to be "success or failure"
May 26 16:50:23.405: INFO: Pod "pod-9014e961-72c4-411f-b855-98a39fc0565d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.62686ms
May 26 16:50:25.419: INFO: Pod "pod-9014e961-72c4-411f-b855-98a39fc0565d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027743627s
May 26 16:50:27.430: INFO: Pod "pod-9014e961-72c4-411f-b855-98a39fc0565d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039403806s
STEP: Saw pod success
May 26 16:50:27.430: INFO: Pod "pod-9014e961-72c4-411f-b855-98a39fc0565d" satisfied condition "success or failure"
May 26 16:50:27.441: INFO: Trying to get logs from node 10.113.231.185 pod pod-9014e961-72c4-411f-b855-98a39fc0565d container test-container: <nil>
STEP: delete the pod
May 26 16:50:27.523: INFO: Waiting for pod pod-9014e961-72c4-411f-b855-98a39fc0565d to disappear
May 26 16:50:27.535: INFO: Pod pod-9014e961-72c4-411f-b855-98a39fc0565d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:50:27.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4804" for this suite.
May 26 16:50:33.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:50:34.100: INFO: namespace emptydir-4804 deletion completed in 6.547547008s

• [SLOW TEST:10.973 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:50:34.101: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 26 16:50:34.448: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38657,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 26 16:50:34.448: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38658,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 26 16:50:34.448: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38659,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 26 16:50:44.566: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38677,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 26 16:50:44.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38678,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 26 16:50:44.567: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4106,SelfLink:/api/v1/namespaces/watch-4106/configmaps/e2e-watch-test-label-changed,UID:c9b894dc-3846-47ee-a272-3b21faa138d9,ResourceVersion:38679,Generation:0,CreationTimestamp:2020-05-26 16:50:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:50:44.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4106" for this suite.
May 26 16:50:52.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:50:53.079: INFO: namespace watch-4106 deletion completed in 8.49396337s

• [SLOW TEST:18.979 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:50:53.080: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 16:50:53.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b" in namespace "downward-api-6156" to be "success or failure"
May 26 16:50:53.360: INFO: Pod "downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.413723ms
May 26 16:50:55.375: INFO: Pod "downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b": Phase="Running", Reason="", readiness=true. Elapsed: 2.027401609s
May 26 16:50:57.388: INFO: Pod "downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040888328s
STEP: Saw pod success
May 26 16:50:57.388: INFO: Pod "downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b" satisfied condition "success or failure"
May 26 16:50:57.400: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b container client-container: <nil>
STEP: delete the pod
May 26 16:50:57.483: INFO: Waiting for pod downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b to disappear
May 26 16:50:57.493: INFO: Pod downwardapi-volume-7cd50ea4-6704-44d1-92ae-b72c9803489b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:50:57.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6156" for this suite.
May 26 16:51:03.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:51:04.086: INFO: namespace downward-api-6156 deletion completed in 6.573518676s

• [SLOW TEST:11.006 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:51:04.086: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-962
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-962
STEP: Deleting pre-stop pod
May 26 16:51:19.544: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:51:19.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-962" for this suite.
May 26 16:52:01.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:52:02.186: INFO: namespace prestop-962 deletion completed in 42.596773546s

• [SLOW TEST:58.100 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:52:02.187: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
May 26 16:52:02.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 api-versions'
May 26 16:52:02.623: INFO: stderr: ""
May 26 16:52:02.623: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:52:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3479" for this suite.
May 26 16:52:08.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:52:09.164: INFO: namespace kubectl-3479 deletion completed in 6.521412712s

• [SLOW TEST:6.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:52:09.165: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-09de2738-84d7-42c3-9656-af7b4b3f3492
STEP: Creating a pod to test consume secrets
May 26 16:52:09.469: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549" in namespace "projected-6187" to be "success or failure"
May 26 16:52:09.481: INFO: Pod "pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549": Phase="Pending", Reason="", readiness=false. Elapsed: 11.391939ms
May 26 16:52:11.502: INFO: Pod "pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032557953s
STEP: Saw pod success
May 26 16:52:11.502: INFO: Pod "pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549" satisfied condition "success or failure"
May 26 16:52:11.515: INFO: Trying to get logs from node 10.113.231.185 pod pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 26 16:52:11.626: INFO: Waiting for pod pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549 to disappear
May 26 16:52:11.640: INFO: Pod pod-projected-secrets-eb30f89a-bbcd-4f21-a66c-0bbec6e85549 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:52:11.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6187" for this suite.
May 26 16:52:19.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:52:20.185: INFO: namespace projected-6187 deletion completed in 8.528942027s

• [SLOW TEST:11.021 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:52:20.187: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8729
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8729
STEP: Creating statefulset with conflicting port in namespace statefulset-8729
STEP: Waiting until pod test-pod will start running in namespace statefulset-8729
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8729
May 26 16:52:24.544: INFO: Observed stateful pod in namespace: statefulset-8729, name: ss-0, uid: 7b83856b-2f92-4b9f-af62-fc81ddd0128b, status phase: Failed. Waiting for statefulset controller to delete.
May 26 16:52:24.547: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8729
STEP: Removing pod with conflicting port in namespace statefulset-8729
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8729 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
May 26 16:52:28.622: INFO: Deleting all statefulset in ns statefulset-8729
May 26 16:52:28.636: INFO: Scaling statefulset ss to 0
May 26 16:52:38.702: INFO: Waiting for statefulset status.replicas updated to 0
May 26 16:52:38.716: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:52:38.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8729" for this suite.
May 26 16:52:46.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:52:47.290: INFO: namespace statefulset-8729 deletion completed in 8.488416844s

• [SLOW TEST:27.103 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:52:47.294: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:52:47.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-306" for this suite.
May 26 16:53:11.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:53:12.122: INFO: namespace pods-306 deletion completed in 24.536160718s

• [SLOW TEST:24.832 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:53:12.130: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8728
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8728
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 26 16:53:12.370: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 26 16:53:34.674: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.213:8080/dial?request=hostName&protocol=udp&host=172.30.21.212&port=8081&tries=1'] Namespace:pod-network-test-8728 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:53:34.675: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:53:35.164: INFO: Waiting for endpoints: map[]
May 26 16:53:35.175: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.213:8080/dial?request=hostName&protocol=udp&host=172.30.125.146&port=8081&tries=1'] Namespace:pod-network-test-8728 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:53:35.175: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:53:35.432: INFO: Waiting for endpoints: map[]
May 26 16:53:35.445: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.213:8080/dial?request=hostName&protocol=udp&host=172.30.57.234&port=8081&tries=1'] Namespace:pod-network-test-8728 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 16:53:35.445: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 16:53:35.692: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:53:35.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8728" for this suite.
May 26 16:53:59.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:54:00.232: INFO: namespace pod-network-test-8728 deletion completed in 24.51304331s

• [SLOW TEST:48.103 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:54:00.233: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
May 26 16:54:00.486: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:54:04.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1192" for this suite.
May 26 16:54:12.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:54:13.130: INFO: namespace init-container-1192 deletion completed in 8.536545276s

• [SLOW TEST:12.897 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:54:13.130: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-fc9b734a-2ebb-4fa6-bb74-ab44133485ac
STEP: Creating a pod to test consume secrets
May 26 16:54:13.427: INFO: Waiting up to 5m0s for pod "pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621" in namespace "secrets-2609" to be "success or failure"
May 26 16:54:13.437: INFO: Pod "pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621": Phase="Pending", Reason="", readiness=false. Elapsed: 9.9775ms
May 26 16:54:15.451: INFO: Pod "pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621": Phase="Running", Reason="", readiness=true. Elapsed: 2.024134695s
May 26 16:54:17.465: INFO: Pod "pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03814891s
STEP: Saw pod success
May 26 16:54:17.465: INFO: Pod "pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621" satisfied condition "success or failure"
May 26 16:54:17.476: INFO: Trying to get logs from node 10.113.231.144 pod pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621 container secret-volume-test: <nil>
STEP: delete the pod
May 26 16:54:17.550: INFO: Waiting for pod pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621 to disappear
May 26 16:54:17.560: INFO: Pod pod-secrets-63efb7cc-1bdd-4b15-a369-1d707c286621 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:54:17.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2609" for this suite.
May 26 16:54:25.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:54:26.192: INFO: namespace secrets-2609 deletion completed in 8.608762535s

• [SLOW TEST:13.062 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:54:26.193: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 26 16:54:34.643: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:34.658: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:36.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:36.670: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:38.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:38.671: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:40.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:40.670: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:42.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:42.672: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:44.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:44.672: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:46.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:46.671: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:48.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:48.671: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:50.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:50.669: INFO: Pod pod-with-poststart-exec-hook still exists
May 26 16:54:52.659: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 26 16:54:52.673: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:54:52.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7890" for this suite.
May 26 16:55:16.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:55:17.191: INFO: namespace container-lifecycle-hook-7890 deletion completed in 24.499672659s

• [SLOW TEST:50.999 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:55:17.193: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0526 16:55:27.893104      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 26 16:55:27.893: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:55:27.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7619" for this suite.
May 26 16:55:35.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:55:36.457: INFO: namespace gc-7619 deletion completed in 8.5494239s

• [SLOW TEST:19.264 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:55:36.458: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 16:55:36.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 version'
May 26 16:55:36.818: INFO: stderr: ""
May 26 16:55:36.818: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.12\", GitCommit:\"e2a822d9f3c2fdb5c9bfbe64313cf9f657f0a725\", GitTreeState:\"clean\", BuildDate:\"2020-05-06T05:17:59Z\", GoVersion:\"go1.12.17\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.12+IKS\", GitCommit:\"ab8a13f032bccd858fa0232d64fcdd05671f57e6\", GitTreeState:\"clean\", BuildDate:\"2020-05-08T15:08:35Z\", GoVersion:\"go1.12.17\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:55:36.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8911" for this suite.
May 26 16:55:42.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:55:43.374: INFO: namespace kubectl-8911 deletion completed in 6.54070271s

• [SLOW TEST:6.916 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:55:43.374: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 26 16:55:47.702: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-dc6f2049-219f-444f-99fc-6f99d8a9c665,GenerateName:,Namespace:events-6435,SelfLink:/api/v1/namespaces/events-6435/pods/send-events-dc6f2049-219f-444f-99fc-6f99d8a9c665,UID:ba97dfab-8f8b-4452-8f19-170e6e34d217,ResourceVersion:40243,Generation:0,CreationTimestamp:2020-05-26 16:55:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 618334379,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d8zfr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d8zfr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-d8zfr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.113.231.185,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002510ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002510ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:55:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:55:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:55:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-26 16:55:43 +0000 UTC  }],Message:,Reason:,HostIP:10.113.231.185,PodIP:172.30.57.238,StartTime:2020-05-26 16:55:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-05-26 16:55:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://42b99b59e285a140d132e25d2d2c4ee705a0ffaaf6ccf2ab18ee9cb75d4a0e2f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 26 16:55:49.719: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 26 16:55:51.733: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:55:51.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6435" for this suite.
May 26 16:56:33.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:56:34.476: INFO: namespace events-6435 deletion completed in 42.555045846s

• [SLOW TEST:51.103 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:56:34.480: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 26 16:56:34.751: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40350,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 26 16:56:34.751: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40350,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 26 16:56:44.783: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40367,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 26 16:56:44.783: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40367,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 26 16:56:54.812: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40383,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 26 16:56:54.813: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40383,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 26 16:57:04.844: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40399,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 26 16:57:04.844: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-a,UID:1d82d00c-13d3-4ce3-9013-b20d73989244,ResourceVersion:40399,Generation:0,CreationTimestamp:2020-05-26 16:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 26 16:57:14.871: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-b,UID:0fe0f780-7ecb-447b-abff-64239bd8ae62,ResourceVersion:40417,Generation:0,CreationTimestamp:2020-05-26 16:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 26 16:57:14.872: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-b,UID:0fe0f780-7ecb-447b-abff-64239bd8ae62,ResourceVersion:40417,Generation:0,CreationTimestamp:2020-05-26 16:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 26 16:57:24.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-b,UID:0fe0f780-7ecb-447b-abff-64239bd8ae62,ResourceVersion:40434,Generation:0,CreationTimestamp:2020-05-26 16:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 26 16:57:24.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4097,SelfLink:/api/v1/namespaces/watch-4097/configmaps/e2e-watch-test-configmap-b,UID:0fe0f780-7ecb-447b-abff-64239bd8ae62,ResourceVersion:40434,Generation:0,CreationTimestamp:2020-05-26 16:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 16:57:34.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4097" for this suite.
May 26 16:57:40.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 16:57:41.632: INFO: namespace watch-4097 deletion completed in 6.705585765s

• [SLOW TEST:67.153 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 16:57:41.633: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-f125305a-e2e9-4242-adc4-a5db5c9ead67 in namespace container-probe-7896
May 26 16:57:45.940: INFO: Started pod busybox-f125305a-e2e9-4242-adc4-a5db5c9ead67 in namespace container-probe-7896
STEP: checking the pod's current state and verifying that restartCount is present
May 26 16:57:45.957: INFO: Initial restart count of pod busybox-f125305a-e2e9-4242-adc4-a5db5c9ead67 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:01:47.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7896" for this suite.
May 26 17:01:56.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:01:56.483: INFO: namespace container-probe-7896 deletion completed in 8.519083142s

• [SLOW TEST:254.850 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:01:56.484: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-0c093865-2611-4a1d-a9e9-64019a6f29f4 in namespace container-probe-7828
May 26 17:02:00.806: INFO: Started pod liveness-0c093865-2611-4a1d-a9e9-64019a6f29f4 in namespace container-probe-7828
STEP: checking the pod's current state and verifying that restartCount is present
May 26 17:02:00.817: INFO: Initial restart count of pod liveness-0c093865-2611-4a1d-a9e9-64019a6f29f4 is 0
May 26 17:02:14.919: INFO: Restart count of pod container-probe-7828/liveness-0c093865-2611-4a1d-a9e9-64019a6f29f4 is now 1 (14.101218758s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:02:14.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7828" for this suite.
May 26 17:02:23.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:02:23.518: INFO: namespace container-probe-7828 deletion completed in 8.542410806s

• [SLOW TEST:27.035 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:02:23.519: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-b545a086-c5ff-4ef4-adcd-c7656921ee96
STEP: Creating a pod to test consume secrets
May 26 17:02:23.805: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20" in namespace "projected-4540" to be "success or failure"
May 26 17:02:23.816: INFO: Pod "pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20": Phase="Pending", Reason="", readiness=false. Elapsed: 11.417079ms
May 26 17:02:25.829: INFO: Pod "pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023700024s
STEP: Saw pod success
May 26 17:02:25.829: INFO: Pod "pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20" satisfied condition "success or failure"
May 26 17:02:25.841: INFO: Trying to get logs from node 10.113.231.185 pod pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 26 17:02:25.935: INFO: Waiting for pod pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20 to disappear
May 26 17:02:25.953: INFO: Pod pod-projected-secrets-5330b6ac-d7c4-4c06-be60-b3cead658b20 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:02:25.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4540" for this suite.
May 26 17:02:34.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:02:34.495: INFO: namespace projected-4540 deletion completed in 8.521243368s

• [SLOW TEST:10.977 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:02:34.499: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3013.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3013.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3013.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3013.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3013.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3013.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 26 17:02:36.992: INFO: DNS probes using dns-3013/dns-test-4a0fd08f-180f-44cb-aa78-52642f53d003 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:02:37.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3013" for this suite.
May 26 17:02:45.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:02:45.571: INFO: namespace dns-3013 deletion completed in 8.52015289s

• [SLOW TEST:11.072 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:02:45.571: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8527
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
May 26 17:02:50.471: INFO: Successfully updated pod "annotationupdatea66751cf-304c-4ae8-8381-d31275acad39"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:02:52.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8527" for this suite.
May 26 17:03:16.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:03:17.068: INFO: namespace downward-api-8527 deletion completed in 24.502517644s

• [SLOW TEST:31.496 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:03:17.070: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:03:21.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5391" for this suite.
May 26 17:03:29.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:03:29.954: INFO: namespace kubelet-test-5391 deletion completed in 8.556201325s

• [SLOW TEST:12.884 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:03:29.954: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-968
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 26 17:03:30.255: INFO: Waiting up to 5m0s for pod "pod-b7c46c41-711d-46b1-893c-07609b5eddcc" in namespace "emptydir-968" to be "success or failure"
May 26 17:03:30.267: INFO: Pod "pod-b7c46c41-711d-46b1-893c-07609b5eddcc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.771162ms
May 26 17:03:32.280: INFO: Pod "pod-b7c46c41-711d-46b1-893c-07609b5eddcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02466378s
STEP: Saw pod success
May 26 17:03:32.280: INFO: Pod "pod-b7c46c41-711d-46b1-893c-07609b5eddcc" satisfied condition "success or failure"
May 26 17:03:32.293: INFO: Trying to get logs from node 10.113.231.133 pod pod-b7c46c41-711d-46b1-893c-07609b5eddcc container test-container: <nil>
STEP: delete the pod
May 26 17:03:32.374: INFO: Waiting for pod pod-b7c46c41-711d-46b1-893c-07609b5eddcc to disappear
May 26 17:03:32.385: INFO: Pod pod-b7c46c41-711d-46b1-893c-07609b5eddcc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:03:32.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-968" for this suite.
May 26 17:03:40.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:03:41.002: INFO: namespace emptydir-968 deletion completed in 8.597431296s

• [SLOW TEST:11.048 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:03:41.002: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5508
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 26 17:03:41.240: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 26 17:04:03.552: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.21.219:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5508 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:04:03.552: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:04:03.895: INFO: Found all expected endpoints: [netserver-0]
May 26 17:04:03.908: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.57.240:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5508 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:04:03.908: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:04:04.163: INFO: Found all expected endpoints: [netserver-1]
May 26 17:04:04.200: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.125.157:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5508 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:04:04.200: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:04:04.502: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:04:04.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5508" for this suite.
May 26 17:04:28.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:04:29.361: INFO: namespace pod-network-test-5508 deletion completed in 24.837054701s

• [SLOW TEST:48.359 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:04:29.363: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-e2675688-3a85-48de-88a2-6410897f1d5f
STEP: Creating a pod to test consume configMaps
May 26 17:04:29.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571" in namespace "configmap-8920" to be "success or failure"
May 26 17:04:29.655: INFO: Pod "pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571": Phase="Pending", Reason="", readiness=false. Elapsed: 13.12949ms
May 26 17:04:31.667: INFO: Pod "pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024490854s
May 26 17:04:33.683: INFO: Pod "pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040480126s
STEP: Saw pod success
May 26 17:04:33.683: INFO: Pod "pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571" satisfied condition "success or failure"
May 26 17:04:33.697: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 17:04:33.775: INFO: Waiting for pod pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571 to disappear
May 26 17:04:33.791: INFO: Pod pod-configmaps-c1d2dc17-cfd3-491f-8b68-7cf7249ce571 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:04:33.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8920" for this suite.
May 26 17:04:41.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:04:42.462: INFO: namespace configmap-8920 deletion completed in 8.651073366s

• [SLOW TEST:13.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:04:42.463: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 17:04:42.742: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689" in namespace "downward-api-7487" to be "success or failure"
May 26 17:04:42.754: INFO: Pod "downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689": Phase="Pending", Reason="", readiness=false. Elapsed: 11.350159ms
May 26 17:04:44.765: INFO: Pod "downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022684612s
STEP: Saw pod success
May 26 17:04:44.765: INFO: Pod "downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689" satisfied condition "success or failure"
May 26 17:04:44.778: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689 container client-container: <nil>
STEP: delete the pod
May 26 17:04:44.848: INFO: Waiting for pod downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689 to disappear
May 26 17:04:44.862: INFO: Pod downwardapi-volume-79e321fe-2636-4df4-9fb4-2a593491f689 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:04:44.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7487" for this suite.
May 26 17:04:50.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:04:51.420: INFO: namespace downward-api-7487 deletion completed in 6.532121474s

• [SLOW TEST:8.957 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:04:51.420: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-2ba9ee9e-d616-4de8-b9c1-3f9905dadb30
STEP: Creating a pod to test consume configMaps
May 26 17:04:51.716: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9" in namespace "projected-9067" to be "success or failure"
May 26 17:04:51.726: INFO: Pod "pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.04009ms
May 26 17:04:53.738: INFO: Pod "pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021327085s
May 26 17:04:55.750: INFO: Pod "pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033794228s
STEP: Saw pod success
May 26 17:04:55.750: INFO: Pod "pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9" satisfied condition "success or failure"
May 26 17:04:55.762: INFO: Trying to get logs from node 10.113.231.185 pod pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 17:04:55.839: INFO: Waiting for pod pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9 to disappear
May 26 17:04:55.850: INFO: Pod pod-projected-configmaps-7bb3d891-e1a9-4633-b1da-1ef18ebec6a9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:04:55.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9067" for this suite.
May 26 17:05:03.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:05:04.406: INFO: namespace projected-9067 deletion completed in 8.536087444s

• [SLOW TEST:12.986 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:05:04.407: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:05:06.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2016" for this suite.
May 26 17:05:56.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:05:57.318: INFO: namespace kubelet-test-2016 deletion completed in 50.518044006s

• [SLOW TEST:52.911 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:05:57.318: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4180
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 26 17:05:57.565: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 26 17:06:19.868: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.57.243:8080/dial?request=hostName&protocol=http&host=172.30.57.242&port=8080&tries=1'] Namespace:pod-network-test-4180 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:06:19.868: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:06:20.152: INFO: Waiting for endpoints: map[]
May 26 17:06:20.163: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.57.243:8080/dial?request=hostName&protocol=http&host=172.30.21.223&port=8080&tries=1'] Namespace:pod-network-test-4180 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:06:20.163: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:06:20.420: INFO: Waiting for endpoints: map[]
May 26 17:06:20.432: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.57.243:8080/dial?request=hostName&protocol=http&host=172.30.125.160&port=8080&tries=1'] Namespace:pod-network-test-4180 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 26 17:06:20.432: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
May 26 17:06:20.709: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:06:20.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4180" for this suite.
May 26 17:06:44.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:06:45.269: INFO: namespace pod-network-test-4180 deletion completed in 24.5363402s

• [SLOW TEST:47.951 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:06:45.270: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
May 26 17:06:45.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 cluster-info'
May 26 17:06:45.798: INFO: stderr: ""
May 26 17:06:45.798: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:06:45.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4574" for this suite.
May 26 17:06:51.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:06:52.320: INFO: namespace kubectl-4574 deletion completed in 6.502730636s

• [SLOW TEST:7.051 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:06:52.320: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-8f20eb98-0a40-4979-90ef-bc401378ae58
STEP: Creating a pod to test consume configMaps
May 26 17:06:52.621: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b" in namespace "projected-4824" to be "success or failure"
May 26 17:06:52.634: INFO: Pod "pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.701945ms
May 26 17:06:54.649: INFO: Pod "pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027399839s
STEP: Saw pod success
May 26 17:06:54.649: INFO: Pod "pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b" satisfied condition "success or failure"
May 26 17:06:54.659: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 26 17:06:54.724: INFO: Waiting for pod pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b to disappear
May 26 17:06:54.738: INFO: Pod pod-projected-configmaps-0a8fbfc0-2cdf-40d9-ac79-558371e0ed9b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:06:54.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4824" for this suite.
May 26 17:07:02.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:07:03.277: INFO: namespace projected-4824 deletion completed in 8.521864247s

• [SLOW TEST:10.957 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:07:03.278: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 26 17:07:03.562: INFO: Pod name pod-release: Found 0 pods out of 1
May 26 17:07:08.574: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:07:08.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2106" for this suite.
May 26 17:07:16.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:07:17.173: INFO: namespace replication-controller-2106 deletion completed in 8.530525009s

• [SLOW TEST:13.896 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:07:17.179: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
May 26 17:07:17.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 create -f - --namespace=kubectl-9482'
May 26 17:07:18.500: INFO: stderr: ""
May 26 17:07:18.500: INFO: stdout: "pod/pause created\n"
May 26 17:07:18.500: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 26 17:07:18.500: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9482" to be "running and ready"
May 26 17:07:18.511: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.29783ms
May 26 17:07:20.522: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.021621628s
May 26 17:07:20.522: INFO: Pod "pause" satisfied condition "running and ready"
May 26 17:07:20.522: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
May 26 17:07:20.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 label pods pause testing-label=testing-label-value --namespace=kubectl-9482'
May 26 17:07:20.705: INFO: stderr: ""
May 26 17:07:20.705: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 26 17:07:20.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pod pause -L testing-label --namespace=kubectl-9482'
May 26 17:07:20.841: INFO: stderr: ""
May 26 17:07:20.841: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 26 17:07:20.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 label pods pause testing-label- --namespace=kubectl-9482'
May 26 17:07:20.995: INFO: stderr: ""
May 26 17:07:20.995: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 26 17:07:20.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pod pause -L testing-label --namespace=kubectl-9482'
May 26 17:07:21.164: INFO: stderr: ""
May 26 17:07:21.164: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
May 26 17:07:21.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete --grace-period=0 --force -f - --namespace=kubectl-9482'
May 26 17:07:21.369: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 26 17:07:21.369: INFO: stdout: "pod \"pause\" force deleted\n"
May 26 17:07:21.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get rc,svc -l name=pause --no-headers --namespace=kubectl-9482'
May 26 17:07:21.547: INFO: stderr: "No resources found.\n"
May 26 17:07:21.547: INFO: stdout: ""
May 26 17:07:21.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -l name=pause --namespace=kubectl-9482 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 26 17:07:21.695: INFO: stderr: ""
May 26 17:07:21.695: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:07:21.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9482" for this suite.
May 26 17:07:27.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:07:28.236: INFO: namespace kubectl-9482 deletion completed in 6.522581307s

• [SLOW TEST:11.057 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:07:28.237: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 17:07:32.605: INFO: Waiting up to 5m0s for pod "client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6" in namespace "pods-7910" to be "success or failure"
May 26 17:07:32.616: INFO: Pod "client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.8491ms
May 26 17:07:34.627: INFO: Pod "client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022119202s
STEP: Saw pod success
May 26 17:07:34.627: INFO: Pod "client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6" satisfied condition "success or failure"
May 26 17:07:34.637: INFO: Trying to get logs from node 10.113.231.185 pod client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6 container env3cont: <nil>
STEP: delete the pod
May 26 17:07:34.745: INFO: Waiting for pod client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6 to disappear
May 26 17:07:34.757: INFO: Pod client-envvars-53cd6ae6-ad7b-44fd-a126-ad4a80b2a7e6 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:07:34.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7910" for this suite.
May 26 17:08:22.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:08:23.871: INFO: namespace pods-7910 deletion completed in 49.091233533s

• [SLOW TEST:55.634 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:08:23.872: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 26 17:08:32.309: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 26 17:08:32.318: INFO: Pod pod-with-prestop-http-hook still exists
May 26 17:08:34.319: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 26 17:08:34.332: INFO: Pod pod-with-prestop-http-hook still exists
May 26 17:08:36.319: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 26 17:08:36.330: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:08:36.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2216" for this suite.
May 26 17:09:00.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:09:00.925: INFO: namespace container-lifecycle-hook-2216 deletion completed in 24.539645759s

• [SLOW TEST:37.053 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:09:00.926: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-1b5c115e-d29d-449e-acbe-eaf2460c97d6
STEP: Creating a pod to test consume configMaps
May 26 17:09:01.235: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0bee874-33c5-465f-b808-245241037003" in namespace "configmap-6073" to be "success or failure"
May 26 17:09:01.245: INFO: Pod "pod-configmaps-a0bee874-33c5-465f-b808-245241037003": Phase="Pending", Reason="", readiness=false. Elapsed: 10.48798ms
May 26 17:09:03.745: INFO: Pod "pod-configmaps-a0bee874-33c5-465f-b808-245241037003": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.510566886s
STEP: Saw pod success
May 26 17:09:03.746: INFO: Pod "pod-configmaps-a0bee874-33c5-465f-b808-245241037003" satisfied condition "success or failure"
May 26 17:09:03.759: INFO: Trying to get logs from node 10.113.231.144 pod pod-configmaps-a0bee874-33c5-465f-b808-245241037003 container configmap-volume-test: <nil>
STEP: delete the pod
May 26 17:09:03.862: INFO: Waiting for pod pod-configmaps-a0bee874-33c5-465f-b808-245241037003 to disappear
May 26 17:09:03.880: INFO: Pod pod-configmaps-a0bee874-33c5-465f-b808-245241037003 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:09:03.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6073" for this suite.
May 26 17:09:11.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:09:12.475: INFO: namespace configmap-6073 deletion completed in 8.567285622s

• [SLOW TEST:11.549 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:09:12.475: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 26 17:09:15.426: INFO: Successfully updated pod "pod-update-a504edd3-fa53-439d-856a-32f46155ecba"
STEP: verifying the updated pod is in kubernetes
May 26 17:09:15.452: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:09:15.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7777" for this suite.
May 26 17:09:39.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:09:40.320: INFO: namespace pods-7777 deletion completed in 24.846718648s

• [SLOW TEST:27.845 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:09:40.320: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-654
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-e33da3b7-44fe-49b4-9c01-4f10f583a9b4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:09:40.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-654" for this suite.
May 26 17:09:48.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:09:49.194: INFO: namespace configmap-654 deletion completed in 8.60119751s

• [SLOW TEST:8.874 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:09:49.195: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3163
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 17:09:49.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92" in namespace "projected-3163" to be "success or failure"
May 26 17:09:49.511: INFO: Pod "downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92": Phase="Pending", Reason="", readiness=false. Elapsed: 14.120896ms
May 26 17:09:51.523: INFO: Pod "downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92": Phase="Running", Reason="", readiness=true. Elapsed: 2.025842162s
May 26 17:09:53.535: INFO: Pod "downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038008511s
STEP: Saw pod success
May 26 17:09:53.535: INFO: Pod "downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92" satisfied condition "success or failure"
May 26 17:09:53.550: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92 container client-container: <nil>
STEP: delete the pod
May 26 17:09:53.644: INFO: Waiting for pod downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92 to disappear
May 26 17:09:53.655: INFO: Pod downwardapi-volume-d3d33a1e-bf61-46f8-8501-d8eec1330f92 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:09:53.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3163" for this suite.
May 26 17:09:59.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:10:00.219: INFO: namespace projected-3163 deletion completed in 6.528639131s

• [SLOW TEST:11.024 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:10:00.220: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 17:10:00.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2867'
May 26 17:10:00.618: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 26 17:10:00.618: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 26 17:10:00.640: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
May 26 17:10:00.652: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 26 17:10:00.682: INFO: scanned /root for discovery docs: <nil>
May 26 17:10:00.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-2867'
May 26 17:10:16.789: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 26 17:10:16.789: INFO: stdout: "Created e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3\nScaling up e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 26 17:10:16.789: INFO: stdout: "Created e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3\nScaling up e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 26 17:10:16.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-2867'
May 26 17:10:16.947: INFO: stderr: ""
May 26 17:10:16.947: INFO: stdout: "e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3-82cb6 "
May 26 17:10:16.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3-82cb6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2867'
May 26 17:10:17.102: INFO: stderr: ""
May 26 17:10:17.102: INFO: stdout: "true"
May 26 17:10:17.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 get pods e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3-82cb6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2867'
May 26 17:10:17.252: INFO: stderr: ""
May 26 17:10:17.253: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 26 17:10:17.253: INFO: e2e-test-nginx-rc-53f4b772de0861ea6a01a4d57b4d5fd3-82cb6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
May 26 17:10:17.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete rc e2e-test-nginx-rc --namespace=kubectl-2867'
May 26 17:10:17.428: INFO: stderr: ""
May 26 17:10:17.429: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:10:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2867" for this suite.
May 26 17:10:41.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:10:41.956: INFO: namespace kubectl-2867 deletion completed in 24.508983254s

• [SLOW TEST:41.737 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:10:41.957: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
May 26 17:10:42.251: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:10:46.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9474" for this suite.
May 26 17:11:10.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:11:10.793: INFO: namespace init-container-9474 deletion completed in 24.536615754s

• [SLOW TEST:28.836 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:11:10.793: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 26 17:11:11.146: INFO: Waiting up to 5m0s for pod "pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2" in namespace "emptydir-4895" to be "success or failure"
May 26 17:11:11.162: INFO: Pod "pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.782836ms
May 26 17:11:13.173: INFO: Pod "pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026842288s
May 26 17:11:15.188: INFO: Pod "pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041547544s
STEP: Saw pod success
May 26 17:11:15.188: INFO: Pod "pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2" satisfied condition "success or failure"
May 26 17:11:15.199: INFO: Trying to get logs from node 10.113.231.185 pod pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2 container test-container: <nil>
STEP: delete the pod
May 26 17:11:15.273: INFO: Waiting for pod pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2 to disappear
May 26 17:11:15.286: INFO: Pod pod-1d3ea006-72b1-4002-8d4c-bb55165a67b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:11:15.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4895" for this suite.
May 26 17:11:23.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:11:23.841: INFO: namespace emptydir-4895 deletion completed in 8.536747392s

• [SLOW TEST:13.048 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:11:23.842: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9327/configmap-test-5938504d-1ec4-45b6-ab96-645cf15dce46
STEP: Creating a pod to test consume configMaps
May 26 17:11:24.135: INFO: Waiting up to 5m0s for pod "pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14" in namespace "configmap-9327" to be "success or failure"
May 26 17:11:24.147: INFO: Pod "pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14": Phase="Pending", Reason="", readiness=false. Elapsed: 11.248469ms
May 26 17:11:26.159: INFO: Pod "pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023292814s
STEP: Saw pod success
May 26 17:11:26.159: INFO: Pod "pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14" satisfied condition "success or failure"
May 26 17:11:26.170: INFO: Trying to get logs from node 10.113.231.133 pod pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14 container env-test: <nil>
STEP: delete the pod
May 26 17:11:26.244: INFO: Waiting for pod pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14 to disappear
May 26 17:11:26.256: INFO: Pod pod-configmaps-080ff0c8-23ef-4a81-8c6a-fd8a2d1bfe14 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:11:26.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9327" for this suite.
May 26 17:11:32.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:11:32.947: INFO: namespace configmap-9327 deletion completed in 6.671353818s

• [SLOW TEST:9.105 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:11:32.948: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-r55m
STEP: Creating a pod to test atomic-volume-subpath
May 26 17:11:33.261: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-r55m" in namespace "subpath-6330" to be "success or failure"
May 26 17:11:33.272: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Pending", Reason="", readiness=false. Elapsed: 10.537966ms
May 26 17:11:35.286: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025254179s
May 26 17:11:37.301: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 4.039593679s
May 26 17:11:39.314: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 6.052413265s
May 26 17:11:41.326: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 8.065164669s
May 26 17:11:43.340: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 10.078822722s
May 26 17:11:45.353: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 12.092010488s
May 26 17:11:47.365: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 14.10381719s
May 26 17:11:49.378: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 16.117202911s
May 26 17:11:51.390: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 18.129267201s
May 26 17:11:53.404: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Running", Reason="", readiness=true. Elapsed: 20.142944694s
May 26 17:11:55.415: INFO: Pod "pod-subpath-test-projected-r55m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.15353995s
STEP: Saw pod success
May 26 17:11:55.415: INFO: Pod "pod-subpath-test-projected-r55m" satisfied condition "success or failure"
May 26 17:11:55.438: INFO: Trying to get logs from node 10.113.231.144 pod pod-subpath-test-projected-r55m container test-container-subpath-projected-r55m: <nil>
STEP: delete the pod
May 26 17:11:55.515: INFO: Waiting for pod pod-subpath-test-projected-r55m to disappear
May 26 17:11:55.531: INFO: Pod pod-subpath-test-projected-r55m no longer exists
STEP: Deleting pod pod-subpath-test-projected-r55m
May 26 17:11:55.531: INFO: Deleting pod "pod-subpath-test-projected-r55m" in namespace "subpath-6330"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:11:55.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6330" for this suite.
May 26 17:12:03.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:12:04.159: INFO: namespace subpath-6330 deletion completed in 8.593923743s

• [SLOW TEST:31.212 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:12:04.159: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6062
I0526 17:12:04.458363      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6062, replica count: 1
I0526 17:12:05.508814      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0526 17:12:06.509124      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0526 17:12:07.509437      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 26 17:12:07.644: INFO: Created: latency-svc-86jgf
May 26 17:12:07.662: INFO: Got endpoints: latency-svc-86jgf [52.771814ms]
May 26 17:12:07.698: INFO: Created: latency-svc-zbftr
May 26 17:12:07.713: INFO: Got endpoints: latency-svc-zbftr [50.661816ms]
May 26 17:12:07.716: INFO: Created: latency-svc-9ktvs
May 26 17:12:07.733: INFO: Got endpoints: latency-svc-9ktvs [70.322595ms]
May 26 17:12:07.735: INFO: Created: latency-svc-ssgml
May 26 17:12:07.754: INFO: Got endpoints: latency-svc-ssgml [91.605469ms]
May 26 17:12:07.760: INFO: Created: latency-svc-6977r
May 26 17:12:07.778: INFO: Got endpoints: latency-svc-6977r [115.335899ms]
May 26 17:12:07.786: INFO: Created: latency-svc-c9btx
May 26 17:12:07.801: INFO: Got endpoints: latency-svc-c9btx [137.912878ms]
May 26 17:12:07.806: INFO: Created: latency-svc-qfb8b
May 26 17:12:07.821: INFO: Created: latency-svc-twt4q
May 26 17:12:07.840: INFO: Created: latency-svc-2p9nb
May 26 17:12:07.859: INFO: Created: latency-svc-pzh8g
May 26 17:12:07.886: INFO: Created: latency-svc-mbjjv
May 26 17:12:07.904: INFO: Created: latency-svc-6xx9v
May 26 17:12:07.927: INFO: Created: latency-svc-jlx6l
May 26 17:12:07.949: INFO: Created: latency-svc-nnhwh
May 26 17:12:07.970: INFO: Created: latency-svc-vrkl4
May 26 17:12:07.987: INFO: Created: latency-svc-jkmj2
May 26 17:12:08.011: INFO: Created: latency-svc-frls4
May 26 17:12:08.024: INFO: Created: latency-svc-ggdw6
May 26 17:12:08.043: INFO: Created: latency-svc-jwvw5
May 26 17:12:08.046: INFO: Got endpoints: latency-svc-2p9nb [382.682331ms]
May 26 17:12:08.046: INFO: Got endpoints: latency-svc-pzh8g [382.997778ms]
May 26 17:12:08.046: INFO: Got endpoints: latency-svc-qfb8b [383.090527ms]
May 26 17:12:08.046: INFO: Got endpoints: latency-svc-twt4q [383.525205ms]
May 26 17:12:08.047: INFO: Got endpoints: latency-svc-mbjjv [384.331729ms]
May 26 17:12:08.059: INFO: Got endpoints: latency-svc-6xx9v [395.62025ms]
May 26 17:12:08.059: INFO: Got endpoints: latency-svc-jlx6l [396.253389ms]
May 26 17:12:08.062: INFO: Got endpoints: latency-svc-vrkl4 [398.975206ms]
May 26 17:12:08.064: INFO: Got endpoints: latency-svc-nnhwh [400.758256ms]
May 26 17:12:08.066: INFO: Got endpoints: latency-svc-jkmj2 [402.511851ms]
May 26 17:12:08.067: INFO: Created: latency-svc-vbhhl
May 26 17:12:08.076: INFO: Got endpoints: latency-svc-frls4 [363.193362ms]
May 26 17:12:08.079: INFO: Got endpoints: latency-svc-jwvw5 [324.989508ms]
May 26 17:12:08.080: INFO: Got endpoints: latency-svc-ggdw6 [346.793301ms]
May 26 17:12:08.084: INFO: Got endpoints: latency-svc-vbhhl [305.612125ms]
May 26 17:12:08.093: INFO: Created: latency-svc-tr48x
May 26 17:12:08.110: INFO: Created: latency-svc-f6qmn
May 26 17:12:08.111: INFO: Got endpoints: latency-svc-tr48x [310.604865ms]
May 26 17:12:08.132: INFO: Got endpoints: latency-svc-f6qmn [86.199833ms]
May 26 17:12:08.137: INFO: Created: latency-svc-82gr6
May 26 17:12:08.160: INFO: Got endpoints: latency-svc-82gr6 [114.48379ms]
May 26 17:12:08.173: INFO: Created: latency-svc-gxzzn
May 26 17:12:08.186: INFO: Got endpoints: latency-svc-gxzzn [140.292545ms]
May 26 17:12:08.189: INFO: Created: latency-svc-pnwk9
May 26 17:12:08.204: INFO: Created: latency-svc-r5hhl
May 26 17:12:08.204: INFO: Got endpoints: latency-svc-pnwk9 [157.078321ms]
May 26 17:12:08.216: INFO: Got endpoints: latency-svc-r5hhl [168.826469ms]
May 26 17:12:08.222: INFO: Created: latency-svc-v548l
May 26 17:12:08.237: INFO: Got endpoints: latency-svc-v548l [177.701384ms]
May 26 17:12:08.242: INFO: Created: latency-svc-bmhv9
May 26 17:12:08.252: INFO: Got endpoints: latency-svc-bmhv9 [47.917525ms]
May 26 17:12:08.263: INFO: Created: latency-svc-pvds4
May 26 17:12:08.279: INFO: Got endpoints: latency-svc-pvds4 [219.948733ms]
May 26 17:12:08.284: INFO: Created: latency-svc-4t2nm
May 26 17:12:08.300: INFO: Got endpoints: latency-svc-4t2nm [237.53377ms]
May 26 17:12:08.304: INFO: Created: latency-svc-fb4mv
May 26 17:12:08.323: INFO: Created: latency-svc-lsvnx
May 26 17:12:08.326: INFO: Got endpoints: latency-svc-fb4mv [261.826442ms]
May 26 17:12:08.351: INFO: Got endpoints: latency-svc-lsvnx [285.026966ms]
May 26 17:12:08.354: INFO: Created: latency-svc-wghrf
May 26 17:12:08.369: INFO: Got endpoints: latency-svc-wghrf [292.517527ms]
May 26 17:12:08.381: INFO: Created: latency-svc-gbgwk
May 26 17:12:08.392: INFO: Got endpoints: latency-svc-gbgwk [312.037032ms]
May 26 17:12:08.404: INFO: Created: latency-svc-xxq76
May 26 17:12:08.420: INFO: Created: latency-svc-zhn27
May 26 17:12:08.421: INFO: Got endpoints: latency-svc-xxq76 [340.903319ms]
May 26 17:12:08.433: INFO: Got endpoints: latency-svc-zhn27 [349.272269ms]
May 26 17:12:08.438: INFO: Created: latency-svc-b7gqp
May 26 17:12:08.452: INFO: Created: latency-svc-2xdhn
May 26 17:12:08.459: INFO: Got endpoints: latency-svc-b7gqp [347.117719ms]
May 26 17:12:08.463: INFO: Got endpoints: latency-svc-2xdhn [331.589081ms]
May 26 17:12:08.469: INFO: Created: latency-svc-cl9zv
May 26 17:12:08.487: INFO: Got endpoints: latency-svc-cl9zv [326.220176ms]
May 26 17:12:08.492: INFO: Created: latency-svc-6fwjx
May 26 17:12:08.504: INFO: Got endpoints: latency-svc-6fwjx [317.078867ms]
May 26 17:12:08.509: INFO: Created: latency-svc-gvkxr
May 26 17:12:08.524: INFO: Created: latency-svc-5pwxc
May 26 17:12:08.525: INFO: Got endpoints: latency-svc-gvkxr [308.766297ms]
May 26 17:12:08.541: INFO: Created: latency-svc-trlrz
May 26 17:12:08.541: INFO: Got endpoints: latency-svc-5pwxc [303.951499ms]
May 26 17:12:08.558: INFO: Got endpoints: latency-svc-trlrz [306.3137ms]
May 26 17:12:08.570: INFO: Created: latency-svc-2ssvq
May 26 17:12:08.586: INFO: Created: latency-svc-kx7xk
May 26 17:12:08.589: INFO: Got endpoints: latency-svc-2ssvq [310.25414ms]
May 26 17:12:08.598: INFO: Created: latency-svc-ktxxr
May 26 17:12:08.600: INFO: Got endpoints: latency-svc-kx7xk [300.053226ms]
May 26 17:12:08.621: INFO: Got endpoints: latency-svc-ktxxr [294.835467ms]
May 26 17:12:08.631: INFO: Created: latency-svc-zltkc
May 26 17:12:08.648: INFO: Got endpoints: latency-svc-zltkc [297.208513ms]
May 26 17:12:08.657: INFO: Created: latency-svc-xtkgb
May 26 17:12:08.672: INFO: Got endpoints: latency-svc-xtkgb [303.347221ms]
May 26 17:12:08.676: INFO: Created: latency-svc-nht94
May 26 17:12:08.692: INFO: Got endpoints: latency-svc-nht94 [300.228053ms]
May 26 17:12:08.702: INFO: Created: latency-svc-4xs4f
May 26 17:12:08.716: INFO: Got endpoints: latency-svc-4xs4f [295.48129ms]
May 26 17:12:08.721: INFO: Created: latency-svc-zpblk
May 26 17:12:08.738: INFO: Got endpoints: latency-svc-zpblk [304.692307ms]
May 26 17:12:08.739: INFO: Created: latency-svc-tt82b
May 26 17:12:08.756: INFO: Got endpoints: latency-svc-tt82b [297.181989ms]
May 26 17:12:08.762: INFO: Created: latency-svc-kgpnq
May 26 17:12:08.778: INFO: Got endpoints: latency-svc-kgpnq [314.749593ms]
May 26 17:12:08.788: INFO: Created: latency-svc-hmp7w
May 26 17:12:08.800: INFO: Created: latency-svc-fdtq9
May 26 17:12:08.802: INFO: Got endpoints: latency-svc-hmp7w [315.122953ms]
May 26 17:12:08.812: INFO: Got endpoints: latency-svc-fdtq9 [308.860672ms]
May 26 17:12:08.819: INFO: Created: latency-svc-m5mss
May 26 17:12:08.833: INFO: Created: latency-svc-ncb49
May 26 17:12:08.834: INFO: Got endpoints: latency-svc-m5mss [308.664334ms]
May 26 17:12:08.846: INFO: Got endpoints: latency-svc-ncb49 [304.72834ms]
May 26 17:12:08.850: INFO: Created: latency-svc-4rdfw
May 26 17:12:08.872: INFO: Created: latency-svc-94g9s
May 26 17:12:08.872: INFO: Got endpoints: latency-svc-4rdfw [314.201276ms]
May 26 17:12:08.886: INFO: Got endpoints: latency-svc-94g9s [296.701564ms]
May 26 17:12:08.894: INFO: Created: latency-svc-lmwv8
May 26 17:12:08.908: INFO: Got endpoints: latency-svc-lmwv8 [308.164969ms]
May 26 17:12:08.911: INFO: Created: latency-svc-rvb67
May 26 17:12:08.926: INFO: Got endpoints: latency-svc-rvb67 [305.46818ms]
May 26 17:12:08.931: INFO: Created: latency-svc-nrtfr
May 26 17:12:08.941: INFO: Got endpoints: latency-svc-nrtfr [293.030979ms]
May 26 17:12:08.947: INFO: Created: latency-svc-lwljz
May 26 17:12:08.960: INFO: Got endpoints: latency-svc-lwljz [287.790503ms]
May 26 17:12:08.963: INFO: Created: latency-svc-ln68b
May 26 17:12:08.977: INFO: Got endpoints: latency-svc-ln68b [285.442423ms]
May 26 17:12:08.988: INFO: Created: latency-svc-r4f82
May 26 17:12:09.004: INFO: Got endpoints: latency-svc-r4f82 [287.666729ms]
May 26 17:12:09.013: INFO: Created: latency-svc-bmvx9
May 26 17:12:09.029: INFO: Got endpoints: latency-svc-bmvx9 [290.824212ms]
May 26 17:12:09.031: INFO: Created: latency-svc-85hx9
May 26 17:12:09.052: INFO: Created: latency-svc-44j6v
May 26 17:12:09.057: INFO: Got endpoints: latency-svc-85hx9 [300.738224ms]
May 26 17:12:09.066: INFO: Got endpoints: latency-svc-44j6v [287.42183ms]
May 26 17:12:09.072: INFO: Created: latency-svc-5bwn2
May 26 17:12:09.087: INFO: Got endpoints: latency-svc-5bwn2 [285.128397ms]
May 26 17:12:09.101: INFO: Created: latency-svc-qc5rd
May 26 17:12:09.113: INFO: Got endpoints: latency-svc-qc5rd [300.388947ms]
May 26 17:12:09.118: INFO: Created: latency-svc-ksgb2
May 26 17:12:09.136: INFO: Got endpoints: latency-svc-ksgb2 [301.972757ms]
May 26 17:12:09.140: INFO: Created: latency-svc-g6lw4
May 26 17:12:09.152: INFO: Got endpoints: latency-svc-g6lw4 [305.726924ms]
May 26 17:12:09.159: INFO: Created: latency-svc-dg49m
May 26 17:12:09.180: INFO: Got endpoints: latency-svc-dg49m [307.350073ms]
May 26 17:12:09.183: INFO: Created: latency-svc-4gw42
May 26 17:12:09.195: INFO: Got endpoints: latency-svc-4gw42 [309.735164ms]
May 26 17:12:09.203: INFO: Created: latency-svc-7bzd6
May 26 17:12:09.217: INFO: Got endpoints: latency-svc-7bzd6 [308.939038ms]
May 26 17:12:09.218: INFO: Created: latency-svc-987kk
May 26 17:12:09.241: INFO: Got endpoints: latency-svc-987kk [314.481525ms]
May 26 17:12:09.242: INFO: Created: latency-svc-v8kk4
May 26 17:12:09.255: INFO: Got endpoints: latency-svc-v8kk4 [314.146097ms]
May 26 17:12:09.261: INFO: Created: latency-svc-252nw
May 26 17:12:09.274: INFO: Got endpoints: latency-svc-252nw [314.123942ms]
May 26 17:12:09.280: INFO: Created: latency-svc-lw9bm
May 26 17:12:09.297: INFO: Got endpoints: latency-svc-lw9bm [319.270105ms]
May 26 17:12:09.302: INFO: Created: latency-svc-rtlx9
May 26 17:12:09.320: INFO: Created: latency-svc-98kwd
May 26 17:12:09.345: INFO: Got endpoints: latency-svc-98kwd [316.128011ms]
May 26 17:12:09.345: INFO: Got endpoints: latency-svc-rtlx9 [340.968894ms]
May 26 17:12:09.346: INFO: Created: latency-svc-j4rth
May 26 17:12:09.364: INFO: Got endpoints: latency-svc-j4rth [307.508425ms]
May 26 17:12:09.368: INFO: Created: latency-svc-bq4jj
May 26 17:12:09.384: INFO: Got endpoints: latency-svc-bq4jj [317.791604ms]
May 26 17:12:09.390: INFO: Created: latency-svc-qdqbr
May 26 17:12:09.404: INFO: Got endpoints: latency-svc-qdqbr [316.952551ms]
May 26 17:12:09.414: INFO: Created: latency-svc-ptb7k
May 26 17:12:09.427: INFO: Got endpoints: latency-svc-ptb7k [313.966726ms]
May 26 17:12:09.430: INFO: Created: latency-svc-msw5m
May 26 17:12:09.449: INFO: Got endpoints: latency-svc-msw5m [312.903135ms]
May 26 17:12:09.457: INFO: Created: latency-svc-tfw6f
May 26 17:12:09.472: INFO: Got endpoints: latency-svc-tfw6f [319.832507ms]
May 26 17:12:09.476: INFO: Created: latency-svc-9kg6h
May 26 17:12:09.489: INFO: Got endpoints: latency-svc-9kg6h [309.216689ms]
May 26 17:12:09.501: INFO: Created: latency-svc-mnl6g
May 26 17:12:09.515: INFO: Got endpoints: latency-svc-mnl6g [319.854932ms]
May 26 17:12:09.519: INFO: Created: latency-svc-2pnm9
May 26 17:12:09.537: INFO: Got endpoints: latency-svc-2pnm9 [320.33176ms]
May 26 17:12:09.545: INFO: Created: latency-svc-dgxh8
May 26 17:12:09.565: INFO: Got endpoints: latency-svc-dgxh8 [324.188527ms]
May 26 17:12:09.571: INFO: Created: latency-svc-mfhdz
May 26 17:12:09.590: INFO: Created: latency-svc-dlfjm
May 26 17:12:09.592: INFO: Got endpoints: latency-svc-mfhdz [336.323899ms]
May 26 17:12:09.605: INFO: Got endpoints: latency-svc-dlfjm [330.100511ms]
May 26 17:12:09.614: INFO: Created: latency-svc-qjqkr
May 26 17:12:09.624: INFO: Created: latency-svc-kqcnv
May 26 17:12:09.627: INFO: Got endpoints: latency-svc-qjqkr [329.758619ms]
May 26 17:12:09.640: INFO: Got endpoints: latency-svc-kqcnv [294.594293ms]
May 26 17:12:09.645: INFO: Created: latency-svc-sczvb
May 26 17:12:09.665: INFO: Created: latency-svc-vbd6j
May 26 17:12:09.667: INFO: Got endpoints: latency-svc-sczvb [322.438095ms]
May 26 17:12:09.701: INFO: Got endpoints: latency-svc-vbd6j [337.040807ms]
May 26 17:12:09.713: INFO: Created: latency-svc-s2rdl
May 26 17:12:09.727: INFO: Got endpoints: latency-svc-s2rdl [343.708719ms]
May 26 17:12:09.737: INFO: Created: latency-svc-d95jt
May 26 17:12:09.750: INFO: Got endpoints: latency-svc-d95jt [345.302962ms]
May 26 17:12:09.754: INFO: Created: latency-svc-wbpwf
May 26 17:12:09.772: INFO: Got endpoints: latency-svc-wbpwf [344.730846ms]
May 26 17:12:09.783: INFO: Created: latency-svc-fhrbz
May 26 17:12:09.796: INFO: Got endpoints: latency-svc-fhrbz [347.38358ms]
May 26 17:12:09.801: INFO: Created: latency-svc-hdwxt
May 26 17:12:09.819: INFO: Got endpoints: latency-svc-hdwxt [347.109607ms]
May 26 17:12:09.825: INFO: Created: latency-svc-4jfml
May 26 17:12:09.842: INFO: Got endpoints: latency-svc-4jfml [352.031383ms]
May 26 17:12:09.854: INFO: Created: latency-svc-62t7c
May 26 17:12:09.868: INFO: Got endpoints: latency-svc-62t7c [352.90307ms]
May 26 17:12:09.878: INFO: Created: latency-svc-gxn9j
May 26 17:12:09.904: INFO: Got endpoints: latency-svc-gxn9j [366.551281ms]
May 26 17:12:09.904: INFO: Created: latency-svc-4z6p9
May 26 17:12:09.921: INFO: Got endpoints: latency-svc-4z6p9 [355.722405ms]
May 26 17:12:09.921: INFO: Created: latency-svc-qrbgn
May 26 17:12:09.935: INFO: Got endpoints: latency-svc-qrbgn [342.798475ms]
May 26 17:12:09.937: INFO: Created: latency-svc-dgs8n
May 26 17:12:09.958: INFO: Created: latency-svc-4ldc4
May 26 17:12:09.964: INFO: Got endpoints: latency-svc-dgs8n [359.214402ms]
May 26 17:12:09.977: INFO: Got endpoints: latency-svc-4ldc4 [350.754822ms]
May 26 17:12:09.978: INFO: Created: latency-svc-ckz8c
May 26 17:12:10.002: INFO: Got endpoints: latency-svc-ckz8c [362.094476ms]
May 26 17:12:10.003: INFO: Created: latency-svc-vpvpv
May 26 17:12:10.016: INFO: Got endpoints: latency-svc-vpvpv [348.607476ms]
May 26 17:12:10.034: INFO: Created: latency-svc-pmpw9
May 26 17:12:10.060: INFO: Got endpoints: latency-svc-pmpw9 [358.661561ms]
May 26 17:12:10.060: INFO: Created: latency-svc-dmc9t
May 26 17:12:10.081: INFO: Created: latency-svc-lk8z5
May 26 17:12:10.084: INFO: Got endpoints: latency-svc-dmc9t [356.620636ms]
May 26 17:12:10.095: INFO: Got endpoints: latency-svc-lk8z5 [345.504153ms]
May 26 17:12:10.104: INFO: Created: latency-svc-wkz7l
May 26 17:12:10.121: INFO: Got endpoints: latency-svc-wkz7l [349.508163ms]
May 26 17:12:10.122: INFO: Created: latency-svc-2lcjz
May 26 17:12:10.139: INFO: Got endpoints: latency-svc-2lcjz [342.346286ms]
May 26 17:12:10.147: INFO: Created: latency-svc-9js8w
May 26 17:12:10.156: INFO: Created: latency-svc-zpszf
May 26 17:12:10.160: INFO: Got endpoints: latency-svc-9js8w [341.557348ms]
May 26 17:12:10.168: INFO: Got endpoints: latency-svc-zpszf [326.534294ms]
May 26 17:12:10.172: INFO: Created: latency-svc-8s48k
May 26 17:12:10.188: INFO: Got endpoints: latency-svc-8s48k [319.313059ms]
May 26 17:12:10.191: INFO: Created: latency-svc-r7dpc
May 26 17:12:10.205: INFO: Got endpoints: latency-svc-r7dpc [301.398289ms]
May 26 17:12:10.212: INFO: Created: latency-svc-mxznz
May 26 17:12:10.231: INFO: Got endpoints: latency-svc-mxznz [310.169288ms]
May 26 17:12:10.236: INFO: Created: latency-svc-pglfc
May 26 17:12:10.256: INFO: Created: latency-svc-7fn2f
May 26 17:12:10.256: INFO: Got endpoints: latency-svc-pglfc [321.596524ms]
May 26 17:12:10.281: INFO: Got endpoints: latency-svc-7fn2f [316.769342ms]
May 26 17:12:10.284: INFO: Created: latency-svc-ndl69
May 26 17:12:10.298: INFO: Got endpoints: latency-svc-ndl69 [320.217326ms]
May 26 17:12:10.302: INFO: Created: latency-svc-nbkgw
May 26 17:12:10.317: INFO: Got endpoints: latency-svc-nbkgw [315.460501ms]
May 26 17:12:10.320: INFO: Created: latency-svc-jffxq
May 26 17:12:10.332: INFO: Got endpoints: latency-svc-jffxq [315.682942ms]
May 26 17:12:10.334: INFO: Created: latency-svc-hpp8k
May 26 17:12:10.348: INFO: Got endpoints: latency-svc-hpp8k [288.173349ms]
May 26 17:12:10.359: INFO: Created: latency-svc-mg9wn
May 26 17:12:10.374: INFO: Got endpoints: latency-svc-mg9wn [289.59067ms]
May 26 17:12:10.377: INFO: Created: latency-svc-58qbr
May 26 17:12:10.393: INFO: Got endpoints: latency-svc-58qbr [297.550148ms]
May 26 17:12:10.405: INFO: Created: latency-svc-p9r9b
May 26 17:12:10.423: INFO: Got endpoints: latency-svc-p9r9b [301.624121ms]
May 26 17:12:10.441: INFO: Created: latency-svc-fx2ll
May 26 17:12:10.460: INFO: Got endpoints: latency-svc-fx2ll [321.322985ms]
May 26 17:12:10.472: INFO: Created: latency-svc-jq9k6
May 26 17:12:10.488: INFO: Got endpoints: latency-svc-jq9k6 [327.709984ms]
May 26 17:12:10.500: INFO: Created: latency-svc-qm8r4
May 26 17:12:10.515: INFO: Got endpoints: latency-svc-qm8r4 [346.504579ms]
May 26 17:12:10.521: INFO: Created: latency-svc-bxnhl
May 26 17:12:10.536: INFO: Got endpoints: latency-svc-bxnhl [347.908467ms]
May 26 17:12:10.536: INFO: Created: latency-svc-wds68
May 26 17:12:10.554: INFO: Got endpoints: latency-svc-wds68 [348.962844ms]
May 26 17:12:10.559: INFO: Created: latency-svc-qktxs
May 26 17:12:10.572: INFO: Got endpoints: latency-svc-qktxs [340.483862ms]
May 26 17:12:10.583: INFO: Created: latency-svc-9c4kk
May 26 17:12:10.594: INFO: Created: latency-svc-g8crg
May 26 17:12:10.597: INFO: Got endpoints: latency-svc-9c4kk [340.52815ms]
May 26 17:12:10.613: INFO: Got endpoints: latency-svc-g8crg [332.261559ms]
May 26 17:12:10.622: INFO: Created: latency-svc-nlzsw
May 26 17:12:10.635: INFO: Got endpoints: latency-svc-nlzsw [337.316829ms]
May 26 17:12:10.639: INFO: Created: latency-svc-5mtg9
May 26 17:12:10.653: INFO: Got endpoints: latency-svc-5mtg9 [335.576851ms]
May 26 17:12:10.661: INFO: Created: latency-svc-k2q9l
May 26 17:12:10.675: INFO: Got endpoints: latency-svc-k2q9l [343.056805ms]
May 26 17:12:10.681: INFO: Created: latency-svc-t8crd
May 26 17:12:10.695: INFO: Got endpoints: latency-svc-t8crd [346.318376ms]
May 26 17:12:10.695: INFO: Created: latency-svc-sb5zx
May 26 17:12:10.712: INFO: Created: latency-svc-qwkxg
May 26 17:12:10.716: INFO: Got endpoints: latency-svc-sb5zx [342.075987ms]
May 26 17:12:10.729: INFO: Got endpoints: latency-svc-qwkxg [336.594688ms]
May 26 17:12:10.729: INFO: Created: latency-svc-dc7mm
May 26 17:12:10.754: INFO: Created: latency-svc-zllmz
May 26 17:12:10.754: INFO: Got endpoints: latency-svc-dc7mm [330.82313ms]
May 26 17:12:10.760: INFO: Got endpoints: latency-svc-zllmz [299.644131ms]
May 26 17:12:10.767: INFO: Created: latency-svc-mx8h8
May 26 17:12:10.783: INFO: Got endpoints: latency-svc-mx8h8 [294.518394ms]
May 26 17:12:10.784: INFO: Created: latency-svc-fpggr
May 26 17:12:10.799: INFO: Got endpoints: latency-svc-fpggr [283.760401ms]
May 26 17:12:10.803: INFO: Created: latency-svc-fqhpc
May 26 17:12:10.818: INFO: Got endpoints: latency-svc-fqhpc [282.550125ms]
May 26 17:12:10.827: INFO: Created: latency-svc-4m5vg
May 26 17:12:10.840: INFO: Got endpoints: latency-svc-4m5vg [285.431177ms]
May 26 17:12:10.840: INFO: Created: latency-svc-w9thc
May 26 17:12:10.851: INFO: Got endpoints: latency-svc-w9thc [279.816689ms]
May 26 17:12:10.857: INFO: Created: latency-svc-7lxx8
May 26 17:12:10.869: INFO: Got endpoints: latency-svc-7lxx8 [271.970827ms]
May 26 17:12:10.872: INFO: Created: latency-svc-5vkj2
May 26 17:12:10.885: INFO: Got endpoints: latency-svc-5vkj2 [271.490025ms]
May 26 17:12:10.890: INFO: Created: latency-svc-6dqp6
May 26 17:12:10.904: INFO: Got endpoints: latency-svc-6dqp6 [269.101009ms]
May 26 17:12:10.910: INFO: Created: latency-svc-vtvc2
May 26 17:12:10.924: INFO: Got endpoints: latency-svc-vtvc2 [270.971508ms]
May 26 17:12:10.934: INFO: Created: latency-svc-t6pnt
May 26 17:12:10.946: INFO: Got endpoints: latency-svc-t6pnt [270.492645ms]
May 26 17:12:10.948: INFO: Created: latency-svc-mm4ln
May 26 17:12:10.965: INFO: Got endpoints: latency-svc-mm4ln [270.704113ms]
May 26 17:12:10.966: INFO: Created: latency-svc-nxcq2
May 26 17:12:10.983: INFO: Got endpoints: latency-svc-nxcq2 [267.167865ms]
May 26 17:12:10.985: INFO: Created: latency-svc-hslc2
May 26 17:12:10.997: INFO: Got endpoints: latency-svc-hslc2 [267.79799ms]
May 26 17:12:11.004: INFO: Created: latency-svc-62zwb
May 26 17:12:11.021: INFO: Got endpoints: latency-svc-62zwb [266.826253ms]
May 26 17:12:11.021: INFO: Created: latency-svc-7kxdx
May 26 17:12:11.036: INFO: Got endpoints: latency-svc-7kxdx [276.240528ms]
May 26 17:12:11.038: INFO: Created: latency-svc-nm4cp
May 26 17:12:11.052: INFO: Got endpoints: latency-svc-nm4cp [269.107857ms]
May 26 17:12:11.057: INFO: Created: latency-svc-ggl6g
May 26 17:12:11.074: INFO: Created: latency-svc-9frwf
May 26 17:12:11.077: INFO: Got endpoints: latency-svc-ggl6g [278.21242ms]
May 26 17:12:11.089: INFO: Got endpoints: latency-svc-9frwf [270.469349ms]
May 26 17:12:11.097: INFO: Created: latency-svc-cj52l
May 26 17:12:11.112: INFO: Got endpoints: latency-svc-cj52l [271.818668ms]
May 26 17:12:11.119: INFO: Created: latency-svc-ld475
May 26 17:12:11.134: INFO: Got endpoints: latency-svc-ld475 [282.973877ms]
May 26 17:12:11.139: INFO: Created: latency-svc-shc4v
May 26 17:12:11.160: INFO: Got endpoints: latency-svc-shc4v [291.256386ms]
May 26 17:12:11.165: INFO: Created: latency-svc-c7hdq
May 26 17:12:11.179: INFO: Got endpoints: latency-svc-c7hdq [294.800688ms]
May 26 17:12:11.185: INFO: Created: latency-svc-bzrbd
May 26 17:12:11.200: INFO: Got endpoints: latency-svc-bzrbd [294.951042ms]
May 26 17:12:11.200: INFO: Created: latency-svc-j7j2r
May 26 17:12:11.215: INFO: Got endpoints: latency-svc-j7j2r [290.862064ms]
May 26 17:12:11.219: INFO: Created: latency-svc-nl59v
May 26 17:12:11.235: INFO: Got endpoints: latency-svc-nl59v [288.931954ms]
May 26 17:12:11.238: INFO: Created: latency-svc-glpn5
May 26 17:12:11.252: INFO: Got endpoints: latency-svc-glpn5 [286.523054ms]
May 26 17:12:11.256: INFO: Created: latency-svc-4lzvc
May 26 17:12:11.268: INFO: Got endpoints: latency-svc-4lzvc [285.214413ms]
May 26 17:12:11.271: INFO: Created: latency-svc-j5znq
May 26 17:12:11.286: INFO: Got endpoints: latency-svc-j5znq [288.353334ms]
May 26 17:12:11.293: INFO: Created: latency-svc-whprx
May 26 17:12:11.313: INFO: Created: latency-svc-kl5xb
May 26 17:12:11.313: INFO: Got endpoints: latency-svc-whprx [291.785959ms]
May 26 17:12:11.325: INFO: Got endpoints: latency-svc-kl5xb [288.839417ms]
May 26 17:12:11.338: INFO: Created: latency-svc-hwz6j
May 26 17:12:11.356: INFO: Got endpoints: latency-svc-hwz6j [304.124008ms]
May 26 17:12:11.380: INFO: Created: latency-svc-lxjfl
May 26 17:12:11.393: INFO: Got endpoints: latency-svc-lxjfl [315.895733ms]
May 26 17:12:11.394: INFO: Created: latency-svc-lzgcv
May 26 17:12:11.409: INFO: Got endpoints: latency-svc-lzgcv [319.961889ms]
May 26 17:12:11.410: INFO: Created: latency-svc-vdwdp
May 26 17:12:11.425: INFO: Got endpoints: latency-svc-vdwdp [313.341419ms]
May 26 17:12:11.427: INFO: Created: latency-svc-dt4b7
May 26 17:12:11.441: INFO: Got endpoints: latency-svc-dt4b7 [306.280999ms]
May 26 17:12:11.454: INFO: Created: latency-svc-8zdkh
May 26 17:12:11.468: INFO: Got endpoints: latency-svc-8zdkh [307.949182ms]
May 26 17:12:11.479: INFO: Created: latency-svc-nx66z
May 26 17:12:11.496: INFO: Got endpoints: latency-svc-nx66z [316.191451ms]
May 26 17:12:11.499: INFO: Created: latency-svc-rhcnv
May 26 17:12:11.511: INFO: Got endpoints: latency-svc-rhcnv [311.760625ms]
May 26 17:12:11.520: INFO: Created: latency-svc-74s4q
May 26 17:12:11.540: INFO: Created: latency-svc-snklp
May 26 17:12:11.542: INFO: Got endpoints: latency-svc-74s4q [326.762471ms]
May 26 17:12:11.562: INFO: Got endpoints: latency-svc-snklp [327.409976ms]
May 26 17:12:11.566: INFO: Created: latency-svc-dxdnz
May 26 17:12:11.581: INFO: Got endpoints: latency-svc-dxdnz [329.460354ms]
May 26 17:12:11.587: INFO: Created: latency-svc-hnb2b
May 26 17:12:11.619: INFO: Got endpoints: latency-svc-hnb2b [350.904562ms]
May 26 17:12:11.646: INFO: Created: latency-svc-px8zg
May 26 17:12:11.659: INFO: Got endpoints: latency-svc-px8zg [372.875579ms]
May 26 17:12:11.664: INFO: Created: latency-svc-2m7c6
May 26 17:12:11.679: INFO: Got endpoints: latency-svc-2m7c6 [365.078857ms]
May 26 17:12:11.683: INFO: Created: latency-svc-285vr
May 26 17:12:11.694: INFO: Created: latency-svc-rkczp
May 26 17:12:11.698: INFO: Got endpoints: latency-svc-285vr [373.38919ms]
May 26 17:12:11.708: INFO: Got endpoints: latency-svc-rkczp [351.851994ms]
May 26 17:12:11.711: INFO: Created: latency-svc-7k65w
May 26 17:12:11.725: INFO: Got endpoints: latency-svc-7k65w [332.39046ms]
May 26 17:12:11.729: INFO: Created: latency-svc-9nprq
May 26 17:12:11.748: INFO: Got endpoints: latency-svc-9nprq [339.37993ms]
May 26 17:12:11.750: INFO: Created: latency-svc-4kf2n
May 26 17:12:11.772: INFO: Created: latency-svc-pj4fn
May 26 17:12:11.775: INFO: Got endpoints: latency-svc-4kf2n [349.966877ms]
May 26 17:12:11.795: INFO: Got endpoints: latency-svc-pj4fn [354.321188ms]
May 26 17:12:11.801: INFO: Created: latency-svc-vtklp
May 26 17:12:11.811: INFO: Got endpoints: latency-svc-vtklp [342.832403ms]
May 26 17:12:11.819: INFO: Created: latency-svc-l7h4c
May 26 17:12:11.831: INFO: Got endpoints: latency-svc-l7h4c [335.586048ms]
May 26 17:12:11.837: INFO: Created: latency-svc-8svhj
May 26 17:12:11.854: INFO: Got endpoints: latency-svc-8svhj [342.724679ms]
May 26 17:12:11.854: INFO: Created: latency-svc-tjhzw
May 26 17:12:11.870: INFO: Got endpoints: latency-svc-tjhzw [327.885832ms]
May 26 17:12:11.870: INFO: Created: latency-svc-xsx9l
May 26 17:12:11.884: INFO: Got endpoints: latency-svc-xsx9l [321.78159ms]
May 26 17:12:11.884: INFO: Latencies: [47.917525ms 50.661816ms 70.322595ms 86.199833ms 91.605469ms 114.48379ms 115.335899ms 137.912878ms 140.292545ms 157.078321ms 168.826469ms 177.701384ms 219.948733ms 237.53377ms 261.826442ms 266.826253ms 267.167865ms 267.79799ms 269.101009ms 269.107857ms 270.469349ms 270.492645ms 270.704113ms 270.971508ms 271.490025ms 271.818668ms 271.970827ms 276.240528ms 278.21242ms 279.816689ms 282.550125ms 282.973877ms 283.760401ms 285.026966ms 285.128397ms 285.214413ms 285.431177ms 285.442423ms 286.523054ms 287.42183ms 287.666729ms 287.790503ms 288.173349ms 288.353334ms 288.839417ms 288.931954ms 289.59067ms 290.824212ms 290.862064ms 291.256386ms 291.785959ms 292.517527ms 293.030979ms 294.518394ms 294.594293ms 294.800688ms 294.835467ms 294.951042ms 295.48129ms 296.701564ms 297.181989ms 297.208513ms 297.550148ms 299.644131ms 300.053226ms 300.228053ms 300.388947ms 300.738224ms 301.398289ms 301.624121ms 301.972757ms 303.347221ms 303.951499ms 304.124008ms 304.692307ms 304.72834ms 305.46818ms 305.612125ms 305.726924ms 306.280999ms 306.3137ms 307.350073ms 307.508425ms 307.949182ms 308.164969ms 308.664334ms 308.766297ms 308.860672ms 308.939038ms 309.216689ms 309.735164ms 310.169288ms 310.25414ms 310.604865ms 311.760625ms 312.037032ms 312.903135ms 313.341419ms 313.966726ms 314.123942ms 314.146097ms 314.201276ms 314.481525ms 314.749593ms 315.122953ms 315.460501ms 315.682942ms 315.895733ms 316.128011ms 316.191451ms 316.769342ms 316.952551ms 317.078867ms 317.791604ms 319.270105ms 319.313059ms 319.832507ms 319.854932ms 319.961889ms 320.217326ms 320.33176ms 321.322985ms 321.596524ms 321.78159ms 322.438095ms 324.188527ms 324.989508ms 326.220176ms 326.534294ms 326.762471ms 327.409976ms 327.709984ms 327.885832ms 329.460354ms 329.758619ms 330.100511ms 330.82313ms 331.589081ms 332.261559ms 332.39046ms 335.576851ms 335.586048ms 336.323899ms 336.594688ms 337.040807ms 337.316829ms 339.37993ms 340.483862ms 340.52815ms 340.903319ms 340.968894ms 341.557348ms 342.075987ms 342.346286ms 342.724679ms 342.798475ms 342.832403ms 343.056805ms 343.708719ms 344.730846ms 345.302962ms 345.504153ms 346.318376ms 346.504579ms 346.793301ms 347.109607ms 347.117719ms 347.38358ms 347.908467ms 348.607476ms 348.962844ms 349.272269ms 349.508163ms 349.966877ms 350.754822ms 350.904562ms 351.851994ms 352.031383ms 352.90307ms 354.321188ms 355.722405ms 356.620636ms 358.661561ms 359.214402ms 362.094476ms 363.193362ms 365.078857ms 366.551281ms 372.875579ms 373.38919ms 382.682331ms 382.997778ms 383.090527ms 383.525205ms 384.331729ms 395.62025ms 396.253389ms 398.975206ms 400.758256ms 402.511851ms]
May 26 17:12:11.884: INFO: 50 %ile: 314.146097ms
May 26 17:12:11.884: INFO: 90 %ile: 355.722405ms
May 26 17:12:11.884: INFO: 99 %ile: 400.758256ms
May 26 17:12:11.884: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:12:11.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6062" for this suite.
May 26 17:12:37.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:12:38.443: INFO: namespace svc-latency-6062 deletion completed in 26.538780634s

• [SLOW TEST:34.284 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:12:38.446: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-eba65e85-0562-4894-ae9a-73763c3096d7
STEP: Creating a pod to test consume secrets
May 26 17:12:38.745: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf" in namespace "projected-6301" to be "success or failure"
May 26 17:12:38.757: INFO: Pod "pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.65927ms
May 26 17:12:40.779: INFO: Pod "pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033846082s
May 26 17:12:42.791: INFO: Pod "pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046238993s
STEP: Saw pod success
May 26 17:12:42.791: INFO: Pod "pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf" satisfied condition "success or failure"
May 26 17:12:42.803: INFO: Trying to get logs from node 10.113.231.133 pod pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf container secret-volume-test: <nil>
STEP: delete the pod
May 26 17:12:42.886: INFO: Waiting for pod pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf to disappear
May 26 17:12:42.897: INFO: Pod pod-projected-secrets-85f17cb2-e210-4eb7-a9d1-61fb450459cf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:12:42.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6301" for this suite.
May 26 17:12:50.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:12:51.888: INFO: namespace projected-6301 deletion completed in 8.971652308s

• [SLOW TEST:13.442 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:12:51.888: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2869
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 17:12:52.137: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:12:53.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2869" for this suite.
May 26 17:12:59.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:12:59.862: INFO: namespace custom-resource-definition-2869 deletion completed in 6.556767643s

• [SLOW TEST:7.974 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:12:59.866: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
May 26 17:13:00.118: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
May 26 17:13:01.814: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 26 17:13:03.993: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:06.009: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:08.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:10.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:12.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:14.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63726109981, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 26 17:13:17.141: INFO: Waited 1.110717089s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:13:17.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2084" for this suite.
May 26 17:13:25.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:13:26.376: INFO: namespace aggregator-2084 deletion completed in 8.507549828s

• [SLOW TEST:26.511 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:13:26.378: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
May 26 17:13:26.681: INFO: Waiting up to 5m0s for pod "client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54" in namespace "containers-6742" to be "success or failure"
May 26 17:13:26.695: INFO: Pod "client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54": Phase="Pending", Reason="", readiness=false. Elapsed: 14.364468ms
May 26 17:13:28.708: INFO: Pod "client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026426479s
May 26 17:13:30.720: INFO: Pod "client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039267225s
STEP: Saw pod success
May 26 17:13:30.720: INFO: Pod "client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54" satisfied condition "success or failure"
May 26 17:13:30.733: INFO: Trying to get logs from node 10.113.231.185 pod client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54 container test-container: <nil>
STEP: delete the pod
May 26 17:13:30.808: INFO: Waiting for pod client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54 to disappear
May 26 17:13:30.821: INFO: Pod client-containers-3a4d79d1-cb39-4cb2-998f-896f1c93ee54 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:13:30.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6742" for this suite.
May 26 17:13:38.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:13:39.368: INFO: namespace containers-6742 deletion completed in 8.529675588s

• [SLOW TEST:12.990 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:13:39.370: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 26 17:13:39.648: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 26 17:13:46.808: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:13:46.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1458" for this suite.
May 26 17:13:54.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:13:55.364: INFO: namespace pods-1458 deletion completed in 8.53026645s

• [SLOW TEST:15.994 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:13:55.365: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 17:13:55.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781" in namespace "downward-api-4104" to be "success or failure"
May 26 17:13:55.661: INFO: Pod "downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781": Phase="Pending", Reason="", readiness=false. Elapsed: 10.392531ms
May 26 17:13:57.679: INFO: Pod "downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028495557s
May 26 17:13:59.694: INFO: Pod "downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042901797s
STEP: Saw pod success
May 26 17:13:59.694: INFO: Pod "downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781" satisfied condition "success or failure"
May 26 17:13:59.706: INFO: Trying to get logs from node 10.113.231.144 pod downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781 container client-container: <nil>
STEP: delete the pod
May 26 17:13:59.787: INFO: Waiting for pod downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781 to disappear
May 26 17:13:59.799: INFO: Pod downwardapi-volume-c796c3f0-a80e-409e-80ea-ea1192317781 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:13:59.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4104" for this suite.
May 26 17:14:07.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:14:08.348: INFO: namespace downward-api-4104 deletion completed in 8.532039693s

• [SLOW TEST:12.983 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:14:08.349: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0122e148-6a3a-47e2-a1ac-ba7c6201d8dd
STEP: Creating a pod to test consume secrets
May 26 17:14:08.679: INFO: Waiting up to 5m0s for pod "pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a" in namespace "secrets-8452" to be "success or failure"
May 26 17:14:08.690: INFO: Pod "pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.926083ms
May 26 17:14:10.702: INFO: Pod "pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a": Phase="Running", Reason="", readiness=true. Elapsed: 2.023162486s
May 26 17:14:12.714: INFO: Pod "pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035083252s
STEP: Saw pod success
May 26 17:14:12.714: INFO: Pod "pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a" satisfied condition "success or failure"
May 26 17:14:12.724: INFO: Trying to get logs from node 10.113.231.185 pod pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a container secret-volume-test: <nil>
STEP: delete the pod
May 26 17:14:12.810: INFO: Waiting for pod pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a to disappear
May 26 17:14:12.826: INFO: Pod pod-secrets-e9260a32-5037-4824-a704-74cd6c9aab8a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:14:12.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8452" for this suite.
May 26 17:14:20.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:14:21.651: INFO: namespace secrets-8452 deletion completed in 8.808094152s

• [SLOW TEST:13.302 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:14:21.651: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 26 17:14:26.538: INFO: Successfully updated pod "pod-update-activedeadlineseconds-11e3d86f-292e-4406-a29b-f5bb413f3af2"
May 26 17:14:26.538: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-11e3d86f-292e-4406-a29b-f5bb413f3af2" in namespace "pods-3854" to be "terminated due to deadline exceeded"
May 26 17:14:26.560: INFO: Pod "pod-update-activedeadlineseconds-11e3d86f-292e-4406-a29b-f5bb413f3af2": Phase="Running", Reason="", readiness=true. Elapsed: 21.879074ms
May 26 17:14:28.574: INFO: Pod "pod-update-activedeadlineseconds-11e3d86f-292e-4406-a29b-f5bb413f3af2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.036419407s
May 26 17:14:28.574: INFO: Pod "pod-update-activedeadlineseconds-11e3d86f-292e-4406-a29b-f5bb413f3af2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:14:28.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3854" for this suite.
May 26 17:14:36.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:14:37.118: INFO: namespace pods-3854 deletion completed in 8.52576322s

• [SLOW TEST:15.467 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:14:37.119: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 17:14:37.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3448'
May 26 17:14:37.535: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 26 17:14:37.535: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
May 26 17:14:39.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3448'
May 26 17:14:39.717: INFO: stderr: ""
May 26 17:14:39.717: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:14:39.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3448" for this suite.
May 26 17:14:47.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:14:48.244: INFO: namespace kubectl-3448 deletion completed in 8.50801134s

• [SLOW TEST:11.125 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:14:48.245: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
May 26 17:14:48.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8" in namespace "downward-api-8176" to be "success or failure"
May 26 17:14:48.540: INFO: Pod "downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.812912ms
May 26 17:14:50.552: INFO: Pod "downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024940722s
STEP: Saw pod success
May 26 17:14:50.552: INFO: Pod "downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8" satisfied condition "success or failure"
May 26 17:14:50.569: INFO: Trying to get logs from node 10.113.231.185 pod downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8 container client-container: <nil>
STEP: delete the pod
May 26 17:14:50.658: INFO: Waiting for pod downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8 to disappear
May 26 17:14:50.671: INFO: Pod downwardapi-volume-c4305efb-c323-4fe0-ad1a-9d831ac64fb8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:14:50.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8176" for this suite.
May 26 17:14:56.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:14:57.233: INFO: namespace downward-api-8176 deletion completed in 6.538857429s

• [SLOW TEST:8.989 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:14:57.233: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
May 26 17:14:57.485: INFO: Waiting up to 5m0s for pod "downward-api-3774a664-de3b-4593-b58b-878690a5b59d" in namespace "downward-api-7431" to be "success or failure"
May 26 17:14:57.501: INFO: Pod "downward-api-3774a664-de3b-4593-b58b-878690a5b59d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.894404ms
May 26 17:14:59.512: INFO: Pod "downward-api-3774a664-de3b-4593-b58b-878690a5b59d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027089385s
STEP: Saw pod success
May 26 17:14:59.512: INFO: Pod "downward-api-3774a664-de3b-4593-b58b-878690a5b59d" satisfied condition "success or failure"
May 26 17:14:59.525: INFO: Trying to get logs from node 10.113.231.133 pod downward-api-3774a664-de3b-4593-b58b-878690a5b59d container dapi-container: <nil>
STEP: delete the pod
May 26 17:14:59.626: INFO: Waiting for pod downward-api-3774a664-de3b-4593-b58b-878690a5b59d to disappear
May 26 17:14:59.639: INFO: Pod downward-api-3774a664-de3b-4593-b58b-878690a5b59d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:14:59.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7431" for this suite.
May 26 17:15:07.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:15:08.204: INFO: namespace downward-api-7431 deletion completed in 8.548439344s

• [SLOW TEST:10.971 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:15:08.206: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
May 26 17:15:08.505: INFO: Waiting up to 5m0s for pod "downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef" in namespace "downward-api-9026" to be "success or failure"
May 26 17:15:08.516: INFO: Pod "downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.826ms
May 26 17:15:10.529: INFO: Pod "downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023550105s
May 26 17:15:12.543: INFO: Pod "downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038123545s
STEP: Saw pod success
May 26 17:15:12.543: INFO: Pod "downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef" satisfied condition "success or failure"
May 26 17:15:12.559: INFO: Trying to get logs from node 10.113.231.144 pod downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef container dapi-container: <nil>
STEP: delete the pod
May 26 17:15:12.639: INFO: Waiting for pod downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef to disappear
May 26 17:15:12.655: INFO: Pod downward-api-4f72e575-e80d-4dec-87c2-3ac5b660f1ef no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:15:12.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9026" for this suite.
May 26 17:15:20.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:15:21.392: INFO: namespace downward-api-9026 deletion completed in 8.719002283s

• [SLOW TEST:13.186 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:15:21.393: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8341
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-8341
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8341 to expose endpoints map[]
May 26 17:15:21.712: INFO: successfully validated that service multi-endpoint-test in namespace services-8341 exposes endpoints map[] (15.717255ms elapsed)
STEP: Creating pod pod1 in namespace services-8341
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8341 to expose endpoints map[pod1:[100]]
May 26 17:15:24.848: INFO: successfully validated that service multi-endpoint-test in namespace services-8341 exposes endpoints map[pod1:[100]] (3.109901765s elapsed)
STEP: Creating pod pod2 in namespace services-8341
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8341 to expose endpoints map[pod1:[100] pod2:[101]]
May 26 17:15:26.978: INFO: successfully validated that service multi-endpoint-test in namespace services-8341 exposes endpoints map[pod1:[100] pod2:[101]] (2.115576054s elapsed)
STEP: Deleting pod pod1 in namespace services-8341
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8341 to expose endpoints map[pod2:[101]]
May 26 17:15:27.030: INFO: successfully validated that service multi-endpoint-test in namespace services-8341 exposes endpoints map[pod2:[101]] (26.037992ms elapsed)
STEP: Deleting pod pod2 in namespace services-8341
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8341 to expose endpoints map[]
May 26 17:15:28.079: INFO: successfully validated that service multi-endpoint-test in namespace services-8341 exposes endpoints map[] (1.029808447s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:15:28.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8341" for this suite.
May 26 17:15:36.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:15:36.734: INFO: namespace services-8341 deletion completed in 8.55574725s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:15.341 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:15:36.734: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
May 26 17:15:36.979: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May 26 17:15:38.098: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:15:38.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9535" for this suite.
May 26 17:15:46.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:15:46.686: INFO: namespace replication-controller-9535 deletion completed in 8.540571764s

• [SLOW TEST:9.952 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:15:46.686: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
May 26 17:15:46.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1101'
May 26 17:15:47.059: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 26 17:15:47.059: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
May 26 17:15:47.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131493333 delete jobs e2e-test-nginx-job --namespace=kubectl-1101'
May 26 17:15:47.240: INFO: stderr: ""
May 26 17:15:47.240: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:15:47.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1101" for this suite.
May 26 17:16:11.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:16:11.811: INFO: namespace kubectl-1101 deletion completed in 24.554492862s

• [SLOW TEST:25.125 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
May 26 17:16:11.812: INFO: >>> kubeConfig: /tmp/kubeconfig-131493333
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
May 26 17:16:12.792: INFO: created pod pod-service-account-defaultsa
May 26 17:16:12.792: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 26 17:16:12.807: INFO: created pod pod-service-account-mountsa
May 26 17:16:12.807: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 26 17:16:12.823: INFO: created pod pod-service-account-nomountsa
May 26 17:16:12.823: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 26 17:16:12.838: INFO: created pod pod-service-account-defaultsa-mountspec
May 26 17:16:12.838: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 26 17:16:12.854: INFO: created pod pod-service-account-mountsa-mountspec
May 26 17:16:12.854: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 26 17:16:12.869: INFO: created pod pod-service-account-nomountsa-mountspec
May 26 17:16:12.869: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 26 17:16:12.884: INFO: created pod pod-service-account-defaultsa-nomountspec
May 26 17:16:12.884: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 26 17:16:12.898: INFO: created pod pod-service-account-mountsa-nomountspec
May 26 17:16:12.898: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 26 17:16:12.930: INFO: created pod pod-service-account-nomountsa-nomountspec
May 26 17:16:12.930: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
May 26 17:16:12.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8867" for this suite.
May 26 17:16:21.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 26 17:16:21.507: INFO: namespace svcaccounts-8867 deletion completed in 8.546905159s

• [SLOW TEST:9.695 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSMay 26 17:16:21.507: INFO: Running AfterSuite actions on all nodes
May 26 17:16:21.507: INFO: Running AfterSuite actions on node 1
May 26 17:16:21.507: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6104.532 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h41m46.335339965s
Test Suite Passed
