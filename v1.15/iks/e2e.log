I1021 15:55:42.296904      16 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-373207704
I1021 15:55:42.297032      16 e2e.go:243] Starting e2e run "fe02a8c6-8073-42e2-8fdf-53fda8f0199f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571673341 - Will randomize all specs
Will run 215 of 4413 specs

Oct 21 15:55:42.481: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 15:55:42.483: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 21 15:55:42.527: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 21 15:55:42.595: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 21 15:55:42.595: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Oct 21 15:55:42.595: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 21 15:55:42.615: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct 21 15:55:42.615: INFO: e2e test version: v1.15.5
Oct 21 15:55:42.617: INFO: kube-apiserver version: v1.15.5+IKS
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:55:42.618: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename svc-latency
Oct 21 15:55:42.714: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 21 15:55:42.750: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-9687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9687
I1021 15:55:42.890417      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9687, replica count: 1
I1021 15:55:43.941026      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 15:55:44.941246      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 15:55:45.941452      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 15:55:46.066: INFO: Created: latency-svc-j44gq
Oct 21 15:55:46.086: INFO: Got endpoints: latency-svc-j44gq [44.584966ms]
Oct 21 15:55:46.110: INFO: Created: latency-svc-dlpt8
Oct 21 15:55:46.124: INFO: Got endpoints: latency-svc-dlpt8 [37.657577ms]
Oct 21 15:55:46.131: INFO: Created: latency-svc-88782
Oct 21 15:55:46.137: INFO: Got endpoints: latency-svc-88782 [50.632059ms]
Oct 21 15:55:46.145: INFO: Created: latency-svc-bd8m4
Oct 21 15:55:46.152: INFO: Got endpoints: latency-svc-bd8m4 [65.516481ms]
Oct 21 15:55:46.160: INFO: Created: latency-svc-qmn26
Oct 21 15:55:46.166: INFO: Got endpoints: latency-svc-qmn26 [79.776204ms]
Oct 21 15:55:46.174: INFO: Created: latency-svc-pxtzg
Oct 21 15:55:46.180: INFO: Got endpoints: latency-svc-pxtzg [94.242963ms]
Oct 21 15:55:46.188: INFO: Created: latency-svc-dwwrf
Oct 21 15:55:46.193: INFO: Got endpoints: latency-svc-dwwrf [107.104627ms]
Oct 21 15:55:46.202: INFO: Created: latency-svc-x2zxm
Oct 21 15:55:46.208: INFO: Got endpoints: latency-svc-x2zxm [122.100187ms]
Oct 21 15:55:46.217: INFO: Created: latency-svc-9h4vq
Oct 21 15:55:46.222: INFO: Got endpoints: latency-svc-9h4vq [136.250455ms]
Oct 21 15:55:46.231: INFO: Created: latency-svc-6w7xw
Oct 21 15:55:46.236: INFO: Got endpoints: latency-svc-6w7xw [150.041476ms]
Oct 21 15:55:46.245: INFO: Created: latency-svc-b4p92
Oct 21 15:55:46.251: INFO: Got endpoints: latency-svc-b4p92 [164.654089ms]
Oct 21 15:55:46.259: INFO: Created: latency-svc-vxwzf
Oct 21 15:55:46.265: INFO: Got endpoints: latency-svc-vxwzf [178.420326ms]
Oct 21 15:55:46.273: INFO: Created: latency-svc-xnrb4
Oct 21 15:55:46.279: INFO: Got endpoints: latency-svc-xnrb4 [192.461779ms]
Oct 21 15:55:46.287: INFO: Created: latency-svc-vlhlr
Oct 21 15:55:46.293: INFO: Got endpoints: latency-svc-vlhlr [206.613979ms]
Oct 21 15:55:46.323: INFO: Created: latency-svc-zk4lp
Oct 21 15:55:46.323: INFO: Got endpoints: latency-svc-zk4lp [236.774824ms]
Oct 21 15:55:46.323: INFO: Created: latency-svc-knw6x
Oct 21 15:55:46.323: INFO: Got endpoints: latency-svc-knw6x [236.318164ms]
Oct 21 15:55:46.332: INFO: Created: latency-svc-mg69k
Oct 21 15:55:46.338: INFO: Got endpoints: latency-svc-mg69k [214.26017ms]
Oct 21 15:55:46.347: INFO: Created: latency-svc-hmqbm
Oct 21 15:55:46.353: INFO: Got endpoints: latency-svc-hmqbm [30.384674ms]
Oct 21 15:55:46.362: INFO: Created: latency-svc-d8htp
Oct 21 15:55:46.369: INFO: Got endpoints: latency-svc-d8htp [231.999647ms]
Oct 21 15:55:46.384: INFO: Created: latency-svc-hzm42
Oct 21 15:55:46.390: INFO: Got endpoints: latency-svc-hzm42 [238.610722ms]
Oct 21 15:55:46.399: INFO: Created: latency-svc-dzqdq
Oct 21 15:55:46.405: INFO: Got endpoints: latency-svc-dzqdq [239.129443ms]
Oct 21 15:55:46.413: INFO: Created: latency-svc-n7lmx
Oct 21 15:55:46.419: INFO: Got endpoints: latency-svc-n7lmx [238.577728ms]
Oct 21 15:55:46.427: INFO: Created: latency-svc-wtc7d
Oct 21 15:55:46.433: INFO: Got endpoints: latency-svc-wtc7d [239.987838ms]
Oct 21 15:55:46.441: INFO: Created: latency-svc-8l4hp
Oct 21 15:55:46.447: INFO: Got endpoints: latency-svc-8l4hp [238.583977ms]
Oct 21 15:55:46.456: INFO: Created: latency-svc-242dx
Oct 21 15:55:46.462: INFO: Got endpoints: latency-svc-242dx [239.810453ms]
Oct 21 15:55:46.470: INFO: Created: latency-svc-sdcln
Oct 21 15:55:46.477: INFO: Got endpoints: latency-svc-sdcln [240.692573ms]
Oct 21 15:55:46.484: INFO: Created: latency-svc-9hndl
Oct 21 15:55:46.490: INFO: Got endpoints: latency-svc-9hndl [239.479488ms]
Oct 21 15:55:46.499: INFO: Created: latency-svc-m88pf
Oct 21 15:55:46.505: INFO: Got endpoints: latency-svc-m88pf [239.866924ms]
Oct 21 15:55:46.514: INFO: Created: latency-svc-gnkgl
Oct 21 15:55:46.520: INFO: Got endpoints: latency-svc-gnkgl [240.716591ms]
Oct 21 15:55:46.528: INFO: Created: latency-svc-2zvxn
Oct 21 15:55:46.534: INFO: Got endpoints: latency-svc-2zvxn [241.290947ms]
Oct 21 15:55:46.543: INFO: Created: latency-svc-zc7x9
Oct 21 15:55:46.548: INFO: Got endpoints: latency-svc-zc7x9 [225.660332ms]
Oct 21 15:55:46.557: INFO: Created: latency-svc-498jb
Oct 21 15:55:46.562: INFO: Got endpoints: latency-svc-498jb [224.538264ms]
Oct 21 15:55:46.571: INFO: Created: latency-svc-bqn9v
Oct 21 15:55:46.576: INFO: Got endpoints: latency-svc-bqn9v [223.211755ms]
Oct 21 15:55:46.584: INFO: Created: latency-svc-jlhfh
Oct 21 15:55:46.590: INFO: Got endpoints: latency-svc-jlhfh [221.45654ms]
Oct 21 15:55:46.599: INFO: Created: latency-svc-z8d4t
Oct 21 15:55:46.604: INFO: Got endpoints: latency-svc-z8d4t [213.930047ms]
Oct 21 15:55:46.613: INFO: Created: latency-svc-fhj77
Oct 21 15:55:46.619: INFO: Got endpoints: latency-svc-fhj77 [214.198797ms]
Oct 21 15:55:46.628: INFO: Created: latency-svc-28hqh
Oct 21 15:55:46.635: INFO: Got endpoints: latency-svc-28hqh [215.889233ms]
Oct 21 15:55:46.642: INFO: Created: latency-svc-tdr7h
Oct 21 15:55:46.647: INFO: Got endpoints: latency-svc-tdr7h [213.748509ms]
Oct 21 15:55:46.657: INFO: Created: latency-svc-284k2
Oct 21 15:55:46.663: INFO: Got endpoints: latency-svc-284k2 [216.499616ms]
Oct 21 15:55:46.672: INFO: Created: latency-svc-gr78n
Oct 21 15:55:46.680: INFO: Got endpoints: latency-svc-gr78n [217.494502ms]
Oct 21 15:55:46.687: INFO: Created: latency-svc-xlmqh
Oct 21 15:55:46.698: INFO: Got endpoints: latency-svc-xlmqh [221.213973ms]
Oct 21 15:55:46.701: INFO: Created: latency-svc-g77x4
Oct 21 15:55:46.707: INFO: Got endpoints: latency-svc-g77x4 [216.947466ms]
Oct 21 15:55:46.716: INFO: Created: latency-svc-6wmv9
Oct 21 15:55:46.722: INFO: Got endpoints: latency-svc-6wmv9 [217.198324ms]
Oct 21 15:55:46.730: INFO: Created: latency-svc-4t9zd
Oct 21 15:55:46.736: INFO: Got endpoints: latency-svc-4t9zd [216.783477ms]
Oct 21 15:55:46.745: INFO: Created: latency-svc-dcnkw
Oct 21 15:55:46.751: INFO: Got endpoints: latency-svc-dcnkw [216.191742ms]
Oct 21 15:55:46.760: INFO: Created: latency-svc-zkswn
Oct 21 15:55:46.766: INFO: Got endpoints: latency-svc-zkswn [217.157191ms]
Oct 21 15:55:46.773: INFO: Created: latency-svc-c7dj6
Oct 21 15:55:46.780: INFO: Got endpoints: latency-svc-c7dj6 [217.083242ms]
Oct 21 15:55:46.790: INFO: Created: latency-svc-rbtxt
Oct 21 15:55:46.794: INFO: Got endpoints: latency-svc-rbtxt [217.231585ms]
Oct 21 15:55:46.802: INFO: Created: latency-svc-n8jw6
Oct 21 15:55:46.808: INFO: Got endpoints: latency-svc-n8jw6 [217.876347ms]
Oct 21 15:55:46.816: INFO: Created: latency-svc-zc2nj
Oct 21 15:55:46.822: INFO: Got endpoints: latency-svc-zc2nj [217.417367ms]
Oct 21 15:55:46.830: INFO: Created: latency-svc-nbtgm
Oct 21 15:55:46.837: INFO: Got endpoints: latency-svc-nbtgm [217.447879ms]
Oct 21 15:55:46.845: INFO: Created: latency-svc-2hr72
Oct 21 15:55:46.851: INFO: Got endpoints: latency-svc-2hr72 [215.849923ms]
Oct 21 15:55:46.860: INFO: Created: latency-svc-g567z
Oct 21 15:55:46.866: INFO: Got endpoints: latency-svc-g567z [218.538809ms]
Oct 21 15:55:46.874: INFO: Created: latency-svc-2g45x
Oct 21 15:55:46.881: INFO: Got endpoints: latency-svc-2g45x [217.126707ms]
Oct 21 15:55:46.889: INFO: Created: latency-svc-m947t
Oct 21 15:55:46.895: INFO: Got endpoints: latency-svc-m947t [215.178335ms]
Oct 21 15:55:46.903: INFO: Created: latency-svc-62rs2
Oct 21 15:55:46.909: INFO: Got endpoints: latency-svc-62rs2 [211.094015ms]
Oct 21 15:55:46.917: INFO: Created: latency-svc-q9kfl
Oct 21 15:55:46.925: INFO: Got endpoints: latency-svc-q9kfl [217.113751ms]
Oct 21 15:55:46.935: INFO: Created: latency-svc-54fm9
Oct 21 15:55:46.941: INFO: Got endpoints: latency-svc-54fm9 [219.406307ms]
Oct 21 15:55:46.947: INFO: Created: latency-svc-bb4bn
Oct 21 15:55:46.953: INFO: Got endpoints: latency-svc-bb4bn [216.659725ms]
Oct 21 15:55:46.962: INFO: Created: latency-svc-ggt8k
Oct 21 15:55:46.969: INFO: Got endpoints: latency-svc-ggt8k [217.908592ms]
Oct 21 15:55:46.977: INFO: Created: latency-svc-4wj4r
Oct 21 15:55:46.983: INFO: Got endpoints: latency-svc-4wj4r [217.614908ms]
Oct 21 15:55:46.992: INFO: Created: latency-svc-6fpkr
Oct 21 15:55:46.998: INFO: Got endpoints: latency-svc-6fpkr [218.20555ms]
Oct 21 15:55:47.006: INFO: Created: latency-svc-x27qn
Oct 21 15:55:47.013: INFO: Got endpoints: latency-svc-x27qn [219.162278ms]
Oct 21 15:55:47.020: INFO: Created: latency-svc-w798f
Oct 21 15:55:47.026: INFO: Got endpoints: latency-svc-w798f [217.58272ms]
Oct 21 15:55:47.034: INFO: Created: latency-svc-c52gt
Oct 21 15:55:47.040: INFO: Got endpoints: latency-svc-c52gt [218.154143ms]
Oct 21 15:55:47.048: INFO: Created: latency-svc-9h5lh
Oct 21 15:55:47.054: INFO: Got endpoints: latency-svc-9h5lh [217.056903ms]
Oct 21 15:55:47.063: INFO: Created: latency-svc-pdgb8
Oct 21 15:55:47.068: INFO: Got endpoints: latency-svc-pdgb8 [217.297692ms]
Oct 21 15:55:47.077: INFO: Created: latency-svc-vl5qb
Oct 21 15:55:47.082: INFO: Got endpoints: latency-svc-vl5qb [216.244219ms]
Oct 21 15:55:47.090: INFO: Created: latency-svc-pp684
Oct 21 15:55:47.096: INFO: Got endpoints: latency-svc-pp684 [215.194984ms]
Oct 21 15:55:47.106: INFO: Created: latency-svc-9fc99
Oct 21 15:55:47.110: INFO: Got endpoints: latency-svc-9fc99 [214.597542ms]
Oct 21 15:55:47.119: INFO: Created: latency-svc-7xvsz
Oct 21 15:55:47.125: INFO: Got endpoints: latency-svc-7xvsz [215.36449ms]
Oct 21 15:55:47.132: INFO: Created: latency-svc-fk4bb
Oct 21 15:55:47.138: INFO: Got endpoints: latency-svc-fk4bb [213.135499ms]
Oct 21 15:55:47.146: INFO: Created: latency-svc-68rgc
Oct 21 15:55:47.152: INFO: Got endpoints: latency-svc-68rgc [210.45535ms]
Oct 21 15:55:47.172: INFO: Created: latency-svc-z95z8
Oct 21 15:55:47.172: INFO: Got endpoints: latency-svc-z95z8 [218.734056ms]
Oct 21 15:55:47.175: INFO: Created: latency-svc-cr6w7
Oct 21 15:55:47.181: INFO: Got endpoints: latency-svc-cr6w7 [212.159152ms]
Oct 21 15:55:47.190: INFO: Created: latency-svc-nxq2n
Oct 21 15:55:47.195: INFO: Got endpoints: latency-svc-nxq2n [211.7326ms]
Oct 21 15:55:47.204: INFO: Created: latency-svc-pwqzp
Oct 21 15:55:47.210: INFO: Got endpoints: latency-svc-pwqzp [212.038401ms]
Oct 21 15:55:47.219: INFO: Created: latency-svc-nx87z
Oct 21 15:55:47.225: INFO: Got endpoints: latency-svc-nx87z [211.881803ms]
Oct 21 15:55:47.233: INFO: Created: latency-svc-nrqsv
Oct 21 15:55:47.239: INFO: Got endpoints: latency-svc-nrqsv [212.815933ms]
Oct 21 15:55:47.261: INFO: Created: latency-svc-wfscr
Oct 21 15:55:47.261: INFO: Got endpoints: latency-svc-wfscr [220.688274ms]
Oct 21 15:55:47.262: INFO: Created: latency-svc-cf7dk
Oct 21 15:55:47.269: INFO: Got endpoints: latency-svc-cf7dk [215.167087ms]
Oct 21 15:55:47.276: INFO: Created: latency-svc-bq62d
Oct 21 15:55:47.283: INFO: Got endpoints: latency-svc-bq62d [214.451307ms]
Oct 21 15:55:47.292: INFO: Created: latency-svc-th92t
Oct 21 15:55:47.298: INFO: Got endpoints: latency-svc-th92t [215.62401ms]
Oct 21 15:55:47.308: INFO: Created: latency-svc-sxxk8
Oct 21 15:55:47.314: INFO: Got endpoints: latency-svc-sxxk8 [217.929114ms]
Oct 21 15:55:47.322: INFO: Created: latency-svc-cqztm
Oct 21 15:55:47.328: INFO: Got endpoints: latency-svc-cqztm [218.10292ms]
Oct 21 15:55:47.336: INFO: Created: latency-svc-hrgvx
Oct 21 15:55:47.343: INFO: Got endpoints: latency-svc-hrgvx [217.793485ms]
Oct 21 15:55:47.351: INFO: Created: latency-svc-qvjmv
Oct 21 15:55:47.358: INFO: Got endpoints: latency-svc-qvjmv [219.674305ms]
Oct 21 15:55:47.365: INFO: Created: latency-svc-z44wk
Oct 21 15:55:47.372: INFO: Got endpoints: latency-svc-z44wk [219.639304ms]
Oct 21 15:55:47.379: INFO: Created: latency-svc-5ntmq
Oct 21 15:55:47.387: INFO: Got endpoints: latency-svc-5ntmq [214.654104ms]
Oct 21 15:55:47.394: INFO: Created: latency-svc-2b2t5
Oct 21 15:55:47.400: INFO: Got endpoints: latency-svc-2b2t5 [218.938538ms]
Oct 21 15:55:47.409: INFO: Created: latency-svc-t66j5
Oct 21 15:55:47.415: INFO: Got endpoints: latency-svc-t66j5 [219.596991ms]
Oct 21 15:55:47.433: INFO: Created: latency-svc-s75t6
Oct 21 15:55:47.440: INFO: Got endpoints: latency-svc-s75t6 [229.594333ms]
Oct 21 15:55:47.448: INFO: Created: latency-svc-pgktb
Oct 21 15:55:47.454: INFO: Got endpoints: latency-svc-pgktb [229.136351ms]
Oct 21 15:55:47.462: INFO: Created: latency-svc-fsszt
Oct 21 15:55:47.467: INFO: Got endpoints: latency-svc-fsszt [228.625099ms]
Oct 21 15:55:47.477: INFO: Created: latency-svc-qd2rq
Oct 21 15:55:47.483: INFO: Got endpoints: latency-svc-qd2rq [221.673485ms]
Oct 21 15:55:47.491: INFO: Created: latency-svc-24shx
Oct 21 15:55:47.497: INFO: Got endpoints: latency-svc-24shx [228.154275ms]
Oct 21 15:55:47.506: INFO: Created: latency-svc-cwbf9
Oct 21 15:55:47.512: INFO: Got endpoints: latency-svc-cwbf9 [228.889016ms]
Oct 21 15:55:47.523: INFO: Created: latency-svc-pf969
Oct 21 15:55:47.526: INFO: Got endpoints: latency-svc-pf969 [228.458059ms]
Oct 21 15:55:47.534: INFO: Created: latency-svc-xlwp5
Oct 21 15:55:47.539: INFO: Got endpoints: latency-svc-xlwp5 [225.476074ms]
Oct 21 15:55:47.548: INFO: Created: latency-svc-shn2f
Oct 21 15:55:47.554: INFO: Got endpoints: latency-svc-shn2f [225.818158ms]
Oct 21 15:55:47.563: INFO: Created: latency-svc-fjc8h
Oct 21 15:55:47.570: INFO: Got endpoints: latency-svc-fjc8h [227.590016ms]
Oct 21 15:55:47.576: INFO: Created: latency-svc-gqrh6
Oct 21 15:55:47.583: INFO: Got endpoints: latency-svc-gqrh6 [225.720786ms]
Oct 21 15:55:47.591: INFO: Created: latency-svc-9q9hz
Oct 21 15:55:47.598: INFO: Got endpoints: latency-svc-9q9hz [226.176072ms]
Oct 21 15:55:47.606: INFO: Created: latency-svc-xf6lv
Oct 21 15:55:47.613: INFO: Got endpoints: latency-svc-xf6lv [225.828862ms]
Oct 21 15:55:47.620: INFO: Created: latency-svc-bjgs9
Oct 21 15:55:47.626: INFO: Got endpoints: latency-svc-bjgs9 [225.838003ms]
Oct 21 15:55:47.634: INFO: Created: latency-svc-97cr2
Oct 21 15:55:47.641: INFO: Got endpoints: latency-svc-97cr2 [226.104233ms]
Oct 21 15:55:47.657: INFO: Created: latency-svc-rc4vm
Oct 21 15:55:47.662: INFO: Got endpoints: latency-svc-rc4vm [222.479691ms]
Oct 21 15:55:47.663: INFO: Created: latency-svc-7q9f5
Oct 21 15:55:47.670: INFO: Got endpoints: latency-svc-7q9f5 [215.500945ms]
Oct 21 15:55:47.679: INFO: Created: latency-svc-zdn4z
Oct 21 15:55:47.684: INFO: Got endpoints: latency-svc-zdn4z [216.704621ms]
Oct 21 15:55:47.694: INFO: Created: latency-svc-zkwph
Oct 21 15:55:47.700: INFO: Got endpoints: latency-svc-zkwph [216.865669ms]
Oct 21 15:55:47.708: INFO: Created: latency-svc-685ch
Oct 21 15:55:47.715: INFO: Got endpoints: latency-svc-685ch [217.833742ms]
Oct 21 15:55:47.723: INFO: Created: latency-svc-wfwz5
Oct 21 15:55:47.729: INFO: Got endpoints: latency-svc-wfwz5 [216.967497ms]
Oct 21 15:55:47.739: INFO: Created: latency-svc-z96fp
Oct 21 15:55:47.746: INFO: Got endpoints: latency-svc-z96fp [219.912093ms]
Oct 21 15:55:47.755: INFO: Created: latency-svc-78qzm
Oct 21 15:55:47.761: INFO: Got endpoints: latency-svc-78qzm [221.994746ms]
Oct 21 15:55:47.771: INFO: Created: latency-svc-bnfb7
Oct 21 15:55:47.778: INFO: Got endpoints: latency-svc-bnfb7 [223.969785ms]
Oct 21 15:55:47.787: INFO: Created: latency-svc-xvm4t
Oct 21 15:55:47.793: INFO: Got endpoints: latency-svc-xvm4t [222.185018ms]
Oct 21 15:55:47.800: INFO: Created: latency-svc-g7qc8
Oct 21 15:55:47.806: INFO: Got endpoints: latency-svc-g7qc8 [222.733215ms]
Oct 21 15:55:47.815: INFO: Created: latency-svc-r6xtv
Oct 21 15:55:47.820: INFO: Got endpoints: latency-svc-r6xtv [222.314505ms]
Oct 21 15:55:47.829: INFO: Created: latency-svc-ckrjx
Oct 21 15:55:47.835: INFO: Got endpoints: latency-svc-ckrjx [222.044554ms]
Oct 21 15:55:47.843: INFO: Created: latency-svc-cv4jl
Oct 21 15:55:47.850: INFO: Got endpoints: latency-svc-cv4jl [224.13867ms]
Oct 21 15:55:47.860: INFO: Created: latency-svc-dw4t4
Oct 21 15:55:47.865: INFO: Got endpoints: latency-svc-dw4t4 [223.642917ms]
Oct 21 15:55:47.873: INFO: Created: latency-svc-z6n47
Oct 21 15:55:47.879: INFO: Got endpoints: latency-svc-z6n47 [217.131392ms]
Oct 21 15:55:47.888: INFO: Created: latency-svc-jjpvk
Oct 21 15:55:47.894: INFO: Got endpoints: latency-svc-jjpvk [224.395968ms]
Oct 21 15:55:47.903: INFO: Created: latency-svc-d8ljl
Oct 21 15:55:47.909: INFO: Got endpoints: latency-svc-d8ljl [224.717632ms]
Oct 21 15:55:47.918: INFO: Created: latency-svc-fhfkf
Oct 21 15:55:47.923: INFO: Got endpoints: latency-svc-fhfkf [223.436762ms]
Oct 21 15:55:47.932: INFO: Created: latency-svc-shf7l
Oct 21 15:55:47.937: INFO: Got endpoints: latency-svc-shf7l [221.876635ms]
Oct 21 15:55:47.948: INFO: Created: latency-svc-thpxd
Oct 21 15:55:47.953: INFO: Got endpoints: latency-svc-thpxd [224.587555ms]
Oct 21 15:55:47.962: INFO: Created: latency-svc-bn2rp
Oct 21 15:55:47.968: INFO: Got endpoints: latency-svc-bn2rp [222.024309ms]
Oct 21 15:55:47.975: INFO: Created: latency-svc-gslj2
Oct 21 15:55:47.982: INFO: Got endpoints: latency-svc-gslj2 [220.090328ms]
Oct 21 15:55:47.990: INFO: Created: latency-svc-2l4xl
Oct 21 15:55:47.997: INFO: Got endpoints: latency-svc-2l4xl [219.164455ms]
Oct 21 15:55:48.005: INFO: Created: latency-svc-wgjk6
Oct 21 15:55:48.011: INFO: Got endpoints: latency-svc-wgjk6 [218.193269ms]
Oct 21 15:55:48.019: INFO: Created: latency-svc-hk2gv
Oct 21 15:55:48.026: INFO: Got endpoints: latency-svc-hk2gv [219.571223ms]
Oct 21 15:55:48.040: INFO: Created: latency-svc-c4tmv
Oct 21 15:55:48.048: INFO: Got endpoints: latency-svc-c4tmv [227.596545ms]
Oct 21 15:55:48.054: INFO: Created: latency-svc-lzv8j
Oct 21 15:55:48.060: INFO: Got endpoints: latency-svc-lzv8j [224.943164ms]
Oct 21 15:55:48.068: INFO: Created: latency-svc-wvx7q
Oct 21 15:55:48.074: INFO: Got endpoints: latency-svc-wvx7q [224.377865ms]
Oct 21 15:55:48.083: INFO: Created: latency-svc-frhwh
Oct 21 15:55:48.090: INFO: Got endpoints: latency-svc-frhwh [225.072304ms]
Oct 21 15:55:48.099: INFO: Created: latency-svc-xfjpq
Oct 21 15:55:48.105: INFO: Got endpoints: latency-svc-xfjpq [225.68636ms]
Oct 21 15:55:48.114: INFO: Created: latency-svc-cvs6r
Oct 21 15:55:48.120: INFO: Got endpoints: latency-svc-cvs6r [225.4752ms]
Oct 21 15:55:48.128: INFO: Created: latency-svc-4vn6x
Oct 21 15:55:48.135: INFO: Got endpoints: latency-svc-4vn6x [225.725679ms]
Oct 21 15:55:48.143: INFO: Created: latency-svc-gdldw
Oct 21 15:55:48.150: INFO: Got endpoints: latency-svc-gdldw [227.359411ms]
Oct 21 15:55:48.157: INFO: Created: latency-svc-qnhr7
Oct 21 15:55:48.163: INFO: Got endpoints: latency-svc-qnhr7 [225.820123ms]
Oct 21 15:55:48.172: INFO: Created: latency-svc-db4pn
Oct 21 15:55:48.178: INFO: Got endpoints: latency-svc-db4pn [224.874484ms]
Oct 21 15:55:48.186: INFO: Created: latency-svc-wk2sv
Oct 21 15:55:48.195: INFO: Got endpoints: latency-svc-wk2sv [227.012274ms]
Oct 21 15:55:48.202: INFO: Created: latency-svc-zmlkn
Oct 21 15:55:48.210: INFO: Got endpoints: latency-svc-zmlkn [228.1685ms]
Oct 21 15:55:48.216: INFO: Created: latency-svc-wmtwb
Oct 21 15:55:48.223: INFO: Got endpoints: latency-svc-wmtwb [225.663301ms]
Oct 21 15:55:48.231: INFO: Created: latency-svc-lfhvp
Oct 21 15:55:48.237: INFO: Got endpoints: latency-svc-lfhvp [226.234145ms]
Oct 21 15:55:48.245: INFO: Created: latency-svc-t6n7f
Oct 21 15:55:48.251: INFO: Got endpoints: latency-svc-t6n7f [224.606156ms]
Oct 21 15:55:48.259: INFO: Created: latency-svc-s25rm
Oct 21 15:55:48.265: INFO: Got endpoints: latency-svc-s25rm [217.076564ms]
Oct 21 15:55:48.273: INFO: Created: latency-svc-4zmz2
Oct 21 15:55:48.280: INFO: Got endpoints: latency-svc-4zmz2 [220.484792ms]
Oct 21 15:55:48.287: INFO: Created: latency-svc-5c62d
Oct 21 15:55:48.294: INFO: Got endpoints: latency-svc-5c62d [219.693153ms]
Oct 21 15:55:48.302: INFO: Created: latency-svc-n2clx
Oct 21 15:55:48.311: INFO: Got endpoints: latency-svc-n2clx [221.107951ms]
Oct 21 15:55:48.320: INFO: Created: latency-svc-nvv45
Oct 21 15:55:48.325: INFO: Got endpoints: latency-svc-nvv45 [220.150753ms]
Oct 21 15:55:48.334: INFO: Created: latency-svc-v5f24
Oct 21 15:55:48.341: INFO: Got endpoints: latency-svc-v5f24 [221.344571ms]
Oct 21 15:55:48.348: INFO: Created: latency-svc-c77jm
Oct 21 15:55:48.355: INFO: Got endpoints: latency-svc-c77jm [220.0855ms]
Oct 21 15:55:48.363: INFO: Created: latency-svc-vhdx4
Oct 21 15:55:48.369: INFO: Got endpoints: latency-svc-vhdx4 [219.086427ms]
Oct 21 15:55:48.377: INFO: Created: latency-svc-8bz49
Oct 21 15:55:48.385: INFO: Got endpoints: latency-svc-8bz49 [221.652633ms]
Oct 21 15:55:48.392: INFO: Created: latency-svc-fjqbd
Oct 21 15:55:48.398: INFO: Got endpoints: latency-svc-fjqbd [219.406043ms]
Oct 21 15:55:48.407: INFO: Created: latency-svc-z5td5
Oct 21 15:55:48.413: INFO: Got endpoints: latency-svc-z5td5 [217.334381ms]
Oct 21 15:55:48.420: INFO: Created: latency-svc-szckh
Oct 21 15:55:48.427: INFO: Got endpoints: latency-svc-szckh [216.903258ms]
Oct 21 15:55:48.435: INFO: Created: latency-svc-79xvv
Oct 21 15:55:48.441: INFO: Got endpoints: latency-svc-79xvv [218.620142ms]
Oct 21 15:55:48.450: INFO: Created: latency-svc-ck68z
Oct 21 15:55:48.456: INFO: Got endpoints: latency-svc-ck68z [218.940018ms]
Oct 21 15:55:48.464: INFO: Created: latency-svc-2pghj
Oct 21 15:55:48.470: INFO: Got endpoints: latency-svc-2pghj [219.710936ms]
Oct 21 15:55:48.483: INFO: Created: latency-svc-bp2qd
Oct 21 15:55:48.490: INFO: Got endpoints: latency-svc-bp2qd [225.273625ms]
Oct 21 15:55:48.497: INFO: Created: latency-svc-4cbrs
Oct 21 15:55:48.503: INFO: Got endpoints: latency-svc-4cbrs [222.687703ms]
Oct 21 15:55:48.512: INFO: Created: latency-svc-d69wk
Oct 21 15:55:48.518: INFO: Got endpoints: latency-svc-d69wk [224.129728ms]
Oct 21 15:55:48.527: INFO: Created: latency-svc-bx24p
Oct 21 15:55:48.533: INFO: Got endpoints: latency-svc-bx24p [221.847502ms]
Oct 21 15:55:48.542: INFO: Created: latency-svc-grg5b
Oct 21 15:55:48.548: INFO: Got endpoints: latency-svc-grg5b [222.717136ms]
Oct 21 15:55:48.557: INFO: Created: latency-svc-q2xcq
Oct 21 15:55:48.562: INFO: Got endpoints: latency-svc-q2xcq [221.395933ms]
Oct 21 15:55:48.572: INFO: Created: latency-svc-ntblv
Oct 21 15:55:48.577: INFO: Got endpoints: latency-svc-ntblv [222.440664ms]
Oct 21 15:55:48.586: INFO: Created: latency-svc-lxwhx
Oct 21 15:55:48.592: INFO: Got endpoints: latency-svc-lxwhx [222.62447ms]
Oct 21 15:55:48.602: INFO: Created: latency-svc-2wmcg
Oct 21 15:55:48.608: INFO: Got endpoints: latency-svc-2wmcg [222.999703ms]
Oct 21 15:55:48.617: INFO: Created: latency-svc-vg8vx
Oct 21 15:55:48.623: INFO: Got endpoints: latency-svc-vg8vx [224.899284ms]
Oct 21 15:55:48.632: INFO: Created: latency-svc-4plnb
Oct 21 15:55:48.638: INFO: Got endpoints: latency-svc-4plnb [225.297801ms]
Oct 21 15:55:48.646: INFO: Created: latency-svc-l2pfs
Oct 21 15:55:48.653: INFO: Got endpoints: latency-svc-l2pfs [225.902398ms]
Oct 21 15:55:48.661: INFO: Created: latency-svc-f5wh6
Oct 21 15:55:48.668: INFO: Got endpoints: latency-svc-f5wh6 [226.324681ms]
Oct 21 15:55:48.676: INFO: Created: latency-svc-hdwt6
Oct 21 15:55:48.682: INFO: Got endpoints: latency-svc-hdwt6 [225.654392ms]
Oct 21 15:55:48.691: INFO: Created: latency-svc-8c68v
Oct 21 15:55:48.696: INFO: Got endpoints: latency-svc-8c68v [225.837738ms]
Oct 21 15:55:48.704: INFO: Created: latency-svc-9gwgr
Oct 21 15:55:48.710: INFO: Got endpoints: latency-svc-9gwgr [220.115421ms]
Oct 21 15:55:48.719: INFO: Created: latency-svc-5rh6m
Oct 21 15:55:48.726: INFO: Got endpoints: latency-svc-5rh6m [222.699994ms]
Oct 21 15:55:48.734: INFO: Created: latency-svc-47qzd
Oct 21 15:55:48.740: INFO: Got endpoints: latency-svc-47qzd [221.480197ms]
Oct 21 15:55:48.749: INFO: Created: latency-svc-j8qzq
Oct 21 15:55:48.754: INFO: Got endpoints: latency-svc-j8qzq [221.279267ms]
Oct 21 15:55:48.763: INFO: Created: latency-svc-r9cm7
Oct 21 15:55:48.769: INFO: Got endpoints: latency-svc-r9cm7 [221.208113ms]
Oct 21 15:55:48.778: INFO: Created: latency-svc-knn6p
Oct 21 15:55:48.783: INFO: Got endpoints: latency-svc-knn6p [220.93418ms]
Oct 21 15:55:48.792: INFO: Created: latency-svc-qbc66
Oct 21 15:55:48.798: INFO: Got endpoints: latency-svc-qbc66 [220.816114ms]
Oct 21 15:55:48.807: INFO: Created: latency-svc-cp5g2
Oct 21 15:55:48.812: INFO: Got endpoints: latency-svc-cp5g2 [219.921757ms]
Oct 21 15:55:48.820: INFO: Created: latency-svc-jftzc
Oct 21 15:55:48.826: INFO: Got endpoints: latency-svc-jftzc [218.532136ms]
Oct 21 15:55:48.835: INFO: Created: latency-svc-69gmq
Oct 21 15:55:48.841: INFO: Got endpoints: latency-svc-69gmq [217.797583ms]
Oct 21 15:55:48.850: INFO: Created: latency-svc-f7dql
Oct 21 15:55:48.865: INFO: Got endpoints: latency-svc-f7dql [226.508503ms]
Oct 21 15:55:48.872: INFO: Created: latency-svc-5jzn2
Oct 21 15:55:48.877: INFO: Got endpoints: latency-svc-5jzn2 [224.258984ms]
Oct 21 15:55:48.887: INFO: Created: latency-svc-82cm8
Oct 21 15:55:48.892: INFO: Got endpoints: latency-svc-82cm8 [224.607861ms]
Oct 21 15:55:48.901: INFO: Created: latency-svc-wljrk
Oct 21 15:55:48.907: INFO: Got endpoints: latency-svc-wljrk [224.92279ms]
Oct 21 15:55:48.916: INFO: Created: latency-svc-fg4qq
Oct 21 15:55:48.923: INFO: Got endpoints: latency-svc-fg4qq [227.117734ms]
Oct 21 15:55:48.933: INFO: Created: latency-svc-fjcd7
Oct 21 15:55:48.936: INFO: Got endpoints: latency-svc-fjcd7 [225.677085ms]
Oct 21 15:55:48.945: INFO: Created: latency-svc-6llxj
Oct 21 15:55:48.951: INFO: Got endpoints: latency-svc-6llxj [225.239503ms]
Oct 21 15:55:48.962: INFO: Created: latency-svc-fmzx6
Oct 21 15:55:48.967: INFO: Got endpoints: latency-svc-fmzx6 [226.802955ms]
Oct 21 15:55:48.976: INFO: Created: latency-svc-2qvmx
Oct 21 15:55:48.981: INFO: Got endpoints: latency-svc-2qvmx [227.177288ms]
Oct 21 15:55:48.989: INFO: Created: latency-svc-mvqf4
Oct 21 15:55:48.995: INFO: Got endpoints: latency-svc-mvqf4 [225.56004ms]
Oct 21 15:55:49.004: INFO: Created: latency-svc-xmf7g
Oct 21 15:55:49.010: INFO: Got endpoints: latency-svc-xmf7g [226.853359ms]
Oct 21 15:55:49.019: INFO: Created: latency-svc-l684v
Oct 21 15:55:49.025: INFO: Got endpoints: latency-svc-l684v [226.352022ms]
Oct 21 15:55:49.033: INFO: Created: latency-svc-kt9s6
Oct 21 15:55:49.039: INFO: Got endpoints: latency-svc-kt9s6 [227.245084ms]
Oct 21 15:55:49.048: INFO: Created: latency-svc-7hmsr
Oct 21 15:55:49.054: INFO: Got endpoints: latency-svc-7hmsr [227.673495ms]
Oct 21 15:55:49.054: INFO: Latencies: [30.384674ms 37.657577ms 50.632059ms 65.516481ms 79.776204ms 94.242963ms 107.104627ms 122.100187ms 136.250455ms 150.041476ms 164.654089ms 178.420326ms 192.461779ms 206.613979ms 210.45535ms 211.094015ms 211.7326ms 211.881803ms 212.038401ms 212.159152ms 212.815933ms 213.135499ms 213.748509ms 213.930047ms 214.198797ms 214.26017ms 214.451307ms 214.597542ms 214.654104ms 215.167087ms 215.178335ms 215.194984ms 215.36449ms 215.500945ms 215.62401ms 215.849923ms 215.889233ms 216.191742ms 216.244219ms 216.499616ms 216.659725ms 216.704621ms 216.783477ms 216.865669ms 216.903258ms 216.947466ms 216.967497ms 217.056903ms 217.076564ms 217.083242ms 217.113751ms 217.126707ms 217.131392ms 217.157191ms 217.198324ms 217.231585ms 217.297692ms 217.334381ms 217.417367ms 217.447879ms 217.494502ms 217.58272ms 217.614908ms 217.793485ms 217.797583ms 217.833742ms 217.876347ms 217.908592ms 217.929114ms 218.10292ms 218.154143ms 218.193269ms 218.20555ms 218.532136ms 218.538809ms 218.620142ms 218.734056ms 218.938538ms 218.940018ms 219.086427ms 219.162278ms 219.164455ms 219.406043ms 219.406307ms 219.571223ms 219.596991ms 219.639304ms 219.674305ms 219.693153ms 219.710936ms 219.912093ms 219.921757ms 220.0855ms 220.090328ms 220.115421ms 220.150753ms 220.484792ms 220.688274ms 220.816114ms 220.93418ms 221.107951ms 221.208113ms 221.213973ms 221.279267ms 221.344571ms 221.395933ms 221.45654ms 221.480197ms 221.652633ms 221.673485ms 221.847502ms 221.876635ms 221.994746ms 222.024309ms 222.044554ms 222.185018ms 222.314505ms 222.440664ms 222.479691ms 222.62447ms 222.687703ms 222.699994ms 222.717136ms 222.733215ms 222.999703ms 223.211755ms 223.436762ms 223.642917ms 223.969785ms 224.129728ms 224.13867ms 224.258984ms 224.377865ms 224.395968ms 224.538264ms 224.587555ms 224.606156ms 224.607861ms 224.717632ms 224.874484ms 224.899284ms 224.92279ms 224.943164ms 225.072304ms 225.239503ms 225.273625ms 225.297801ms 225.4752ms 225.476074ms 225.56004ms 225.654392ms 225.660332ms 225.663301ms 225.677085ms 225.68636ms 225.720786ms 225.725679ms 225.818158ms 225.820123ms 225.828862ms 225.837738ms 225.838003ms 225.902398ms 226.104233ms 226.176072ms 226.234145ms 226.324681ms 226.352022ms 226.508503ms 226.802955ms 226.853359ms 227.012274ms 227.117734ms 227.177288ms 227.245084ms 227.359411ms 227.590016ms 227.596545ms 227.673495ms 228.154275ms 228.1685ms 228.458059ms 228.625099ms 228.889016ms 229.136351ms 229.594333ms 231.999647ms 236.318164ms 236.774824ms 238.577728ms 238.583977ms 238.610722ms 239.129443ms 239.479488ms 239.810453ms 239.866924ms 239.987838ms 240.692573ms 240.716591ms 241.290947ms]
Oct 21 15:55:49.054: INFO: 50 %ile: 221.107951ms
Oct 21 15:55:49.054: INFO: 90 %ile: 228.1685ms
Oct 21 15:55:49.054: INFO: 99 %ile: 240.716591ms
Oct 21 15:55:49.054: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:55:49.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9687" for this suite.
Oct 21 15:56:19.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:56:19.376: INFO: namespace svc-latency-9687 deletion completed in 30.312887559s

• [SLOW TEST:36.758 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:56:19.376: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-baa43600-de61-44d8-9f56-785cecca21ed
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:56:19.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9827" for this suite.
Oct 21 15:56:25.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:56:25.892: INFO: namespace secrets-9827 deletion completed in 6.306267476s

• [SLOW TEST:6.516 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:56:25.892: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9038
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 15:56:26.166: INFO: Number of nodes with available pods: 0
Oct 21 15:56:26.166: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:27.183: INFO: Number of nodes with available pods: 0
Oct 21 15:56:27.183: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:28.183: INFO: Number of nodes with available pods: 0
Oct 21 15:56:28.183: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:29.183: INFO: Number of nodes with available pods: 0
Oct 21 15:56:29.183: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:30.188: INFO: Number of nodes with available pods: 0
Oct 21 15:56:30.188: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:31.183: INFO: Number of nodes with available pods: 0
Oct 21 15:56:31.183: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:32.183: INFO: Number of nodes with available pods: 0
Oct 21 15:56:32.183: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 15:56:33.182: INFO: Number of nodes with available pods: 3
Oct 21 15:56:33.182: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 21 15:56:33.220: INFO: Number of nodes with available pods: 2
Oct 21 15:56:33.220: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 15:56:34.237: INFO: Number of nodes with available pods: 2
Oct 21 15:56:34.237: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 15:56:35.236: INFO: Number of nodes with available pods: 2
Oct 21 15:56:35.236: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 15:56:36.235: INFO: Number of nodes with available pods: 3
Oct 21 15:56:36.235: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9038, will wait for the garbage collector to delete the pods
Oct 21 15:56:36.335: INFO: Deleting DaemonSet.extensions daemon-set took: 23.479577ms
Oct 21 15:56:36.436: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.332107ms
Oct 21 15:56:42.843: INFO: Number of nodes with available pods: 0
Oct 21 15:56:42.843: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 15:56:42.854: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9038/daemonsets","resourceVersion":"21884"},"items":null}

Oct 21 15:56:42.860: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9038/pods","resourceVersion":"21884"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:56:42.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9038" for this suite.
Oct 21 15:56:48.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:56:49.225: INFO: namespace daemonsets-9038 deletion completed in 6.329892151s

• [SLOW TEST:23.333 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:56:49.225: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 15:56:49.430: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 21 15:56:49.446: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 21 15:56:54.454: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 15:56:54.454: INFO: Creating deployment "test-rolling-update-deployment"
Oct 21 15:56:54.464: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 21 15:56:54.481: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 21 15:56:56.500: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 21 15:56:56.508: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 15:56:58.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707270214, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 15:57:00.517: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 21 15:57:00.542: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8397,SelfLink:/apis/apps/v1/namespaces/deployment-8397/deployments/test-rolling-update-deployment,UID:df95e522-a7b4-4a1a-8ce1-52ced8d4593a,ResourceVersion:22006,Generation:1,CreationTimestamp:2019-10-21 15:56:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 15:56:54 +0000 UTC 2019-10-21 15:56:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 15:56:59 +0000 UTC 2019-10-21 15:56:54 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 15:57:00.550: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-8397,SelfLink:/apis/apps/v1/namespaces/deployment-8397/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:b1ce5893-6c01-4238-baf0-8f12a9871563,ResourceVersion:21996,Generation:1,CreationTimestamp:2019-10-21 15:56:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df95e522-a7b4-4a1a-8ce1-52ced8d4593a 0xc002d8f8d7 0xc002d8f8d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 15:57:00.550: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 21 15:57:00.550: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8397,SelfLink:/apis/apps/v1/namespaces/deployment-8397/replicasets/test-rolling-update-controller,UID:5cfc2ec8-3681-4ffe-ace9-065e1b175c17,ResourceVersion:22005,Generation:2,CreationTimestamp:2019-10-21 15:56:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df95e522-a7b4-4a1a-8ce1-52ced8d4593a 0xc002d8f807 0xc002d8f808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 15:57:00.556: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-mbkpz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-mbkpz,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-8397,SelfLink:/api/v1/namespaces/deployment-8397/pods/test-rolling-update-deployment-79f6b9d75c-mbkpz,UID:c4059294-cb6b-4221-8759-f9fcb2a2a44d,ResourceVersion:21995,Generation:0,CreationTimestamp:2019-10-21 15:56:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c b1ce5893-6c01-4238-baf0-8f12a9871563 0xc002ef61c7 0xc002ef61c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zls5b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zls5b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zls5b true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ef6240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ef6260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 15:56:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 15:56:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 15:56:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 15:56:54 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.193,StartTime:2019-10-21 15:56:54 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 15:56:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://fce67fceface558eceb9d16a7e1ff533c56f4395f833f18f283ea787e9dcb20e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:57:00.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8397" for this suite.
Oct 21 15:57:06.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:57:06.902: INFO: namespace deployment-8397 deletion completed in 6.336485541s

• [SLOW TEST:17.676 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:57:06.903: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-c1b67879-26e7-4e53-ab62-2093f8b2795b
STEP: Creating a pod to test consume secrets
Oct 21 15:57:07.130: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da" in namespace "projected-342" to be "success or failure"
Oct 21 15:57:07.135: INFO: Pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.672976ms
Oct 21 15:57:09.143: INFO: Pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012988821s
Oct 21 15:57:11.150: INFO: Pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020387164s
Oct 21 15:57:13.157: INFO: Pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026957036s
STEP: Saw pod success
Oct 21 15:57:13.157: INFO: Pod "pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da" satisfied condition "success or failure"
Oct 21 15:57:13.163: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 15:57:13.202: INFO: Waiting for pod pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da to disappear
Oct 21 15:57:13.208: INFO: Pod pod-projected-secrets-ea89b6f3-bc57-4861-afe4-597a567402da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:57:13.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-342" for this suite.
Oct 21 15:57:19.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:57:19.539: INFO: namespace projected-342 deletion completed in 6.322360028s

• [SLOW TEST:12.635 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:57:19.539: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:58:19.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9686" for this suite.
Oct 21 15:58:41.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:58:42.122: INFO: namespace container-probe-9686 deletion completed in 22.351508012s

• [SLOW TEST:82.583 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:58:42.123: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 21 15:58:42.345: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 21 15:58:47.375: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 15:58:48.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6941" for this suite.
Oct 21 15:58:54.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 15:58:54.718: INFO: namespace replication-controller-6941 deletion completed in 6.308707623s

• [SLOW TEST:12.595 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 15:58:54.719: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3115
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-b00af843-e244-4c2a-81e7-9d114dd99df9
STEP: Creating secret with name s-test-opt-upd-ab4d15be-a93c-4799-b283-4a820fa77922
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b00af843-e244-4c2a-81e7-9d114dd99df9
STEP: Updating secret s-test-opt-upd-ab4d15be-a93c-4799-b283-4a820fa77922
STEP: Creating secret with name s-test-opt-create-152eea2c-846b-4cbf-8ddc-f1f7fd16fe62
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:00:20.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3115" for this suite.
Oct 21 16:00:44.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:00:44.417: INFO: namespace secrets-3115 deletion completed in 24.340854194s

• [SLOW TEST:109.698 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:00:44.417: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 21 16:00:44.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-7093'
Oct 21 16:00:45.085: INFO: stderr: ""
Oct 21 16:00:45.085: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:00:45.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7093'
Oct 21 16:00:45.188: INFO: stderr: ""
Oct 21 16:00:45.188: INFO: stdout: "update-demo-nautilus-k9ncx update-demo-nautilus-qt9xn "
Oct 21 16:00:45.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-k9ncx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:45.294: INFO: stderr: ""
Oct 21 16:00:45.294: INFO: stdout: ""
Oct 21 16:00:45.294: INFO: update-demo-nautilus-k9ncx is created but not running
Oct 21 16:00:50.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7093'
Oct 21 16:00:50.389: INFO: stderr: ""
Oct 21 16:00:50.389: INFO: stdout: "update-demo-nautilus-k9ncx update-demo-nautilus-qt9xn "
Oct 21 16:00:50.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-k9ncx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:50.498: INFO: stderr: ""
Oct 21 16:00:50.498: INFO: stdout: ""
Oct 21 16:00:50.498: INFO: update-demo-nautilus-k9ncx is created but not running
Oct 21 16:00:55.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7093'
Oct 21 16:00:55.603: INFO: stderr: ""
Oct 21 16:00:55.603: INFO: stdout: "update-demo-nautilus-k9ncx update-demo-nautilus-qt9xn "
Oct 21 16:00:55.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-k9ncx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:55.705: INFO: stderr: ""
Oct 21 16:00:55.705: INFO: stdout: "true"
Oct 21 16:00:55.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-k9ncx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:55.811: INFO: stderr: ""
Oct 21 16:00:55.811: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:00:55.811: INFO: validating pod update-demo-nautilus-k9ncx
Oct 21 16:00:55.831: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:00:55.831: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:00:55.831: INFO: update-demo-nautilus-k9ncx is verified up and running
Oct 21 16:00:55.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-qt9xn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:55.934: INFO: stderr: ""
Oct 21 16:00:55.934: INFO: stdout: "true"
Oct 21 16:00:55.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-qt9xn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7093'
Oct 21 16:00:56.035: INFO: stderr: ""
Oct 21 16:00:56.035: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:00:56.035: INFO: validating pod update-demo-nautilus-qt9xn
Oct 21 16:00:56.052: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:00:56.052: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:00:56.052: INFO: update-demo-nautilus-qt9xn is verified up and running
STEP: using delete to clean up resources
Oct 21 16:00:56.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-7093'
Oct 21 16:00:56.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:00:56.186: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 16:00:56.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7093'
Oct 21 16:00:56.312: INFO: stderr: "No resources found.\n"
Oct 21 16:00:56.312: INFO: stdout: ""
Oct 21 16:00:56.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -l name=update-demo --namespace=kubectl-7093 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:00:56.485: INFO: stderr: ""
Oct 21 16:00:56.485: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:00:56.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7093" for this suite.
Oct 21 16:01:20.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:20.833: INFO: namespace kubectl-7093 deletion completed in 24.338496292s

• [SLOW TEST:36.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:01:20.833: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0d46c3b1-cf00-488a-b503-4a5225822866
STEP: Creating a pod to test consume configMaps
Oct 21 16:01:21.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500" in namespace "configmap-733" to be "success or failure"
Oct 21 16:01:21.065: INFO: Pod "pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500": Phase="Pending", Reason="", readiness=false. Elapsed: 5.49607ms
Oct 21 16:01:23.071: INFO: Pod "pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011662311s
STEP: Saw pod success
Oct 21 16:01:23.071: INFO: Pod "pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500" satisfied condition "success or failure"
Oct 21 16:01:23.077: INFO: Trying to get logs from node 10.195.18.154 pod pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:01:23.105: INFO: Waiting for pod pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500 to disappear
Oct 21 16:01:23.110: INFO: Pod pod-configmaps-7208fbd3-0a54-4107-a897-f22d480fe500 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:01:23.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-733" for this suite.
Oct 21 16:01:29.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:01:29.436: INFO: namespace configmap-733 deletion completed in 6.317085406s

• [SLOW TEST:8.603 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:01:29.438: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 21 16:01:36.242: INFO: Successfully updated pod "annotationupdate8408c68f-0f56-477c-9124-a21951d452cc"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:01:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4701" for this suite.
Oct 21 16:02:00.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:00.588: INFO: namespace downward-api-4701 deletion completed in 22.308273875s

• [SLOW TEST:31.150 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:02:00.589: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 21 16:02:06.867: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:02:06.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6454" for this suite.
Oct 21 16:02:12.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:13.239: INFO: namespace container-runtime-6454 deletion completed in 6.339000353s

• [SLOW TEST:12.650 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:02:13.239: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1037
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:02:13.444: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:02:14.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1037" for this suite.
Oct 21 16:02:20.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:20.857: INFO: namespace custom-resource-definition-1037 deletion completed in 6.31001954s

• [SLOW TEST:7.618 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:02:20.859: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:02:21.073: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b" in namespace "projected-3898" to be "success or failure"
Oct 21 16:02:21.079: INFO: Pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.889003ms
Oct 21 16:02:23.087: INFO: Pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013801174s
Oct 21 16:02:25.094: INFO: Pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02064671s
Oct 21 16:02:27.100: INFO: Pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027289843s
STEP: Saw pod success
Oct 21 16:02:27.100: INFO: Pod "downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b" satisfied condition "success or failure"
Oct 21 16:02:27.106: INFO: Trying to get logs from node 10.195.18.160 pod downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b container client-container: <nil>
STEP: delete the pod
Oct 21 16:02:27.206: INFO: Waiting for pod downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b to disappear
Oct 21 16:02:27.223: INFO: Pod downwardapi-volume-41f70f35-7436-48bb-9a30-a3821494062b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:02:27.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3898" for this suite.
Oct 21 16:02:33.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:33.567: INFO: namespace projected-3898 deletion completed in 6.334950305s

• [SLOW TEST:12.708 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:02:33.567: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8664
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 21 16:02:33.780: INFO: Waiting up to 5m0s for pod "pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec" in namespace "emptydir-8664" to be "success or failure"
Oct 21 16:02:33.785: INFO: Pod "pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.618179ms
Oct 21 16:02:35.793: INFO: Pod "pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013326025s
Oct 21 16:02:37.800: INFO: Pod "pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020613426s
STEP: Saw pod success
Oct 21 16:02:37.800: INFO: Pod "pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec" satisfied condition "success or failure"
Oct 21 16:02:37.807: INFO: Trying to get logs from node 10.195.18.159 pod pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec container test-container: <nil>
STEP: delete the pod
Oct 21 16:02:37.840: INFO: Waiting for pod pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec to disappear
Oct 21 16:02:37.845: INFO: Pod pod-d7b2bee0-fa26-4056-91de-a20a7b1d3aec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:02:37.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8664" for this suite.
Oct 21 16:02:43.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:02:44.178: INFO: namespace emptydir-8664 deletion completed in 6.324269221s

• [SLOW TEST:10.611 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:02:44.178: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-e4503726-433d-49aa-987c-ead18d3e4009 in namespace container-probe-9400
Oct 21 16:02:52.406: INFO: Started pod busybox-e4503726-433d-49aa-987c-ead18d3e4009 in namespace container-probe-9400
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 16:02:52.411: INFO: Initial restart count of pod busybox-e4503726-433d-49aa-987c-ead18d3e4009 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:06:53.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9400" for this suite.
Oct 21 16:06:59.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:06:59.954: INFO: namespace container-probe-9400 deletion completed in 6.552736989s

• [SLOW TEST:255.775 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:06:59.954: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6556
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6556
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6556
Oct 21 16:07:00.191: INFO: Found 0 stateful pods, waiting for 1
Oct 21 16:07:10.202: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 21 16:07:10.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:07:10.548: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:07:10.548: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:07:10.548: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:07:10.555: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 16:07:20.564: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:07:20.564: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:07:20.602: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998359s
Oct 21 16:07:21.609: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993449506s
Oct 21 16:07:22.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985820248s
Oct 21 16:07:23.627: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978171461s
Oct 21 16:07:24.635: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.96765564s
Oct 21 16:07:25.642: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960426417s
Oct 21 16:07:26.650: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.952868106s
Oct 21 16:07:27.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.945069206s
Oct 21 16:07:28.664: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.937863024s
Oct 21 16:07:29.672: INFO: Verifying statefulset ss doesn't scale past 1 for another 930.475516ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6556
Oct 21 16:07:30.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:07:31.002: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:07:31.003: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:07:31.003: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:07:31.010: INFO: Found 1 stateful pods, waiting for 3
Oct 21 16:07:41.019: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:07:41.019: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:07:41.019: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 21 16:07:41.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:07:41.385: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:07:41.385: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:07:41.385: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:07:41.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:07:41.675: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:07:41.675: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:07:41.675: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:07:41.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:07:42.052: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:07:42.052: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:07:42.052: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:07:42.052: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:07:42.062: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 21 16:07:52.082: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:07:52.082: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:07:52.082: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 16:07:52.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998431s
Oct 21 16:07:53.117: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993635643s
Oct 21 16:07:54.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98623194s
Oct 21 16:07:55.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978566145s
Oct 21 16:07:56.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97046977s
Oct 21 16:07:57.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962942617s
Oct 21 16:07:58.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955558931s
Oct 21 16:07:59.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.947852709s
Oct 21 16:08:00.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.940406356s
Oct 21 16:08:01.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.721643ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6556
Oct 21 16:08:02.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:02.534: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:02.534: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:02.534: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:02.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:02.855: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:02.855: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:02.855: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:02.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-6556 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:08:03.200: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:08:03.200: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:08:03.200: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:08:03.200: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 16:08:33.235: INFO: Deleting all statefulset in ns statefulset-6556
Oct 21 16:08:33.245: INFO: Scaling statefulset ss to 0
Oct 21 16:08:33.270: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:08:33.294: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:08:33.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6556" for this suite.
Oct 21 16:08:39.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:08:39.657: INFO: namespace statefulset-6556 deletion completed in 6.313563857s

• [SLOW TEST:99.703 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:08:39.658: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Oct 21 16:08:39.867: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-373207704 proxy --unix-socket=/tmp/kubectl-proxy-unix382613271/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:08:39.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8460" for this suite.
Oct 21 16:08:45.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:08:46.225: INFO: namespace kubectl-8460 deletion completed in 6.296037984s

• [SLOW TEST:6.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:08:46.228: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Oct 21 16:08:46.449: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9345" to be "success or failure"
Oct 21 16:08:46.455: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.79237ms
Oct 21 16:08:48.461: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012470018s
STEP: Saw pod success
Oct 21 16:08:48.461: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 21 16:08:48.467: INFO: Trying to get logs from node 10.195.18.160 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 21 16:08:48.503: INFO: Waiting for pod pod-host-path-test to disappear
Oct 21 16:08:48.509: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:08:48.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9345" for this suite.
Oct 21 16:08:54.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:08:54.855: INFO: namespace hostpath-9345 deletion completed in 6.336679181s

• [SLOW TEST:8.627 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:08:54.855: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-664
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 21 16:08:55.100: INFO: Found 0 stateful pods, waiting for 3
Oct 21 16:09:05.108: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:09:05.108: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:09:05.108: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:09:05.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-664 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:09:05.476: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:09:05.476: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:09:05.476: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 16:09:15.544: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 21 16:09:25.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-664 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:09:25.911: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:09:25.911: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:09:25.911: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:09:35.961: INFO: Waiting for StatefulSet statefulset-664/ss2 to complete update
Oct 21 16:09:35.961: INFO: Waiting for Pod statefulset-664/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:09:35.961: INFO: Waiting for Pod statefulset-664/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:09:45.980: INFO: Waiting for StatefulSet statefulset-664/ss2 to complete update
Oct 21 16:09:45.980: INFO: Waiting for Pod statefulset-664/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:09:55.985: INFO: Waiting for StatefulSet statefulset-664/ss2 to complete update
STEP: Rolling back to a previous revision
Oct 21 16:10:05.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-664 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 16:10:06.382: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 16:10:06.382: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 16:10:06.382: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 16:10:16.447: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 21 16:10:26.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-664 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 16:10:26.832: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 16:10:26.832: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 16:10:26.832: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 16:10:46.883: INFO: Waiting for StatefulSet statefulset-664/ss2 to complete update
Oct 21 16:10:46.883: INFO: Waiting for Pod statefulset-664/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Oct 21 16:10:56.903: INFO: Waiting for StatefulSet statefulset-664/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 16:11:06.909: INFO: Deleting all statefulset in ns statefulset-664
Oct 21 16:11:06.919: INFO: Scaling statefulset ss2 to 0
Oct 21 16:11:26.962: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:11:26.973: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:11:27.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-664" for this suite.
Oct 21 16:11:35.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:35.322: INFO: namespace statefulset-664 deletion completed in 8.299404808s

• [SLOW TEST:160.467 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:11:35.322: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-eac45837-84c2-4982-8307-ae6beae34856
STEP: Creating a pod to test consume secrets
Oct 21 16:11:35.547: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922" in namespace "projected-8227" to be "success or failure"
Oct 21 16:11:35.553: INFO: Pod "pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922": Phase="Pending", Reason="", readiness=false. Elapsed: 5.951805ms
Oct 21 16:11:37.561: INFO: Pod "pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014203406s
STEP: Saw pod success
Oct 21 16:11:37.561: INFO: Pod "pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922" satisfied condition "success or failure"
Oct 21 16:11:37.568: INFO: Trying to get logs from node 10.195.18.159 pod pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:11:37.601: INFO: Waiting for pod pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922 to disappear
Oct 21 16:11:37.607: INFO: Pod pod-projected-secrets-0cdf8681-bf03-43b1-be35-25b4e7c05922 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:11:37.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8227" for this suite.
Oct 21 16:11:43.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:11:43.943: INFO: namespace projected-8227 deletion completed in 6.326274155s

• [SLOW TEST:8.620 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:11:43.943: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5208
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 16:11:54.215: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:11:54.221: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:11:56.221: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:11:56.228: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:11:58.221: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:11:58.230: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:12:00.221: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:12:00.229: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:12:02.221: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:12:02.228: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 16:12:04.221: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 16:12:04.228: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:12:04.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5208" for this suite.
Oct 21 16:12:28.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:12:28.597: INFO: namespace container-lifecycle-hook-5208 deletion completed in 24.339316939s

• [SLOW TEST:44.655 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:12:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:12:33.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4679" for this suite.
Oct 21 16:12:57.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:12:58.186: INFO: namespace replication-controller-4679 deletion completed in 24.305363886s

• [SLOW TEST:29.589 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:12:58.187: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 21 16:12:58.391: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:13:01.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1863" for this suite.
Oct 21 16:13:07.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:08.037: INFO: namespace init-container-1863 deletion completed in 6.290602041s

• [SLOW TEST:9.850 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:13:08.042: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5620
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4725
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:13:14.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8449" for this suite.
Oct 21 16:13:20.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:21.085: INFO: namespace namespaces-8449 deletion completed in 6.354105635s
STEP: Destroying namespace "nsdeletetest-5620" for this suite.
Oct 21 16:13:21.094: INFO: Namespace nsdeletetest-5620 was already deleted
STEP: Destroying namespace "nsdeletetest-4725" for this suite.
Oct 21 16:13:27.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:27.395: INFO: namespace nsdeletetest-4725 deletion completed in 6.301375694s

• [SLOW TEST:19.353 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:13:27.395: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:13:27.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 version'
Oct 21 16:13:27.690: INFO: stderr: ""
Oct 21 16:13:27.691: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5+IKS\", GitCommit:\"46ea161061498e0ebd9b11d66b3b7dba16fa594d\", GitTreeState:\"clean\", BuildDate:\"2019-10-17T13:24:04Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:13:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9718" for this suite.
Oct 21 16:13:33.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:33.999: INFO: namespace kubectl-9718 deletion completed in 6.300370229s

• [SLOW TEST:6.604 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:13:34.000: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:13:34.226: INFO: (0) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.15426ms)
Oct 21 16:13:34.235: INFO: (1) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.861776ms)
Oct 21 16:13:34.245: INFO: (2) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.597249ms)
Oct 21 16:13:34.267: INFO: (3) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.713681ms)
Oct 21 16:13:34.279: INFO: (4) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.448998ms)
Oct 21 16:13:34.289: INFO: (5) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.074542ms)
Oct 21 16:13:34.299: INFO: (6) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.872508ms)
Oct 21 16:13:34.308: INFO: (7) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.633167ms)
Oct 21 16:13:34.318: INFO: (8) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.995591ms)
Oct 21 16:13:34.328: INFO: (9) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.596742ms)
Oct 21 16:13:34.340: INFO: (10) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.336438ms)
Oct 21 16:13:34.350: INFO: (11) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.18144ms)
Oct 21 16:13:34.360: INFO: (12) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.303295ms)
Oct 21 16:13:34.370: INFO: (13) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.426271ms)
Oct 21 16:13:34.379: INFO: (14) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.39123ms)
Oct 21 16:13:34.389: INFO: (15) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.311328ms)
Oct 21 16:13:34.400: INFO: (16) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.281958ms)
Oct 21 16:13:34.410: INFO: (17) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.12344ms)
Oct 21 16:13:34.429: INFO: (18) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.541031ms)
Oct 21 16:13:34.440: INFO: (19) /api/v1/nodes/10.195.18.154/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.50844ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:13:34.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6435" for this suite.
Oct 21 16:13:40.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:40.742: INFO: namespace proxy-6435 deletion completed in 6.294540873s

• [SLOW TEST:6.742 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:13:40.742: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 21 16:13:42.993: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-373207704 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 21 16:13:48.137: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:13:48.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6845" for this suite.
Oct 21 16:13:54.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:13:54.472: INFO: namespace pods-6845 deletion completed in 6.322982085s

• [SLOW TEST:13.730 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:13:54.476: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9225, will wait for the garbage collector to delete the pods
Oct 21 16:14:02.780: INFO: Deleting Job.batch foo took: 20.083633ms
Oct 21 16:14:02.880: INFO: Terminating Job.batch foo pods took: 100.19662ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:14:43.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9225" for this suite.
Oct 21 16:14:49.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:14:49.911: INFO: namespace job-9225 deletion completed in 6.312151973s

• [SLOW TEST:55.435 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:14:49.911: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:14:50.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea" in namespace "downward-api-5017" to be "success or failure"
Oct 21 16:14:50.135: INFO: Pod "downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.757624ms
Oct 21 16:14:52.142: INFO: Pod "downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017666871s
Oct 21 16:14:54.150: INFO: Pod "downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025930972s
STEP: Saw pod success
Oct 21 16:14:54.150: INFO: Pod "downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea" satisfied condition "success or failure"
Oct 21 16:14:54.156: INFO: Trying to get logs from node 10.195.18.154 pod downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea container client-container: <nil>
STEP: delete the pod
Oct 21 16:14:54.187: INFO: Waiting for pod downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea to disappear
Oct 21 16:14:54.193: INFO: Pod downwardapi-volume-8c69e264-b5d6-49a2-b814-e27652bedcea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:14:54.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5017" for this suite.
Oct 21 16:15:00.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:15:00.523: INFO: namespace downward-api-5017 deletion completed in 6.321102543s

• [SLOW TEST:10.612 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:15:00.526: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4191
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-a3800df0-ecf2-44fe-868a-5f2de3fdd57d
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:15:00.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4191" for this suite.
Oct 21 16:15:06.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:15:07.047: INFO: namespace configmap-4191 deletion completed in 6.310246548s

• [SLOW TEST:6.521 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:15:07.049: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4760
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 21 16:15:09.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec pod-sharedvolume-e2f358d9-9f73-4981-8ee7-998d5a769267 -c busybox-main-container --namespace=emptydir-4760 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 21 16:15:09.746: INFO: stderr: ""
Oct 21 16:15:09.746: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:15:09.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4760" for this suite.
Oct 21 16:15:15.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:15:16.136: INFO: namespace emptydir-4760 deletion completed in 6.379882809s

• [SLOW TEST:9.086 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:15:16.136: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 21 16:15:16.334: INFO: PodSpec: initContainers in spec.initContainers
Oct 21 16:16:00.389: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7fceeb77-33ab-4ee3-a327-b05cf62312d2", GenerateName:"", Namespace:"init-container-4670", SelfLink:"/api/v1/namespaces/init-container-4670/pods/pod-init-7fceeb77-33ab-4ee3-a327-b05cf62312d2", UID:"5573f6a5-be48-4f6a-b528-3b90bb12a7f0", ResourceVersion:"25653", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707271316, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"334586156"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6l9nd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001dda380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6l9nd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6l9nd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6l9nd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003b7a488), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.195.18.154", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026140c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003b7a510)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003b7a530)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003b7a538), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003b7a53c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271316, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271316, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271316, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707271316, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.195.18.154", PodIP:"172.30.78.245", StartTime:(*v1.Time)(0xc002728220), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c302a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c30310)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://9b78ce60d5f38c60f0a367cc684263446c314aafa99c22eb6bdf300e15ebed49"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002728260), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002728240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:16:00.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4670" for this suite.
Oct 21 16:16:24.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:16:24.727: INFO: namespace init-container-4670 deletion completed in 24.328097744s

• [SLOW TEST:68.592 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:16:24.728: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 21 16:16:27.497: INFO: Successfully updated pod "annotationupdate0c08e5a0-b097-4bdc-a518-5bc42572c926"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:16:29.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1063" for this suite.
Oct 21 16:16:45.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:16:45.873: INFO: namespace projected-1063 deletion completed in 16.337016596s

• [SLOW TEST:21.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:16:45.874: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 16:16:46.149: INFO: Number of nodes with available pods: 0
Oct 21 16:16:46.149: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:47.166: INFO: Number of nodes with available pods: 0
Oct 21 16:16:47.167: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:48.164: INFO: Number of nodes with available pods: 1
Oct 21 16:16:48.164: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:49.165: INFO: Number of nodes with available pods: 3
Oct 21 16:16:49.165: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 21 16:16:49.208: INFO: Number of nodes with available pods: 2
Oct 21 16:16:49.208: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:50.224: INFO: Number of nodes with available pods: 2
Oct 21 16:16:50.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:51.225: INFO: Number of nodes with available pods: 2
Oct 21 16:16:51.225: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:52.223: INFO: Number of nodes with available pods: 2
Oct 21 16:16:52.223: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:53.224: INFO: Number of nodes with available pods: 2
Oct 21 16:16:53.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:54.224: INFO: Number of nodes with available pods: 2
Oct 21 16:16:54.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:55.224: INFO: Number of nodes with available pods: 2
Oct 21 16:16:55.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:56.235: INFO: Number of nodes with available pods: 2
Oct 21 16:16:56.235: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:57.223: INFO: Number of nodes with available pods: 2
Oct 21 16:16:57.223: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:58.224: INFO: Number of nodes with available pods: 2
Oct 21 16:16:58.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:16:59.225: INFO: Number of nodes with available pods: 2
Oct 21 16:16:59.225: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:00.228: INFO: Number of nodes with available pods: 2
Oct 21 16:17:00.228: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:01.224: INFO: Number of nodes with available pods: 2
Oct 21 16:17:01.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:02.224: INFO: Number of nodes with available pods: 2
Oct 21 16:17:02.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:03.224: INFO: Number of nodes with available pods: 2
Oct 21 16:17:03.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:04.224: INFO: Number of nodes with available pods: 2
Oct 21 16:17:04.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:05.224: INFO: Number of nodes with available pods: 2
Oct 21 16:17:05.224: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:06.243: INFO: Number of nodes with available pods: 3
Oct 21 16:17:06.243: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2591, will wait for the garbage collector to delete the pods
Oct 21 16:17:06.337: INFO: Deleting DaemonSet.extensions daemon-set took: 24.377814ms
Oct 21 16:17:06.437: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.215966ms
Oct 21 16:17:14.944: INFO: Number of nodes with available pods: 0
Oct 21 16:17:14.944: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 16:17:14.953: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2591/daemonsets","resourceVersion":"25934"},"items":null}

Oct 21 16:17:14.959: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2591/pods","resourceVersion":"25934"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:17:14.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2591" for this suite.
Oct 21 16:17:21.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:17:21.355: INFO: namespace daemonsets-2591 deletion completed in 6.360082035s

• [SLOW TEST:35.481 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:17:21.355: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 16:17:29.647: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:17:29.654: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:17:31.654: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:17:31.661: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 16:17:33.654: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 16:17:33.662: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:17:33.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9454" for this suite.
Oct 21 16:17:57.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:17:57.982: INFO: namespace container-lifecycle-hook-9454 deletion completed in 24.311546354s

• [SLOW TEST:36.627 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:17:57.983: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:17:58.233: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 21 16:17:58.250: INFO: Number of nodes with available pods: 0
Oct 21 16:17:58.250: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 21 16:17:58.278: INFO: Number of nodes with available pods: 0
Oct 21 16:17:58.278: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:17:59.286: INFO: Number of nodes with available pods: 0
Oct 21 16:17:59.286: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:00.286: INFO: Number of nodes with available pods: 1
Oct 21 16:18:00.287: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 21 16:18:00.321: INFO: Number of nodes with available pods: 1
Oct 21 16:18:00.321: INFO: Number of running nodes: 0, number of available pods: 1
Oct 21 16:18:01.328: INFO: Number of nodes with available pods: 0
Oct 21 16:18:01.328: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 21 16:18:01.349: INFO: Number of nodes with available pods: 0
Oct 21 16:18:01.349: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:02.356: INFO: Number of nodes with available pods: 0
Oct 21 16:18:02.357: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:03.356: INFO: Number of nodes with available pods: 0
Oct 21 16:18:03.356: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:04.356: INFO: Number of nodes with available pods: 0
Oct 21 16:18:04.356: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:05.357: INFO: Number of nodes with available pods: 0
Oct 21 16:18:05.357: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 16:18:06.356: INFO: Number of nodes with available pods: 1
Oct 21 16:18:06.356: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2485, will wait for the garbage collector to delete the pods
Oct 21 16:18:06.460: INFO: Deleting DaemonSet.extensions daemon-set took: 23.949438ms
Oct 21 16:18:06.560: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.230348ms
Oct 21 16:18:09.666: INFO: Number of nodes with available pods: 0
Oct 21 16:18:09.666: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 16:18:09.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2485/daemonsets","resourceVersion":"26185"},"items":null}

Oct 21 16:18:09.681: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2485/pods","resourceVersion":"26185"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:18:09.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2485" for this suite.
Oct 21 16:18:15.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:16.069: INFO: namespace daemonsets-2485 deletion completed in 6.343702669s

• [SLOW TEST:18.086 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:18:16.070: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Oct 21 16:18:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-4658'
Oct 21 16:18:16.583: INFO: stderr: ""
Oct 21 16:18:16.583: INFO: stdout: "pod/pause created\n"
Oct 21 16:18:16.583: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 21 16:18:16.583: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4658" to be "running and ready"
Oct 21 16:18:16.589: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16386ms
Oct 21 16:18:18.596: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.013072926s
Oct 21 16:18:18.597: INFO: Pod "pause" satisfied condition "running and ready"
Oct 21 16:18:18.597: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 21 16:18:18.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 label pods pause testing-label=testing-label-value --namespace=kubectl-4658'
Oct 21 16:18:18.698: INFO: stderr: ""
Oct 21 16:18:18.698: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 21 16:18:18.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pod pause -L testing-label --namespace=kubectl-4658'
Oct 21 16:18:18.807: INFO: stderr: ""
Oct 21 16:18:18.807: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 21 16:18:18.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 label pods pause testing-label- --namespace=kubectl-4658'
Oct 21 16:18:18.940: INFO: stderr: ""
Oct 21 16:18:18.940: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 21 16:18:18.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pod pause -L testing-label --namespace=kubectl-4658'
Oct 21 16:18:19.036: INFO: stderr: ""
Oct 21 16:18:19.036: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Oct 21 16:18:19.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-4658'
Oct 21 16:18:19.162: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:18:19.162: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 21 16:18:19.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get rc,svc -l name=pause --no-headers --namespace=kubectl-4658'
Oct 21 16:18:19.299: INFO: stderr: "No resources found.\n"
Oct 21 16:18:19.299: INFO: stdout: ""
Oct 21 16:18:19.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -l name=pause --namespace=kubectl-4658 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:18:19.414: INFO: stderr: ""
Oct 21 16:18:19.414: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:18:19.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4658" for this suite.
Oct 21 16:18:25.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:25.721: INFO: namespace kubectl-4658 deletion completed in 6.298093493s

• [SLOW TEST:9.651 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:18:25.724: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:18:25.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638" in namespace "projected-9687" to be "success or failure"
Oct 21 16:18:25.944: INFO: Pod "downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638": Phase="Pending", Reason="", readiness=false. Elapsed: 5.910819ms
Oct 21 16:18:27.951: INFO: Pod "downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013194s
STEP: Saw pod success
Oct 21 16:18:27.951: INFO: Pod "downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638" satisfied condition "success or failure"
Oct 21 16:18:27.958: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638 container client-container: <nil>
STEP: delete the pod
Oct 21 16:18:27.998: INFO: Waiting for pod downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638 to disappear
Oct 21 16:18:28.004: INFO: Pod downwardapi-volume-9e5ba7c0-f4ee-4757-b403-c561e39bd638 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:18:28.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9687" for this suite.
Oct 21 16:18:34.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:34.362: INFO: namespace projected-9687 deletion completed in 6.3477794s

• [SLOW TEST:8.638 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:18:34.362: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 21 16:18:34.565: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 16:18:34.580: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 16:18:34.589: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.154 before test
Oct 21 16:18:34.618: INFO: ibm-storage-watcher-786667d59-lmgwt from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.618: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 16:18:34.619: INFO: ibm-file-plugin-5f9d7d6c49-8g6s6 from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 16:18:34.619: INFO: calico-kube-controllers-9d8994658-lxjks from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 16:18:34.619: INFO: metrics-server-76c7b9bb54-xvv8g from kube-system started at 2019-10-21 14:15:49 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 16:18:34.619: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 16:18:34.619: INFO: ibm-master-proxy-static-10.195.18.154 from kube-system started at 2019-10-21 14:14:53 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 16:18:34.619: INFO: 	Container pause ready: true, restart count 0
Oct 21 16:18:34.619: INFO: ibm-keepalived-watcher-6lnrw from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:18:34.619: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:55:03 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 16:18:34.619: INFO: kubernetes-dashboard-596f947ff4-r2hbp from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 16:18:34.619: INFO: coredns-autoscaler-74cb66766b-whr2s from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 16:18:34.619: INFO: ibm-kube-fluentd-dqtjd from kube-system started at 2019-10-21 14:15:28 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:18:34.619: INFO: calico-node-sxqjc from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:18:34.619: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-h72dv from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:18:34.619: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 16:18:34.619: INFO: vpn-75d8697c68-rldfs from kube-system started at 2019-10-21 14:40:12 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container vpn ready: true, restart count 0
Oct 21 16:18:34.619: INFO: coredns-64f45bf67-lxgz9 from kube-system started at 2019-10-21 14:40:34 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.619: INFO: 	Container coredns ready: true, restart count 0
Oct 21 16:18:34.619: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.159 before test
Oct 21 16:18:34.643: INFO: ibm-master-proxy-static-10.195.18.159 from kube-system started at 2019-10-21 14:15:24 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container pause ready: true, restart count 0
Oct 21 16:18:34.643: INFO: ibm-kube-fluentd-j2hrm from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:18:34.643: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-f8jd9 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 16:18:34.643: INFO: sonobuoy-e2e-job-65107fb0e85542d6 from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container e2e ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:18:34.643: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-xsfvb from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 16:18:34.643: INFO: ibm-keepalived-watcher-97gq4 from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:18:34.643: INFO: calico-node-7l5tz from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:18:34.643: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-4mbpj from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.643: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 16:18:34.643: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.160 before test
Oct 21 16:18:34.680: INFO: ibm-keepalived-watcher-xnjtx from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 16:18:34.680: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:17:37 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 16:18:34.680: INFO: ibm-master-proxy-static-10.195.18.160 from kube-system started at 2019-10-21 14:15:42 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 16:18:34.680: INFO: 	Container pause ready: true, restart count 0
Oct 21 16:18:34.680: INFO: ibm-kube-fluentd-g6rld from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 16:18:34.680: INFO: calico-node-n8566 from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 16:18:34.680: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-xfzc5 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 16:18:34.680: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 16:18:34.680: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 16:18:34.680: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 16:18:34.680: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-bp6nm from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 16:18:34.680: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 16:18:34.680: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-2c6zf from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 16:18:34.680: INFO: coredns-64f45bf67-cv68m from kube-system started at 2019-10-21 14:40:33 +0000 UTC (1 container statuses recorded)
Oct 21 16:18:34.680: INFO: 	Container coredns ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.195.18.154
STEP: verifying the node has the label node 10.195.18.159
STEP: verifying the node has the label node 10.195.18.160
Oct 21 16:18:34.751: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.195.18.160
Oct 21 16:18:34.751: INFO: Pod ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-2c6zf requesting resource cpu=5m on Node 10.195.18.160
Oct 21 16:18:34.751: INFO: Pod ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-xsfvb requesting resource cpu=5m on Node 10.195.18.159
Oct 21 16:18:34.751: INFO: Pod calico-kube-controllers-9d8994658-lxjks requesting resource cpu=10m on Node 10.195.18.154
Oct 21 16:18:34.751: INFO: Pod calico-node-7l5tz requesting resource cpu=250m on Node 10.195.18.159
Oct 21 16:18:34.751: INFO: Pod calico-node-n8566 requesting resource cpu=250m on Node 10.195.18.160
Oct 21 16:18:34.751: INFO: Pod calico-node-sxqjc requesting resource cpu=250m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod coredns-64f45bf67-cv68m requesting resource cpu=100m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod coredns-64f45bf67-lxgz9 requesting resource cpu=100m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod coredns-autoscaler-74cb66766b-whr2s requesting resource cpu=20m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod ibm-file-plugin-5f9d7d6c49-8g6s6 requesting resource cpu=50m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod ibm-keepalived-watcher-6lnrw requesting resource cpu=5m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod ibm-keepalived-watcher-97gq4 requesting resource cpu=5m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod ibm-keepalived-watcher-xnjtx requesting resource cpu=5m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod ibm-kube-fluentd-dqtjd requesting resource cpu=25m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod ibm-kube-fluentd-g6rld requesting resource cpu=25m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod ibm-kube-fluentd-j2hrm requesting resource cpu=25m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod ibm-master-proxy-static-10.195.18.154 requesting resource cpu=25m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod ibm-master-proxy-static-10.195.18.159 requesting resource cpu=25m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod ibm-master-proxy-static-10.195.18.160 requesting resource cpu=25m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod ibm-storage-watcher-786667d59-lmgwt requesting resource cpu=50m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod kubernetes-dashboard-596f947ff4-r2hbp requesting resource cpu=50m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod metrics-server-76c7b9bb54-xvv8g requesting resource cpu=53m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-f8jd9 requesting resource cpu=0m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-xfzc5 requesting resource cpu=0m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod vpn-75d8697c68-rldfs requesting resource cpu=5m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.195.18.154
Oct 21 16:18:34.752: INFO: Pod sonobuoy-e2e-job-65107fb0e85542d6 requesting resource cpu=0m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-4mbpj requesting resource cpu=0m on Node 10.195.18.159
Oct 21 16:18:34.752: INFO: Pod sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-bp6nm requesting resource cpu=0m on Node 10.195.18.160
Oct 21 16:18:34.752: INFO: Pod sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-h72dv requesting resource cpu=0m on Node 10.195.18.154
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f.15cfb5d37456cbf3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9488/filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f to 10.195.18.159]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f.15cfb5d3acfc2df3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f.15cfb5d3b0a739fb], Reason = [Created], Message = [Created container filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f.15cfb5d3bbcefbd1], Reason = [Started], Message = [Started container filler-pod-3ba2375e-e059-42f5-972d-77f5dbf66d6f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6c415bbd-1edc-4759-9a04-95c305851041.15cfb5d374d42c08], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9488/filler-pod-6c415bbd-1edc-4759-9a04-95c305851041 to 10.195.18.160]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6c415bbd-1edc-4759-9a04-95c305851041.15cfb5d3b1c8beb9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6c415bbd-1edc-4759-9a04-95c305851041.15cfb5d3b51d9219], Reason = [Created], Message = [Created container filler-pod-6c415bbd-1edc-4759-9a04-95c305851041]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6c415bbd-1edc-4759-9a04-95c305851041.15cfb5d3bebeb1e1], Reason = [Started], Message = [Started container filler-pod-6c415bbd-1edc-4759-9a04-95c305851041]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640.15cfb5d373dcc02f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9488/filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640 to 10.195.18.154]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640.15cfb5d3acebe302], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640.15cfb5d3b071f938], Reason = [Created], Message = [Created container filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640.15cfb5d3b9ed89ed], Reason = [Started], Message = [Started container filler-pod-d27ffb09-7d3f-4a69-997a-429de8363640]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cfb5d3eee453c1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.195.18.154
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.195.18.159
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.195.18.160
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:18:37.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9488" for this suite.
Oct 21 16:18:43.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:18:44.215: INFO: namespace sched-pred-9488 deletion completed in 6.302095063s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.854 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:18:44.217: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 21 16:18:44.436: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26442,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 16:18:44.437: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26442,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 21 16:18:54.452: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26461,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 16:18:54.452: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26461,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 21 16:19:04.471: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26480,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 16:19:04.472: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26480,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 21 16:19:14.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26497,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 16:19:14.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-a,UID:835931cf-0520-4699-8355-5961bce9c3bb,ResourceVersion:26497,Generation:0,CreationTimestamp:2019-10-21 16:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 21 16:19:24.501: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-b,UID:1089f84f-46a1-432d-a1c6-896199c8a0f8,ResourceVersion:26515,Generation:0,CreationTimestamp:2019-10-21 16:19:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 16:19:24.501: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-b,UID:1089f84f-46a1-432d-a1c6-896199c8a0f8,ResourceVersion:26515,Generation:0,CreationTimestamp:2019-10-21 16:19:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 21 16:19:34.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-b,UID:1089f84f-46a1-432d-a1c6-896199c8a0f8,ResourceVersion:26532,Generation:0,CreationTimestamp:2019-10-21 16:19:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 16:19:34.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6594,SelfLink:/api/v1/namespaces/watch-6594/configmaps/e2e-watch-test-configmap-b,UID:1089f84f-46a1-432d-a1c6-896199c8a0f8,ResourceVersion:26532,Generation:0,CreationTimestamp:2019-10-21 16:19:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:19:44.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6594" for this suite.
Oct 21 16:19:50.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:19:50.893: INFO: namespace watch-6594 deletion completed in 6.365358778s

• [SLOW TEST:66.677 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:19:50.893: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3999
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3109
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:20:18.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6687" for this suite.
Oct 21 16:20:24.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:20:24.895: INFO: namespace namespaces-6687 deletion completed in 6.31904052s
STEP: Destroying namespace "nsdeletetest-3999" for this suite.
Oct 21 16:20:24.904: INFO: Namespace nsdeletetest-3999 was already deleted
STEP: Destroying namespace "nsdeletetest-3109" for this suite.
Oct 21 16:20:30.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:20:31.263: INFO: namespace nsdeletetest-3109 deletion completed in 6.358349373s

• [SLOW TEST:40.370 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:20:31.264: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Oct 21 16:20:31.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8045'
Oct 21 16:20:31.673: INFO: stderr: ""
Oct 21 16:20:31.673: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:20:31.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:31.790: INFO: stderr: ""
Oct 21 16:20:31.790: INFO: stdout: "update-demo-nautilus-65w57 update-demo-nautilus-q4666 "
Oct 21 16:20:31.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-65w57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:31.896: INFO: stderr: ""
Oct 21 16:20:31.896: INFO: stdout: ""
Oct 21 16:20:31.896: INFO: update-demo-nautilus-65w57 is created but not running
Oct 21 16:20:36.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:37.002: INFO: stderr: ""
Oct 21 16:20:37.002: INFO: stdout: "update-demo-nautilus-65w57 update-demo-nautilus-q4666 "
Oct 21 16:20:37.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-65w57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:37.108: INFO: stderr: ""
Oct 21 16:20:37.108: INFO: stdout: "true"
Oct 21 16:20:37.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-65w57 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:37.219: INFO: stderr: ""
Oct 21 16:20:37.220: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:20:37.220: INFO: validating pod update-demo-nautilus-65w57
Oct 21 16:20:37.233: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:20:37.233: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:20:37.234: INFO: update-demo-nautilus-65w57 is verified up and running
Oct 21 16:20:37.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:37.338: INFO: stderr: ""
Oct 21 16:20:37.338: INFO: stdout: "true"
Oct 21 16:20:37.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:37.442: INFO: stderr: ""
Oct 21 16:20:37.442: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:20:37.442: INFO: validating pod update-demo-nautilus-q4666
Oct 21 16:20:37.458: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:20:37.458: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:20:37.458: INFO: update-demo-nautilus-q4666 is verified up and running
STEP: scaling down the replication controller
Oct 21 16:20:37.459: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:20:37.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8045'
Oct 21 16:20:38.620: INFO: stderr: ""
Oct 21 16:20:38.620: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:20:38.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:38.733: INFO: stderr: ""
Oct 21 16:20:38.733: INFO: stdout: "update-demo-nautilus-65w57 update-demo-nautilus-q4666 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 16:20:43.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:43.841: INFO: stderr: ""
Oct 21 16:20:43.841: INFO: stdout: "update-demo-nautilus-65w57 update-demo-nautilus-q4666 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 16:20:48.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:48.943: INFO: stderr: ""
Oct 21 16:20:48.944: INFO: stdout: "update-demo-nautilus-q4666 "
Oct 21 16:20:48.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:49.052: INFO: stderr: ""
Oct 21 16:20:49.052: INFO: stdout: "true"
Oct 21 16:20:49.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:49.148: INFO: stderr: ""
Oct 21 16:20:49.148: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:20:49.148: INFO: validating pod update-demo-nautilus-q4666
Oct 21 16:20:49.160: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:20:49.160: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:20:49.160: INFO: update-demo-nautilus-q4666 is verified up and running
STEP: scaling up the replication controller
Oct 21 16:20:49.161: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:20:49.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8045'
Oct 21 16:20:50.337: INFO: stderr: ""
Oct 21 16:20:50.337: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:20:50.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:50.445: INFO: stderr: ""
Oct 21 16:20:50.445: INFO: stdout: "update-demo-nautilus-frq6g update-demo-nautilus-q4666 "
Oct 21 16:20:50.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-frq6g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:50.542: INFO: stderr: ""
Oct 21 16:20:50.542: INFO: stdout: ""
Oct 21 16:20:50.542: INFO: update-demo-nautilus-frq6g is created but not running
Oct 21 16:20:55.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8045'
Oct 21 16:20:55.648: INFO: stderr: ""
Oct 21 16:20:55.648: INFO: stdout: "update-demo-nautilus-frq6g update-demo-nautilus-q4666 "
Oct 21 16:20:55.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-frq6g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:55.740: INFO: stderr: ""
Oct 21 16:20:55.740: INFO: stdout: "true"
Oct 21 16:20:55.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-frq6g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:55.851: INFO: stderr: ""
Oct 21 16:20:55.851: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:20:55.851: INFO: validating pod update-demo-nautilus-frq6g
Oct 21 16:20:55.866: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:20:55.866: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:20:55.866: INFO: update-demo-nautilus-frq6g is verified up and running
Oct 21 16:20:55.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:55.978: INFO: stderr: ""
Oct 21 16:20:55.978: INFO: stdout: "true"
Oct 21 16:20:55.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-q4666 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8045'
Oct 21 16:20:56.076: INFO: stderr: ""
Oct 21 16:20:56.076: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:20:56.076: INFO: validating pod update-demo-nautilus-q4666
Oct 21 16:20:56.087: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:20:56.087: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:20:56.087: INFO: update-demo-nautilus-q4666 is verified up and running
STEP: using delete to clean up resources
Oct 21 16:20:56.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8045'
Oct 21 16:20:56.212: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 16:20:56.212: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 16:20:56.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8045'
Oct 21 16:20:56.330: INFO: stderr: "No resources found.\n"
Oct 21 16:20:56.330: INFO: stdout: ""
Oct 21 16:20:56.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -l name=update-demo --namespace=kubectl-8045 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 16:20:56.444: INFO: stderr: ""
Oct 21 16:20:56.444: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:20:56.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8045" for this suite.
Oct 21 16:21:20.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:21:20.780: INFO: namespace kubectl-8045 deletion completed in 24.326904821s

• [SLOW TEST:49.516 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:21:20.780: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Oct 21 16:21:21.006: INFO: Waiting up to 5m0s for pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1" in namespace "containers-2715" to be "success or failure"
Oct 21 16:21:21.014: INFO: Pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.967466ms
Oct 21 16:21:23.021: INFO: Pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014768335s
Oct 21 16:21:25.028: INFO: Pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021660663s
Oct 21 16:21:27.035: INFO: Pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028564159s
STEP: Saw pod success
Oct 21 16:21:27.035: INFO: Pod "client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1" satisfied condition "success or failure"
Oct 21 16:21:27.041: INFO: Trying to get logs from node 10.195.18.160 pod client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1 container test-container: <nil>
STEP: delete the pod
Oct 21 16:21:27.073: INFO: Waiting for pod client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1 to disappear
Oct 21 16:21:27.078: INFO: Pod client-containers-a225803c-93fd-4f5f-904f-b246eeeb0ed1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:21:27.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2715" for this suite.
Oct 21 16:21:33.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:21:33.404: INFO: namespace containers-2715 deletion completed in 6.317553402s

• [SLOW TEST:12.624 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:21:33.404: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6685
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-rrn4
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 16:21:33.633: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rrn4" in namespace "subpath-6685" to be "success or failure"
Oct 21 16:21:33.638: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.4134ms
Oct 21 16:21:35.645: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 2.011690875s
Oct 21 16:21:37.652: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 4.018774001s
Oct 21 16:21:39.658: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 6.025504334s
Oct 21 16:21:41.667: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 8.033810521s
Oct 21 16:21:43.675: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 10.042068263s
Oct 21 16:21:45.682: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 12.0492445s
Oct 21 16:21:47.690: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 14.057054752s
Oct 21 16:21:49.697: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 16.06396872s
Oct 21 16:21:51.704: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 18.070891747s
Oct 21 16:21:53.712: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 20.079470046s
Oct 21 16:21:55.719: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Running", Reason="", readiness=true. Elapsed: 22.086332118s
Oct 21 16:21:57.726: INFO: Pod "pod-subpath-test-configmap-rrn4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.093426995s
STEP: Saw pod success
Oct 21 16:21:57.726: INFO: Pod "pod-subpath-test-configmap-rrn4" satisfied condition "success or failure"
Oct 21 16:21:57.732: INFO: Trying to get logs from node 10.195.18.159 pod pod-subpath-test-configmap-rrn4 container test-container-subpath-configmap-rrn4: <nil>
STEP: delete the pod
Oct 21 16:21:57.764: INFO: Waiting for pod pod-subpath-test-configmap-rrn4 to disappear
Oct 21 16:21:57.769: INFO: Pod pod-subpath-test-configmap-rrn4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rrn4
Oct 21 16:21:57.769: INFO: Deleting pod "pod-subpath-test-configmap-rrn4" in namespace "subpath-6685"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:21:57.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6685" for this suite.
Oct 21 16:22:03.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:04.109: INFO: namespace subpath-6685 deletion completed in 6.325030558s

• [SLOW TEST:30.705 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:04.109: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 16:22:04.343: INFO: Waiting up to 5m0s for pod "pod-5e19af44-ee73-4331-88dc-15f659ddecd4" in namespace "emptydir-2987" to be "success or failure"
Oct 21 16:22:04.349: INFO: Pod "pod-5e19af44-ee73-4331-88dc-15f659ddecd4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.946006ms
Oct 21 16:22:06.356: INFO: Pod "pod-5e19af44-ee73-4331-88dc-15f659ddecd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01329635s
STEP: Saw pod success
Oct 21 16:22:06.356: INFO: Pod "pod-5e19af44-ee73-4331-88dc-15f659ddecd4" satisfied condition "success or failure"
Oct 21 16:22:06.363: INFO: Trying to get logs from node 10.195.18.154 pod pod-5e19af44-ee73-4331-88dc-15f659ddecd4 container test-container: <nil>
STEP: delete the pod
Oct 21 16:22:06.396: INFO: Waiting for pod pod-5e19af44-ee73-4331-88dc-15f659ddecd4 to disappear
Oct 21 16:22:06.403: INFO: Pod pod-5e19af44-ee73-4331-88dc-15f659ddecd4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:22:06.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2987" for this suite.
Oct 21 16:22:12.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:12.714: INFO: namespace emptydir-2987 deletion completed in 6.302092689s

• [SLOW TEST:8.605 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:12.716: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d6cc13f6-4b35-4466-bb99-fb1142c458dd
STEP: Creating a pod to test consume secrets
Oct 21 16:22:12.936: INFO: Waiting up to 5m0s for pod "pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322" in namespace "secrets-7416" to be "success or failure"
Oct 21 16:22:12.942: INFO: Pod "pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322": Phase="Pending", Reason="", readiness=false. Elapsed: 6.516987ms
Oct 21 16:22:14.950: INFO: Pod "pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01428287s
STEP: Saw pod success
Oct 21 16:22:14.950: INFO: Pod "pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322" satisfied condition "success or failure"
Oct 21 16:22:14.956: INFO: Trying to get logs from node 10.195.18.160 pod pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:22:14.989: INFO: Waiting for pod pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322 to disappear
Oct 21 16:22:14.995: INFO: Pod pod-secrets-f2f8f0b3-be86-4920-9299-f7a56b637322 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:22:14.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7416" for this suite.
Oct 21 16:22:21.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:21.423: INFO: namespace secrets-7416 deletion completed in 6.419630191s

• [SLOW TEST:8.707 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:21.423: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Oct 21 16:22:21.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 cluster-info'
Oct 21 16:22:21.740: INFO: stderr: ""
Oct 21 16:22:21.740: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:22:21.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6004" for this suite.
Oct 21 16:22:27.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:28.045: INFO: namespace kubectl-6004 deletion completed in 6.297426757s

• [SLOW TEST:6.622 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-756c3ea7-6ca6-41c8-acee-4b17201cc6b2
STEP: Creating a pod to test consume configMaps
Oct 21 16:22:28.266: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a" in namespace "projected-1233" to be "success or failure"
Oct 21 16:22:28.272: INFO: Pod "pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.452735ms
Oct 21 16:22:30.279: INFO: Pod "pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012612701s
STEP: Saw pod success
Oct 21 16:22:30.279: INFO: Pod "pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a" satisfied condition "success or failure"
Oct 21 16:22:30.286: INFO: Trying to get logs from node 10.195.18.159 pod pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:22:30.318: INFO: Waiting for pod pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a to disappear
Oct 21 16:22:30.324: INFO: Pod pod-projected-configmaps-df8e5a60-4e0c-4e23-8c7d-ac8c1d382b8a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:22:30.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1233" for this suite.
Oct 21 16:22:36.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:36.649: INFO: namespace projected-1233 deletion completed in 6.315952397s

• [SLOW TEST:8.601 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:36.649: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3534
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 16:22:36.859: INFO: Waiting up to 5m0s for pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f" in namespace "emptydir-3534" to be "success or failure"
Oct 21 16:22:36.866: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.422373ms
Oct 21 16:22:38.874: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015096413s
Oct 21 16:22:40.881: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022090333s
Oct 21 16:22:42.889: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f": Phase="Running", Reason="", readiness=true. Elapsed: 6.029930257s
Oct 21 16:22:44.896: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.036511111s
STEP: Saw pod success
Oct 21 16:22:44.896: INFO: Pod "pod-7b0742ed-bcb2-4945-8092-f8940519c81f" satisfied condition "success or failure"
Oct 21 16:22:44.902: INFO: Trying to get logs from node 10.195.18.154 pod pod-7b0742ed-bcb2-4945-8092-f8940519c81f container test-container: <nil>
STEP: delete the pod
Oct 21 16:22:44.931: INFO: Waiting for pod pod-7b0742ed-bcb2-4945-8092-f8940519c81f to disappear
Oct 21 16:22:44.937: INFO: Pod pod-7b0742ed-bcb2-4945-8092-f8940519c81f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:22:44.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3534" for this suite.
Oct 21 16:22:50.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:22:51.346: INFO: namespace emptydir-3534 deletion completed in 6.400173097s

• [SLOW TEST:14.697 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:22:51.346: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 21 16:23:01.698: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1021 16:23:01.698926      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:23:01.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-793" for this suite.
Oct 21 16:23:09.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:10.010: INFO: namespace gc-793 deletion completed in 8.303373561s

• [SLOW TEST:18.664 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:23:10.010: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4560.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4560.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4560.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4560.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4560.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4560.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 16:23:24.330: INFO: DNS probes using dns-4560/dns-test-931bd108-4127-4557-8ff7-8f5412b37d59 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:23:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4560" for this suite.
Oct 21 16:23:30.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:23:30.707: INFO: namespace dns-4560 deletion completed in 6.350973109s

• [SLOW TEST:20.697 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:23:30.707: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2997
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:23:32.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2997" for this suite.
Oct 21 16:24:13.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:13.352: INFO: namespace kubelet-test-2997 deletion completed in 40.354758785s

• [SLOW TEST:42.645 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:24:13.352: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Oct 21 16:24:13.574: INFO: Waiting up to 5m0s for pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0" in namespace "containers-9955" to be "success or failure"
Oct 21 16:24:13.580: INFO: Pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.223887ms
Oct 21 16:24:15.587: INFO: Pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012854794s
Oct 21 16:24:17.594: INFO: Pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020438195s
Oct 21 16:24:19.604: INFO: Pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030042886s
STEP: Saw pod success
Oct 21 16:24:19.604: INFO: Pod "client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0" satisfied condition "success or failure"
Oct 21 16:24:19.616: INFO: Trying to get logs from node 10.195.18.154 pod client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0 container test-container: <nil>
STEP: delete the pod
Oct 21 16:24:19.659: INFO: Waiting for pod client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0 to disappear
Oct 21 16:24:19.665: INFO: Pod client-containers-2f45b6fb-dea3-4cfa-a76b-bd3e2a04edd0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:24:19.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9955" for this suite.
Oct 21 16:24:25.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:26.012: INFO: namespace containers-9955 deletion completed in 6.334149624s

• [SLOW TEST:12.660 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:24:26.015: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 21 16:24:26.218: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:24:30.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6645" for this suite.
Oct 21 16:24:54.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:24:54.506: INFO: namespace init-container-6645 deletion completed in 24.355438293s

• [SLOW TEST:28.491 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:24:54.506: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5210
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 16:24:54.745: INFO: Waiting up to 5m0s for pod "pod-a2d0bf1b-d217-4f01-804e-1624e207964b" in namespace "emptydir-5210" to be "success or failure"
Oct 21 16:24:54.751: INFO: Pod "pod-a2d0bf1b-d217-4f01-804e-1624e207964b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.801136ms
Oct 21 16:24:56.758: INFO: Pod "pod-a2d0bf1b-d217-4f01-804e-1624e207964b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012882759s
Oct 21 16:24:58.765: INFO: Pod "pod-a2d0bf1b-d217-4f01-804e-1624e207964b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019382414s
STEP: Saw pod success
Oct 21 16:24:58.765: INFO: Pod "pod-a2d0bf1b-d217-4f01-804e-1624e207964b" satisfied condition "success or failure"
Oct 21 16:24:58.770: INFO: Trying to get logs from node 10.195.18.160 pod pod-a2d0bf1b-d217-4f01-804e-1624e207964b container test-container: <nil>
STEP: delete the pod
Oct 21 16:24:58.807: INFO: Waiting for pod pod-a2d0bf1b-d217-4f01-804e-1624e207964b to disappear
Oct 21 16:24:58.813: INFO: Pod pod-a2d0bf1b-d217-4f01-804e-1624e207964b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:24:58.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5210" for this suite.
Oct 21 16:25:04.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:25:05.145: INFO: namespace emptydir-5210 deletion completed in 6.323011296s

• [SLOW TEST:10.639 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:25:05.145: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 21 16:25:05.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28013,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 16:25:05.378: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28014,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 16:25:05.378: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28015,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 21 16:25:15.427: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28033,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 16:25:15.428: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28034,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 21 16:25:15.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-5730,SelfLink:/api/v1/namespaces/watch-5730/configmaps/e2e-watch-test-label-changed,UID:904c150d-f463-4940-a291-41c5cf229563,ResourceVersion:28035,Generation:0,CreationTimestamp:2019-10-21 16:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:25:15.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5730" for this suite.
Oct 21 16:25:21.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:25:21.738: INFO: namespace watch-5730 deletion completed in 6.298743536s

• [SLOW TEST:16.592 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:25:21.738: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4756
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4756
STEP: Creating statefulset with conflicting port in namespace statefulset-4756
STEP: Waiting until pod test-pod will start running in namespace statefulset-4756
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4756
Oct 21 16:25:23.997: INFO: Observed stateful pod in namespace: statefulset-4756, name: ss-0, uid: 9b4d9407-f67c-4aba-ab74-3bbfe9ad13ae, status phase: Pending. Waiting for statefulset controller to delete.
Oct 21 16:25:33.490: INFO: Observed stateful pod in namespace: statefulset-4756, name: ss-0, uid: 9b4d9407-f67c-4aba-ab74-3bbfe9ad13ae, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 16:25:33.500: INFO: Observed stateful pod in namespace: statefulset-4756, name: ss-0, uid: 9b4d9407-f67c-4aba-ab74-3bbfe9ad13ae, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 16:25:33.508: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4756
STEP: Removing pod with conflicting port in namespace statefulset-4756
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4756 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 16:25:47.580: INFO: Deleting all statefulset in ns statefulset-4756
Oct 21 16:25:47.590: INFO: Scaling statefulset ss to 0
Oct 21 16:25:57.625: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:25:57.635: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:25:57.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4756" for this suite.
Oct 21 16:26:03.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:04.010: INFO: namespace statefulset-4756 deletion completed in 6.298601044s

• [SLOW TEST:42.272 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:04.011: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Oct 21 16:26:04.217: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-373207704 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:04.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-712" for this suite.
Oct 21 16:26:10.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:10.632: INFO: namespace kubectl-712 deletion completed in 6.313635822s

• [SLOW TEST:6.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:10.633: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e361076a-9586-45c8-8d51-bad79f431d01
STEP: Creating a pod to test consume configMaps
Oct 21 16:26:10.874: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810" in namespace "projected-5496" to be "success or failure"
Oct 21 16:26:10.880: INFO: Pod "pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810": Phase="Pending", Reason="", readiness=false. Elapsed: 5.966893ms
Oct 21 16:26:12.888: INFO: Pod "pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014268068s
STEP: Saw pod success
Oct 21 16:26:12.888: INFO: Pod "pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810" satisfied condition "success or failure"
Oct 21 16:26:12.898: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:26:12.927: INFO: Waiting for pod pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810 to disappear
Oct 21 16:26:12.933: INFO: Pod pod-projected-configmaps-d946cf51-1f0b-44f0-bccf-3b0252f8d810 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:12.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5496" for this suite.
Oct 21 16:26:18.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:19.337: INFO: namespace projected-5496 deletion completed in 6.395469422s

• [SLOW TEST:8.704 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:19.337: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2f26990a-652e-4812-b770-e78809db468a
STEP: Creating a pod to test consume configMaps
Oct 21 16:26:19.565: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f" in namespace "configmap-3416" to be "success or failure"
Oct 21 16:26:19.572: INFO: Pod "pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.354378ms
Oct 21 16:26:21.579: INFO: Pod "pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013314464s
STEP: Saw pod success
Oct 21 16:26:21.579: INFO: Pod "pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f" satisfied condition "success or failure"
Oct 21 16:26:21.585: INFO: Trying to get logs from node 10.195.18.159 pod pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:26:21.614: INFO: Waiting for pod pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f to disappear
Oct 21 16:26:21.619: INFO: Pod pod-configmaps-cb322521-2c72-4cbf-9d25-5a5e8705361f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:21.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3416" for this suite.
Oct 21 16:26:27.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:27.933: INFO: namespace configmap-3416 deletion completed in 6.305295932s

• [SLOW TEST:8.596 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:27.933: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 16:26:28.146: INFO: Waiting up to 5m0s for pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1" in namespace "emptydir-1928" to be "success or failure"
Oct 21 16:26:28.151: INFO: Pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.470302ms
Oct 21 16:26:30.159: INFO: Pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012839256s
Oct 21 16:26:32.166: INFO: Pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019878763s
Oct 21 16:26:34.172: INFO: Pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026626272s
STEP: Saw pod success
Oct 21 16:26:34.172: INFO: Pod "pod-62eacfff-adef-44c6-8edd-223fc01d4db1" satisfied condition "success or failure"
Oct 21 16:26:34.178: INFO: Trying to get logs from node 10.195.18.160 pod pod-62eacfff-adef-44c6-8edd-223fc01d4db1 container test-container: <nil>
STEP: delete the pod
Oct 21 16:26:34.207: INFO: Waiting for pod pod-62eacfff-adef-44c6-8edd-223fc01d4db1 to disappear
Oct 21 16:26:34.213: INFO: Pod pod-62eacfff-adef-44c6-8edd-223fc01d4db1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:34.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1928" for this suite.
Oct 21 16:26:40.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:40.525: INFO: namespace emptydir-1928 deletion completed in 6.304114969s

• [SLOW TEST:12.592 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:40.526: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:40.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5811" for this suite.
Oct 21 16:26:46.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:47.078: INFO: namespace kubelet-test-5811 deletion completed in 6.296924515s

• [SLOW TEST:6.552 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:47.079: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 16:26:47.289: INFO: Waiting up to 5m0s for pod "pod-512d706f-4e76-471d-96d9-707d11602221" in namespace "emptydir-2958" to be "success or failure"
Oct 21 16:26:47.295: INFO: Pod "pod-512d706f-4e76-471d-96d9-707d11602221": Phase="Pending", Reason="", readiness=false. Elapsed: 6.161844ms
Oct 21 16:26:49.302: INFO: Pod "pod-512d706f-4e76-471d-96d9-707d11602221": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012908677s
Oct 21 16:26:51.310: INFO: Pod "pod-512d706f-4e76-471d-96d9-707d11602221": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020998328s
Oct 21 16:26:53.318: INFO: Pod "pod-512d706f-4e76-471d-96d9-707d11602221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028330813s
STEP: Saw pod success
Oct 21 16:26:53.318: INFO: Pod "pod-512d706f-4e76-471d-96d9-707d11602221" satisfied condition "success or failure"
Oct 21 16:26:53.324: INFO: Trying to get logs from node 10.195.18.159 pod pod-512d706f-4e76-471d-96d9-707d11602221 container test-container: <nil>
STEP: delete the pod
Oct 21 16:26:53.353: INFO: Waiting for pod pod-512d706f-4e76-471d-96d9-707d11602221 to disappear
Oct 21 16:26:53.360: INFO: Pod pod-512d706f-4e76-471d-96d9-707d11602221 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:26:53.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2958" for this suite.
Oct 21 16:26:59.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:26:59.899: INFO: namespace emptydir-2958 deletion completed in 6.529244717s

• [SLOW TEST:12.820 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:26:59.899: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 21 16:27:40.191: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1021 16:27:40.191115      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 16:27:40.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7322" for this suite.
Oct 21 16:27:48.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:27:48.553: INFO: namespace gc-7322 deletion completed in 8.355708481s

• [SLOW TEST:48.654 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:27:48.553: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:27:48.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7646'
Oct 21 16:27:48.988: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:27:48.988: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Oct 21 16:27:51.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7646'
Oct 21 16:27:51.116: INFO: stderr: ""
Oct 21 16:27:51.116: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:27:51.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7646" for this suite.
Oct 21 16:28:13.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:13.418: INFO: namespace kubectl-7646 deletion completed in 22.293358488s

• [SLOW TEST:24.865 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:28:13.419: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 21 16:28:13.621: INFO: namespace kubectl-7664
Oct 21 16:28:13.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-7664'
Oct 21 16:28:13.886: INFO: stderr: ""
Oct 21 16:28:13.886: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 16:28:14.893: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:28:14.893: INFO: Found 0 / 1
Oct 21 16:28:15.893: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:28:15.893: INFO: Found 1 / 1
Oct 21 16:28:15.893: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 16:28:15.900: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:28:15.900: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 16:28:15.900: INFO: wait on redis-master startup in kubectl-7664 
Oct 21 16:28:15.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-hzwrz redis-master --namespace=kubectl-7664'
Oct 21 16:28:16.069: INFO: stderr: ""
Oct 21 16:28:16.069: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 16:28:15.107 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 16:28:15.107 # Server started, Redis version 3.2.12\n1:M 21 Oct 16:28:15.107 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 16:28:15.107 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 21 16:28:16.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7664'
Oct 21 16:28:16.201: INFO: stderr: ""
Oct 21 16:28:16.201: INFO: stdout: "service/rm2 exposed\n"
Oct 21 16:28:16.210: INFO: Service rm2 in namespace kubectl-7664 found.
STEP: exposing service
Oct 21 16:28:18.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7664'
Oct 21 16:28:18.370: INFO: stderr: ""
Oct 21 16:28:18.370: INFO: stdout: "service/rm3 exposed\n"
Oct 21 16:28:18.378: INFO: Service rm3 in namespace kubectl-7664 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:28:20.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7664" for this suite.
Oct 21 16:28:44.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:44.725: INFO: namespace kubectl-7664 deletion completed in 24.319528472s

• [SLOW TEST:31.307 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:28:44.726: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Oct 21 16:28:44.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 --namespace=kubectl-145 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 21 16:28:47.020: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 21 16:28:47.020: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:28:49.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-145" for this suite.
Oct 21 16:28:55.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:28:55.366: INFO: namespace kubectl-145 deletion completed in 6.312177793s

• [SLOW TEST:10.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:28:55.368: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-123
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 21 16:29:00.633: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:29:01.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-123" for this suite.
Oct 21 16:29:23.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:29:24.008: INFO: namespace replicaset-123 deletion completed in 22.336378642s

• [SLOW TEST:28.640 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:29:24.011: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2086
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-e1e2633c-b667-46d2-8e31-51310ca5add1
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:29:26.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2086" for this suite.
Oct 21 16:29:50.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:29:50.630: INFO: namespace configmap-2086 deletion completed in 24.329339466s

• [SLOW TEST:26.619 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:29:50.631: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:29:50.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8051'
Oct 21 16:29:50.940: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:29:50.940: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Oct 21 16:29:50.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete jobs e2e-test-nginx-job --namespace=kubectl-8051'
Oct 21 16:29:51.073: INFO: stderr: ""
Oct 21 16:29:51.073: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:29:51.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8051" for this suite.
Oct 21 16:30:13.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:30:13.412: INFO: namespace kubectl-8051 deletion completed in 22.332248012s

• [SLOW TEST:22.782 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:30:13.413: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7874
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-07aadab1-e7a4-4e78-b26a-571b5b898c09
STEP: Creating a pod to test consume configMaps
Oct 21 16:30:13.638: INFO: Waiting up to 5m0s for pod "pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10" in namespace "configmap-7874" to be "success or failure"
Oct 21 16:30:13.666: INFO: Pod "pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10": Phase="Pending", Reason="", readiness=false. Elapsed: 27.79105ms
Oct 21 16:30:15.674: INFO: Pod "pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036047078s
Oct 21 16:30:17.682: INFO: Pod "pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043842913s
STEP: Saw pod success
Oct 21 16:30:17.682: INFO: Pod "pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10" satisfied condition "success or failure"
Oct 21 16:30:17.688: INFO: Trying to get logs from node 10.195.18.159 pod pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:30:17.720: INFO: Waiting for pod pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10 to disappear
Oct 21 16:30:17.726: INFO: Pod pod-configmaps-02ec6b33-51a7-45ce-8700-6e62d6d82f10 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:30:17.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7874" for this suite.
Oct 21 16:30:23.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:30:24.069: INFO: namespace configmap-7874 deletion completed in 6.334134844s

• [SLOW TEST:10.656 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:30:24.070: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-1a119804-1302-4e71-a214-a12f6968e9e3 in namespace container-probe-1053
Oct 21 16:30:30.294: INFO: Started pod test-webserver-1a119804-1302-4e71-a214-a12f6968e9e3 in namespace container-probe-1053
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 16:30:30.300: INFO: Initial restart count of pod test-webserver-1a119804-1302-4e71-a214-a12f6968e9e3 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:34:31.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1053" for this suite.
Oct 21 16:34:37.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:34:37.560: INFO: namespace container-probe-1053 deletion completed in 6.326699891s

• [SLOW TEST:253.490 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:34:37.560: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Oct 21 16:34:37.781: INFO: Waiting up to 5m0s for pod "var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a" in namespace "var-expansion-5378" to be "success or failure"
Oct 21 16:34:37.787: INFO: Pod "var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.3938ms
Oct 21 16:34:39.794: INFO: Pod "var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013115971s
Oct 21 16:34:41.800: INFO: Pod "var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019753385s
STEP: Saw pod success
Oct 21 16:34:41.800: INFO: Pod "var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a" satisfied condition "success or failure"
Oct 21 16:34:41.806: INFO: Trying to get logs from node 10.195.18.160 pod var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:34:41.844: INFO: Waiting for pod var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a to disappear
Oct 21 16:34:41.862: INFO: Pod var-expansion-61d04d28-41a6-413f-9a6c-7175a263020a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:34:41.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5378" for this suite.
Oct 21 16:34:47.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:34:48.187: INFO: namespace var-expansion-5378 deletion completed in 6.316036073s

• [SLOW TEST:10.627 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:34:48.187: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:34:48.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-5277'
Oct 21 16:34:48.600: INFO: stderr: ""
Oct 21 16:34:48.600: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 21 16:34:48.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-5277'
Oct 21 16:34:48.943: INFO: stderr: ""
Oct 21 16:34:48.943: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 16:34:49.951: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:34:49.951: INFO: Found 0 / 1
Oct 21 16:34:50.951: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:34:50.951: INFO: Found 1 / 1
Oct 21 16:34:50.951: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 16:34:50.957: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:34:50.957: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 16:34:50.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 describe pod redis-master-9zjsn --namespace=kubectl-5277'
Oct 21 16:34:51.102: INFO: stderr: ""
Oct 21 16:34:51.102: INFO: stdout: "Name:           redis-master-9zjsn\nNamespace:      kubectl-5277\nPriority:       0\nNode:           10.195.18.159/10.195.18.159\nStart Time:     Mon, 21 Oct 2019 16:34:48 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             172.30.106.227\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://dd618a219c747346c76695b9aea263913caf6109da1b21888fb714a3e048cfd3\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Oct 2019 16:34:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8xmpr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-8xmpr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-8xmpr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  3s    default-scheduler       Successfully assigned kubectl-5277/redis-master-9zjsn to 10.195.18.159\n  Normal  Pulled     2s    kubelet, 10.195.18.159  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.195.18.159  Created container redis-master\n  Normal  Started    2s    kubelet, 10.195.18.159  Started container redis-master\n"
Oct 21 16:34:51.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 describe rc redis-master --namespace=kubectl-5277'
Oct 21 16:34:51.278: INFO: stderr: ""
Oct 21 16:34:51.278: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5277\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-9zjsn\n"
Oct 21 16:34:51.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 describe service redis-master --namespace=kubectl-5277'
Oct 21 16:34:51.416: INFO: stderr: ""
Oct 21 16:34:51.416: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5277\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.210.151\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.106.227:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 21 16:34:51.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 describe node 10.195.18.154'
Oct 21 16:34:51.608: INFO: stderr: ""
Oct 21 16:34:51.608: INFO: stdout: "Name:               10.195.18.154\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=au-syd\n                    failure-domain.beta.kubernetes.io/zone=syd05\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=135.90.76.82\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.195.18.154\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=au-syd\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bmmrjnus0umui569cj50-kubee2epvgk-default-0000012f\n                    ibm-cloud.kubernetes.io/worker-pool-id=bmmrjnus0umui569cj50-8e6e103\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.15.4_1519\n                    ibm-cloud.kubernetes.io/zone=syd05\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.195.18.154\n                    kubernetes.io/os=linux\n                    privateVLAN=2659723\n                    publicVLAN=2659721\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Oct 2019 14:14:59 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 21 Oct 2019 16:34:26 +0000   Mon, 21 Oct 2019 14:14:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 21 Oct 2019 16:34:26 +0000   Mon, 21 Oct 2019 14:14:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 21 Oct 2019 16:34:26 +0000   Mon, 21 Oct 2019 14:14:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 21 Oct 2019 16:34:26 +0000   Mon, 21 Oct 2019 14:15:09 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.195.18.154\n  ExternalIP:  135.90.76.82\n  Hostname:    10.195.18.154\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419960Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627512Ki\n pods:               110\nSystem Info:\n Machine ID:                 1069c1d000ac435fbb35b3b636f2d8f5\n System UUID:                E96B9805-5BB7-3103-AAAF-81F4B62D7BEA\n Boot ID:                    11e9e3b0-6147-4853-9af1-a6e2ce2d09fa\n Kernel Version:             4.15.0-65-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.10\n Kubelet Version:            v1.15.4+IKS\n Kube-Proxy Version:         v1.15.4+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bmmrjnus0umui569cj50/kube-bmmrjnus0umui569cj50-kubee2epvgk-default-0000012f\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-kube-controllers-9d8994658-lxjks                    10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      145m\n  kube-system                calico-node-sxqjc                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         139m\n  kube-system                coredns-64f45bf67-lxgz9                                    100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     114m\n  kube-system                coredns-autoscaler-74cb66766b-whr2s                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         144m\n  kube-system                ibm-file-plugin-5f9d7d6c49-8g6s6                           50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         144m\n  kube-system                ibm-keepalived-watcher-6lnrw                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         139m\n  kube-system                ibm-kube-fluentd-dqtjd                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    139m\n  kube-system                ibm-master-proxy-static-10.195.18.154                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      138m\n  kube-system                ibm-storage-watcher-786667d59-lmgwt                        50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         144m\n  kube-system                kubernetes-dashboard-596f947ff4-r2hbp                      50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         142m\n  kube-system                metrics-server-76c7b9bb54-xvv8g                            53m (1%)      148m (3%)   154Mi (1%)       404Mi (3%)     139m\n  kube-system                vpn-75d8697c68-rldfs                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         114m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-h72dv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                643m (16%)     1148m (29%)\n  memory             854546Ki (6%)  6031524Ki (44%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Oct 21 16:34:51.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 describe namespace kubectl-5277'
Oct 21 16:34:51.738: INFO: stderr: ""
Oct 21 16:34:51.738: INFO: stdout: "Name:         kubectl-5277\nLabels:       e2e-framework=kubectl\n              e2e-run=fe02a8c6-8073-42e2-8fdf-53fda8f0199f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:34:51.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5277" for this suite.
Oct 21 16:35:15.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:35:16.063: INFO: namespace kubectl-5277 deletion completed in 24.315462876s

• [SLOW TEST:27.876 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:35:16.063: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 21 16:35:16.280: INFO: Waiting up to 5m0s for pod "downward-api-dac04dbe-66a9-4696-b409-60de032d5688" in namespace "downward-api-2240" to be "success or failure"
Oct 21 16:35:16.286: INFO: Pod "downward-api-dac04dbe-66a9-4696-b409-60de032d5688": Phase="Pending", Reason="", readiness=false. Elapsed: 5.798068ms
Oct 21 16:35:18.293: INFO: Pod "downward-api-dac04dbe-66a9-4696-b409-60de032d5688": Phase="Running", Reason="", readiness=true. Elapsed: 2.013304237s
Oct 21 16:35:20.301: INFO: Pod "downward-api-dac04dbe-66a9-4696-b409-60de032d5688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020409941s
STEP: Saw pod success
Oct 21 16:35:20.301: INFO: Pod "downward-api-dac04dbe-66a9-4696-b409-60de032d5688" satisfied condition "success or failure"
Oct 21 16:35:20.306: INFO: Trying to get logs from node 10.195.18.154 pod downward-api-dac04dbe-66a9-4696-b409-60de032d5688 container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:35:20.345: INFO: Waiting for pod downward-api-dac04dbe-66a9-4696-b409-60de032d5688 to disappear
Oct 21 16:35:20.350: INFO: Pod downward-api-dac04dbe-66a9-4696-b409-60de032d5688 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:35:20.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2240" for this suite.
Oct 21 16:35:26.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:35:26.710: INFO: namespace downward-api-2240 deletion completed in 6.3518451s

• [SLOW TEST:10.647 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:35:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-1e21ea80-d9f5-4491-9c0a-aa10a98a1d48 in namespace container-probe-9539
Oct 21 16:35:30.936: INFO: Started pod busybox-1e21ea80-d9f5-4491-9c0a-aa10a98a1d48 in namespace container-probe-9539
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 16:35:30.941: INFO: Initial restart count of pod busybox-1e21ea80-d9f5-4491-9c0a-aa10a98a1d48 is 0
Oct 21 16:36:21.127: INFO: Restart count of pod container-probe-9539/busybox-1e21ea80-d9f5-4491-9c0a-aa10a98a1d48 is now 1 (50.18605627s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:36:21.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9539" for this suite.
Oct 21 16:36:27.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:36:27.525: INFO: namespace container-probe-9539 deletion completed in 6.372195622s

• [SLOW TEST:60.813 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:36:27.526: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-qcf9x in namespace proxy-2540
I1021 16:36:27.768288      16 runners.go:180] Created replication controller with name: proxy-service-qcf9x, namespace: proxy-2540, replica count: 1
I1021 16:36:28.818840      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 16:36:29.819112      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 16:36:30.819340      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 16:36:31.819607      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 16:36:32.819845      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 16:36:33.820032      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:34.820209      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:35.820483      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:36.820700      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:37.821004      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:38.821282      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:39.821552      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:40.821771      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 16:36:41.822058      16 runners.go:180] proxy-service-qcf9x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 16:36:41.832: INFO: setup took 14.101854774s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 21 16:36:41.845: INFO: (0) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 12.856409ms)
Oct 21 16:36:41.849: INFO: (0) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 16.433374ms)
Oct 21 16:36:41.849: INFO: (0) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 16.27514ms)
Oct 21 16:36:41.849: INFO: (0) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 16.358767ms)
Oct 21 16:36:41.849: INFO: (0) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 16.348069ms)
Oct 21 16:36:41.849: INFO: (0) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 16.852207ms)
Oct 21 16:36:41.850: INFO: (0) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 17.063105ms)
Oct 21 16:36:41.850: INFO: (0) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 17.103118ms)
Oct 21 16:36:41.851: INFO: (0) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.69344ms)
Oct 21 16:36:41.854: INFO: (0) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 21.009257ms)
Oct 21 16:36:41.854: INFO: (0) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 21.175859ms)
Oct 21 16:36:41.857: INFO: (0) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 24.232286ms)
Oct 21 16:36:41.859: INFO: (0) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 26.220976ms)
Oct 21 16:36:41.860: INFO: (0) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 27.275119ms)
Oct 21 16:36:41.867: INFO: (0) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 34.094951ms)
Oct 21 16:36:41.868: INFO: (0) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 34.976531ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 12.659069ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 12.696239ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 12.989387ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.923469ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 13.691466ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 13.571618ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 13.664253ms)
Oct 21 16:36:41.882: INFO: (1) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 13.701563ms)
Oct 21 16:36:41.881: INFO: (1) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 13.835374ms)
Oct 21 16:36:41.882: INFO: (1) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 13.783502ms)
Oct 21 16:36:41.884: INFO: (1) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 16.627034ms)
Oct 21 16:36:41.885: INFO: (1) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 17.560858ms)
Oct 21 16:36:41.887: INFO: (1) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.693233ms)
Oct 21 16:36:41.887: INFO: (1) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.723678ms)
Oct 21 16:36:41.887: INFO: (1) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 19.624183ms)
Oct 21 16:36:41.888: INFO: (1) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 20.062884ms)
Oct 21 16:36:41.897: INFO: (2) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 9.215815ms)
Oct 21 16:36:41.900: INFO: (2) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.268288ms)
Oct 21 16:36:41.900: INFO: (2) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.563867ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 16.632817ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 16.757232ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 16.777031ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 16.685347ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 16.888243ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 16.849292ms)
Oct 21 16:36:41.905: INFO: (2) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 16.87109ms)
Oct 21 16:36:41.906: INFO: (2) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.115311ms)
Oct 21 16:36:41.908: INFO: (2) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 20.308993ms)
Oct 21 16:36:41.908: INFO: (2) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 20.340074ms)
Oct 21 16:36:41.908: INFO: (2) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 20.230437ms)
Oct 21 16:36:41.909: INFO: (2) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 20.516584ms)
Oct 21 16:36:41.909: INFO: (2) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 20.401556ms)
Oct 21 16:36:41.919: INFO: (3) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.39917ms)
Oct 21 16:36:41.920: INFO: (3) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 11.569562ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.665992ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.732453ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.522449ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.702717ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 11.806204ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.838869ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.838691ms)
Oct 21 16:36:41.921: INFO: (3) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.00154ms)
Oct 21 16:36:41.924: INFO: (3) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 14.955694ms)
Oct 21 16:36:41.927: INFO: (3) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 17.691363ms)
Oct 21 16:36:41.929: INFO: (3) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.830462ms)
Oct 21 16:36:41.929: INFO: (3) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 19.634289ms)
Oct 21 16:36:41.929: INFO: (3) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.711114ms)
Oct 21 16:36:41.929: INFO: (3) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.957284ms)
Oct 21 16:36:41.940: INFO: (4) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.517732ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 12.783919ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 12.968489ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 12.803352ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 13.011686ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 13.126982ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 13.085618ms)
Oct 21 16:36:41.942: INFO: (4) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 13.107914ms)
Oct 21 16:36:41.943: INFO: (4) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 13.259602ms)
Oct 21 16:36:41.943: INFO: (4) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 13.469872ms)
Oct 21 16:36:41.945: INFO: (4) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 15.56036ms)
Oct 21 16:36:41.949: INFO: (4) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.760804ms)
Oct 21 16:36:41.951: INFO: (4) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 21.534513ms)
Oct 21 16:36:41.961: INFO: (4) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 31.501497ms)
Oct 21 16:36:41.961: INFO: (4) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 31.526155ms)
Oct 21 16:36:41.961: INFO: (4) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 31.622416ms)
Oct 21 16:36:41.972: INFO: (5) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.802214ms)
Oct 21 16:36:41.973: INFO: (5) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.36611ms)
Oct 21 16:36:41.973: INFO: (5) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 12.192087ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.507928ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 12.43915ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 12.591564ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 12.445934ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 12.567337ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 12.927532ms)
Oct 21 16:36:41.974: INFO: (5) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 12.942037ms)
Oct 21 16:36:41.975: INFO: (5) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 14.354334ms)
Oct 21 16:36:41.978: INFO: (5) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 17.15933ms)
Oct 21 16:36:41.980: INFO: (5) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.029148ms)
Oct 21 16:36:41.980: INFO: (5) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.227951ms)
Oct 21 16:36:41.980: INFO: (5) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.067903ms)
Oct 21 16:36:41.980: INFO: (5) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 19.335067ms)
Oct 21 16:36:41.990: INFO: (6) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 9.079965ms)
Oct 21 16:36:41.993: INFO: (6) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.681308ms)
Oct 21 16:36:41.993: INFO: (6) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.930692ms)
Oct 21 16:36:41.993: INFO: (6) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.740034ms)
Oct 21 16:36:41.993: INFO: (6) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 12.414729ms)
Oct 21 16:36:41.993: INFO: (6) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 12.564211ms)
Oct 21 16:36:41.994: INFO: (6) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 12.581143ms)
Oct 21 16:36:41.994: INFO: (6) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.459405ms)
Oct 21 16:36:41.994: INFO: (6) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 12.6679ms)
Oct 21 16:36:41.994: INFO: (6) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 12.550642ms)
Oct 21 16:36:41.995: INFO: (6) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 14.300203ms)
Oct 21 16:36:41.999: INFO: (6) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 17.955718ms)
Oct 21 16:36:42.000: INFO: (6) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.457051ms)
Oct 21 16:36:42.000: INFO: (6) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.319102ms)
Oct 21 16:36:42.000: INFO: (6) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 19.40567ms)
Oct 21 16:36:42.000: INFO: (6) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.549652ms)
Oct 21 16:36:42.009: INFO: (7) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 8.364314ms)
Oct 21 16:36:42.011: INFO: (7) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.242454ms)
Oct 21 16:36:42.011: INFO: (7) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.427129ms)
Oct 21 16:36:42.011: INFO: (7) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.250667ms)
Oct 21 16:36:42.011: INFO: (7) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.844219ms)
Oct 21 16:36:42.011: INFO: (7) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.018678ms)
Oct 21 16:36:42.012: INFO: (7) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.008358ms)
Oct 21 16:36:42.012: INFO: (7) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.134449ms)
Oct 21 16:36:42.012: INFO: (7) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.145171ms)
Oct 21 16:36:42.012: INFO: (7) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.077377ms)
Oct 21 16:36:42.014: INFO: (7) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 13.454149ms)
Oct 21 16:36:42.019: INFO: (7) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 17.962263ms)
Oct 21 16:36:42.021: INFO: (7) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.719642ms)
Oct 21 16:36:42.021: INFO: (7) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 19.752443ms)
Oct 21 16:36:42.021: INFO: (7) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 20.053976ms)
Oct 21 16:36:42.021: INFO: (7) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.945429ms)
Oct 21 16:36:42.030: INFO: (8) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 9.409855ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.83759ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.716735ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 10.900299ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.751651ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.132166ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.238926ms)
Oct 21 16:36:42.032: INFO: (8) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.427741ms)
Oct 21 16:36:42.033: INFO: (8) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.284694ms)
Oct 21 16:36:42.033: INFO: (8) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.533891ms)
Oct 21 16:36:42.035: INFO: (8) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 14.017025ms)
Oct 21 16:36:42.039: INFO: (8) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 17.697066ms)
Oct 21 16:36:42.041: INFO: (8) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.203107ms)
Oct 21 16:36:42.041: INFO: (8) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.3917ms)
Oct 21 16:36:42.041: INFO: (8) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 19.666651ms)
Oct 21 16:36:42.041: INFO: (8) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.783921ms)
Oct 21 16:36:42.050: INFO: (9) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 8.935344ms)
Oct 21 16:36:42.051: INFO: (9) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 9.986615ms)
Oct 21 16:36:42.051: INFO: (9) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 9.899352ms)
Oct 21 16:36:42.051: INFO: (9) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.02002ms)
Oct 21 16:36:42.052: INFO: (9) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.109069ms)
Oct 21 16:36:42.052: INFO: (9) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.941623ms)
Oct 21 16:36:42.052: INFO: (9) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 10.974316ms)
Oct 21 16:36:42.052: INFO: (9) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.225794ms)
Oct 21 16:36:42.053: INFO: (9) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.434454ms)
Oct 21 16:36:42.053: INFO: (9) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.445684ms)
Oct 21 16:36:42.054: INFO: (9) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 12.941208ms)
Oct 21 16:36:42.058: INFO: (9) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 17.067493ms)
Oct 21 16:36:42.060: INFO: (9) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 18.539684ms)
Oct 21 16:36:42.060: INFO: (9) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.699627ms)
Oct 21 16:36:42.060: INFO: (9) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.864948ms)
Oct 21 16:36:42.060: INFO: (9) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 18.822708ms)
Oct 21 16:36:42.069: INFO: (10) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 8.738157ms)
Oct 21 16:36:42.071: INFO: (10) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.098958ms)
Oct 21 16:36:42.071: INFO: (10) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.589165ms)
Oct 21 16:36:42.071: INFO: (10) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.23827ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.13573ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.091598ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.763672ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.922337ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.265951ms)
Oct 21 16:36:42.072: INFO: (10) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.587208ms)
Oct 21 16:36:42.074: INFO: (10) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 13.472094ms)
Oct 21 16:36:42.077: INFO: (10) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 17.170848ms)
Oct 21 16:36:42.079: INFO: (10) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.783688ms)
Oct 21 16:36:42.079: INFO: (10) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.581307ms)
Oct 21 16:36:42.079: INFO: (10) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.192469ms)
Oct 21 16:36:42.079: INFO: (10) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.247754ms)
Oct 21 16:36:42.088: INFO: (11) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 8.058633ms)
Oct 21 16:36:42.090: INFO: (11) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 9.778966ms)
Oct 21 16:36:42.090: INFO: (11) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 9.722894ms)
Oct 21 16:36:42.090: INFO: (11) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 10.716799ms)
Oct 21 16:36:42.090: INFO: (11) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 9.982409ms)
Oct 21 16:36:42.091: INFO: (11) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.44155ms)
Oct 21 16:36:42.091: INFO: (11) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.408807ms)
Oct 21 16:36:42.091: INFO: (11) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.866224ms)
Oct 21 16:36:42.091: INFO: (11) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.497338ms)
Oct 21 16:36:42.091: INFO: (11) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 10.799298ms)
Oct 21 16:36:42.094: INFO: (11) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 14.017331ms)
Oct 21 16:36:42.098: INFO: (11) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.211909ms)
Oct 21 16:36:42.099: INFO: (11) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 18.392981ms)
Oct 21 16:36:42.099: INFO: (11) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.652203ms)
Oct 21 16:36:42.099: INFO: (11) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.969116ms)
Oct 21 16:36:42.099: INFO: (11) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.821137ms)
Oct 21 16:36:42.108: INFO: (12) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 8.122063ms)
Oct 21 16:36:42.110: INFO: (12) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 9.5224ms)
Oct 21 16:36:42.110: INFO: (12) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 9.315713ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.976822ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 10.690265ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 11.249175ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.42549ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 10.290824ms)
Oct 21 16:36:42.111: INFO: (12) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.208404ms)
Oct 21 16:36:42.112: INFO: (12) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.519839ms)
Oct 21 16:36:42.115: INFO: (12) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 14.561016ms)
Oct 21 16:36:42.117: INFO: (12) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 16.781193ms)
Oct 21 16:36:42.119: INFO: (12) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.83888ms)
Oct 21 16:36:42.119: INFO: (12) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 18.729719ms)
Oct 21 16:36:42.119: INFO: (12) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.691864ms)
Oct 21 16:36:42.119: INFO: (12) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.303758ms)
Oct 21 16:36:42.129: INFO: (13) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 9.518104ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 10.833511ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 11.191606ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 11.302705ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 11.620894ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.418072ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 11.316535ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.239368ms)
Oct 21 16:36:42.131: INFO: (13) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.507734ms)
Oct 21 16:36:42.132: INFO: (13) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.813014ms)
Oct 21 16:36:42.134: INFO: (13) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 14.202104ms)
Oct 21 16:36:42.137: INFO: (13) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 17.05029ms)
Oct 21 16:36:42.139: INFO: (13) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.111711ms)
Oct 21 16:36:42.139: INFO: (13) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.695448ms)
Oct 21 16:36:42.139: INFO: (13) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 19.573437ms)
Oct 21 16:36:42.139: INFO: (13) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 19.470735ms)
Oct 21 16:36:42.148: INFO: (14) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 8.512994ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.340768ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 10.214221ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.31499ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 10.441193ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.246764ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.31731ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.552161ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 10.923341ms)
Oct 21 16:36:42.150: INFO: (14) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.04463ms)
Oct 21 16:36:42.153: INFO: (14) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 13.900944ms)
Oct 21 16:36:42.156: INFO: (14) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 16.734709ms)
Oct 21 16:36:42.159: INFO: (14) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.977108ms)
Oct 21 16:36:42.159: INFO: (14) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 19.068967ms)
Oct 21 16:36:42.159: INFO: (14) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 19.15157ms)
Oct 21 16:36:42.159: INFO: (14) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.012009ms)
Oct 21 16:36:42.168: INFO: (15) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 9.391713ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.589198ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.582875ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.714959ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 11.705165ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 11.74465ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.613512ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 12.135009ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.83859ms)
Oct 21 16:36:42.171: INFO: (15) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.923165ms)
Oct 21 16:36:42.174: INFO: (15) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 15.323264ms)
Oct 21 16:36:42.175: INFO: (15) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 16.211696ms)
Oct 21 16:36:42.177: INFO: (15) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.03606ms)
Oct 21 16:36:42.177: INFO: (15) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 17.908525ms)
Oct 21 16:36:42.177: INFO: (15) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.244812ms)
Oct 21 16:36:42.177: INFO: (15) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.280634ms)
Oct 21 16:36:42.186: INFO: (16) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 9.235481ms)
Oct 21 16:36:42.188: INFO: (16) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 10.23405ms)
Oct 21 16:36:42.188: INFO: (16) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.732298ms)
Oct 21 16:36:42.188: INFO: (16) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.941437ms)
Oct 21 16:36:42.188: INFO: (16) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 10.869463ms)
Oct 21 16:36:42.189: INFO: (16) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.852996ms)
Oct 21 16:36:42.189: INFO: (16) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 11.417318ms)
Oct 21 16:36:42.189: INFO: (16) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 11.620759ms)
Oct 21 16:36:42.189: INFO: (16) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 11.559713ms)
Oct 21 16:36:42.189: INFO: (16) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.78658ms)
Oct 21 16:36:42.191: INFO: (16) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 13.980643ms)
Oct 21 16:36:42.195: INFO: (16) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 16.807358ms)
Oct 21 16:36:42.196: INFO: (16) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.46022ms)
Oct 21 16:36:42.196: INFO: (16) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.610244ms)
Oct 21 16:36:42.196: INFO: (16) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.558993ms)
Oct 21 16:36:42.196: INFO: (16) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.922145ms)
Oct 21 16:36:42.205: INFO: (17) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 8.922662ms)
Oct 21 16:36:42.207: INFO: (17) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.851653ms)
Oct 21 16:36:42.207: INFO: (17) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.669781ms)
Oct 21 16:36:42.207: INFO: (17) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 10.320727ms)
Oct 21 16:36:42.207: INFO: (17) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.77198ms)
Oct 21 16:36:42.208: INFO: (17) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.437053ms)
Oct 21 16:36:42.208: INFO: (17) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 11.109374ms)
Oct 21 16:36:42.209: INFO: (17) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 11.570555ms)
Oct 21 16:36:42.209: INFO: (17) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 11.700404ms)
Oct 21 16:36:42.209: INFO: (17) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 12.14601ms)
Oct 21 16:36:42.211: INFO: (17) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 13.99911ms)
Oct 21 16:36:42.214: INFO: (17) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 16.841683ms)
Oct 21 16:36:42.215: INFO: (17) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 18.2416ms)
Oct 21 16:36:42.215: INFO: (17) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 18.232142ms)
Oct 21 16:36:42.215: INFO: (17) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 18.395687ms)
Oct 21 16:36:42.215: INFO: (17) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.545797ms)
Oct 21 16:36:42.226: INFO: (18) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 10.975003ms)
Oct 21 16:36:42.228: INFO: (18) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.377209ms)
Oct 21 16:36:42.228: INFO: (18) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 12.488954ms)
Oct 21 16:36:42.228: INFO: (18) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 12.45399ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 13.274764ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 13.258398ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 13.260792ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 13.379177ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 13.300581ms)
Oct 21 16:36:42.229: INFO: (18) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 13.507881ms)
Oct 21 16:36:42.232: INFO: (18) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 16.143544ms)
Oct 21 16:36:42.234: INFO: (18) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 18.8046ms)
Oct 21 16:36:42.236: INFO: (18) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 20.405702ms)
Oct 21 16:36:42.236: INFO: (18) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 20.59765ms)
Oct 21 16:36:42.236: INFO: (18) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 20.753512ms)
Oct 21 16:36:42.237: INFO: (18) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 21.219205ms)
Oct 21 16:36:42.246: INFO: (19) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:462/proxy/: tls qux (200; 8.653703ms)
Oct 21 16:36:42.247: INFO: (19) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:160/proxy/: foo (200; 10.131004ms)
Oct 21 16:36:42.247: INFO: (19) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.29093ms)
Oct 21 16:36:42.247: INFO: (19) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:162/proxy/: bar (200; 10.215819ms)
Oct 21 16:36:42.247: INFO: (19) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929:1080/proxy/rewriteme">test<... (200; 10.346147ms)
Oct 21 16:36:42.247: INFO: (19) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:443/proxy/tlsrewritem... (200; 10.332156ms)
Oct 21 16:36:42.248: INFO: (19) /api/v1/namespaces/proxy-2540/pods/https:proxy-service-qcf9x-jr929:460/proxy/: tls baz (200; 10.244848ms)
Oct 21 16:36:42.250: INFO: (19) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:1080/proxy/rewriteme">... (200; 12.534627ms)
Oct 21 16:36:42.250: INFO: (19) /api/v1/namespaces/proxy-2540/pods/http:proxy-service-qcf9x-jr929:160/proxy/: foo (200; 12.445695ms)
Oct 21 16:36:42.250: INFO: (19) /api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/: <a href="/api/v1/namespaces/proxy-2540/pods/proxy-service-qcf9x-jr929/proxy/rewriteme">test</a> (200; 12.704169ms)
Oct 21 16:36:42.251: INFO: (19) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname1/proxy/: foo (200; 13.93367ms)
Oct 21 16:36:42.255: INFO: (19) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname2/proxy/: bar (200; 17.521918ms)
Oct 21 16:36:42.256: INFO: (19) /api/v1/namespaces/proxy-2540/services/http:proxy-service-qcf9x:portname2/proxy/: bar (200; 18.545488ms)
Oct 21 16:36:42.256: INFO: (19) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname2/proxy/: tls qux (200; 18.464871ms)
Oct 21 16:36:42.256: INFO: (19) /api/v1/namespaces/proxy-2540/services/https:proxy-service-qcf9x:tlsportname1/proxy/: tls baz (200; 18.681718ms)
Oct 21 16:36:42.256: INFO: (19) /api/v1/namespaces/proxy-2540/services/proxy-service-qcf9x:portname1/proxy/: foo (200; 19.109776ms)
STEP: deleting ReplicationController proxy-service-qcf9x in namespace proxy-2540, will wait for the garbage collector to delete the pods
Oct 21 16:36:42.340: INFO: Deleting ReplicationController proxy-service-qcf9x took: 24.238964ms
Oct 21 16:36:42.441: INFO: Terminating ReplicationController proxy-service-qcf9x pods took: 100.636764ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:36:54.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2540" for this suite.
Oct 21 16:37:00.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:37:01.411: INFO: namespace proxy-2540 deletion completed in 6.459365544s

• [SLOW TEST:33.885 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:37:01.413: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-d5643b7e-5d5d-47a4-adab-9d9678610320
STEP: Creating a pod to test consume secrets
Oct 21 16:37:01.637: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a" in namespace "projected-9810" to be "success or failure"
Oct 21 16:37:01.643: INFO: Pod "pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.459876ms
Oct 21 16:37:03.650: INFO: Pod "pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0124306s
Oct 21 16:37:05.658: INFO: Pod "pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020259159s
STEP: Saw pod success
Oct 21 16:37:05.658: INFO: Pod "pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a" satisfied condition "success or failure"
Oct 21 16:37:05.664: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:37:05.702: INFO: Waiting for pod pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a to disappear
Oct 21 16:37:05.710: INFO: Pod pod-projected-secrets-f136d0a5-4fa9-48e5-ac68-57e0182b9b5a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:37:05.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9810" for this suite.
Oct 21 16:37:11.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:37:12.085: INFO: namespace projected-9810 deletion completed in 6.365605833s

• [SLOW TEST:10.672 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:37:12.085: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 16:37:12.304: INFO: Waiting up to 5m0s for pod "pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9" in namespace "emptydir-102" to be "success or failure"
Oct 21 16:37:12.310: INFO: Pod "pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.050614ms
Oct 21 16:37:14.316: INFO: Pod "pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012627988s
STEP: Saw pod success
Oct 21 16:37:14.316: INFO: Pod "pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9" satisfied condition "success or failure"
Oct 21 16:37:14.322: INFO: Trying to get logs from node 10.195.18.160 pod pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9 container test-container: <nil>
STEP: delete the pod
Oct 21 16:37:14.351: INFO: Waiting for pod pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9 to disappear
Oct 21 16:37:14.357: INFO: Pod pod-4d3f9cb8-ee79-4f33-ab01-1f4dc3b9eee9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:37:14.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-102" for this suite.
Oct 21 16:37:20.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:37:20.753: INFO: namespace emptydir-102 deletion completed in 6.387440588s

• [SLOW TEST:8.668 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:37:20.754: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 16:37:29.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:29.025: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:31.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:31.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:33.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:33.033: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:35.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:35.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:37.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:37.034: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:39.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:39.033: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:41.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:41.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:43.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:43.033: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:45.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:45.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:47.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:47.032: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 16:37:49.025: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 16:37:49.033: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:37:49.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6826" for this suite.
Oct 21 16:38:13.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:38:13.442: INFO: namespace container-lifecycle-hook-6826 deletion completed in 24.380676945s

• [SLOW TEST:52.688 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:38:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6834/secret-test-476938ca-5e93-4959-840f-30db7b46b066
STEP: Creating a pod to test consume secrets
Oct 21 16:38:13.667: INFO: Waiting up to 5m0s for pod "pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70" in namespace "secrets-6834" to be "success or failure"
Oct 21 16:38:13.673: INFO: Pod "pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70": Phase="Pending", Reason="", readiness=false. Elapsed: 5.484416ms
Oct 21 16:38:15.680: INFO: Pod "pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012190695s
Oct 21 16:38:17.697: INFO: Pod "pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02961455s
STEP: Saw pod success
Oct 21 16:38:17.697: INFO: Pod "pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70" satisfied condition "success or failure"
Oct 21 16:38:17.705: INFO: Trying to get logs from node 10.195.18.154 pod pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70 container env-test: <nil>
STEP: delete the pod
Oct 21 16:38:17.740: INFO: Waiting for pod pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70 to disappear
Oct 21 16:38:17.745: INFO: Pod pod-configmaps-59145eab-3d15-42e5-86dd-38ddf7d80a70 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:38:17.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6834" for this suite.
Oct 21 16:38:23.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:38:24.236: INFO: namespace secrets-6834 deletion completed in 6.481163089s

• [SLOW TEST:10.794 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:38:24.237: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:38:24.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5407" for this suite.
Oct 21 16:38:30.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:38:30.767: INFO: namespace services-5407 deletion completed in 6.311962732s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.530 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:38:30.769: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Oct 21 16:38:33.037: INFO: Pod pod-hostip-56d698a0-c9d6-4c02-a5dd-4dc2a7b551af has hostIP: 10.195.18.159
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:38:33.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1384" for this suite.
Oct 21 16:38:55.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:38:55.423: INFO: namespace pods-1384 deletion completed in 22.377381875s

• [SLOW TEST:24.654 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:38:55.423: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 16:38:58.180: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b"
Oct 21 16:38:58.180: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b" in namespace "pods-8156" to be "terminated due to deadline exceeded"
Oct 21 16:38:58.192: INFO: Pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b": Phase="Running", Reason="", readiness=true. Elapsed: 11.78324ms
Oct 21 16:39:00.198: INFO: Pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.018208599s
Oct 21 16:39:02.204: INFO: Pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.024314435s
Oct 21 16:39:02.204: INFO: Pod "pod-update-activedeadlineseconds-c8ab7419-a3c2-43a8-9c71-c8bec64b9e7b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:39:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8156" for this suite.
Oct 21 16:39:08.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:08.513: INFO: namespace pods-8156 deletion completed in 6.300727185s

• [SLOW TEST:13.090 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:39:08.514: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct 21 16:39:38.791: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:39:38.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1021 16:39:38.791855      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3254" for this suite.
Oct 21 16:39:44.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:45.139: INFO: namespace gc-3254 deletion completed in 6.338873462s

• [SLOW TEST:36.625 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:39:45.149: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:39:45.363: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e" in namespace "projected-3740" to be "success or failure"
Oct 21 16:39:45.370: INFO: Pod "downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.11323ms
Oct 21 16:39:47.377: INFO: Pod "downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013268479s
STEP: Saw pod success
Oct 21 16:39:47.377: INFO: Pod "downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e" satisfied condition "success or failure"
Oct 21 16:39:47.383: INFO: Trying to get logs from node 10.195.18.154 pod downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e container client-container: <nil>
STEP: delete the pod
Oct 21 16:39:47.417: INFO: Waiting for pod downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e to disappear
Oct 21 16:39:47.422: INFO: Pod downwardapi-volume-c8a5ba3c-34c1-4cc4-9f78-6d1dce54bd8e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:39:47.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3740" for this suite.
Oct 21 16:39:53.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:39:53.744: INFO: namespace projected-3740 deletion completed in 6.3130607s

• [SLOW TEST:8.595 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:39:53.745: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 21 16:40:02.005: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:02.005: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:02.301: INFO: Exec stderr: ""
Oct 21 16:40:02.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:02.302: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:02.551: INFO: Exec stderr: ""
Oct 21 16:40:02.551: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:02.551: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:02.811: INFO: Exec stderr: ""
Oct 21 16:40:02.811: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:02.811: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:03.055: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 21 16:40:03.055: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:03.055: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:03.287: INFO: Exec stderr: ""
Oct 21 16:40:03.287: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:03.287: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:03.516: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 21 16:40:03.516: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:03.516: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:03.934: INFO: Exec stderr: ""
Oct 21 16:40:03.934: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:03.934: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:04.136: INFO: Exec stderr: ""
Oct 21 16:40:04.137: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:04.137: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:04.339: INFO: Exec stderr: ""
Oct 21 16:40:04.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5135 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:40:04.340: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:40:04.562: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:40:04.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5135" for this suite.
Oct 21 16:40:58.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:40:58.932: INFO: namespace e2e-kubelet-etc-hosts-5135 deletion completed in 54.359249501s

• [SLOW TEST:65.187 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:40:58.932: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1183
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 16:40:59.150: INFO: Waiting up to 5m0s for pod "pod-a3d19e62-25db-4840-b284-9370cc29f519" in namespace "emptydir-1183" to be "success or failure"
Oct 21 16:40:59.156: INFO: Pod "pod-a3d19e62-25db-4840-b284-9370cc29f519": Phase="Pending", Reason="", readiness=false. Elapsed: 6.216187ms
Oct 21 16:41:01.163: INFO: Pod "pod-a3d19e62-25db-4840-b284-9370cc29f519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012816951s
STEP: Saw pod success
Oct 21 16:41:01.163: INFO: Pod "pod-a3d19e62-25db-4840-b284-9370cc29f519" satisfied condition "success or failure"
Oct 21 16:41:01.170: INFO: Trying to get logs from node 10.195.18.154 pod pod-a3d19e62-25db-4840-b284-9370cc29f519 container test-container: <nil>
STEP: delete the pod
Oct 21 16:41:01.203: INFO: Waiting for pod pod-a3d19e62-25db-4840-b284-9370cc29f519 to disappear
Oct 21 16:41:01.208: INFO: Pod pod-a3d19e62-25db-4840-b284-9370cc29f519 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:41:01.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1183" for this suite.
Oct 21 16:41:07.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:41:07.542: INFO: namespace emptydir-1183 deletion completed in 6.318552173s

• [SLOW TEST:8.610 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:41:07.542: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:41:07.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd" in namespace "downward-api-8889" to be "success or failure"
Oct 21 16:41:07.764: INFO: Pod "downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.704533ms
Oct 21 16:41:09.772: INFO: Pod "downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013285349s
STEP: Saw pod success
Oct 21 16:41:09.772: INFO: Pod "downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd" satisfied condition "success or failure"
Oct 21 16:41:09.778: INFO: Trying to get logs from node 10.195.18.160 pod downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd container client-container: <nil>
STEP: delete the pod
Oct 21 16:41:09.814: INFO: Waiting for pod downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd to disappear
Oct 21 16:41:09.819: INFO: Pod downwardapi-volume-97cfcf0b-512f-4a6e-bdc7-348af727facd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:41:09.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8889" for this suite.
Oct 21 16:41:15.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:41:16.138: INFO: namespace downward-api-8889 deletion completed in 6.310342007s

• [SLOW TEST:8.596 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:41:16.138: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-741
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-2a44d08d-dd33-4887-b2d5-834a2a9fb449
STEP: Creating secret with name s-test-opt-upd-9cb1204b-e0e7-4342-992b-b6d20d54f74c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2a44d08d-dd33-4887-b2d5-834a2a9fb449
STEP: Updating secret s-test-opt-upd-9cb1204b-e0e7-4342-992b-b6d20d54f74c
STEP: Creating secret with name s-test-opt-create-4e735aad-a511-418c-9869-df3e683ffe10
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:42:33.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-741" for this suite.
Oct 21 16:42:57.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:42:57.501: INFO: namespace projected-741 deletion completed in 24.319002763s

• [SLOW TEST:101.364 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:42:57.502: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2185.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2185.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 16:43:01.812: INFO: DNS probes using dns-2185/dns-test-7c5ee172-8712-40b6-a884-afd50918fc16 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:01.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2185" for this suite.
Oct 21 16:43:07.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:08.183: INFO: namespace dns-2185 deletion completed in 6.343254716s

• [SLOW TEST:10.681 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:43:08.183: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 21 16:43:10.423: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:10.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1233" for this suite.
Oct 21 16:43:16.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:16.793: INFO: namespace container-runtime-1233 deletion completed in 6.336418602s

• [SLOW TEST:8.610 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:43:16.794: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:43:17.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a" in namespace "downward-api-8117" to be "success or failure"
Oct 21 16:43:17.024: INFO: Pod "downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.099693ms
Oct 21 16:43:19.031: INFO: Pod "downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015749015s
STEP: Saw pod success
Oct 21 16:43:19.031: INFO: Pod "downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a" satisfied condition "success or failure"
Oct 21 16:43:19.036: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a container client-container: <nil>
STEP: delete the pod
Oct 21 16:43:19.073: INFO: Waiting for pod downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a to disappear
Oct 21 16:43:19.079: INFO: Pod downwardapi-volume-902cb551-554f-4183-83cd-e21b184a324a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:19.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8117" for this suite.
Oct 21 16:43:25.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:25.458: INFO: namespace downward-api-8117 deletion completed in 6.357398912s

• [SLOW TEST:8.665 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:43:25.459: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4177
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-50f2bc70-050e-4b34-a667-a00197b8322d
STEP: Creating a pod to test consume configMaps
Oct 21 16:43:25.686: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba" in namespace "projected-4177" to be "success or failure"
Oct 21 16:43:25.692: INFO: Pod "pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba": Phase="Pending", Reason="", readiness=false. Elapsed: 5.984468ms
Oct 21 16:43:27.700: INFO: Pod "pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013399805s
Oct 21 16:43:29.707: INFO: Pod "pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020657604s
STEP: Saw pod success
Oct 21 16:43:29.707: INFO: Pod "pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba" satisfied condition "success or failure"
Oct 21 16:43:29.713: INFO: Trying to get logs from node 10.195.18.160 pod pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:43:29.749: INFO: Waiting for pod pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba to disappear
Oct 21 16:43:29.755: INFO: Pod pod-projected-configmaps-19a39360-a3e6-4178-bcf1-a8bb3b4668ba no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:29.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4177" for this suite.
Oct 21 16:43:35.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:36.086: INFO: namespace projected-4177 deletion completed in 6.322717979s

• [SLOW TEST:10.628 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:43:36.086: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:40.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5453" for this suite.
Oct 21 16:43:46.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:43:46.867: INFO: namespace kubelet-test-5453 deletion completed in 6.510412535s

• [SLOW TEST:10.780 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:43:46.867: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7072
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-68423b08-6a53-47fa-b44b-c6e345c02395
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-68423b08-6a53-47fa-b44b-c6e345c02395
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:43:51.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7072" for this suite.
Oct 21 16:44:15.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:15.484: INFO: namespace projected-7072 deletion completed in 24.311563082s

• [SLOW TEST:28.616 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:44:15.484: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8036
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:44:15.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca" in namespace "projected-8036" to be "success or failure"
Oct 21 16:44:15.706: INFO: Pod "downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.152303ms
Oct 21 16:44:17.715: INFO: Pod "downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca": Phase="Running", Reason="", readiness=true. Elapsed: 2.014573072s
Oct 21 16:44:19.726: INFO: Pod "downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025568718s
STEP: Saw pod success
Oct 21 16:44:19.726: INFO: Pod "downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca" satisfied condition "success or failure"
Oct 21 16:44:19.732: INFO: Trying to get logs from node 10.195.18.160 pod downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca container client-container: <nil>
STEP: delete the pod
Oct 21 16:44:19.762: INFO: Waiting for pod downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca to disappear
Oct 21 16:44:19.767: INFO: Pod downwardapi-volume-52fd6446-ad1a-40ff-ba44-e3e741bd03ca no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:44:19.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8036" for this suite.
Oct 21 16:44:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:26.096: INFO: namespace projected-8036 deletion completed in 6.320086819s

• [SLOW TEST:10.612 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:44:26.097: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 21 16:44:28.335: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:44:28.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1910" for this suite.
Oct 21 16:44:34.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:34.676: INFO: namespace container-runtime-1910 deletion completed in 6.309100198s

• [SLOW TEST:8.579 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:44:34.677: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:44:34.896: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348" in namespace "downward-api-4056" to be "success or failure"
Oct 21 16:44:34.902: INFO: Pod "downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348": Phase="Pending", Reason="", readiness=false. Elapsed: 5.452575ms
Oct 21 16:44:36.909: INFO: Pod "downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348": Phase="Running", Reason="", readiness=true. Elapsed: 2.013095487s
Oct 21 16:44:38.917: INFO: Pod "downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020624641s
STEP: Saw pod success
Oct 21 16:44:38.917: INFO: Pod "downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348" satisfied condition "success or failure"
Oct 21 16:44:38.924: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348 container client-container: <nil>
STEP: delete the pod
Oct 21 16:44:38.959: INFO: Waiting for pod downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348 to disappear
Oct 21 16:44:38.964: INFO: Pod downwardapi-volume-b5981ddc-c470-4812-abf0-e4f81367e348 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:44:38.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4056" for this suite.
Oct 21 16:44:45.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:44:45.290: INFO: namespace downward-api-4056 deletion completed in 6.316420041s

• [SLOW TEST:10.613 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:44:45.290: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 16:44:51.577: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:44:51.583: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:44:53.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:44:53.589: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:44:55.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:44:55.590: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:44:57.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:44:57.590: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:44:59.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:44:59.591: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:01.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:01.591: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:03.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:03.590: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:05.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:05.593: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:07.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:07.590: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:09.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:09.589: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:11.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:11.590: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 16:45:13.583: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 16:45:13.590: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:45:13.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9927" for this suite.
Oct 21 16:45:35.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:35.921: INFO: namespace container-lifecycle-hook-9927 deletion completed in 22.323083232s

• [SLOW TEST:50.631 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:45:35.921: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7bc04935-d8cc-43bb-9b18-d95287bc486b
STEP: Creating a pod to test consume secrets
Oct 21 16:45:36.141: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d" in namespace "projected-6932" to be "success or failure"
Oct 21 16:45:36.147: INFO: Pod "pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758408ms
Oct 21 16:45:38.154: INFO: Pod "pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013271049s
Oct 21 16:45:40.161: INFO: Pod "pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020215049s
STEP: Saw pod success
Oct 21 16:45:40.161: INFO: Pod "pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d" satisfied condition "success or failure"
Oct 21 16:45:40.167: INFO: Trying to get logs from node 10.195.18.159 pod pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:45:40.198: INFO: Waiting for pod pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d to disappear
Oct 21 16:45:40.205: INFO: Pod pod-projected-secrets-7b1ccc53-be37-44b8-9204-ade5ae2a416d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:45:40.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6932" for this suite.
Oct 21 16:45:46.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:46.592: INFO: namespace projected-6932 deletion completed in 6.377352176s

• [SLOW TEST:10.670 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:45:46.592: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-7ec9167d-0a09-4970-b32e-67156e92eb38
STEP: Creating a pod to test consume configMaps
Oct 21 16:45:46.809: INFO: Waiting up to 5m0s for pod "pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2" in namespace "configmap-3977" to be "success or failure"
Oct 21 16:45:46.815: INFO: Pod "pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.891118ms
Oct 21 16:45:48.823: INFO: Pod "pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013537085s
STEP: Saw pod success
Oct 21 16:45:48.823: INFO: Pod "pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2" satisfied condition "success or failure"
Oct 21 16:45:48.834: INFO: Trying to get logs from node 10.195.18.160 pod pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:45:48.868: INFO: Waiting for pod pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2 to disappear
Oct 21 16:45:48.873: INFO: Pod pod-configmaps-b942725a-c492-4b78-9699-a0ad838c88c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:45:48.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3977" for this suite.
Oct 21 16:45:54.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:45:55.191: INFO: namespace configmap-3977 deletion completed in 6.308521068s

• [SLOW TEST:8.599 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:45:55.192: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-8d3d1e02-111f-447b-a389-0c15f83c7ed9
STEP: Creating a pod to test consume configMaps
Oct 21 16:45:55.408: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd" in namespace "projected-9814" to be "success or failure"
Oct 21 16:45:55.413: INFO: Pod "pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.875325ms
Oct 21 16:45:57.421: INFO: Pod "pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0138779s
STEP: Saw pod success
Oct 21 16:45:57.422: INFO: Pod "pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd" satisfied condition "success or failure"
Oct 21 16:45:57.427: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:45:57.458: INFO: Waiting for pod pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd to disappear
Oct 21 16:45:57.463: INFO: Pod pod-projected-configmaps-d88d42bf-3792-4fb6-90e7-1da813fc75dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:45:57.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9814" for this suite.
Oct 21 16:46:03.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:03.792: INFO: namespace projected-9814 deletion completed in 6.319968975s

• [SLOW TEST:8.600 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:03.792: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1553
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:46:03.999: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 21 16:46:06.073: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:46:06.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1553" for this suite.
Oct 21 16:46:12.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:12.403: INFO: namespace replication-controller-1553 deletion completed in 6.30801008s

• [SLOW TEST:8.611 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:12.403: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:46:12.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5343'
Oct 21 16:46:12.811: INFO: stderr: ""
Oct 21 16:46:12.811: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 21 16:46:17.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pod e2e-test-nginx-pod --namespace=kubectl-5343 -o json'
Oct 21 16:46:17.982: INFO: stderr: ""
Oct 21 16:46:17.982: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-21T16:46:12Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5343\",\n        \"resourceVersion\": \"32494\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5343/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ada354c9-4c51-4779-8438-bdabd3ea30fe\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bbglc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.195.18.154\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bbglc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bbglc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:46:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:46:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:46:14Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T16:46:12Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://b024a062758b9b0a747de8cd43cb213b69e948b068b76febf7a76524ac55e9b1\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-21T16:46:13Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.195.18.154\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.78.228\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-21T16:46:12Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 21 16:46:17.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 replace -f - --namespace=kubectl-5343'
Oct 21 16:46:18.259: INFO: stderr: ""
Oct 21 16:46:18.259: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Oct 21 16:46:18.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete pods e2e-test-nginx-pod --namespace=kubectl-5343'
Oct 21 16:46:23.517: INFO: stderr: ""
Oct 21 16:46:23.517: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:46:23.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5343" for this suite.
Oct 21 16:46:29.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:29.854: INFO: namespace kubectl-5343 deletion completed in 6.327337724s

• [SLOW TEST:17.451 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:29.855: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-456a913f-29f2-4056-9f15-ae3e083d4ff6
STEP: Creating a pod to test consume configMaps
Oct 21 16:46:30.085: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac" in namespace "projected-1536" to be "success or failure"
Oct 21 16:46:30.091: INFO: Pod "pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04087ms
Oct 21 16:46:32.098: INFO: Pod "pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac": Phase="Running", Reason="", readiness=true. Elapsed: 2.012948126s
Oct 21 16:46:34.105: INFO: Pod "pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019681981s
STEP: Saw pod success
Oct 21 16:46:34.105: INFO: Pod "pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac" satisfied condition "success or failure"
Oct 21 16:46:34.111: INFO: Trying to get logs from node 10.195.18.159 pod pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:46:34.141: INFO: Waiting for pod pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac to disappear
Oct 21 16:46:34.147: INFO: Pod pod-projected-configmaps-0d1a8ee0-ea61-4e3d-882c-7c43e75303ac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:46:34.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1536" for this suite.
Oct 21 16:46:40.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:40.513: INFO: namespace projected-1536 deletion completed in 6.357436004s

• [SLOW TEST:10.658 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:40.514: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7539
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 16:46:40.730: INFO: Waiting up to 5m0s for pod "pod-40524856-4eca-4800-913c-a5b966358b4e" in namespace "emptydir-7539" to be "success or failure"
Oct 21 16:46:40.736: INFO: Pod "pod-40524856-4eca-4800-913c-a5b966358b4e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.398652ms
Oct 21 16:46:42.742: INFO: Pod "pod-40524856-4eca-4800-913c-a5b966358b4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01190656s
STEP: Saw pod success
Oct 21 16:46:42.742: INFO: Pod "pod-40524856-4eca-4800-913c-a5b966358b4e" satisfied condition "success or failure"
Oct 21 16:46:42.747: INFO: Trying to get logs from node 10.195.18.154 pod pod-40524856-4eca-4800-913c-a5b966358b4e container test-container: <nil>
STEP: delete the pod
Oct 21 16:46:42.779: INFO: Waiting for pod pod-40524856-4eca-4800-913c-a5b966358b4e to disappear
Oct 21 16:46:42.785: INFO: Pod pod-40524856-4eca-4800-913c-a5b966358b4e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:46:42.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7539" for this suite.
Oct 21 16:46:48.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:49.141: INFO: namespace emptydir-7539 deletion completed in 6.346259552s

• [SLOW TEST:8.627 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:49.141: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5918
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:46:49.364: INFO: (0) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.745219ms)
Oct 21 16:46:49.375: INFO: (1) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.786715ms)
Oct 21 16:46:49.384: INFO: (2) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.613326ms)
Oct 21 16:46:49.394: INFO: (3) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.575773ms)
Oct 21 16:46:49.404: INFO: (4) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.511384ms)
Oct 21 16:46:49.417: INFO: (5) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.956929ms)
Oct 21 16:46:49.426: INFO: (6) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.21203ms)
Oct 21 16:46:49.436: INFO: (7) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.963362ms)
Oct 21 16:46:49.446: INFO: (8) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.912642ms)
Oct 21 16:46:49.457: INFO: (9) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.727662ms)
Oct 21 16:46:49.466: INFO: (10) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.65435ms)
Oct 21 16:46:49.476: INFO: (11) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.499784ms)
Oct 21 16:46:49.486: INFO: (12) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.499023ms)
Oct 21 16:46:49.496: INFO: (13) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.013043ms)
Oct 21 16:46:49.505: INFO: (14) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.663337ms)
Oct 21 16:46:49.515: INFO: (15) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.835742ms)
Oct 21 16:46:49.527: INFO: (16) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.656573ms)
Oct 21 16:46:49.540: INFO: (17) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.01846ms)
Oct 21 16:46:49.550: INFO: (18) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.244266ms)
Oct 21 16:46:49.560: INFO: (19) /api/v1/nodes/10.195.18.154:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 9.832238ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:46:49.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5918" for this suite.
Oct 21 16:46:55.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:46:55.891: INFO: namespace proxy-5918 deletion completed in 6.322921472s

• [SLOW TEST:6.750 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:46:55.892: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-9zk4
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 16:46:56.136: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9zk4" in namespace "subpath-3631" to be "success or failure"
Oct 21 16:46:56.141: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.50851ms
Oct 21 16:46:58.148: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012220097s
Oct 21 16:47:00.155: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 4.019485226s
Oct 21 16:47:02.163: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 6.027436858s
Oct 21 16:47:04.170: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 8.034386982s
Oct 21 16:47:06.177: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 10.040918806s
Oct 21 16:47:08.184: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 12.047849195s
Oct 21 16:47:10.191: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 14.055335061s
Oct 21 16:47:12.199: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 16.063135476s
Oct 21 16:47:14.206: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 18.070036531s
Oct 21 16:47:16.213: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Running", Reason="", readiness=true. Elapsed: 20.077110748s
Oct 21 16:47:18.220: INFO: Pod "pod-subpath-test-secret-9zk4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.084000873s
STEP: Saw pod success
Oct 21 16:47:18.220: INFO: Pod "pod-subpath-test-secret-9zk4" satisfied condition "success or failure"
Oct 21 16:47:18.232: INFO: Trying to get logs from node 10.195.18.154 pod pod-subpath-test-secret-9zk4 container test-container-subpath-secret-9zk4: <nil>
STEP: delete the pod
Oct 21 16:47:18.263: INFO: Waiting for pod pod-subpath-test-secret-9zk4 to disappear
Oct 21 16:47:18.268: INFO: Pod pod-subpath-test-secret-9zk4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-9zk4
Oct 21 16:47:18.269: INFO: Deleting pod "pod-subpath-test-secret-9zk4" in namespace "subpath-3631"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:47:18.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3631" for this suite.
Oct 21 16:47:24.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:47:24.630: INFO: namespace subpath-3631 deletion completed in 6.346374232s

• [SLOW TEST:28.738 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:47:24.630: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7765
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Oct 21 16:47:25.382: INFO: created pod pod-service-account-defaultsa
Oct 21 16:47:25.382: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 21 16:47:25.390: INFO: created pod pod-service-account-mountsa
Oct 21 16:47:25.390: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 21 16:47:25.397: INFO: created pod pod-service-account-nomountsa
Oct 21 16:47:25.397: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 21 16:47:25.405: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 21 16:47:25.405: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 21 16:47:25.412: INFO: created pod pod-service-account-mountsa-mountspec
Oct 21 16:47:25.412: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 21 16:47:25.419: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 21 16:47:25.419: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 21 16:47:25.426: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 21 16:47:25.426: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 21 16:47:25.433: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 21 16:47:25.433: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 21 16:47:25.440: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 21 16:47:25.440: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:47:25.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7765" for this suite.
Oct 21 16:47:31.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:47:31.767: INFO: namespace svcaccounts-7765 deletion completed in 6.317398846s

• [SLOW TEST:7.137 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:47:31.767: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3612
STEP: Creating secret with name secret-test-8f4712ec-097c-4468-af73-a9c354a4977e
STEP: Creating a pod to test consume secrets
Oct 21 16:47:32.193: INFO: Waiting up to 5m0s for pod "pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc" in namespace "secrets-5208" to be "success or failure"
Oct 21 16:47:32.198: INFO: Pod "pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.173703ms
Oct 21 16:47:34.206: INFO: Pod "pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc": Phase="Running", Reason="", readiness=true. Elapsed: 2.012812756s
Oct 21 16:47:36.212: INFO: Pod "pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019677636s
STEP: Saw pod success
Oct 21 16:47:36.212: INFO: Pod "pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc" satisfied condition "success or failure"
Oct 21 16:47:36.218: INFO: Trying to get logs from node 10.195.18.159 pod pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:47:36.246: INFO: Waiting for pod pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc to disappear
Oct 21 16:47:36.252: INFO: Pod pod-secrets-3850654c-9877-41e1-8298-fe83f5fe3efc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:47:36.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5208" for this suite.
Oct 21 16:47:42.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:47:42.572: INFO: namespace secrets-5208 deletion completed in 6.311947s
STEP: Destroying namespace "secret-namespace-3612" for this suite.
Oct 21 16:47:48.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:47:48.890: INFO: namespace secret-namespace-3612 deletion completed in 6.317242895s

• [SLOW TEST:17.122 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:47:48.890: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:47:54.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4630" for this suite.
Oct 21 16:48:00.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:48:01.018: INFO: namespace watch-4630 deletion completed in 6.41639803s

• [SLOW TEST:12.127 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:48:01.018: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:48:09.287: INFO: Waiting up to 5m0s for pod "client-envvars-380ba80e-ee94-4872-95aa-333ade283023" in namespace "pods-2727" to be "success or failure"
Oct 21 16:48:09.293: INFO: Pod "client-envvars-380ba80e-ee94-4872-95aa-333ade283023": Phase="Pending", Reason="", readiness=false. Elapsed: 5.971513ms
Oct 21 16:48:11.299: INFO: Pod "client-envvars-380ba80e-ee94-4872-95aa-333ade283023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012699083s
STEP: Saw pod success
Oct 21 16:48:11.299: INFO: Pod "client-envvars-380ba80e-ee94-4872-95aa-333ade283023" satisfied condition "success or failure"
Oct 21 16:48:11.305: INFO: Trying to get logs from node 10.195.18.154 pod client-envvars-380ba80e-ee94-4872-95aa-333ade283023 container env3cont: <nil>
STEP: delete the pod
Oct 21 16:48:11.337: INFO: Waiting for pod client-envvars-380ba80e-ee94-4872-95aa-333ade283023 to disappear
Oct 21 16:48:11.342: INFO: Pod client-envvars-380ba80e-ee94-4872-95aa-333ade283023 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:48:11.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2727" for this suite.
Oct 21 16:48:55.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:48:55.715: INFO: namespace pods-2727 deletion completed in 44.364642527s

• [SLOW TEST:54.697 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:48:55.715: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-2571
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2571 to expose endpoints map[]
Oct 21 16:48:55.953: INFO: successfully validated that service endpoint-test2 in namespace services-2571 exposes endpoints map[] (8.539015ms elapsed)
STEP: Creating pod pod1 in namespace services-2571
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2571 to expose endpoints map[pod1:[80]]
Oct 21 16:48:58.012: INFO: successfully validated that service endpoint-test2 in namespace services-2571 exposes endpoints map[pod1:[80]] (2.045718169s elapsed)
STEP: Creating pod pod2 in namespace services-2571
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2571 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 21 16:49:00.082: INFO: successfully validated that service endpoint-test2 in namespace services-2571 exposes endpoints map[pod1:[80] pod2:[80]] (2.060942819s elapsed)
STEP: Deleting pod pod1 in namespace services-2571
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2571 to expose endpoints map[pod2:[80]]
Oct 21 16:49:00.103: INFO: successfully validated that service endpoint-test2 in namespace services-2571 exposes endpoints map[pod2:[80]] (12.24974ms elapsed)
STEP: Deleting pod pod2 in namespace services-2571
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2571 to expose endpoints map[]
Oct 21 16:49:00.120: INFO: successfully validated that service endpoint-test2 in namespace services-2571 exposes endpoints map[] (7.71406ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:49:00.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2571" for this suite.
Oct 21 16:49:06.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:49:06.482: INFO: namespace services-2571 deletion completed in 6.301303518s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:10.768 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:49:06.483: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:49:06.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527" in namespace "projected-1399" to be "success or failure"
Oct 21 16:49:06.700: INFO: Pod "downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527": Phase="Pending", Reason="", readiness=false. Elapsed: 5.422127ms
Oct 21 16:49:08.707: INFO: Pod "downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012136794s
STEP: Saw pod success
Oct 21 16:49:08.707: INFO: Pod "downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527" satisfied condition "success or failure"
Oct 21 16:49:08.715: INFO: Trying to get logs from node 10.195.18.160 pod downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527 container client-container: <nil>
STEP: delete the pod
Oct 21 16:49:08.753: INFO: Waiting for pod downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527 to disappear
Oct 21 16:49:08.758: INFO: Pod downwardapi-volume-c9f5dc6f-65e0-4f9e-93f7-143882f30527 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:49:08.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1399" for this suite.
Oct 21 16:49:14.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:49:15.089: INFO: namespace projected-1399 deletion completed in 6.321646611s

• [SLOW TEST:8.607 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:49:15.090: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-18150025-5954-403a-8f2d-3befec2e4745
STEP: Creating a pod to test consume configMaps
Oct 21 16:49:15.305: INFO: Waiting up to 5m0s for pod "pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533" in namespace "configmap-2128" to be "success or failure"
Oct 21 16:49:15.313: INFO: Pod "pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533": Phase="Pending", Reason="", readiness=false. Elapsed: 7.091118ms
Oct 21 16:49:17.320: INFO: Pod "pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533": Phase="Running", Reason="", readiness=true. Elapsed: 2.014317112s
Oct 21 16:49:19.326: INFO: Pod "pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020680748s
STEP: Saw pod success
Oct 21 16:49:19.326: INFO: Pod "pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533" satisfied condition "success or failure"
Oct 21 16:49:19.332: INFO: Trying to get logs from node 10.195.18.159 pod pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:49:19.368: INFO: Waiting for pod pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533 to disappear
Oct 21 16:49:19.374: INFO: Pod pod-configmaps-f8361079-783b-4b92-b23d-75b56c05c533 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:49:19.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2128" for this suite.
Oct 21 16:49:25.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:49:25.735: INFO: namespace configmap-2128 deletion completed in 6.352161928s

• [SLOW TEST:10.646 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:49:25.736: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 16:49:25.961: INFO: Waiting up to 5m0s for pod "pod-e88e15c1-eaa0-4602-bd38-be1246a82129" in namespace "emptydir-774" to be "success or failure"
Oct 21 16:49:25.967: INFO: Pod "pod-e88e15c1-eaa0-4602-bd38-be1246a82129": Phase="Pending", Reason="", readiness=false. Elapsed: 5.592036ms
Oct 21 16:49:27.974: INFO: Pod "pod-e88e15c1-eaa0-4602-bd38-be1246a82129": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013070023s
STEP: Saw pod success
Oct 21 16:49:27.975: INFO: Pod "pod-e88e15c1-eaa0-4602-bd38-be1246a82129" satisfied condition "success or failure"
Oct 21 16:49:27.981: INFO: Trying to get logs from node 10.195.18.160 pod pod-e88e15c1-eaa0-4602-bd38-be1246a82129 container test-container: <nil>
STEP: delete the pod
Oct 21 16:49:28.013: INFO: Waiting for pod pod-e88e15c1-eaa0-4602-bd38-be1246a82129 to disappear
Oct 21 16:49:28.019: INFO: Pod pod-e88e15c1-eaa0-4602-bd38-be1246a82129 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:49:28.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-774" for this suite.
Oct 21 16:49:34.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:49:34.324: INFO: namespace emptydir-774 deletion completed in 6.296536413s

• [SLOW TEST:8.589 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:49:34.325: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:49:58.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3712" for this suite.
Oct 21 16:50:04.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:50:05.257: INFO: namespace container-runtime-3712 deletion completed in 6.322560223s

• [SLOW TEST:30.933 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:50:05.258: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3570
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3570/configmap-test-bcc961bd-e5e4-4664-bebd-8ca79bb696f2
STEP: Creating a pod to test consume configMaps
Oct 21 16:50:05.480: INFO: Waiting up to 5m0s for pod "pod-configmaps-40324625-652a-46c4-b424-c97923488967" in namespace "configmap-3570" to be "success or failure"
Oct 21 16:50:05.486: INFO: Pod "pod-configmaps-40324625-652a-46c4-b424-c97923488967": Phase="Pending", Reason="", readiness=false. Elapsed: 5.904796ms
Oct 21 16:50:07.493: INFO: Pod "pod-configmaps-40324625-652a-46c4-b424-c97923488967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013643304s
STEP: Saw pod success
Oct 21 16:50:07.493: INFO: Pod "pod-configmaps-40324625-652a-46c4-b424-c97923488967" satisfied condition "success or failure"
Oct 21 16:50:07.500: INFO: Trying to get logs from node 10.195.18.154 pod pod-configmaps-40324625-652a-46c4-b424-c97923488967 container env-test: <nil>
STEP: delete the pod
Oct 21 16:50:07.538: INFO: Waiting for pod pod-configmaps-40324625-652a-46c4-b424-c97923488967 to disappear
Oct 21 16:50:07.545: INFO: Pod pod-configmaps-40324625-652a-46c4-b424-c97923488967 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:50:07.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3570" for this suite.
Oct 21 16:50:13.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:50:13.881: INFO: namespace configmap-3570 deletion completed in 6.325785737s

• [SLOW TEST:8.623 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:50:13.882: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:50:14.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5247'
Oct 21 16:50:14.214: INFO: stderr: ""
Oct 21 16:50:14.215: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Oct 21 16:50:14.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete pods e2e-test-nginx-pod --namespace=kubectl-5247'
Oct 21 16:50:24.888: INFO: stderr: ""
Oct 21 16:50:24.888: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:50:24.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5247" for this suite.
Oct 21 16:50:30.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:50:31.216: INFO: namespace kubectl-5247 deletion completed in 6.317233294s

• [SLOW TEST:17.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:50:31.216: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 21 16:50:33.464: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:50:33.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7663" for this suite.
Oct 21 16:50:39.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:50:39.834: INFO: namespace container-runtime-7663 deletion completed in 6.338536202s

• [SLOW TEST:8.618 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:50:39.835: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7632
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7babc657-50f1-48b5-86df-8cd40b003110
STEP: Creating a pod to test consume secrets
Oct 21 16:50:40.063: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897" in namespace "projected-7632" to be "success or failure"
Oct 21 16:50:40.074: INFO: Pod "pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897": Phase="Pending", Reason="", readiness=false. Elapsed: 11.715285ms
Oct 21 16:50:42.082: INFO: Pod "pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019097974s
Oct 21 16:50:44.088: INFO: Pod "pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025629924s
STEP: Saw pod success
Oct 21 16:50:44.088: INFO: Pod "pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897" satisfied condition "success or failure"
Oct 21 16:50:44.094: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:50:44.124: INFO: Waiting for pod pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897 to disappear
Oct 21 16:50:44.129: INFO: Pod pod-projected-secrets-08b1eb67-df07-4ccf-97ef-52ebff0cb897 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:50:44.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7632" for this suite.
Oct 21 16:50:50.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:50:50.471: INFO: namespace projected-7632 deletion completed in 6.332291579s

• [SLOW TEST:10.636 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:50:50.474: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2129
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Oct 21 16:50:50.711: INFO: Found 0 stateful pods, waiting for 3
Oct 21 16:51:00.720: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:00.720: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:00.720: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 16:51:00.775: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 21 16:51:10.857: INFO: Updating stateful set ss2
Oct 21 16:51:10.873: INFO: Waiting for Pod statefulset-2129/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:51:20.893: INFO: Waiting for Pod statefulset-2129/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Oct 21 16:51:30.951: INFO: Found 2 stateful pods, waiting for 3
Oct 21 16:51:40.960: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:40.960: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 16:51:40.960: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 21 16:51:41.014: INFO: Updating stateful set ss2
Oct 21 16:51:41.032: INFO: Waiting for Pod statefulset-2129/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Oct 21 16:51:51.084: INFO: Updating stateful set ss2
Oct 21 16:51:51.099: INFO: Waiting for StatefulSet statefulset-2129/ss2 to complete update
Oct 21 16:51:51.099: INFO: Waiting for Pod statefulset-2129/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 16:52:01.120: INFO: Deleting all statefulset in ns statefulset-2129
Oct 21 16:52:01.130: INFO: Scaling statefulset ss2 to 0
Oct 21 16:52:31.165: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 16:52:31.175: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:52:31.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2129" for this suite.
Oct 21 16:52:39.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:52:39.539: INFO: namespace statefulset-2129 deletion completed in 8.314476596s

• [SLOW TEST:109.066 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:52:39.541: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6683
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-52071c14-a38e-48d3-a7ce-63fda7a99d21
STEP: Creating a pod to test consume secrets
Oct 21 16:52:39.772: INFO: Waiting up to 5m0s for pod "pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96" in namespace "secrets-6683" to be "success or failure"
Oct 21 16:52:39.778: INFO: Pod "pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96": Phase="Pending", Reason="", readiness=false. Elapsed: 5.958844ms
Oct 21 16:52:41.788: INFO: Pod "pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015806674s
STEP: Saw pod success
Oct 21 16:52:41.788: INFO: Pod "pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96" satisfied condition "success or failure"
Oct 21 16:52:41.806: INFO: Trying to get logs from node 10.195.18.154 pod pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:52:41.846: INFO: Waiting for pod pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96 to disappear
Oct 21 16:52:41.851: INFO: Pod pod-secrets-51fc8cb8-0b1a-402a-bda4-bb37ee88fb96 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:52:41.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6683" for this suite.
Oct 21 16:52:47.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:52:48.194: INFO: namespace secrets-6683 deletion completed in 6.33376142s

• [SLOW TEST:8.653 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:52:48.195: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:52:50.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4674" for this suite.
Oct 21 16:53:38.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:53:38.739: INFO: namespace kubelet-test-4674 deletion completed in 48.290502206s

• [SLOW TEST:50.544 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:53:38.739: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 21 16:53:40.048: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1021 16:53:40.048119      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:53:40.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4003" for this suite.
Oct 21 16:53:46.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:53:46.346: INFO: namespace gc-4003 deletion completed in 6.292073351s

• [SLOW TEST:7.607 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:53:46.347: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-bd4e8a11-7b3b-4feb-b1ee-659d01941878
STEP: Creating a pod to test consume secrets
Oct 21 16:53:46.569: INFO: Waiting up to 5m0s for pod "pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331" in namespace "secrets-6372" to be "success or failure"
Oct 21 16:53:46.577: INFO: Pod "pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331": Phase="Pending", Reason="", readiness=false. Elapsed: 8.236416ms
Oct 21 16:53:48.585: INFO: Pod "pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016154382s
STEP: Saw pod success
Oct 21 16:53:48.585: INFO: Pod "pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331" satisfied condition "success or failure"
Oct 21 16:53:48.595: INFO: Trying to get logs from node 10.195.18.159 pod pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 16:53:48.627: INFO: Waiting for pod pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331 to disappear
Oct 21 16:53:48.635: INFO: Pod pod-secrets-7aee5a70-df3b-4bd0-8a6a-b2e6b1416331 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:53:48.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6372" for this suite.
Oct 21 16:53:54.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:53:54.985: INFO: namespace secrets-6372 deletion completed in 6.342035105s

• [SLOW TEST:8.638 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:53:54.988: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:53:55.206: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b" in namespace "downward-api-3591" to be "success or failure"
Oct 21 16:53:55.212: INFO: Pod "downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.512582ms
Oct 21 16:53:57.219: INFO: Pod "downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012256907s
STEP: Saw pod success
Oct 21 16:53:57.219: INFO: Pod "downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b" satisfied condition "success or failure"
Oct 21 16:53:57.224: INFO: Trying to get logs from node 10.195.18.154 pod downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b container client-container: <nil>
STEP: delete the pod
Oct 21 16:53:57.254: INFO: Waiting for pod downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b to disappear
Oct 21 16:53:57.259: INFO: Pod downwardapi-volume-11c84925-9041-4846-af9a-9ae24a57143b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:53:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3591" for this suite.
Oct 21 16:54:03.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:03.563: INFO: namespace downward-api-3591 deletion completed in 6.29475719s

• [SLOW TEST:8.576 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:54:03.564: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8218
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-3a92e623-a74f-4433-98a8-51ca5be43e90
STEP: Creating a pod to test consume configMaps
Oct 21 16:54:03.780: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa" in namespace "configmap-8218" to be "success or failure"
Oct 21 16:54:03.785: INFO: Pod "pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa": Phase="Pending", Reason="", readiness=false. Elapsed: 5.214767ms
Oct 21 16:54:05.792: INFO: Pod "pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011656615s
STEP: Saw pod success
Oct 21 16:54:05.792: INFO: Pod "pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa" satisfied condition "success or failure"
Oct 21 16:54:05.798: INFO: Trying to get logs from node 10.195.18.154 pod pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 16:54:05.830: INFO: Waiting for pod pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa to disappear
Oct 21 16:54:05.836: INFO: Pod pod-configmaps-3e52fae5-2c50-408d-86e8-07cadf1a35fa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:54:05.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8218" for this suite.
Oct 21 16:54:11.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:12.181: INFO: namespace configmap-8218 deletion completed in 6.336259633s

• [SLOW TEST:8.617 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:54:12.182: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:54:12.383: INFO: Creating deployment "nginx-deployment"
Oct 21 16:54:12.392: INFO: Waiting for observed generation 1
Oct 21 16:54:14.409: INFO: Waiting for all required pods to come up
Oct 21 16:54:14.418: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 21 16:54:16.435: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 21 16:54:16.451: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 21 16:54:16.469: INFO: Updating deployment nginx-deployment
Oct 21 16:54:16.469: INFO: Waiting for observed generation 2
Oct 21 16:54:18.486: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 21 16:54:18.494: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 21 16:54:18.501: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:54:18.530: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 21 16:54:18.530: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 21 16:54:18.538: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:54:18.553: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 21 16:54:18.553: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 21 16:54:18.569: INFO: Updating deployment nginx-deployment
Oct 21 16:54:18.569: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 21 16:54:18.584: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 21 16:54:20.602: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 21 16:54:20.617: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2351,SelfLink:/apis/apps/v1/namespaces/deployment-2351/deployments/nginx-deployment,UID:9cee19c7-25c3-45f4-938b-ce0cf3399466,ResourceVersion:35219,Generation:3,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-10-21 16:54:18 +0000 UTC 2019-10-21 16:54:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-21 16:54:20 +0000 UTC 2019-10-21 16:54:12 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Oct 21 16:54:20.627: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-2351,SelfLink:/apis/apps/v1/namespaces/deployment-2351/replicasets/nginx-deployment-55fb7cb77f,UID:82e132be-b294-4e41-b372-2c565adad116,ResourceVersion:35092,Generation:3,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9cee19c7-25c3-45f4-938b-ce0cf3399466 0xc000dd79a7 0xc000dd79a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 16:54:20.627: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 21 16:54:20.628: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-2351,SelfLink:/apis/apps/v1/namespaces/deployment-2351/replicasets/nginx-deployment-7b8c6f4498,UID:ccf4ba1e-da22-4607-a32c-30058f07c230,ResourceVersion:35218,Generation:3,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 9cee19c7-25c3-45f4-938b-ce0cf3399466 0xc000dd7b17 0xc000dd7b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Oct 21 16:54:20.643: INFO: Pod "nginx-deployment-55fb7cb77f-226kk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-226kk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-226kk,UID:a469455f-59d2-4767-bff0-7e38c609c2cd,ResourceVersion:34999,Generation:0,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d6c67 0xc0017d6c68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d6ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d6d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.644: INFO: Pod "nginx-deployment-55fb7cb77f-4wxm2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4wxm2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-4wxm2,UID:aecf263e-7713-49e8-b718-4e5dddbdbba9,ResourceVersion:35126,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d6dd0 0xc0017d6dd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d6e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d6e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.644: INFO: Pod "nginx-deployment-55fb7cb77f-4zxx2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4zxx2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-4zxx2,UID:8bed5bd3-a38a-47fc-9085-349b953a4ffc,ResourceVersion:35096,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d6f40 0xc0017d6f41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d6fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d6fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.644: INFO: Pod "nginx-deployment-55fb7cb77f-8cslj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8cslj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-8cslj,UID:0bd297c7-beb9-456b-a327-0d3ec2b76f42,ResourceVersion:35110,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d70b0 0xc0017d70b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.644: INFO: Pod "nginx-deployment-55fb7cb77f-9sjgb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9sjgb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-9sjgb,UID:6b21aa59-e848-4a62-9c21-b481ae53a559,ResourceVersion:35220,Generation:0,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7220 0xc0017d7221}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d72a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d72c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.251,StartTime:2019-10-21 16:54:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.645: INFO: Pod "nginx-deployment-55fb7cb77f-bgv42" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bgv42,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-bgv42,UID:18429899-01ce-4b15-b646-24487eff98e9,ResourceVersion:35213,Generation:0,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d73b0 0xc0017d73b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:172.30.177.240,StartTime:2019-10-21 16:54:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.645: INFO: Pod "nginx-deployment-55fb7cb77f-fgtzb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fgtzb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-fgtzb,UID:0417e543-886a-4a42-a6ba-4d1300a75641,ResourceVersion:35140,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7550 0xc0017d7551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d75d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.645: INFO: Pod "nginx-deployment-55fb7cb77f-hqxmd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hqxmd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-hqxmd,UID:a684ff66-f8d1-48ac-be74-7f3367d0ba34,ResourceVersion:35121,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d76e0 0xc0017d76e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.645: INFO: Pod "nginx-deployment-55fb7cb77f-jzqrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jzqrr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-jzqrr,UID:78dc1eba-34d9-45e0-b7ae-08ae9fefc8fa,ResourceVersion:35102,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7850 0xc0017d7851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d78d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d78f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.646: INFO: Pod "nginx-deployment-55fb7cb77f-kt9p2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-kt9p2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-kt9p2,UID:1867eb2c-6f9a-438c-b185-7729419a5e83,ResourceVersion:35141,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d79c0 0xc0017d79c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.646: INFO: Pod "nginx-deployment-55fb7cb77f-ms47t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ms47t,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-ms47t,UID:92125424-8ef1-46cf-bbe2-9a279f7507a8,ResourceVersion:35123,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7b30 0xc0017d7b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.646: INFO: Pod "nginx-deployment-55fb7cb77f-nzqf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nzqf9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-nzqf9,UID:908c7dbb-d75d-4208-b9f7-442c8bd1dcbe,ResourceVersion:34973,Generation:0,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7ca0 0xc0017d7ca1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.646: INFO: Pod "nginx-deployment-55fb7cb77f-vxvjz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vxvjz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-55fb7cb77f-vxvjz,UID:8d730912-9692-4741-bbfd-03e1c9964c71,ResourceVersion:35001,Generation:0,CreationTimestamp:2019-10-21 16:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 82e132be-b294-4e41-b372-2c565adad116 0xc0017d7e10 0xc0017d7e11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d7eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:16 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.647: INFO: Pod "nginx-deployment-7b8c6f4498-4d65x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4d65x,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-4d65x,UID:e881d009-c077-4a34-88b5-dfa0f07b8318,ResourceVersion:34941,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc0017d7f80 0xc0017d7f81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d7ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a5c0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.250,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c948e080c6d88660259ca6221961232bdb9b722c0ec3b9204cfd70e71beba7d0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.647: INFO: Pod "nginx-deployment-7b8c6f4498-59zp2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-59zp2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-59zp2,UID:5c24811b-979d-4b0b-83fa-c56c7a2c10c3,ResourceVersion:35082,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc003a5c3c7 0xc003a5c3c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a5c520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a5c540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.647: INFO: Pod "nginx-deployment-7b8c6f4498-87g7h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-87g7h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-87g7h,UID:9673ca19-5b34-4e85-98ab-e6c5efa10543,ResourceVersion:35118,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc003a5c7b7 0xc003a5c7b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a5c950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a5ca10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.647: INFO: Pod "nginx-deployment-7b8c6f4498-8nqmv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8nqmv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-8nqmv,UID:e498cef5-5ca7-4c5e-9bcc-98160d8f5063,ResourceVersion:34916,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc003a5d417 0xc003a5d418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a5d740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a5d760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.250,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://badc153a06b9606a34eb3c6fbb34f103db0b2a3a2bab30a2688065a5291b306e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.648: INFO: Pod "nginx-deployment-7b8c6f4498-9pblh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9pblh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-9pblh,UID:b923a08a-a516-4a6b-ae75-7e8e040e1fe6,ResourceVersion:35216,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc003a5d9a7 0xc003a5d9a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a5dbc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a5dcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.255,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:19 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://223f6106728b650cf6b48b916c670cb6e07756ca17afca31d83a6ebc3a04a68f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.648: INFO: Pod "nginx-deployment-7b8c6f4498-bbfz2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bbfz2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-bbfz2,UID:095bc008-055e-43a9-9baa-c854df763a21,ResourceVersion:34935,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc0026040a7 0xc0026040a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026044e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002604610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.252,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://1c5bc5da512dc89fbb058a39ec72b3fba954c3797a37310db4385c9e545051e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.648: INFO: Pod "nginx-deployment-7b8c6f4498-btqwx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-btqwx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-btqwx,UID:1abcff03-ca5b-4bc3-82ad-6a50ba279a54,ResourceVersion:34921,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002604807 0xc002604808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002604980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002604a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.247,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://00f61333ee089ee66e83c9c4cf045739fb0154c0c923310ade68572ba4b4074c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.648: INFO: Pod "nginx-deployment-7b8c6f4498-fhsx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fhsx9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-fhsx9,UID:2137c621-08c8-4c50-9407-e182fe0c95c5,ResourceVersion:35129,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002604cc7 0xc002604cc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002604e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002604e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.649: INFO: Pod "nginx-deployment-7b8c6f4498-frgbp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-frgbp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-frgbp,UID:0df5c694-c7e2-4101-8ca6-e75d2f0a4964,ResourceVersion:35104,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002605157 0xc002605158}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002605310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002605330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.649: INFO: Pod "nginx-deployment-7b8c6f4498-gr68v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gr68v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-gr68v,UID:30106cc1-bb3d-4921-8e12-8a42d50648f0,ResourceVersion:35114,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002605567 0xc002605568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026057c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002605830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.649: INFO: Pod "nginx-deployment-7b8c6f4498-hm4zl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hm4zl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-hm4zl,UID:9554a2c4-ee2a-45d5-8faf-1f70bcbbd126,ResourceVersion:35135,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc0026059b7 0xc0026059b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002605a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002605a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.649: INFO: Pod "nginx-deployment-7b8c6f4498-k6wpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k6wpn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-k6wpn,UID:5c182a63-2be1-40d7-bf90-4a5a1869a054,ResourceVersion:35144,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002605c97 0xc002605c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002605e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002605e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.650: INFO: Pod "nginx-deployment-7b8c6f4498-k9xgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k9xgk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-k9xgk,UID:010d17b3-8ba7-4844-8553-d291089e7e7d,ResourceVersion:35131,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269c097 0xc00269c098}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269c1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269c260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.650: INFO: Pod "nginx-deployment-7b8c6f4498-kh455" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kh455,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-kh455,UID:e9f40557-db4f-4cca-b09d-3b6eac18b8cb,ResourceVersion:34938,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269c417 0xc00269c418}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269c5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269c5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.247,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b67a9b06fcc615c0bbf0fd5d0bff1a5cefc17fdf395a2e44f1aa99bf6bcf03f8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.650: INFO: Pod "nginx-deployment-7b8c6f4498-m56ql" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m56ql,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-m56ql,UID:e23bd2e7-20ca-4c98-ae93-8943d6911a41,ResourceVersion:34931,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269c797 0xc00269c798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269c950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269c970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.248,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://8419056b09098fa082bab46cd4849b06b03061a4d94a8941072a83dff7a72895}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.650: INFO: Pod "nginx-deployment-7b8c6f4498-n4b5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n4b5s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-n4b5s,UID:4800a47a-5bc7-4181-9213-cdfaaec6cf1d,ResourceVersion:35105,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269cb27 0xc00269cb28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269ce80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269cff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.650: INFO: Pod "nginx-deployment-7b8c6f4498-nb6fc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nb6fc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-nb6fc,UID:3a9b777c-a29a-4cc7-a946-2c87817d63f2,ResourceVersion:34914,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269d857 0xc00269d858}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269d8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269d8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:172.30.177.241,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7e1bec46d4e82bf19e226b8a64b2431a773a2c2dbbeabca75d4f4bf6f1093d08}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.651: INFO: Pod "nginx-deployment-7b8c6f4498-p9s8j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p9s8j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-p9s8j,UID:d9bafc96-7d71-4052-8dd3-87c94424d2f2,ResourceVersion:34911,Generation:0,CreationTimestamp:2019-10-21 16:54:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269d9c7 0xc00269d9c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269daa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00269db20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:12 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:172.30.177.239,StartTime:2019-10-21 16:54:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c4b7ffd060df1ef866507b5aa89e7d562247eb47e0ec8988e6fa83b4022693da}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.651: INFO: Pod "nginx-deployment-7b8c6f4498-pbhrb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pbhrb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-pbhrb,UID:27fc5081-e93a-4441-b43f-3be1012ae105,ResourceVersion:35133,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc00269de97 0xc00269de98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00269df60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bfa020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 16:54:20.651: INFO: Pod "nginx-deployment-7b8c6f4498-sqj4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sqj4t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2351,SelfLink:/api/v1/namespaces/deployment-2351/pods/nginx-deployment-7b8c6f4498-sqj4t,UID:036bf301-e978-4536-8145-073092c9d1dc,ResourceVersion:35111,Generation:0,CreationTimestamp:2019-10-21 16:54:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ccf4ba1e-da22-4607-a32c-30058f07c230 0xc002bfa327 0xc002bfa328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phlmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phlmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-phlmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.160,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bfa3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bfa3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:18 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.160,PodIP:,StartTime:2019-10-21 16:54:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:54:20.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2351" for this suite.
Oct 21 16:54:28.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:29.082: INFO: namespace deployment-2351 deletion completed in 8.420151466s

• [SLOW TEST:16.901 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:54:29.083: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2078
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 21 16:54:29.296: INFO: Waiting up to 5m0s for pod "downward-api-2837e903-3880-4104-bc1b-99514afc292f" in namespace "downward-api-2078" to be "success or failure"
Oct 21 16:54:29.303: INFO: Pod "downward-api-2837e903-3880-4104-bc1b-99514afc292f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.732953ms
Oct 21 16:54:31.313: INFO: Pod "downward-api-2837e903-3880-4104-bc1b-99514afc292f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016488688s
STEP: Saw pod success
Oct 21 16:54:31.313: INFO: Pod "downward-api-2837e903-3880-4104-bc1b-99514afc292f" satisfied condition "success or failure"
Oct 21 16:54:31.319: INFO: Trying to get logs from node 10.195.18.160 pod downward-api-2837e903-3880-4104-bc1b-99514afc292f container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:54:31.364: INFO: Waiting for pod downward-api-2837e903-3880-4104-bc1b-99514afc292f to disappear
Oct 21 16:54:31.369: INFO: Pod downward-api-2837e903-3880-4104-bc1b-99514afc292f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:54:31.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2078" for this suite.
Oct 21 16:54:37.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:37.681: INFO: namespace downward-api-2078 deletion completed in 6.300362654s

• [SLOW TEST:8.598 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:54:37.681: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 16:54:37.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-2839'
Oct 21 16:54:38.031: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 16:54:38.031: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Oct 21 16:54:40.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2839'
Oct 21 16:54:40.176: INFO: stderr: ""
Oct 21 16:54:40.176: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:54:40.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2839" for this suite.
Oct 21 16:54:46.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:54:46.619: INFO: namespace kubectl-2839 deletion completed in 6.433666601s

• [SLOW TEST:8.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:54:46.619: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 21 16:54:52.866: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-14470fd1-bae0-4ea7-94ec-2bc349db74fd,GenerateName:,Namespace:events-6666,SelfLink:/api/v1/namespaces/events-6666/pods/send-events-14470fd1-bae0-4ea7-94ec-2bc349db74fd,UID:2453ceb4-65f1-4869-bd9a-2e1283720c34,ResourceVersion:35838,Generation:0,CreationTimestamp:2019-10-21 16:54:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 824116434,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4kxsd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4kxsd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4kxsd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003fc55a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003fc55c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 16:54:46 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.199,StartTime:2019-10-21 16:54:46 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-21 16:54:52 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://77a58cbdb95180ae2f915e8d5fcbb7ec5896a08805601d2f373426addf39ad9b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 21 16:54:54.877: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 21 16:54:56.888: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:54:56.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6666" for this suite.
Oct 21 16:55:36.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:55:37.219: INFO: namespace events-6666 deletion completed in 40.31035135s

• [SLOW TEST:50.600 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:55:37.219: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:55:39.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1098" for this suite.
Oct 21 16:55:45.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:55:45.864: INFO: namespace emptydir-wrapper-1098 deletion completed in 6.317554524s

• [SLOW TEST:8.645 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:55:45.864: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 16:55:46.069: INFO: Creating ReplicaSet my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f
Oct 21 16:55:46.085: INFO: Pod name my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f: Found 0 pods out of 1
Oct 21 16:55:51.094: INFO: Pod name my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f: Found 1 pods out of 1
Oct 21 16:55:51.094: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f" is running
Oct 21 16:55:53.106: INFO: Pod "my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f-4xph4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:55:46 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:55:46 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:55:46 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 16:55:46 +0000 UTC Reason: Message:}])
Oct 21 16:55:53.106: INFO: Trying to dial the pod
Oct 21 16:55:58.133: INFO: Controller my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f: Got expected result from replica 1 [my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f-4xph4]: "my-hostname-basic-901d2c84-0919-41ff-a046-19d24947d17f-4xph4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:55:58.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5337" for this suite.
Oct 21 16:56:04.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:04.528: INFO: namespace replicaset-5337 deletion completed in 6.385164918s

• [SLOW TEST:18.663 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:56:04.528: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Oct 21 16:56:04.742: INFO: Waiting up to 5m0s for pod "var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af" in namespace "var-expansion-5652" to be "success or failure"
Oct 21 16:56:04.748: INFO: Pod "var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071944ms
Oct 21 16:56:06.755: INFO: Pod "var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012838201s
Oct 21 16:56:08.762: INFO: Pod "var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019900662s
STEP: Saw pod success
Oct 21 16:56:08.762: INFO: Pod "var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af" satisfied condition "success or failure"
Oct 21 16:56:08.768: INFO: Trying to get logs from node 10.195.18.154 pod var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af container dapi-container: <nil>
STEP: delete the pod
Oct 21 16:56:08.802: INFO: Waiting for pod var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af to disappear
Oct 21 16:56:08.807: INFO: Pod var-expansion-d0256797-e4a5-4814-b0ad-fe93b9e527af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:56:08.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5652" for this suite.
Oct 21 16:56:14.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:15.195: INFO: namespace var-expansion-5652 deletion completed in 6.378847642s

• [SLOW TEST:10.667 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:56:15.195: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 21 16:56:17.949: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3100 pod-service-account-3c044f4b-0f9c-4d28-92c4-8cb7020c8a66 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 21 16:56:18.339: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3100 pod-service-account-3c044f4b-0f9c-4d28-92c4-8cb7020c8a66 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 21 16:56:18.665: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3100 pod-service-account-3c044f4b-0f9c-4d28-92c4-8cb7020c8a66 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:56:18.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3100" for this suite.
Oct 21 16:56:25.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:25.337: INFO: namespace svcaccounts-3100 deletion completed in 6.335329436s

• [SLOW TEST:10.142 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:56:25.339: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Oct 21 16:56:25.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-6689'
Oct 21 16:56:25.732: INFO: stderr: ""
Oct 21 16:56:25.733: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 16:56:26.742: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:56:26.742: INFO: Found 0 / 1
Oct 21 16:56:27.740: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:56:27.740: INFO: Found 1 / 1
Oct 21 16:56:27.740: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 21 16:56:27.750: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:56:27.750: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 16:56:27.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 patch pod redis-master-psltg --namespace=kubectl-6689 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 21 16:56:27.870: INFO: stderr: ""
Oct 21 16:56:27.870: INFO: stdout: "pod/redis-master-psltg patched\n"
STEP: checking annotations
Oct 21 16:56:27.876: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 16:56:27.876: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:56:27.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6689" for this suite.
Oct 21 16:56:41.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:42.189: INFO: namespace kubectl-6689 deletion completed in 14.303649279s

• [SLOW TEST:16.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:56:42.190: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 21 16:56:42.486: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 21 16:56:49.559: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:56:49.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9319" for this suite.
Oct 21 16:56:55.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:56:55.892: INFO: namespace pods-9319 deletion completed in 6.311124588s

• [SLOW TEST:13.703 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:56:55.894: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9482/configmap-test-f33ab35c-abc8-4c9d-bc56-ee695e741273
STEP: Creating a pod to test consume configMaps
Oct 21 16:56:56.118: INFO: Waiting up to 5m0s for pod "pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531" in namespace "configmap-9482" to be "success or failure"
Oct 21 16:56:56.124: INFO: Pod "pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039526ms
Oct 21 16:56:58.131: INFO: Pod "pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013104648s
STEP: Saw pod success
Oct 21 16:56:58.131: INFO: Pod "pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531" satisfied condition "success or failure"
Oct 21 16:56:58.137: INFO: Trying to get logs from node 10.195.18.160 pod pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531 container env-test: <nil>
STEP: delete the pod
Oct 21 16:56:58.170: INFO: Waiting for pod pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531 to disappear
Oct 21 16:56:58.176: INFO: Pod pod-configmaps-07107e6e-395f-4585-825a-26c9b877e531 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:56:58.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9482" for this suite.
Oct 21 16:57:04.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:57:04.484: INFO: namespace configmap-9482 deletion completed in 6.299126818s

• [SLOW TEST:8.590 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:57:04.484: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Oct 21 16:57:04.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-1700'
Oct 21 16:57:04.902: INFO: stderr: ""
Oct 21 16:57:04.902: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:57:04.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1700'
Oct 21 16:57:05.025: INFO: stderr: ""
Oct 21 16:57:05.025: INFO: stdout: "update-demo-nautilus-5t7z5 update-demo-nautilus-khh7f "
Oct 21 16:57:05.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-5t7z5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:05.123: INFO: stderr: ""
Oct 21 16:57:05.123: INFO: stdout: ""
Oct 21 16:57:05.123: INFO: update-demo-nautilus-5t7z5 is created but not running
Oct 21 16:57:10.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1700'
Oct 21 16:57:10.244: INFO: stderr: ""
Oct 21 16:57:10.244: INFO: stdout: "update-demo-nautilus-5t7z5 update-demo-nautilus-khh7f "
Oct 21 16:57:10.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-5t7z5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:10.356: INFO: stderr: ""
Oct 21 16:57:10.356: INFO: stdout: "true"
Oct 21 16:57:10.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-5t7z5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:10.463: INFO: stderr: ""
Oct 21 16:57:10.463: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:57:10.463: INFO: validating pod update-demo-nautilus-5t7z5
Oct 21 16:57:10.478: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:57:10.478: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:57:10.478: INFO: update-demo-nautilus-5t7z5 is verified up and running
Oct 21 16:57:10.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-khh7f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:10.582: INFO: stderr: ""
Oct 21 16:57:10.582: INFO: stdout: "true"
Oct 21 16:57:10.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-nautilus-khh7f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:10.685: INFO: stderr: ""
Oct 21 16:57:10.685: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 16:57:10.685: INFO: validating pod update-demo-nautilus-khh7f
Oct 21 16:57:10.703: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 16:57:10.703: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 16:57:10.703: INFO: update-demo-nautilus-khh7f is verified up and running
STEP: rolling-update to new replication controller
Oct 21 16:57:10.705: INFO: scanned /root for discovery docs: <nil>
Oct 21 16:57:10.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1700'
Oct 21 16:57:38.616: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 16:57:38.616: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 16:57:38.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1700'
Oct 21 16:57:38.722: INFO: stderr: ""
Oct 21 16:57:38.722: INFO: stdout: "update-demo-kitten-9tbzn update-demo-kitten-tslg2 "
Oct 21 16:57:38.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-kitten-9tbzn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:38.824: INFO: stderr: ""
Oct 21 16:57:38.825: INFO: stdout: "true"
Oct 21 16:57:38.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-kitten-9tbzn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:38.929: INFO: stderr: ""
Oct 21 16:57:38.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 16:57:38.929: INFO: validating pod update-demo-kitten-9tbzn
Oct 21 16:57:38.944: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 16:57:38.944: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 16:57:38.944: INFO: update-demo-kitten-9tbzn is verified up and running
Oct 21 16:57:38.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-kitten-tslg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:39.061: INFO: stderr: ""
Oct 21 16:57:39.061: INFO: stdout: "true"
Oct 21 16:57:39.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods update-demo-kitten-tslg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1700'
Oct 21 16:57:39.162: INFO: stderr: ""
Oct 21 16:57:39.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 16:57:39.162: INFO: validating pod update-demo-kitten-tslg2
Oct 21 16:57:39.176: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 16:57:39.176: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 16:57:39.176: INFO: update-demo-kitten-tslg2 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:57:39.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1700" for this suite.
Oct 21 16:58:03.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:58:03.512: INFO: namespace kubectl-1700 deletion completed in 24.326342797s

• [SLOW TEST:59.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:58:03.513: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1021 16:58:09.814041      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 16:58:09.814: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:58:09.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-154" for this suite.
Oct 21 16:58:17.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:58:18.148: INFO: namespace gc-154 deletion completed in 8.3269939s

• [SLOW TEST:14.636 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:58:18.150: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-45de59f1-82b0-4c5b-8289-c6811e034e7c
STEP: Creating a pod to test consume secrets
Oct 21 16:58:18.396: INFO: Waiting up to 5m0s for pod "pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c" in namespace "secrets-2545" to be "success or failure"
Oct 21 16:58:18.403: INFO: Pod "pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.275299ms
Oct 21 16:58:20.415: INFO: Pod "pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018892446s
STEP: Saw pod success
Oct 21 16:58:20.416: INFO: Pod "pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c" satisfied condition "success or failure"
Oct 21 16:58:20.422: INFO: Trying to get logs from node 10.195.18.154 pod pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c container secret-env-test: <nil>
STEP: delete the pod
Oct 21 16:58:20.461: INFO: Waiting for pod pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c to disappear
Oct 21 16:58:20.468: INFO: Pod pod-secrets-d492e77c-54c4-4687-93c3-009219193a8c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:58:20.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2545" for this suite.
Oct 21 16:58:26.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:58:26.815: INFO: namespace secrets-2545 deletion completed in 6.337664065s

• [SLOW TEST:8.665 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:58:26.816: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-3524
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3524 to expose endpoints map[]
Oct 21 16:58:27.048: INFO: successfully validated that service multi-endpoint-test in namespace services-3524 exposes endpoints map[] (9.551499ms elapsed)
STEP: Creating pod pod1 in namespace services-3524
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3524 to expose endpoints map[pod1:[100]]
Oct 21 16:58:29.126: INFO: successfully validated that service multi-endpoint-test in namespace services-3524 exposes endpoints map[pod1:[100]] (2.050523988s elapsed)
STEP: Creating pod pod2 in namespace services-3524
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3524 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 21 16:58:31.197: INFO: successfully validated that service multi-endpoint-test in namespace services-3524 exposes endpoints map[pod1:[100] pod2:[101]] (2.062848301s elapsed)
STEP: Deleting pod pod1 in namespace services-3524
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3524 to expose endpoints map[pod2:[101]]
Oct 21 16:58:32.236: INFO: successfully validated that service multi-endpoint-test in namespace services-3524 exposes endpoints map[pod2:[101]] (1.02933968s elapsed)
STEP: Deleting pod pod2 in namespace services-3524
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3524 to expose endpoints map[]
Oct 21 16:58:33.267: INFO: successfully validated that service multi-endpoint-test in namespace services-3524 exposes endpoints map[] (1.020349463s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:58:33.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3524" for this suite.
Oct 21 16:58:57.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:58:57.647: INFO: namespace services-3524 deletion completed in 24.319292538s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:30.832 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:58:57.649: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 16:58:57.864: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2" in namespace "downward-api-425" to be "success or failure"
Oct 21 16:58:57.870: INFO: Pod "downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.222671ms
Oct 21 16:58:59.877: INFO: Pod "downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013344703s
STEP: Saw pod success
Oct 21 16:58:59.877: INFO: Pod "downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2" satisfied condition "success or failure"
Oct 21 16:58:59.883: INFO: Trying to get logs from node 10.195.18.154 pod downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2 container client-container: <nil>
STEP: delete the pod
Oct 21 16:58:59.913: INFO: Waiting for pod downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2 to disappear
Oct 21 16:58:59.919: INFO: Pod downwardapi-volume-e1db8868-05fb-4a9c-9c08-c3419f474cb2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:58:59.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-425" for this suite.
Oct 21 16:59:05.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:59:06.235: INFO: namespace downward-api-425 deletion completed in 6.306513407s

• [SLOW TEST:8.586 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:59:06.235: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 16:59:06.467: INFO: Waiting up to 5m0s for pod "pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14" in namespace "emptydir-5030" to be "success or failure"
Oct 21 16:59:06.472: INFO: Pod "pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14": Phase="Pending", Reason="", readiness=false. Elapsed: 5.633198ms
Oct 21 16:59:08.479: INFO: Pod "pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012441447s
Oct 21 16:59:10.486: INFO: Pod "pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019154314s
STEP: Saw pod success
Oct 21 16:59:10.486: INFO: Pod "pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14" satisfied condition "success or failure"
Oct 21 16:59:10.492: INFO: Trying to get logs from node 10.195.18.159 pod pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14 container test-container: <nil>
STEP: delete the pod
Oct 21 16:59:10.524: INFO: Waiting for pod pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14 to disappear
Oct 21 16:59:10.530: INFO: Pod pod-5576ad31-5bcf-4ba0-bd82-3f799e579c14 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:59:10.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5030" for this suite.
Oct 21 16:59:16.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 16:59:16.928: INFO: namespace emptydir-5030 deletion completed in 6.390292803s

• [SLOW TEST:10.694 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 16:59:16.932: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3308
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 16:59:17.140: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 16:59:39.277: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.201:8080/dial?request=hostName&protocol=http&host=172.30.106.209&port=8080&tries=1'] Namespace:pod-network-test-3308 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:59:39.277: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:59:39.474: INFO: Waiting for endpoints: map[]
Oct 21 16:59:39.480: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.201:8080/dial?request=hostName&protocol=http&host=172.30.177.200&port=8080&tries=1'] Namespace:pod-network-test-3308 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:59:39.480: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:59:39.696: INFO: Waiting for endpoints: map[]
Oct 21 16:59:39.703: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.201:8080/dial?request=hostName&protocol=http&host=172.30.78.215&port=8080&tries=1'] Namespace:pod-network-test-3308 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 16:59:39.703: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 16:59:39.923: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 16:59:39.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3308" for this suite.
Oct 21 17:00:03.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:00:04.286: INFO: namespace pod-network-test-3308 deletion completed in 24.353324314s

• [SLOW TEST:47.355 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:00:04.287: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 17:00:04.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3381'
Oct 21 17:00:04.596: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 17:00:04.596: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 21 17:00:04.609: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct 21 17:00:04.612: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 21 17:00:04.619: INFO: scanned /root for discovery docs: <nil>
Oct 21 17:00:04.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3381'
Oct 21 17:00:20.539: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 17:00:20.539: INFO: stdout: "Created e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d\nScaling up e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 21 17:00:20.540: INFO: stdout: "Created e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d\nScaling up e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 21 17:00:20.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-3381'
Oct 21 17:00:20.643: INFO: stderr: ""
Oct 21 17:00:20.643: INFO: stdout: "e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d-xtnmj "
Oct 21 17:00:20.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d-xtnmj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3381'
Oct 21 17:00:20.762: INFO: stderr: ""
Oct 21 17:00:20.762: INFO: stdout: "true"
Oct 21 17:00:20.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d-xtnmj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3381'
Oct 21 17:00:20.866: INFO: stderr: ""
Oct 21 17:00:20.866: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 21 17:00:20.866: INFO: e2e-test-nginx-rc-086a741b41402693c722a0e53a1efc8d-xtnmj is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Oct 21 17:00:20.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete rc e2e-test-nginx-rc --namespace=kubectl-3381'
Oct 21 17:00:20.986: INFO: stderr: ""
Oct 21 17:00:20.986: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:00:20.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3381" for this suite.
Oct 21 17:00:27.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:00:27.327: INFO: namespace kubectl-3381 deletion completed in 6.331074166s

• [SLOW TEST:23.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:00:27.328: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5963
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:00:27.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de" in namespace "downward-api-5963" to be "success or failure"
Oct 21 17:00:27.551: INFO: Pod "downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788257ms
Oct 21 17:00:29.560: INFO: Pod "downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014643366s
STEP: Saw pod success
Oct 21 17:00:29.560: INFO: Pod "downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de" satisfied condition "success or failure"
Oct 21 17:00:29.566: INFO: Trying to get logs from node 10.195.18.160 pod downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de container client-container: <nil>
STEP: delete the pod
Oct 21 17:00:29.607: INFO: Waiting for pod downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de to disappear
Oct 21 17:00:29.615: INFO: Pod downwardapi-volume-bb65fec5-7f32-413d-a65e-c110e27336de no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:00:29.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5963" for this suite.
Oct 21 17:00:35.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:00:35.919: INFO: namespace downward-api-5963 deletion completed in 6.294777848s

• [SLOW TEST:8.591 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:00:35.919: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:00:36.475: INFO: Pod name wrapped-volume-race-5612dffd-9521-46b4-9482-d5f7fb97b1cd: Found 0 pods out of 5
Oct 21 17:00:41.488: INFO: Pod name wrapped-volume-race-5612dffd-9521-46b4-9482-d5f7fb97b1cd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5612dffd-9521-46b4-9482-d5f7fb97b1cd in namespace emptydir-wrapper-1442, will wait for the garbage collector to delete the pods
Oct 21 17:00:41.607: INFO: Deleting ReplicationController wrapped-volume-race-5612dffd-9521-46b4-9482-d5f7fb97b1cd took: 26.126336ms
Oct 21 17:00:41.707: INFO: Terminating ReplicationController wrapped-volume-race-5612dffd-9521-46b4-9482-d5f7fb97b1cd pods took: 100.25469ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:01:23.739: INFO: Pod name wrapped-volume-race-b3e7ecb5-55a2-4db7-9873-4b96bd667516: Found 0 pods out of 5
Oct 21 17:01:28.751: INFO: Pod name wrapped-volume-race-b3e7ecb5-55a2-4db7-9873-4b96bd667516: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b3e7ecb5-55a2-4db7-9873-4b96bd667516 in namespace emptydir-wrapper-1442, will wait for the garbage collector to delete the pods
Oct 21 17:01:28.866: INFO: Deleting ReplicationController wrapped-volume-race-b3e7ecb5-55a2-4db7-9873-4b96bd667516 took: 25.361233ms
Oct 21 17:01:28.967: INFO: Terminating ReplicationController wrapped-volume-race-b3e7ecb5-55a2-4db7-9873-4b96bd667516 pods took: 100.35063ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 17:02:13.600: INFO: Pod name wrapped-volume-race-d076ba5c-e92e-4911-bd9b-bd6e246fd0a1: Found 0 pods out of 5
Oct 21 17:02:18.620: INFO: Pod name wrapped-volume-race-d076ba5c-e92e-4911-bd9b-bd6e246fd0a1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d076ba5c-e92e-4911-bd9b-bd6e246fd0a1 in namespace emptydir-wrapper-1442, will wait for the garbage collector to delete the pods
Oct 21 17:02:18.737: INFO: Deleting ReplicationController wrapped-volume-race-d076ba5c-e92e-4911-bd9b-bd6e246fd0a1 took: 24.347267ms
Oct 21 17:02:18.837: INFO: Terminating ReplicationController wrapped-volume-race-d076ba5c-e92e-4911-bd9b-bd6e246fd0a1 pods took: 100.243464ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:03:04.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1442" for this suite.
Oct 21 17:03:12.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:03:12.435: INFO: namespace emptydir-wrapper-1442 deletion completed in 8.324770123s

• [SLOW TEST:156.516 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:03:12.438: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 in namespace container-probe-5786
Oct 21 17:03:20.665: INFO: Started pod liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 in namespace container-probe-5786
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 17:03:20.672: INFO: Initial restart count of pod liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is 0
Oct 21 17:03:30.712: INFO: Restart count of pod container-probe-5786/liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is now 1 (10.040252903s elapsed)
Oct 21 17:03:50.791: INFO: Restart count of pod container-probe-5786/liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is now 2 (30.11899292s elapsed)
Oct 21 17:04:10.886: INFO: Restart count of pod container-probe-5786/liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is now 3 (50.214127485s elapsed)
Oct 21 17:04:30.960: INFO: Restart count of pod container-probe-5786/liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is now 4 (1m10.288772633s elapsed)
Oct 21 17:05:41.220: INFO: Restart count of pod container-probe-5786/liveness-85b2e9df-4dcd-4464-9ee6-bb4b1d2a3734 is now 5 (2m20.548138156s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:05:41.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5786" for this suite.
Oct 21 17:05:47.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:05:47.559: INFO: namespace container-probe-5786 deletion completed in 6.31205631s

• [SLOW TEST:155.121 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:05:47.559: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8765
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-c980da62-0588-4e4a-b6b2-df735f36538f
STEP: Creating a pod to test consume secrets
Oct 21 17:05:47.783: INFO: Waiting up to 5m0s for pod "pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870" in namespace "secrets-8765" to be "success or failure"
Oct 21 17:05:47.790: INFO: Pod "pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413656ms
Oct 21 17:05:49.797: INFO: Pod "pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013794189s
STEP: Saw pod success
Oct 21 17:05:49.797: INFO: Pod "pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870" satisfied condition "success or failure"
Oct 21 17:05:49.803: INFO: Trying to get logs from node 10.195.18.160 pod pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:05:49.840: INFO: Waiting for pod pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870 to disappear
Oct 21 17:05:49.845: INFO: Pod pod-secrets-e57eb77a-a2f1-45bb-9573-938c5ff0f870 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:05:49.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8765" for this suite.
Oct 21 17:05:55.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:05:56.163: INFO: namespace secrets-8765 deletion completed in 6.308231647s

• [SLOW TEST:8.604 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:05:56.163: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9079
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9079
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9079
Oct 21 17:05:56.390: INFO: Found 0 stateful pods, waiting for 1
Oct 21 17:06:06.398: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 21 17:06:06.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 17:06:06.735: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 17:06:06.735: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 17:06:06.735: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 17:06:06.742: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 17:06:16.751: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 17:06:16.751: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 17:06:16.789: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:16.789: INFO: ss-0  10.195.18.160  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  }]
Oct 21 17:06:16.789: INFO: 
Oct 21 17:06:16.789: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 21 17:06:17.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991510868s
Oct 21 17:06:18.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984254862s
Oct 21 17:06:19.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966857482s
Oct 21 17:06:20.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95886065s
Oct 21 17:06:21.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.951259594s
Oct 21 17:06:22.845: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943903174s
Oct 21 17:06:23.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.936292283s
Oct 21 17:06:24.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.928919289s
Oct 21 17:06:25.867: INFO: Verifying statefulset ss doesn't scale past 3 for another 920.861653ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9079
Oct 21 17:06:26.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:06:27.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Oct 21 17:06:27.274: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 17:06:27.274: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 17:06:27.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:06:27.619: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 21 17:06:27.619: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 17:06:27.619: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 17:06:27.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 17:06:27.964: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 21 17:06:27.964: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 17:06:27.964: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 17:06:27.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 17:06:27.970: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 17:06:27.970: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 21 17:06:27.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 17:06:28.318: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 17:06:28.318: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 17:06:28.318: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 17:06:28.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 17:06:28.648: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 17:06:28.648: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 17:06:28.648: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 17:06:28.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 exec --namespace=statefulset-9079 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 17:06:28.940: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Oct 21 17:06:28.940: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 17:06:28.940: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 17:06:28.940: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 17:06:28.965: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 21 17:06:38.985: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 17:06:38.985: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 17:06:38.985: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 17:06:39.014: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:39.014: INFO: ss-0  10.195.18.160  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  }]
Oct 21 17:06:39.014: INFO: ss-1  10.195.18.159  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:39.014: INFO: ss-2  10.195.18.154  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:39.014: INFO: 
Oct 21 17:06:39.014: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 17:06:40.021: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:40.021: INFO: ss-0  10.195.18.160  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  }]
Oct 21 17:06:40.021: INFO: ss-1  10.195.18.159  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:40.021: INFO: ss-2  10.195.18.154  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:40.021: INFO: 
Oct 21 17:06:40.021: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 17:06:41.029: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:41.029: INFO: ss-0  10.195.18.160  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:05:56 +0000 UTC  }]
Oct 21 17:06:41.029: INFO: ss-1  10.195.18.159  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:41.029: INFO: ss-2  10.195.18.154  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:41.029: INFO: 
Oct 21 17:06:41.029: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 17:06:42.036: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:42.036: INFO: ss-2  10.195.18.154  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:42.036: INFO: 
Oct 21 17:06:42.036: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 17:06:43.043: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Oct 21 17:06:43.043: INFO: ss-2  10.195.18.154  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:06:16 +0000 UTC  }]
Oct 21 17:06:43.043: INFO: 
Oct 21 17:06:43.043: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 17:06:44.050: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.96345231s
Oct 21 17:06:45.057: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.956453765s
Oct 21 17:06:46.065: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.949406391s
Oct 21 17:06:47.072: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.941936399s
Oct 21 17:06:48.079: INFO: Verifying statefulset ss doesn't scale past 0 for another 934.474836ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9079
Oct 21 17:06:49.087: INFO: Scaling statefulset ss to 0
Oct 21 17:06:49.113: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Oct 21 17:06:49.123: INFO: Deleting all statefulset in ns statefulset-9079
Oct 21 17:06:49.133: INFO: Scaling statefulset ss to 0
Oct 21 17:06:49.159: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 17:06:49.168: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:06:49.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9079" for this suite.
Oct 21 17:06:55.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:06:55.543: INFO: namespace statefulset-9079 deletion completed in 6.323492528s

• [SLOW TEST:59.379 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:06:55.543: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:06:55.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e" in namespace "downward-api-927" to be "success or failure"
Oct 21 17:06:55.780: INFO: Pod "downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.132215ms
Oct 21 17:06:57.787: INFO: Pod "downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013261129s
STEP: Saw pod success
Oct 21 17:06:57.787: INFO: Pod "downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e" satisfied condition "success or failure"
Oct 21 17:06:57.796: INFO: Trying to get logs from node 10.195.18.154 pod downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e container client-container: <nil>
STEP: delete the pod
Oct 21 17:06:57.830: INFO: Waiting for pod downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e to disappear
Oct 21 17:06:57.835: INFO: Pod downwardapi-volume-3022061a-4856-4352-b9dd-36f8c8a0123e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:06:57.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-927" for this suite.
Oct 21 17:07:03.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:07:04.181: INFO: namespace downward-api-927 deletion completed in 6.337806215s

• [SLOW TEST:8.638 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:07:04.186: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:07:08.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-842" for this suite.
Oct 21 17:07:48.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:07:48.754: INFO: namespace kubelet-test-842 deletion completed in 40.306144464s

• [SLOW TEST:44.569 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:07:48.755: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3378
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-58696146-c281-4b40-a06c-09119cba79d5
STEP: Creating configMap with name cm-test-opt-upd-484247c8-16ea-4f73-aa1e-ae8724b7e0c3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-58696146-c281-4b40-a06c-09119cba79d5
STEP: Updating configmap cm-test-opt-upd-484247c8-16ea-4f73-aa1e-ae8724b7e0c3
STEP: Creating configMap with name cm-test-opt-create-41b69366-e9f4-468e-83b5-9809604845b0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:07:53.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3378" for this suite.
Oct 21 17:08:17.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:17.459: INFO: namespace projected-3378 deletion completed in 24.313225616s

• [SLOW TEST:28.704 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:08:17.459: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0
Oct 21 17:08:17.681: INFO: Pod name my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0: Found 0 pods out of 1
Oct 21 17:08:22.690: INFO: Pod name my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0: Found 1 pods out of 1
Oct 21 17:08:22.690: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0" are running
Oct 21 17:08:22.696: INFO: Pod "my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0-gjfwp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 17:08:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 17:08:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 17:08:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 17:08:17 +0000 UTC Reason: Message:}])
Oct 21 17:08:22.696: INFO: Trying to dial the pod
Oct 21 17:08:27.724: INFO: Controller my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0: Got expected result from replica 1 [my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0-gjfwp]: "my-hostname-basic-1ca319ef-1bef-49e7-afcf-736479cab9e0-gjfwp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:08:27.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1119" for this suite.
Oct 21 17:08:33.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:34.053: INFO: namespace replication-controller-1119 deletion completed in 6.319377259s

• [SLOW TEST:16.593 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:08:34.053: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Oct 21 17:08:34.264: INFO: Waiting up to 5m0s for pod "var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503" in namespace "var-expansion-8917" to be "success or failure"
Oct 21 17:08:34.270: INFO: Pod "var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503": Phase="Pending", Reason="", readiness=false. Elapsed: 6.161413ms
Oct 21 17:08:36.277: INFO: Pod "var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012843938s
STEP: Saw pod success
Oct 21 17:08:36.277: INFO: Pod "var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503" satisfied condition "success or failure"
Oct 21 17:08:36.283: INFO: Trying to get logs from node 10.195.18.159 pod var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503 container dapi-container: <nil>
STEP: delete the pod
Oct 21 17:08:36.314: INFO: Waiting for pod var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503 to disappear
Oct 21 17:08:36.320: INFO: Pod var-expansion-6bf1a05d-de5e-4c9b-9de0-70e5a0e77503 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:08:36.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8917" for this suite.
Oct 21 17:08:42.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:08:42.627: INFO: namespace var-expansion-8917 deletion completed in 6.298350379s

• [SLOW TEST:8.574 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:08:42.628: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:08:42.861: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:08:44.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9804" for this suite.
Oct 21 17:09:39.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:09:39.341: INFO: namespace pods-9804 deletion completed in 54.350676395s

• [SLOW TEST:56.714 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:09:39.342: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 21 17:09:42.108: INFO: Successfully updated pod "labelsupdatea683c5de-fc8f-4f37-b78d-cc5cfa391116"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:09:46.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3108" for this suite.
Oct 21 17:10:08.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:08.531: INFO: namespace projected-3108 deletion completed in 22.349494802s

• [SLOW TEST:29.190 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:10:08.531: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 21 17:10:08.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2044,SelfLink:/api/v1/namespaces/watch-2044/configmaps/e2e-watch-test-resource-version,UID:ecce4baa-0282-4527-8d15-d95509f50d6e,ResourceVersion:39684,Generation:0,CreationTimestamp:2019-10-21 17:10:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 17:10:08.782: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2044,SelfLink:/api/v1/namespaces/watch-2044/configmaps/e2e-watch-test-resource-version,UID:ecce4baa-0282-4527-8d15-d95509f50d6e,ResourceVersion:39685,Generation:0,CreationTimestamp:2019-10-21 17:10:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:10:08.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2044" for this suite.
Oct 21 17:10:14.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:15.103: INFO: namespace watch-2044 deletion completed in 6.311788926s

• [SLOW TEST:6.572 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:10:15.106: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1380
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:10:15.328: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 21 17:10:20.336: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 17:10:20.336: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 21 17:10:22.344: INFO: Creating deployment "test-rollover-deployment"
Oct 21 17:10:22.365: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 21 17:10:24.384: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 21 17:10:24.403: INFO: Ensure that both replica sets have 1 created replica
Oct 21 17:10:24.418: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 21 17:10:24.434: INFO: Updating deployment test-rollover-deployment
Oct 21 17:10:24.434: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 21 17:10:26.452: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 21 17:10:26.469: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 21 17:10:26.485: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:26.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274624, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:28.502: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:28.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274624, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:30.503: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:30.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274624, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:32.502: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:32.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274630, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:34.503: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:34.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274630, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:36.505: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:36.505: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274630, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:38.503: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:38.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274630, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:40.504: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 17:10:40.504: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274630, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707274622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:10:42.504: INFO: 
Oct 21 17:10:42.504: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 21 17:10:42.531: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-1380,SelfLink:/apis/apps/v1/namespaces/deployment-1380/deployments/test-rollover-deployment,UID:da32abf2-a00f-465f-89c5-c7d92409903b,ResourceVersion:39836,Generation:2,CreationTimestamp:2019-10-21 17:10:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 17:10:22 +0000 UTC 2019-10-21 17:10:22 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 17:10:40 +0000 UTC 2019-10-21 17:10:22 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 17:10:42.540: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-1380,SelfLink:/apis/apps/v1/namespaces/deployment-1380/replicasets/test-rollover-deployment-854595fc44,UID:f50ef95c-f4b5-41cb-b4ed-c207f6ed4925,ResourceVersion:39825,Generation:2,CreationTimestamp:2019-10-21 17:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment da32abf2-a00f-465f-89c5-c7d92409903b 0xc0027a7617 0xc0027a7618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 17:10:42.540: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 21 17:10:42.540: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-1380,SelfLink:/apis/apps/v1/namespaces/deployment-1380/replicasets/test-rollover-controller,UID:4370cc95-b8d0-494b-9c2d-2fe809c98a8b,ResourceVersion:39834,Generation:2,CreationTimestamp:2019-10-21 17:10:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment da32abf2-a00f-465f-89c5-c7d92409903b 0xc0027a7547 0xc0027a7548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 17:10:42.541: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-1380,SelfLink:/apis/apps/v1/namespaces/deployment-1380/replicasets/test-rollover-deployment-9b8b997cf,UID:96b0e021-a006-4d6c-bd10-a7005bd5fe79,ResourceVersion:39779,Generation:2,CreationTimestamp:2019-10-21 17:10:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment da32abf2-a00f-465f-89c5-c7d92409903b 0xc0027a76e0 0xc0027a76e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 17:10:42.547: INFO: Pod "test-rollover-deployment-854595fc44-gwdb7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-gwdb7,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-1380,SelfLink:/api/v1/namespaces/deployment-1380/pods/test-rollover-deployment-854595fc44-gwdb7,UID:bbac8438-b833-4db9-86fd-cfbbecde7aad,ResourceVersion:39806,Generation:0,CreationTimestamp:2019-10-21 17:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 f50ef95c-f4b5-41cb-b4ed-c207f6ed4925 0xc002f8d4d7 0xc002f8d4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-m26jf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m26jf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-m26jf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.154,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f8d550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f8d570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:10:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:10:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:10:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:10:24 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.154,PodIP:172.30.78.233,StartTime:2019-10-21 17:10:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 17:10:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://9c1d3f61b9929b1828aeb7d67a37e9e876c815a67bb934e16a519a0922addcec}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:10:42.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1380" for this suite.
Oct 21 17:10:48.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:48.886: INFO: namespace deployment-1380 deletion completed in 6.325471111s

• [SLOW TEST:33.780 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:10:48.887: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 17:10:49.101: INFO: Waiting up to 5m0s for pod "pod-a6204e71-9db9-409a-a669-8d1c2d68c85d" in namespace "emptydir-4117" to be "success or failure"
Oct 21 17:10:49.107: INFO: Pod "pod-a6204e71-9db9-409a-a669-8d1c2d68c85d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.760289ms
Oct 21 17:10:51.122: INFO: Pod "pod-a6204e71-9db9-409a-a669-8d1c2d68c85d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020957926s
STEP: Saw pod success
Oct 21 17:10:51.122: INFO: Pod "pod-a6204e71-9db9-409a-a669-8d1c2d68c85d" satisfied condition "success or failure"
Oct 21 17:10:51.128: INFO: Trying to get logs from node 10.195.18.159 pod pod-a6204e71-9db9-409a-a669-8d1c2d68c85d container test-container: <nil>
STEP: delete the pod
Oct 21 17:10:51.165: INFO: Waiting for pod pod-a6204e71-9db9-409a-a669-8d1c2d68c85d to disappear
Oct 21 17:10:51.171: INFO: Pod pod-a6204e71-9db9-409a-a669-8d1c2d68c85d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:10:51.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4117" for this suite.
Oct 21 17:10:57.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:10:57.504: INFO: namespace emptydir-4117 deletion completed in 6.322006045s

• [SLOW TEST:8.617 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:10:57.505: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Oct 21 17:10:57.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 api-versions'
Oct 21 17:10:57.832: INFO: stderr: ""
Oct 21 17:10:57.832: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:10:57.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4322" for this suite.
Oct 21 17:11:03.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:04.208: INFO: namespace kubectl-4322 deletion completed in 6.368333543s

• [SLOW TEST:6.703 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:04.209: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 17:11:04.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6697'
Oct 21 17:11:04.550: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 17:11:04.550: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 21 17:11:04.567: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-s9h5w]
Oct 21 17:11:04.567: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-s9h5w" in namespace "kubectl-6697" to be "running and ready"
Oct 21 17:11:04.572: INFO: Pod "e2e-test-nginx-rc-s9h5w": Phase="Pending", Reason="", readiness=false. Elapsed: 5.773955ms
Oct 21 17:11:06.580: INFO: Pod "e2e-test-nginx-rc-s9h5w": Phase="Running", Reason="", readiness=true. Elapsed: 2.01345592s
Oct 21 17:11:06.580: INFO: Pod "e2e-test-nginx-rc-s9h5w" satisfied condition "running and ready"
Oct 21 17:11:06.580: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-s9h5w]
Oct 21 17:11:06.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs rc/e2e-test-nginx-rc --namespace=kubectl-6697'
Oct 21 17:11:06.717: INFO: stderr: ""
Oct 21 17:11:06.717: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Oct 21 17:11:06.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete rc e2e-test-nginx-rc --namespace=kubectl-6697'
Oct 21 17:11:06.842: INFO: stderr: ""
Oct 21 17:11:06.842: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:11:06.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6697" for this suite.
Oct 21 17:11:12.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:13.176: INFO: namespace kubectl-6697 deletion completed in 6.324094597s

• [SLOW TEST:8.966 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:13.177: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2180
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 21 17:11:13.511: INFO: Waiting up to 5m0s for pod "pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d" in namespace "emptydir-2180" to be "success or failure"
Oct 21 17:11:13.518: INFO: Pod "pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.976254ms
Oct 21 17:11:15.525: INFO: Pod "pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014203572s
STEP: Saw pod success
Oct 21 17:11:15.525: INFO: Pod "pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d" satisfied condition "success or failure"
Oct 21 17:11:15.531: INFO: Trying to get logs from node 10.195.18.160 pod pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d container test-container: <nil>
STEP: delete the pod
Oct 21 17:11:15.569: INFO: Waiting for pod pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d to disappear
Oct 21 17:11:15.575: INFO: Pod pod-a16d0bb6-752b-4cf1-b393-44565ada9d8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:11:15.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2180" for this suite.
Oct 21 17:11:21.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:21.905: INFO: namespace emptydir-2180 deletion completed in 6.320618569s

• [SLOW TEST:8.728 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:21.905: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8993
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:11:22.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d" in namespace "projected-8993" to be "success or failure"
Oct 21 17:11:22.142: INFO: Pod "downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412576ms
Oct 21 17:11:24.149: INFO: Pod "downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012417414s
STEP: Saw pod success
Oct 21 17:11:24.149: INFO: Pod "downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d" satisfied condition "success or failure"
Oct 21 17:11:24.155: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d container client-container: <nil>
STEP: delete the pod
Oct 21 17:11:24.184: INFO: Waiting for pod downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d to disappear
Oct 21 17:11:24.189: INFO: Pod downwardapi-volume-920b871d-19a4-4a56-b7ec-56ba20e2be0d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:11:24.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8993" for this suite.
Oct 21 17:11:30.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:30.556: INFO: namespace projected-8993 deletion completed in 6.357771842s

• [SLOW TEST:8.651 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:30.556: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Oct 21 17:11:30.778: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:11:34.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5346" for this suite.
Oct 21 17:11:40.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:41.193: INFO: namespace init-container-5346 deletion completed in 6.326366051s

• [SLOW TEST:10.637 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:41.194: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1086
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 21 17:11:51.466: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1021 17:11:51.466123      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:11:51.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1086" for this suite.
Oct 21 17:11:57.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:11:57.800: INFO: namespace gc-1086 deletion completed in 6.327531726s

• [SLOW TEST:16.606 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:11:57.801: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-9f31a42f-7775-4323-8781-fdeb4f4cc4b5
STEP: Creating a pod to test consume configMaps
Oct 21 17:11:58.021: INFO: Waiting up to 5m0s for pod "pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557" in namespace "configmap-8981" to be "success or failure"
Oct 21 17:11:58.027: INFO: Pod "pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557": Phase="Pending", Reason="", readiness=false. Elapsed: 5.552866ms
Oct 21 17:12:00.034: INFO: Pod "pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012442039s
STEP: Saw pod success
Oct 21 17:12:00.034: INFO: Pod "pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557" satisfied condition "success or failure"
Oct 21 17:12:00.040: INFO: Trying to get logs from node 10.195.18.154 pod pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:12:00.074: INFO: Waiting for pod pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557 to disappear
Oct 21 17:12:00.081: INFO: Pod pod-configmaps-33ae42ec-2fbb-49ab-96f6-f759c07b3557 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:12:00.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8981" for this suite.
Oct 21 17:12:06.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:06.429: INFO: namespace configmap-8981 deletion completed in 6.338218488s

• [SLOW TEST:8.628 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:12:06.431: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Oct 21 17:12:09.192: INFO: Successfully updated pod "labelsupdateea1c7244-8562-4847-b338-30e461da7767"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:12:13.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8004" for this suite.
Oct 21 17:12:35.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:35.600: INFO: namespace downward-api-8004 deletion completed in 22.336736991s

• [SLOW TEST:29.170 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:12:35.602: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:12:35.844: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"92c31dc3-d686-48de-a2e8-c2c828a7e19d", Controller:(*bool)(0xc0039a2ec6), BlockOwnerDeletion:(*bool)(0xc0039a2ec7)}}
Oct 21 17:12:35.851: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"596b1ea0-4c9b-4f02-9c85-75511da56c6d", Controller:(*bool)(0xc002c054d6), BlockOwnerDeletion:(*bool)(0xc002c054d7)}}
Oct 21 17:12:35.859: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0c4b085d-5eac-481e-9dd0-110032ba5ccb", Controller:(*bool)(0xc001b6e2f6), BlockOwnerDeletion:(*bool)(0xc001b6e2f7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:12:40.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4516" for this suite.
Oct 21 17:12:46.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:47.208: INFO: namespace gc-4516 deletion completed in 6.320694955s

• [SLOW TEST:11.606 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:12:47.208: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 21 17:12:47.414: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 17:12:47.430: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 17:12:47.439: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.154 before test
Oct 21 17:12:47.469: INFO: ibm-kube-fluentd-dqtjd from kube-system started at 2019-10-21 14:15:28 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:12:47.470: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:55:03 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 17:12:47.470: INFO: kubernetes-dashboard-596f947ff4-r2hbp from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 17:12:47.470: INFO: coredns-autoscaler-74cb66766b-whr2s from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 17:12:47.470: INFO: coredns-64f45bf67-lxgz9 from kube-system started at 2019-10-21 14:40:34 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:12:47.470: INFO: calico-node-sxqjc from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:12:47.470: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-h72dv from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:12:47.470: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:12:47.470: INFO: vpn-75d8697c68-rldfs from kube-system started at 2019-10-21 14:40:12 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container vpn ready: true, restart count 0
Oct 21 17:12:47.470: INFO: metrics-server-76c7b9bb54-xvv8g from kube-system started at 2019-10-21 14:15:49 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 17:12:47.470: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 17:12:47.470: INFO: ibm-storage-watcher-786667d59-lmgwt from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 17:12:47.470: INFO: ibm-file-plugin-5f9d7d6c49-8g6s6 from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 17:12:47.470: INFO: calico-kube-controllers-9d8994658-lxjks from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 17:12:47.470: INFO: ibm-master-proxy-static-10.195.18.154 from kube-system started at 2019-10-21 14:14:53 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:12:47.470: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:12:47.470: INFO: ibm-keepalived-watcher-6lnrw from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.470: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:12:47.470: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.159 before test
Oct 21 17:12:47.511: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-f8jd9 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:12:47.511: INFO: sonobuoy-e2e-job-65107fb0e85542d6 from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container e2e ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 17:12:47.511: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-xsfvb from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 17:12:47.511: INFO: ibm-keepalived-watcher-97gq4 from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:12:47.511: INFO: calico-node-7l5tz from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:12:47.511: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-4mbpj from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:12:47.511: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:12:47.511: INFO: ibm-master-proxy-static-10.195.18.159 from kube-system started at 2019-10-21 14:15:24 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:12:47.511: INFO: ibm-kube-fluentd-j2hrm from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.511: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:12:47.511: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.160 before test
Oct 21 17:12:47.540: INFO: ibm-master-proxy-static-10.195.18.160 from kube-system started at 2019-10-21 14:15:42 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.540: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:12:47.540: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:12:47.541: INFO: ibm-kube-fluentd-g6rld from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:12:47.541: INFO: calico-node-n8566 from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:12:47.541: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-xfzc5 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:12:47.541: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:12:47.541: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:12:47.541: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:12:47.541: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-bp6nm from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:12:47.541: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:12:47.541: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-2c6zf from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 17:12:47.541: INFO: coredns-64f45bf67-cv68m from kube-system started at 2019-10-21 14:40:33 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:12:47.541: INFO: ibm-keepalived-watcher-xnjtx from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:12:47.541: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:17:37 +0000 UTC (1 container statuses recorded)
Oct 21 17:12:47.541: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cfb8c8ce396e99], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:12:48.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6108" for this suite.
Oct 21 17:12:54.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:12:54.899: INFO: namespace sched-pred-6108 deletion completed in 6.303824916s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.691 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:12:54.901: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-95
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-rhfd
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 17:12:55.134: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rhfd" in namespace "subpath-95" to be "success or failure"
Oct 21 17:12:55.140: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758471ms
Oct 21 17:12:57.148: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013771471s
Oct 21 17:12:59.155: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 4.020896395s
Oct 21 17:13:01.162: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 6.02725315s
Oct 21 17:13:03.168: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 8.033868184s
Oct 21 17:13:05.175: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 10.040749883s
Oct 21 17:13:07.183: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 12.048426557s
Oct 21 17:13:09.190: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 14.05594782s
Oct 21 17:13:11.198: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 16.063386021s
Oct 21 17:13:13.205: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 18.071039688s
Oct 21 17:13:15.212: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Running", Reason="", readiness=true. Elapsed: 20.078108004s
Oct 21 17:13:17.221: INFO: Pod "pod-subpath-test-projected-rhfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.086155939s
STEP: Saw pod success
Oct 21 17:13:17.221: INFO: Pod "pod-subpath-test-projected-rhfd" satisfied condition "success or failure"
Oct 21 17:13:17.227: INFO: Trying to get logs from node 10.195.18.159 pod pod-subpath-test-projected-rhfd container test-container-subpath-projected-rhfd: <nil>
STEP: delete the pod
Oct 21 17:13:17.256: INFO: Waiting for pod pod-subpath-test-projected-rhfd to disappear
Oct 21 17:13:17.263: INFO: Pod pod-subpath-test-projected-rhfd no longer exists
STEP: Deleting pod pod-subpath-test-projected-rhfd
Oct 21 17:13:17.263: INFO: Deleting pod "pod-subpath-test-projected-rhfd" in namespace "subpath-95"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:13:17.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-95" for this suite.
Oct 21 17:13:23.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:13:23.713: INFO: namespace subpath-95 deletion completed in 6.436632155s

• [SLOW TEST:28.813 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:13:23.716: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9175
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 17:13:26.468: INFO: Successfully updated pod "pod-update-6177d194-bdd4-48b8-8525-88cf053d6b60"
STEP: verifying the updated pod is in kubernetes
Oct 21 17:13:26.479: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:13:26.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9175" for this suite.
Oct 21 17:13:48.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:13:48.829: INFO: namespace pods-9175 deletion completed in 22.340904791s

• [SLOW TEST:25.113 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:13:48.830: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6803
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Oct 21 17:13:49.042: INFO: Waiting up to 5m0s for pod "client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e" in namespace "containers-6803" to be "success or failure"
Oct 21 17:13:49.048: INFO: Pod "client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.329332ms
Oct 21 17:13:51.056: INFO: Pod "client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013102524s
STEP: Saw pod success
Oct 21 17:13:51.056: INFO: Pod "client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e" satisfied condition "success or failure"
Oct 21 17:13:51.062: INFO: Trying to get logs from node 10.195.18.160 pod client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e container test-container: <nil>
STEP: delete the pod
Oct 21 17:13:51.093: INFO: Waiting for pod client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e to disappear
Oct 21 17:13:51.098: INFO: Pod client-containers-03d4dbc2-0989-40d8-b4a5-0a09b1eefa6e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:13:51.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6803" for this suite.
Oct 21 17:13:57.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:13:57.404: INFO: namespace containers-6803 deletion completed in 6.29658555s

• [SLOW TEST:8.575 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:13:57.404: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6011
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6011.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6011.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6011.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6011.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 92.74.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.74.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.74.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.74.92_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6011.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6011.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6011.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6011.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6011.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6011.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 92.74.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.74.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.74.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.74.92_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:14:01.697: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.730: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.740: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.749: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.813: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.833: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.842: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.852: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:01.913: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:06.923: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:06.933: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:06.943: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:06.952: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:07.018: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:07.027: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:07.036: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:07.049: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:07.103: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:11.924: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:11.933: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:11.942: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:11.951: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:12.014: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:12.024: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:12.033: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:12.042: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:12.093: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:16.927: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:16.937: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:16.947: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:16.957: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:17.022: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:17.032: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:17.041: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:17.063: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:17.122: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:21.924: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:21.934: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:21.944: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:21.958: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:22.025: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:22.038: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:22.047: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:22.057: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:22.114: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:26.943: INFO: Unable to read wheezy_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:26.953: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:26.965: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:26.975: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:27.049: INFO: Unable to read jessie_udp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:27.058: INFO: Unable to read jessie_tcp@dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:27.067: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:27.076: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local from pod dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed: the server could not find the requested resource (get pods dns-test-499792d7-e869-4b90-b175-a4e430bc10ed)
Oct 21 17:14:27.128: INFO: Lookups using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed failed for: [wheezy_udp@dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@dns-test-service.dns-6011.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_udp@dns-test-service.dns-6011.svc.cluster.local jessie_tcp@dns-test-service.dns-6011.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6011.svc.cluster.local]

Oct 21 17:14:32.113: INFO: DNS probes using dns-6011/dns-test-499792d7-e869-4b90-b175-a4e430bc10ed succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:14:32.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6011" for this suite.
Oct 21 17:14:38.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:14:38.559: INFO: namespace dns-6011 deletion completed in 6.321312935s

• [SLOW TEST:41.154 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:14:38.559: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3398
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:14:38.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3398" for this suite.
Oct 21 17:15:00.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:15:01.155: INFO: namespace pods-3398 deletion completed in 22.362205431s

• [SLOW TEST:22.597 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:15:01.157: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-48e146a9-136a-4c38-8009-a48a7138fb2a in namespace container-probe-694
Oct 21 17:15:07.396: INFO: Started pod liveness-48e146a9-136a-4c38-8009-a48a7138fb2a in namespace container-probe-694
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 17:15:07.402: INFO: Initial restart count of pod liveness-48e146a9-136a-4c38-8009-a48a7138fb2a is 0
Oct 21 17:15:25.474: INFO: Restart count of pod container-probe-694/liveness-48e146a9-136a-4c38-8009-a48a7138fb2a is now 1 (18.071411803s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:15:25.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-694" for this suite.
Oct 21 17:15:31.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:15:31.826: INFO: namespace container-probe-694 deletion completed in 6.324548076s

• [SLOW TEST:30.669 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:15:31.827: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-6bs6
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 17:15:32.066: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6bs6" in namespace "subpath-7772" to be "success or failure"
Oct 21 17:15:32.072: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.724549ms
Oct 21 17:15:34.079: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 2.01267269s
Oct 21 17:15:36.087: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 4.02036975s
Oct 21 17:15:38.094: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 6.028089978s
Oct 21 17:15:40.102: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 8.035222223s
Oct 21 17:15:42.108: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 10.041994331s
Oct 21 17:15:44.115: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 12.049015953s
Oct 21 17:15:46.123: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 14.056890832s
Oct 21 17:15:48.130: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 16.064010045s
Oct 21 17:15:50.137: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 18.071104075s
Oct 21 17:15:52.145: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Running", Reason="", readiness=true. Elapsed: 20.078245922s
Oct 21 17:15:54.152: INFO: Pod "pod-subpath-test-configmap-6bs6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.085216215s
STEP: Saw pod success
Oct 21 17:15:54.152: INFO: Pod "pod-subpath-test-configmap-6bs6" satisfied condition "success or failure"
Oct 21 17:15:54.158: INFO: Trying to get logs from node 10.195.18.159 pod pod-subpath-test-configmap-6bs6 container test-container-subpath-configmap-6bs6: <nil>
STEP: delete the pod
Oct 21 17:15:54.187: INFO: Waiting for pod pod-subpath-test-configmap-6bs6 to disappear
Oct 21 17:15:54.193: INFO: Pod pod-subpath-test-configmap-6bs6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6bs6
Oct 21 17:15:54.193: INFO: Deleting pod "pod-subpath-test-configmap-6bs6" in namespace "subpath-7772"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:15:54.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7772" for this suite.
Oct 21 17:16:00.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:16:00.568: INFO: namespace subpath-7772 deletion completed in 6.361768743s

• [SLOW TEST:28.742 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:16:00.569: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1855
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-147e20be-1d3e-4ee9-bba5-d0ceff46d2ed
STEP: Creating configMap with name cm-test-opt-upd-262289cf-f272-429c-8f9b-4cee5f029277
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-147e20be-1d3e-4ee9-bba5-d0ceff46d2ed
STEP: Updating configmap cm-test-opt-upd-262289cf-f272-429c-8f9b-4cee5f029277
STEP: Creating configMap with name cm-test-opt-create-8cbb7613-74d5-4685-ac20-cf295746d389
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:17:21.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1855" for this suite.
Oct 21 17:17:45.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:17:45.993: INFO: namespace configmap-1855 deletion completed in 24.31102662s

• [SLOW TEST:105.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:17:45.993: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3635
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3635
STEP: Deleting pre-stop pod
Oct 21 17:18:01.270: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:18:01.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3635" for this suite.
Oct 21 17:18:41.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:18:41.599: INFO: namespace prestop-3635 deletion completed in 40.307198903s

• [SLOW TEST:55.606 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:18:41.600: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:18:41.800: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:18:46.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9744" for this suite.
Oct 21 17:19:26.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:19:26.340: INFO: namespace pods-9744 deletion completed in 40.304670155s

• [SLOW TEST:44.741 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:19:26.340: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:19:26.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf" in namespace "projected-3638" to be "success or failure"
Oct 21 17:19:26.558: INFO: Pod "downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064378ms
Oct 21 17:19:28.566: INFO: Pod "downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf": Phase="Running", Reason="", readiness=true. Elapsed: 2.013360444s
Oct 21 17:19:30.574: INFO: Pod "downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021967353s
STEP: Saw pod success
Oct 21 17:19:30.574: INFO: Pod "downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf" satisfied condition "success or failure"
Oct 21 17:19:30.583: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf container client-container: <nil>
STEP: delete the pod
Oct 21 17:19:30.618: INFO: Waiting for pod downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf to disappear
Oct 21 17:19:30.624: INFO: Pod downwardapi-volume-bbc0cfdb-c3d1-4990-a3c3-817b49e08abf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:19:30.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3638" for this suite.
Oct 21 17:19:36.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:19:36.946: INFO: namespace projected-3638 deletion completed in 6.312989001s

• [SLOW TEST:10.606 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:19:36.947: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:19:37.158: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32" in namespace "projected-6074" to be "success or failure"
Oct 21 17:19:37.164: INFO: Pod "downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32": Phase="Pending", Reason="", readiness=false. Elapsed: 6.101449ms
Oct 21 17:19:39.172: INFO: Pod "downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013749809s
STEP: Saw pod success
Oct 21 17:19:39.172: INFO: Pod "downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32" satisfied condition "success or failure"
Oct 21 17:19:39.178: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32 container client-container: <nil>
STEP: delete the pod
Oct 21 17:19:39.213: INFO: Waiting for pod downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32 to disappear
Oct 21 17:19:39.220: INFO: Pod downwardapi-volume-80ae759d-9d22-4595-904b-fd25fd2d6f32 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:19:39.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6074" for this suite.
Oct 21 17:19:45.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:19:45.542: INFO: namespace projected-6074 deletion completed in 6.312691789s

• [SLOW TEST:8.596 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:19:45.543: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2030
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-95dcd917-9d27-4bb1-8774-410a7b294be6
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-95dcd917-9d27-4bb1-8774-410a7b294be6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:19:49.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2030" for this suite.
Oct 21 17:20:11.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:20:12.202: INFO: namespace configmap-2030 deletion completed in 22.336773674s

• [SLOW TEST:26.660 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:20:12.203: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:20:12.423: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 21 17:20:17.431: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 17:20:17.431: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 21 17:20:19.496: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7020,SelfLink:/apis/apps/v1/namespaces/deployment-7020/deployments/test-cleanup-deployment,UID:7612a9c8-f522-4726-9dd2-062c912a0aa2,ResourceVersion:41877,Generation:1,CreationTimestamp:2019-10-21 17:20:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 17:20:17 +0000 UTC 2019-10-21 17:20:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 17:20:18 +0000 UTC 2019-10-21 17:20:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 17:20:19.508: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-7020,SelfLink:/apis/apps/v1/namespaces/deployment-7020/replicasets/test-cleanup-deployment-55bbcbc84c,UID:dc5cd97a-e40f-4ff5-a3c3-3e5d8e2e7e8a,ResourceVersion:41867,Generation:1,CreationTimestamp:2019-10-21 17:20:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 7612a9c8-f522-4726-9dd2-062c912a0aa2 0xc00286ccf7 0xc00286ccf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 17:20:19.515: INFO: Pod "test-cleanup-deployment-55bbcbc84c-5gzxm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-5gzxm,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-7020,SelfLink:/api/v1/namespaces/deployment-7020/pods/test-cleanup-deployment-55bbcbc84c-5gzxm,UID:c01d7805-e8dc-450a-af29-c8f667fce535,ResourceVersion:41866,Generation:0,CreationTimestamp:2019-10-21 17:20:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c dc5cd97a-e40f-4ff5-a3c3-3e5d8e2e7e8a 0xc00286d317 0xc00286d318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mt2q2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mt2q2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mt2q2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00286d3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00286d3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:20:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:20:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:20:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:20:17 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:172.30.106.224,StartTime:2019-10-21 17:20:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 17:20:18 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://aa93f10d7e764b451b651a458c95e203a334f9570b713df857b5cc992b06314d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:20:19.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7020" for this suite.
Oct 21 17:20:25.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:20:25.869: INFO: namespace deployment-7020 deletion completed in 6.344454219s

• [SLOW TEST:13.666 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:20:25.869: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Oct 21 17:20:26.072: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 21 17:20:26.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:26.358: INFO: stderr: ""
Oct 21 17:20:26.358: INFO: stdout: "service/redis-slave created\n"
Oct 21 17:20:26.359: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 21 17:20:26.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:26.647: INFO: stderr: ""
Oct 21 17:20:26.647: INFO: stdout: "service/redis-master created\n"
Oct 21 17:20:26.647: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 21 17:20:26.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:26.846: INFO: stderr: ""
Oct 21 17:20:26.846: INFO: stdout: "service/frontend created\n"
Oct 21 17:20:26.846: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 21 17:20:26.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:27.154: INFO: stderr: ""
Oct 21 17:20:27.154: INFO: stdout: "deployment.apps/frontend created\n"
Oct 21 17:20:27.154: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 21 17:20:27.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:27.454: INFO: stderr: ""
Oct 21 17:20:27.454: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 21 17:20:27.454: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 21 17:20:27.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-8428'
Oct 21 17:20:27.720: INFO: stderr: ""
Oct 21 17:20:27.720: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 21 17:20:27.720: INFO: Waiting for all frontend pods to be Running.
Oct 21 17:20:47.772: INFO: Waiting for frontend to serve content.
Oct 21 17:20:52.806: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Oct 21 17:20:57.833: INFO: Trying to add a new entry to the guestbook.
Oct 21 17:20:57.859: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 21 17:20:57.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.054: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.054: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 17:20:58.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.201: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.201: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 17:20:58.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.333: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.333: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 17:20:58.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.460: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.460: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 17:20:58.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.582: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.582: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 17:20:58.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-8428'
Oct 21 17:20:58.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:20:58.718: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:20:58.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8428" for this suite.
Oct 21 17:21:38.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:21:39.096: INFO: namespace kubectl-8428 deletion completed in 40.366971443s

• [SLOW TEST:73.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:21:39.100: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 21 17:21:39.318: INFO: Waiting up to 5m0s for pod "downward-api-829b100f-70a9-46a6-bf29-0df423e5327d" in namespace "downward-api-5782" to be "success or failure"
Oct 21 17:21:39.324: INFO: Pod "downward-api-829b100f-70a9-46a6-bf29-0df423e5327d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.965477ms
Oct 21 17:21:41.332: INFO: Pod "downward-api-829b100f-70a9-46a6-bf29-0df423e5327d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014238747s
STEP: Saw pod success
Oct 21 17:21:41.332: INFO: Pod "downward-api-829b100f-70a9-46a6-bf29-0df423e5327d" satisfied condition "success or failure"
Oct 21 17:21:41.338: INFO: Trying to get logs from node 10.195.18.154 pod downward-api-829b100f-70a9-46a6-bf29-0df423e5327d container dapi-container: <nil>
STEP: delete the pod
Oct 21 17:21:41.373: INFO: Waiting for pod downward-api-829b100f-70a9-46a6-bf29-0df423e5327d to disappear
Oct 21 17:21:41.378: INFO: Pod downward-api-829b100f-70a9-46a6-bf29-0df423e5327d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:21:41.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5782" for this suite.
Oct 21 17:21:47.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:21:47.694: INFO: namespace downward-api-5782 deletion completed in 6.30378165s

• [SLOW TEST:8.594 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:21:47.694: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-49hf
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 17:21:47.922: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-49hf" in namespace "subpath-4784" to be "success or failure"
Oct 21 17:21:47.929: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.359463ms
Oct 21 17:21:49.939: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017029093s
Oct 21 17:21:51.947: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 4.02494613s
Oct 21 17:21:53.955: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 6.032156479s
Oct 21 17:21:55.962: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 8.039485374s
Oct 21 17:21:57.969: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 10.046709236s
Oct 21 17:21:59.982: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 12.059845927s
Oct 21 17:22:01.991: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 14.068957547s
Oct 21 17:22:03.999: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 16.076540707s
Oct 21 17:22:06.006: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 18.083703058s
Oct 21 17:22:08.013: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 20.090632792s
Oct 21 17:22:10.020: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Running", Reason="", readiness=true. Elapsed: 22.097962776s
Oct 21 17:22:12.029: INFO: Pod "pod-subpath-test-downwardapi-49hf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.106428507s
STEP: Saw pod success
Oct 21 17:22:12.029: INFO: Pod "pod-subpath-test-downwardapi-49hf" satisfied condition "success or failure"
Oct 21 17:22:12.035: INFO: Trying to get logs from node 10.195.18.154 pod pod-subpath-test-downwardapi-49hf container test-container-subpath-downwardapi-49hf: <nil>
STEP: delete the pod
Oct 21 17:22:12.078: INFO: Waiting for pod pod-subpath-test-downwardapi-49hf to disappear
Oct 21 17:22:12.083: INFO: Pod pod-subpath-test-downwardapi-49hf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-49hf
Oct 21 17:22:12.083: INFO: Deleting pod "pod-subpath-test-downwardapi-49hf" in namespace "subpath-4784"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:22:12.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4784" for this suite.
Oct 21 17:22:18.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:18.449: INFO: namespace subpath-4784 deletion completed in 6.351554378s

• [SLOW TEST:30.755 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:22:18.449: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6481
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:22:18.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a" in namespace "downward-api-6481" to be "success or failure"
Oct 21 17:22:18.675: INFO: Pod "downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.302442ms
Oct 21 17:22:20.682: INFO: Pod "downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018370066s
STEP: Saw pod success
Oct 21 17:22:20.682: INFO: Pod "downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a" satisfied condition "success or failure"
Oct 21 17:22:20.688: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a container client-container: <nil>
STEP: delete the pod
Oct 21 17:22:20.720: INFO: Waiting for pod downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a to disappear
Oct 21 17:22:20.726: INFO: Pod downwardapi-volume-8c403ce2-a4bd-4cc5-bf8c-b8f389e1317a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:22:20.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6481" for this suite.
Oct 21 17:22:26.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:27.044: INFO: namespace downward-api-6481 deletion completed in 6.308313321s

• [SLOW TEST:8.594 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:22:27.044: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 21 17:22:27.262: INFO: Waiting up to 5m0s for pod "downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5" in namespace "downward-api-292" to be "success or failure"
Oct 21 17:22:27.268: INFO: Pod "downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.119748ms
Oct 21 17:22:29.275: INFO: Pod "downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012927087s
STEP: Saw pod success
Oct 21 17:22:29.275: INFO: Pod "downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5" satisfied condition "success or failure"
Oct 21 17:22:29.282: INFO: Trying to get logs from node 10.195.18.154 pod downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5 container dapi-container: <nil>
STEP: delete the pod
Oct 21 17:22:29.315: INFO: Waiting for pod downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5 to disappear
Oct 21 17:22:29.321: INFO: Pod downward-api-9dfec68d-f167-4a0c-9231-51c3d08857b5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:22:29.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-292" for this suite.
Oct 21 17:22:35.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:35.647: INFO: namespace downward-api-292 deletion completed in 6.315938875s

• [SLOW TEST:8.603 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:22:35.648: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Oct 21 17:22:35.874: INFO: Waiting up to 5m0s for pod "downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7" in namespace "downward-api-8588" to be "success or failure"
Oct 21 17:22:35.880: INFO: Pod "downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.472934ms
Oct 21 17:22:37.888: INFO: Pod "downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7": Phase="Running", Reason="", readiness=true. Elapsed: 2.014022517s
Oct 21 17:22:39.896: INFO: Pod "downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022187257s
STEP: Saw pod success
Oct 21 17:22:39.896: INFO: Pod "downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7" satisfied condition "success or failure"
Oct 21 17:22:39.902: INFO: Trying to get logs from node 10.195.18.154 pod downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7 container dapi-container: <nil>
STEP: delete the pod
Oct 21 17:22:39.935: INFO: Waiting for pod downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7 to disappear
Oct 21 17:22:39.941: INFO: Pod downward-api-94c726a8-1b2e-4d57-a48f-f10742e9d5e7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:22:39.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8588" for this suite.
Oct 21 17:22:45.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:46.267: INFO: namespace downward-api-8588 deletion completed in 6.318345486s

• [SLOW TEST:10.619 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:22:46.268: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Oct 21 17:22:46.492: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0" in namespace "projected-3125" to be "success or failure"
Oct 21 17:22:46.498: INFO: Pod "downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.687426ms
Oct 21 17:22:48.515: INFO: Pod "downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023124136s
STEP: Saw pod success
Oct 21 17:22:48.515: INFO: Pod "downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0" satisfied condition "success or failure"
Oct 21 17:22:48.521: INFO: Trying to get logs from node 10.195.18.159 pod downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0 container client-container: <nil>
STEP: delete the pod
Oct 21 17:22:48.554: INFO: Waiting for pod downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0 to disappear
Oct 21 17:22:48.560: INFO: Pod downwardapi-volume-4fe624ac-127e-4d0a-8257-017fc8c64ae0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:22:48.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3125" for this suite.
Oct 21 17:22:54.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:22:54.893: INFO: namespace projected-3125 deletion completed in 6.325357356s

• [SLOW TEST:8.625 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:22:54.895: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2841
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 17:22:55.097: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 17:23:21.247: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.222:8080/dial?request=hostName&protocol=udp&host=172.30.177.219&port=8081&tries=1'] Namespace:pod-network-test-2841 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:23:21.247: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:23:21.487: INFO: Waiting for endpoints: map[]
Oct 21 17:23:21.495: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.222:8080/dial?request=hostName&protocol=udp&host=172.30.106.230&port=8081&tries=1'] Namespace:pod-network-test-2841 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:23:21.495: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:23:21.703: INFO: Waiting for endpoints: map[]
Oct 21 17:23:21.710: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.177.222:8080/dial?request=hostName&protocol=udp&host=172.30.78.249&port=8081&tries=1'] Namespace:pod-network-test-2841 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:23:21.710: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:23:21.936: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:23:21.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2841" for this suite.
Oct 21 17:23:45.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:23:46.277: INFO: namespace pod-network-test-2841 deletion completed in 24.330567975s

• [SLOW TEST:51.383 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:23:46.279: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8603
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 17:23:46.486: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 17:24:08.622: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.106.228 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:24:08.622: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:24:09.851: INFO: Found all expected endpoints: [netserver-0]
Oct 21 17:24:09.858: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.177.221 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:24:09.858: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:24:11.080: INFO: Found all expected endpoints: [netserver-1]
Oct 21 17:24:11.088: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.78.250 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:24:11.088: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:24:12.297: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:24:12.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8603" for this suite.
Oct 21 17:24:36.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:24:36.686: INFO: namespace pod-network-test-8603 deletion completed in 24.377950192s

• [SLOW TEST:50.407 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:24:36.686: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4278
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Oct 21 17:24:36.899: INFO: Waiting up to 5m0s for pod "client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0" in namespace "containers-4278" to be "success or failure"
Oct 21 17:24:36.904: INFO: Pod "client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.446948ms
Oct 21 17:24:38.911: INFO: Pod "client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012679729s
STEP: Saw pod success
Oct 21 17:24:38.911: INFO: Pod "client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0" satisfied condition "success or failure"
Oct 21 17:24:38.919: INFO: Trying to get logs from node 10.195.18.154 pod client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0 container test-container: <nil>
STEP: delete the pod
Oct 21 17:24:38.949: INFO: Waiting for pod client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0 to disappear
Oct 21 17:24:38.954: INFO: Pod client-containers-fb8f1596-3c90-4085-97ad-1379d38906b0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:24:38.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4278" for this suite.
Oct 21 17:24:45.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:24:45.273: INFO: namespace containers-4278 deletion completed in 6.309406878s

• [SLOW TEST:8.588 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:24:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-6ffc1f3a-ca5a-4a2a-8751-929ce4e493e6
STEP: Creating a pod to test consume configMaps
Oct 21 17:24:45.499: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c" in namespace "projected-7362" to be "success or failure"
Oct 21 17:24:45.505: INFO: Pod "pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.88255ms
Oct 21 17:24:47.514: INFO: Pod "pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015170183s
STEP: Saw pod success
Oct 21 17:24:47.514: INFO: Pod "pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c" satisfied condition "success or failure"
Oct 21 17:24:47.521: INFO: Trying to get logs from node 10.195.18.159 pod pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:24:47.557: INFO: Waiting for pod pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c to disappear
Oct 21 17:24:47.562: INFO: Pod pod-projected-configmaps-386bb85e-5ec2-4b9e-a343-c7510bc08c9c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:24:47.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7362" for this suite.
Oct 21 17:24:53.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:24:53.880: INFO: namespace projected-7362 deletion completed in 6.308945365s

• [SLOW TEST:8.607 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:24:53.881: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-293a8641-f502-4fec-89b9-a6ca011e347e
STEP: Creating a pod to test consume secrets
Oct 21 17:24:54.104: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb" in namespace "projected-6818" to be "success or failure"
Oct 21 17:24:54.109: INFO: Pod "pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.273182ms
Oct 21 17:24:56.117: INFO: Pod "pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013024869s
STEP: Saw pod success
Oct 21 17:24:56.117: INFO: Pod "pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb" satisfied condition "success or failure"
Oct 21 17:24:56.123: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:24:56.155: INFO: Waiting for pod pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb to disappear
Oct 21 17:24:56.161: INFO: Pod pod-projected-secrets-2053bb53-b2d3-4aa6-b378-dd7181796bcb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:24:56.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6818" for this suite.
Oct 21 17:25:02.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:02.477: INFO: namespace projected-6818 deletion completed in 6.30648653s

• [SLOW TEST:8.596 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:25:02.477: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9307
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-91d71a57-516d-4447-b32e-3fab5f880f49
STEP: Creating a pod to test consume configMaps
Oct 21 17:25:02.702: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d" in namespace "projected-9307" to be "success or failure"
Oct 21 17:25:02.708: INFO: Pod "pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.811901ms
Oct 21 17:25:04.715: INFO: Pod "pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012777029s
STEP: Saw pod success
Oct 21 17:25:04.715: INFO: Pod "pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d" satisfied condition "success or failure"
Oct 21 17:25:04.722: INFO: Trying to get logs from node 10.195.18.154 pod pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 17:25:04.753: INFO: Waiting for pod pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d to disappear
Oct 21 17:25:04.759: INFO: Pod pod-projected-configmaps-39f97851-5b4a-409b-94e7-1df5c4ee5b2d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:25:04.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9307" for this suite.
Oct 21 17:25:10.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:25:11.118: INFO: namespace projected-9307 deletion completed in 6.350518588s

• [SLOW TEST:8.641 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:25:11.118: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9511
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:25:15.390: INFO: DNS probes using dns-test-c964ac53-8311-4661-ace6-786ec090d5bf succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:25:17.485: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:17.495: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:17.495: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:22.506: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:22.517: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:22.517: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:27.506: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:27.515: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:27.515: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:32.505: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:32.514: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:32.514: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:37.506: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:37.517: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:37.517: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:42.506: INFO: File wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:42.517: INFO: File jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local from pod  dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 21 17:25:42.517: INFO: Lookups using dns-9511/dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 failed for: [wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local]

Oct 21 17:25:47.516: INFO: DNS probes using dns-test-8ee14197-2e51-476a-8113-6b6bb37d0fa5 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9511.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9511.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 17:26:03.650: INFO: DNS probes using dns-test-e0abd938-b2a4-45e7-b178-ae8e2f3533f5 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:26:03.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9511" for this suite.
Oct 21 17:26:11.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:26:12.033: INFO: namespace dns-9511 deletion completed in 8.317404779s

• [SLOW TEST:60.915 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:26:12.034: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7492
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:26:34.270: INFO: Container started at 2019-10-21 17:26:17 +0000 UTC, pod became ready at 2019-10-21 17:26:33 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:26:34.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7492" for this suite.
Oct 21 17:26:58.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:26:58.629: INFO: namespace container-probe-7492 deletion completed in 24.349096992s

• [SLOW TEST:46.595 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:26:58.629: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:26:58.877: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 17:26:58.903: INFO: Number of nodes with available pods: 0
Oct 21 17:26:58.903: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 17:26:59.921: INFO: Number of nodes with available pods: 0
Oct 21 17:26:59.921: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 17:27:00.921: INFO: Number of nodes with available pods: 3
Oct 21 17:27:00.921: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 21 17:27:00.975: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:00.975: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:00.975: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:01.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:01.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:01.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:02.991: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:02.991: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:02.991: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:03.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:03.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:03.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:03.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:04.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:04.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:04.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:04.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:05.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:05.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:05.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:05.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:06.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:06.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:06.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:06.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:07.989: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:07.989: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:07.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:07.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:08.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:08.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:08.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:08.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:09.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:09.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:09.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:09.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:10.991: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:10.991: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:10.991: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:10.991: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:11.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:11.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:11.990: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:11.990: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:13.004: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:13.004: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:13.004: INFO: Wrong image for pod: daemon-set-v5k9f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:13.004: INFO: Pod daemon-set-v5k9f is not available
Oct 21 17:27:13.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:13.991: INFO: Pod daemon-set-kvc8k is not available
Oct 21 17:27:13.991: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:14.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:14.990: INFO: Pod daemon-set-kvc8k is not available
Oct 21 17:27:14.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:15.989: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:15.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:16.991: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:16.991: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:16.991: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:17.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:17.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:17.990: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:18.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:18.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:18.990: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:19.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:19.990: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:19.990: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:20.989: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:20.989: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:20.989: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:21.993: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:21.993: INFO: Wrong image for pod: daemon-set-s8tjt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:21.993: INFO: Pod daemon-set-s8tjt is not available
Oct 21 17:27:22.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:22.990: INFO: Pod daemon-set-f9dcf is not available
Oct 21 17:27:23.991: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:23.992: INFO: Pod daemon-set-f9dcf is not available
Oct 21 17:27:24.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:25.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:25.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:26.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:26.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:27.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:27.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:28.993: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:28.993: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:29.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:29.991: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:30.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:30.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:31.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:31.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:32.991: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:32.991: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:33.990: INFO: Wrong image for pod: daemon-set-5rd4m. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Oct 21 17:27:33.990: INFO: Pod daemon-set-5rd4m is not available
Oct 21 17:27:34.990: INFO: Pod daemon-set-dr8kr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 21 17:27:35.013: INFO: Number of nodes with available pods: 2
Oct 21 17:27:35.013: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 17:27:36.030: INFO: Number of nodes with available pods: 2
Oct 21 17:27:36.030: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 17:27:37.111: INFO: Number of nodes with available pods: 3
Oct 21 17:27:37.111: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9387, will wait for the garbage collector to delete the pods
Oct 21 17:27:37.236: INFO: Deleting DaemonSet.extensions daemon-set took: 24.206452ms
Oct 21 17:27:37.337: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.385584ms
Oct 21 17:27:44.944: INFO: Number of nodes with available pods: 0
Oct 21 17:27:44.944: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 17:27:44.954: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9387/daemonsets","resourceVersion":"43821"},"items":null}

Oct 21 17:27:44.961: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9387/pods","resourceVersion":"43821"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:27:44.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9387" for this suite.
Oct 21 17:27:53.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:27:53.525: INFO: namespace daemonsets-9387 deletion completed in 8.527822861s

• [SLOW TEST:54.897 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:27:53.531: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Oct 21 17:27:53.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 create -f - --namespace=kubectl-9423'
Oct 21 17:27:54.043: INFO: stderr: ""
Oct 21 17:27:54.043: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Oct 21 17:27:55.051: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:27:55.051: INFO: Found 0 / 1
Oct 21 17:27:56.064: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:27:56.064: INFO: Found 1 / 1
Oct 21 17:27:56.064: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 17:27:56.070: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 17:27:56.070: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 21 17:27:56.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423'
Oct 21 17:27:56.262: INFO: stderr: ""
Oct 21 17:27:56.262: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 17:27:55.288 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 17:27:55.288 # Server started, Redis version 3.2.12\n1:M 21 Oct 17:27:55.288 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 17:27:55.288 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 21 17:27:56.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423 --tail=1'
Oct 21 17:27:56.388: INFO: stderr: ""
Oct 21 17:27:56.388: INFO: stdout: "1:M 21 Oct 17:27:55.288 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 21 17:27:56.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423 --limit-bytes=1'
Oct 21 17:27:56.507: INFO: stderr: ""
Oct 21 17:27:56.507: INFO: stdout: " "
STEP: exposing timestamps
Oct 21 17:27:56.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423 --tail=1 --timestamps'
Oct 21 17:27:56.665: INFO: stderr: ""
Oct 21 17:27:56.665: INFO: stdout: "2019-10-21T17:27:55.289074239Z 1:M 21 Oct 17:27:55.288 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 21 17:27:59.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423 --since=1s'
Oct 21 17:27:59.297: INFO: stderr: ""
Oct 21 17:27:59.297: INFO: stdout: ""
Oct 21 17:27:59.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 logs redis-master-v85qm redis-master --namespace=kubectl-9423 --since=24h'
Oct 21 17:27:59.428: INFO: stderr: ""
Oct 21 17:27:59.428: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 17:27:55.288 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 17:27:55.288 # Server started, Redis version 3.2.12\n1:M 21 Oct 17:27:55.288 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 17:27:55.288 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Oct 21 17:27:59.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 delete --grace-period=0 --force -f - --namespace=kubectl-9423'
Oct 21 17:27:59.549: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 17:27:59.550: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 21 17:27:59.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get rc,svc -l name=nginx --no-headers --namespace=kubectl-9423'
Oct 21 17:27:59.674: INFO: stderr: "No resources found.\n"
Oct 21 17:27:59.674: INFO: stdout: ""
Oct 21 17:27:59.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-373207704 get pods -l name=nginx --namespace=kubectl-9423 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 17:27:59.806: INFO: stderr: ""
Oct 21 17:27:59.806: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:27:59.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9423" for this suite.
Oct 21 17:28:21.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:28:22.147: INFO: namespace kubectl-9423 deletion completed in 22.328448289s

• [SLOW TEST:28.616 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:28:22.147: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Oct 21 17:28:22.352: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 17:28:22.374: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 17:28:22.384: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.154 before test
Oct 21 17:28:22.473: INFO: ibm-storage-watcher-786667d59-lmgwt from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 17:28:22.473: INFO: ibm-file-plugin-5f9d7d6c49-8g6s6 from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 17:28:22.473: INFO: calico-kube-controllers-9d8994658-lxjks from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 17:28:22.473: INFO: metrics-server-76c7b9bb54-xvv8g from kube-system started at 2019-10-21 14:15:49 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 17:28:22.473: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 17:28:22.473: INFO: ibm-master-proxy-static-10.195.18.154 from kube-system started at 2019-10-21 14:14:53 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:28:22.473: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:28:22.473: INFO: ibm-keepalived-watcher-6lnrw from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:28:22.473: INFO: sonobuoy from sonobuoy started at 2019-10-21 15:55:03 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 17:28:22.473: INFO: kubernetes-dashboard-596f947ff4-r2hbp from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 17:28:22.473: INFO: coredns-autoscaler-74cb66766b-whr2s from kube-system started at 2019-10-21 14:15:17 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 17:28:22.473: INFO: ibm-kube-fluentd-dqtjd from kube-system started at 2019-10-21 14:15:28 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:28:22.473: INFO: calico-node-sxqjc from kube-system started at 2019-10-21 14:14:59 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:28:22.473: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-h72dv from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:28:22.473: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:28:22.473: INFO: vpn-75d8697c68-rldfs from kube-system started at 2019-10-21 14:40:12 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container vpn ready: true, restart count 0
Oct 21 17:28:22.473: INFO: coredns-64f45bf67-lxgz9 from kube-system started at 2019-10-21 14:40:34 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.473: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:28:22.473: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.159 before test
Oct 21 17:28:22.509: INFO: ibm-master-proxy-static-10.195.18.159 from kube-system started at 2019-10-21 14:15:24 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:28:22.509: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:28:22.509: INFO: ibm-kube-fluentd-j2hrm from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:28:22.509: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-f8jd9 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:28:22.509: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:28:22.509: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:28:22.509: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:28:22.509: INFO: sonobuoy-e2e-job-65107fb0e85542d6 from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container e2e ready: true, restart count 0
Oct 21 17:28:22.509: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 17:28:22.509: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-xsfvb from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 17:28:22.509: INFO: ibm-keepalived-watcher-97gq4 from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:28:22.509: INFO: calico-node-7l5tz from kube-system started at 2019-10-21 14:15:31 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:28:22.509: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-4mbpj from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.509: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:28:22.509: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:28:22.509: INFO: 
Logging pods the kubelet thinks is on node 10.195.18.160 before test
Oct 21 17:28:22.551: INFO: calico-node-n8566 from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 17:28:22.551: INFO: public-crbmmrjnus0umui569cj50-alb1-77459cdcc5-xfzc5 from kube-system started at 2019-10-21 14:24:43 +0000 UTC (4 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 17:28:22.551: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 17:28:22.551: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 17:28:22.551: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 17:28:22.551: INFO: sonobuoy-systemd-logs-daemon-set-0720db0cb5684c9a-bp6nm from sonobuoy started at 2019-10-21 15:55:12 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 17:28:22.551: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 17:28:22.551: INFO: ibm-master-proxy-static-10.195.18.160 from kube-system started at 2019-10-21 14:15:42 +0000 UTC (2 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Oct 21 17:28:22.551: INFO: 	Container pause ready: true, restart count 0
Oct 21 17:28:22.551: INFO: ibm-kube-fluentd-g6rld from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 17:28:22.551: INFO: ibm-cloud-provider-ip-135-90-68-42-8557dfd9dc-2c6zf from ibm-system started at 2019-10-21 14:21:01 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container ibm-cloud-provider-ip-135-90-68-42 ready: true, restart count 0
Oct 21 17:28:22.551: INFO: coredns-64f45bf67-cv68m from kube-system started at 2019-10-21 14:40:33 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container coredns ready: true, restart count 0
Oct 21 17:28:22.551: INFO: ibm-keepalived-watcher-xnjtx from kube-system started at 2019-10-21 14:15:49 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 17:28:22.551: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 14:17:37 +0000 UTC (1 container statuses recorded)
Oct 21 17:28:22.551: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-cf2bc420-7b48-4c77-ba74-f88c5b43e910 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-cf2bc420-7b48-4c77-ba74-f88c5b43e910 off the node 10.195.18.160
STEP: verifying the node doesn't have the label kubernetes.io/e2e-cf2bc420-7b48-4c77-ba74-f88c5b43e910
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:28:26.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-367" for this suite.
Oct 21 17:28:48.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:28:49.053: INFO: namespace sched-pred-367 deletion completed in 22.357039461s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:26.906 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:28:49.053: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-e1e13a1b-02f6-470a-8904-c6c8b2d2bf88
STEP: Creating a pod to test consume secrets
Oct 21 17:28:49.280: INFO: Waiting up to 5m0s for pod "pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee" in namespace "secrets-9005" to be "success or failure"
Oct 21 17:28:49.286: INFO: Pod "pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.287648ms
Oct 21 17:28:51.294: INFO: Pod "pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01417107s
STEP: Saw pod success
Oct 21 17:28:51.294: INFO: Pod "pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee" satisfied condition "success or failure"
Oct 21 17:28:51.301: INFO: Trying to get logs from node 10.195.18.159 pod pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:28:51.335: INFO: Waiting for pod pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee to disappear
Oct 21 17:28:51.342: INFO: Pod pod-secrets-e41f7cd0-833c-4fec-90c7-421559e908ee no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:28:51.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9005" for this suite.
Oct 21 17:28:57.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:28:57.690: INFO: namespace secrets-9005 deletion completed in 6.337722378s

• [SLOW TEST:8.636 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:28:57.690: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 17:28:57.895: INFO: Waiting up to 5m0s for pod "pod-2b211d2d-6215-4923-8656-0b5f775f9316" in namespace "emptydir-7453" to be "success or failure"
Oct 21 17:28:57.901: INFO: Pod "pod-2b211d2d-6215-4923-8656-0b5f775f9316": Phase="Pending", Reason="", readiness=false. Elapsed: 5.660616ms
Oct 21 17:28:59.908: INFO: Pod "pod-2b211d2d-6215-4923-8656-0b5f775f9316": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012592344s
Oct 21 17:29:01.916: INFO: Pod "pod-2b211d2d-6215-4923-8656-0b5f775f9316": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020416769s
STEP: Saw pod success
Oct 21 17:29:01.916: INFO: Pod "pod-2b211d2d-6215-4923-8656-0b5f775f9316" satisfied condition "success or failure"
Oct 21 17:29:01.922: INFO: Trying to get logs from node 10.195.18.160 pod pod-2b211d2d-6215-4923-8656-0b5f775f9316 container test-container: <nil>
STEP: delete the pod
Oct 21 17:29:01.953: INFO: Waiting for pod pod-2b211d2d-6215-4923-8656-0b5f775f9316 to disappear
Oct 21 17:29:01.958: INFO: Pod pod-2b211d2d-6215-4923-8656-0b5f775f9316 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:29:01.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7453" for this suite.
Oct 21 17:29:08.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:29:08.356: INFO: namespace emptydir-7453 deletion completed in 6.388530687s

• [SLOW TEST:10.666 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:29:08.356: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:29:08.615: INFO: Create a RollingUpdate DaemonSet
Oct 21 17:29:08.626: INFO: Check that daemon pods launch on every node of the cluster
Oct 21 17:29:08.639: INFO: Number of nodes with available pods: 0
Oct 21 17:29:08.639: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 17:29:09.673: INFO: Number of nodes with available pods: 0
Oct 21 17:29:09.673: INFO: Node 10.195.18.154 is running more than one daemon pod
Oct 21 17:29:10.654: INFO: Number of nodes with available pods: 2
Oct 21 17:29:10.654: INFO: Node 10.195.18.159 is running more than one daemon pod
Oct 21 17:29:11.661: INFO: Number of nodes with available pods: 3
Oct 21 17:29:11.661: INFO: Number of running nodes: 3, number of available pods: 3
Oct 21 17:29:11.661: INFO: Update the DaemonSet to trigger a rollout
Oct 21 17:29:11.683: INFO: Updating DaemonSet daemon-set
Oct 21 17:29:15.713: INFO: Roll back the DaemonSet before rollout is complete
Oct 21 17:29:15.737: INFO: Updating DaemonSet daemon-set
Oct 21 17:29:15.737: INFO: Make sure DaemonSet rollback is complete
Oct 21 17:29:15.744: INFO: Wrong image for pod: daemon-set-266nh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 21 17:29:15.744: INFO: Pod daemon-set-266nh is not available
Oct 21 17:29:16.762: INFO: Wrong image for pod: daemon-set-266nh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 21 17:29:16.762: INFO: Pod daemon-set-266nh is not available
Oct 21 17:29:17.759: INFO: Wrong image for pod: daemon-set-266nh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Oct 21 17:29:17.759: INFO: Pod daemon-set-266nh is not available
Oct 21 17:29:18.758: INFO: Pod daemon-set-qrlqk is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9849, will wait for the garbage collector to delete the pods
Oct 21 17:29:18.873: INFO: Deleting DaemonSet.extensions daemon-set took: 24.035099ms
Oct 21 17:29:18.973: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.410509ms
Oct 21 17:29:24.981: INFO: Number of nodes with available pods: 0
Oct 21 17:29:24.981: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 17:29:24.991: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9849/daemonsets","resourceVersion":"44335"},"items":null}

Oct 21 17:29:24.997: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9849/pods","resourceVersion":"44335"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:29:25.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9849" for this suite.
Oct 21 17:29:31.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:29:31.392: INFO: namespace daemonsets-9849 deletion completed in 6.359599137s

• [SLOW TEST:23.036 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:29:31.393: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8029
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 17:29:31.592: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 17:29:57.745: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.106.240:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8029 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:29:57.746: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:29:57.978: INFO: Found all expected endpoints: [netserver-0]
Oct 21 17:29:57.985: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.177.232:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8029 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:29:57.985: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:29:58.201: INFO: Found all expected endpoints: [netserver-1]
Oct 21 17:29:58.208: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.78.198:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8029 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 17:29:58.208: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
Oct 21 17:29:58.450: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:29:58.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8029" for this suite.
Oct 21 17:30:22.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:30:22.929: INFO: namespace pod-network-test-8029 deletion completed in 24.470366318s

• [SLOW TEST:51.537 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:30:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-6226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Oct 21 17:30:23.133: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Oct 21 17:30:23.592: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 21 17:30:25.689: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:27.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:29.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:31.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:33.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:35.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:37.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:39.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:41.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275823, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:30:44.681: INFO: Waited 966.497458ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:30:45.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6226" for this suite.
Oct 21 17:30:51.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:30:51.567: INFO: namespace aggregator-6226 deletion completed in 6.431322898s

• [SLOW TEST:28.634 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:30:51.567: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 21 17:30:51.795: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1540,SelfLink:/api/v1/namespaces/watch-1540/configmaps/e2e-watch-test-watch-closed,UID:a2b40e62-b300-455b-a097-04f0b385d949,ResourceVersion:44737,Generation:0,CreationTimestamp:2019-10-21 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 17:30:51.796: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1540,SelfLink:/api/v1/namespaces/watch-1540/configmaps/e2e-watch-test-watch-closed,UID:a2b40e62-b300-455b-a097-04f0b385d949,ResourceVersion:44738,Generation:0,CreationTimestamp:2019-10-21 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 21 17:30:51.823: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1540,SelfLink:/api/v1/namespaces/watch-1540/configmaps/e2e-watch-test-watch-closed,UID:a2b40e62-b300-455b-a097-04f0b385d949,ResourceVersion:44739,Generation:0,CreationTimestamp:2019-10-21 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 17:30:51.823: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1540,SelfLink:/api/v1/namespaces/watch-1540/configmaps/e2e-watch-test-watch-closed,UID:a2b40e62-b300-455b-a097-04f0b385d949,ResourceVersion:44740,Generation:0,CreationTimestamp:2019-10-21 17:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:30:51.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1540" for this suite.
Oct 21 17:30:57.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:30:58.152: INFO: namespace watch-1540 deletion completed in 6.319553556s

• [SLOW TEST:6.585 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:30:58.153: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Oct 21 17:30:58.356: INFO: Creating deployment "test-recreate-deployment"
Oct 21 17:30:58.376: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 21 17:30:58.394: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 21 17:30:58.402: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275858, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275858, loc:(*time.Location)(0x7ed0a20)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-6df85df6b9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275858, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707275858, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Oct 21 17:31:00.413: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 21 17:31:00.439: INFO: Updating deployment test-recreate-deployment
Oct 21 17:31:00.439: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Oct 21 17:31:00.519: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-9703,SelfLink:/apis/apps/v1/namespaces/deployment-9703/deployments/test-recreate-deployment,UID:d76cdf0b-31cc-464a-8d52-db5f3331dd8f,ResourceVersion:44811,Generation:2,CreationTimestamp:2019-10-21 17:30:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-21 17:31:00 +0000 UTC 2019-10-21 17:31:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-21 17:31:00 +0000 UTC 2019-10-21 17:30:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 21 17:31:00.528: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-9703,SelfLink:/apis/apps/v1/namespaces/deployment-9703/replicasets/test-recreate-deployment-5c8c9cc69d,UID:0af6a088-9be7-4ae8-b351-34e1661b4f46,ResourceVersion:44808,Generation:1,CreationTimestamp:2019-10-21 17:31:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d76cdf0b-31cc-464a-8d52-db5f3331dd8f 0xc001e47867 0xc001e47868}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 17:31:00.528: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 21 17:31:00.528: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-9703,SelfLink:/apis/apps/v1/namespaces/deployment-9703/replicasets/test-recreate-deployment-6df85df6b9,UID:c8bd3356-e733-4294-b14b-5bdc30abbdd0,ResourceVersion:44800,Generation:2,CreationTimestamp:2019-10-21 17:30:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d76cdf0b-31cc-464a-8d52-db5f3331dd8f 0xc001e47937 0xc001e47938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 17:31:00.535: INFO: Pod "test-recreate-deployment-5c8c9cc69d-97qpp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-97qpp,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-9703,SelfLink:/api/v1/namespaces/deployment-9703/pods/test-recreate-deployment-5c8c9cc69d-97qpp,UID:7c98e858-19b7-41ee-b00d-c1ae49e70f29,ResourceVersion:44812,Generation:0,CreationTimestamp:2019-10-21 17:31:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 0af6a088-9be7-4ae8-b351-34e1661b4f46 0xc002886277 0xc002886278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xlft6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xlft6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xlft6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.195.18.159,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028862f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002886310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:31:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:31:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:31:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 17:31:00 +0000 UTC  }],Message:,Reason:,HostIP:10.195.18.159,PodIP:,StartTime:2019-10-21 17:31:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:31:00.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9703" for this suite.
Oct 21 17:31:06.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:31:06.847: INFO: namespace deployment-9703 deletion completed in 6.303375245s

• [SLOW TEST:8.694 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:31:06.847: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-341a4681-dec7-42ad-95a1-1010d83fb5e4
STEP: Creating a pod to test consume secrets
Oct 21 17:31:07.074: INFO: Waiting up to 5m0s for pod "pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d" in namespace "secrets-1822" to be "success or failure"
Oct 21 17:31:07.080: INFO: Pod "pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.915046ms
Oct 21 17:31:09.088: INFO: Pod "pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013876479s
Oct 21 17:31:11.094: INFO: Pod "pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020772707s
STEP: Saw pod success
Oct 21 17:31:11.094: INFO: Pod "pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d" satisfied condition "success or failure"
Oct 21 17:31:11.102: INFO: Trying to get logs from node 10.195.18.154 pod pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 17:31:11.152: INFO: Waiting for pod pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d to disappear
Oct 21 17:31:11.160: INFO: Pod pod-secrets-da14521c-7948-4acd-b6ec-dc15e9dd5e8d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:31:11.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1822" for this suite.
Oct 21 17:31:17.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:31:17.517: INFO: namespace secrets-1822 deletion completed in 6.347941575s

• [SLOW TEST:10.670 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Oct 21 17:31:17.517: INFO: >>> kubeConfig: /tmp/kubeconfig-373207704
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-afd9c6b6-bd67-4067-86a2-c5f58bce00f2
STEP: Creating secret with name secret-projected-all-test-volume-514d4f36-df40-4972-b027-eebe833cee05
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 21 17:31:17.752: INFO: Waiting up to 5m0s for pod "projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf" in namespace "projected-1073" to be "success or failure"
Oct 21 17:31:17.759: INFO: Pod "projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.161081ms
Oct 21 17:31:19.769: INFO: Pod "projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016280799s
STEP: Saw pod success
Oct 21 17:31:19.769: INFO: Pod "projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf" satisfied condition "success or failure"
Oct 21 17:31:19.775: INFO: Trying to get logs from node 10.195.18.160 pod projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 21 17:31:19.809: INFO: Waiting for pod projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf to disappear
Oct 21 17:31:19.814: INFO: Pod projected-volume-7b59621a-9a27-43fb-a696-5e5b84ce6bdf no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Oct 21 17:31:19.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1073" for this suite.
Oct 21 17:31:25.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 17:31:26.145: INFO: namespace projected-1073 deletion completed in 6.322094102s

• [SLOW TEST:8.628 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSOct 21 17:31:26.146: INFO: Running AfterSuite actions on all nodes
Oct 21 17:31:26.146: INFO: Running AfterSuite actions on node 1
Oct 21 17:31:26.146: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5743.670 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h35m45.005458558s
Test Suite Passed
