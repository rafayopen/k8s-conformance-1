I1105 20:39:27.092239      17 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-243470310
I1105 20:39:27.092362      17 e2e.go:241] Starting e2e run "e5580e23-ecb8-43ac-b56b-b62a0cdda1af" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572986365 - Will randomize all specs
Will run 215 of 4413 specs

Nov  5 20:39:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 20:39:27.203: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  5 20:39:27.220: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  5 20:39:27.250: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  5 20:39:27.250: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov  5 20:39:27.250: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  5 20:39:27.258: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov  5 20:39:27.258: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  5 20:39:27.258: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Nov  5 20:39:27.258: INFO: e2e test version: v1.15.3
Nov  5 20:39:27.260: INFO: kube-apiserver version: v1.15.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:39:27.260: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
Nov  5 20:39:27.292: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:39:27.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188" in namespace "projected-3961" to be "success or failure"
Nov  5 20:39:27.300: INFO: Pod "downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188": Phase="Pending", Reason="", readiness=false. Elapsed: 1.923755ms
Nov  5 20:39:29.303: INFO: Pod "downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004586485s
Nov  5 20:39:31.306: INFO: Pod "downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007459701s
STEP: Saw pod success
Nov  5 20:39:31.306: INFO: Pod "downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188" satisfied condition "success or failure"
Nov  5 20:39:31.308: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188 container client-container: <nil>
STEP: delete the pod
Nov  5 20:39:31.333: INFO: Waiting for pod downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188 to disappear
Nov  5 20:39:31.335: INFO: Pod downwardapi-volume-9e4fc02b-fbd6-4335-85f7-b72a7c509188 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:39:31.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3961" for this suite.
Nov  5 20:39:37.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:39:37.401: INFO: namespace projected-3961 deletion completed in 6.063221073s

• [SLOW TEST:10.141 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:39:37.401: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-9036234e-3e74-478b-b8fc-a74b20899eba
STEP: Creating a pod to test consume secrets
Nov  5 20:39:37.431: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30" in namespace "projected-4715" to be "success or failure"
Nov  5 20:39:37.433: INFO: Pod "pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316878ms
Nov  5 20:39:39.436: INFO: Pod "pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004967785s
Nov  5 20:39:41.438: INFO: Pod "pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007770557s
STEP: Saw pod success
Nov  5 20:39:41.438: INFO: Pod "pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30" satisfied condition "success or failure"
Nov  5 20:39:41.440: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  5 20:39:41.467: INFO: Waiting for pod pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30 to disappear
Nov  5 20:39:41.469: INFO: Pod pod-projected-secrets-f188418f-ef2a-4a3a-b2bc-8eab344b9c30 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:39:41.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4715" for this suite.
Nov  5 20:39:47.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:39:47.538: INFO: namespace projected-4715 deletion completed in 6.066828089s

• [SLOW TEST:10.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:39:47.539: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov  5 20:40:18.106: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 7
	[quantile=0.9] = 7
	[quantile=0.99] = 7
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 37
	[quantile=0.9] = 37
	[quantile=0.99] = 37
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 7
	[quantile=0.9] = 219770
	[quantile=0.99] = 219770
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 1971
	[quantile=0.9] = 220155
	[quantile=0.99] = 220155
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 5
	[quantile=0.99] = 25
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 26
	[quantile=0.99] = 51
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 23
	[quantile=0.9] = 36
	[quantile=0.99] = 36
For namespace_queue_latency_sum:
	[] = 59
For namespace_queue_latency_count:
	[] = 2
For namespace_retries:
	[] = 3
For namespace_work_duration:
	[quantile=0.5] = 142545
	[quantile=0.9] = 153411
	[quantile=0.99] = 153411
For namespace_work_duration_sum:
	[] = 295956
For namespace_work_duration_count:
	[] = 2
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:40:18.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7316" for this suite.
Nov  5 20:40:24.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:40:24.179: INFO: namespace gc-7316 deletion completed in 6.069755483s

• [SLOW TEST:36.640 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:40:24.179: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  5 20:40:32.238: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  5 20:40:32.240: INFO: Pod pod-with-poststart-http-hook still exists
Nov  5 20:40:34.240: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  5 20:40:34.243: INFO: Pod pod-with-poststart-http-hook still exists
Nov  5 20:40:36.240: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  5 20:40:36.243: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:40:36.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4251" for this suite.
Nov  5 20:40:58.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:40:58.315: INFO: namespace container-lifecycle-hook-4251 deletion completed in 22.069807184s

• [SLOW TEST:34.136 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:40:58.316: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-701555fa-f08e-4d1b-93aa-ded3da51bc79
STEP: Creating a pod to test consume configMaps
Nov  5 20:40:58.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa" in namespace "configmap-2569" to be "success or failure"
Nov  5 20:40:58.350: INFO: Pod "pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363135ms
Nov  5 20:41:00.353: INFO: Pod "pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005815479s
STEP: Saw pod success
Nov  5 20:41:00.353: INFO: Pod "pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa" satisfied condition "success or failure"
Nov  5 20:41:00.355: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 20:41:00.367: INFO: Waiting for pod pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa to disappear
Nov  5 20:41:00.369: INFO: Pod pod-configmaps-0efcc79c-adf6-4418-87ec-c137a51d7aaa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:00.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2569" for this suite.
Nov  5 20:41:06.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:41:06.441: INFO: namespace configmap-2569 deletion completed in 6.069232713s

• [SLOW TEST:8.125 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:41:06.441: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-cc9fe845-330e-4ae6-b1d8-24e4c0431063
STEP: Creating a pod to test consume secrets
Nov  5 20:41:06.470: INFO: Waiting up to 5m0s for pod "pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264" in namespace "secrets-6077" to be "success or failure"
Nov  5 20:41:06.472: INFO: Pod "pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264": Phase="Pending", Reason="", readiness=false. Elapsed: 1.78006ms
Nov  5 20:41:08.474: INFO: Pod "pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004231716s
STEP: Saw pod success
Nov  5 20:41:08.475: INFO: Pod "pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264" satisfied condition "success or failure"
Nov  5 20:41:08.477: INFO: Trying to get logs from node k8s-node-1 pod pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 20:41:08.493: INFO: Waiting for pod pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264 to disappear
Nov  5 20:41:08.494: INFO: Pod pod-secrets-fe377e60-7b06-48ee-aef5-66bfdfcf6264 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:08.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6077" for this suite.
Nov  5 20:41:14.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:41:14.567: INFO: namespace secrets-6077 deletion completed in 6.070013624s

• [SLOW TEST:8.126 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:41:14.568: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:41:14.596: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3" in namespace "projected-8600" to be "success or failure"
Nov  5 20:41:14.600: INFO: Pod "downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.637152ms
Nov  5 20:41:16.602: INFO: Pod "downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006179358s
Nov  5 20:41:18.605: INFO: Pod "downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008882182s
STEP: Saw pod success
Nov  5 20:41:18.605: INFO: Pod "downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3" satisfied condition "success or failure"
Nov  5 20:41:18.607: INFO: Trying to get logs from node k8s-node-3 pod downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3 container client-container: <nil>
STEP: delete the pod
Nov  5 20:41:18.630: INFO: Waiting for pod downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3 to disappear
Nov  5 20:41:18.632: INFO: Pod downwardapi-volume-2292d9db-c101-4dba-b769-56af04495ad3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:18.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8600" for this suite.
Nov  5 20:41:24.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:41:24.706: INFO: namespace projected-8600 deletion completed in 6.070296834s

• [SLOW TEST:10.138 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:41:24.706: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Nov  5 20:41:24.741: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-243470310 proxy --unix-socket=/tmp/kubectl-proxy-unix742041613/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:24.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6252" for this suite.
Nov  5 20:41:30.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:41:30.879: INFO: namespace kubectl-6252 deletion completed in 6.062819874s

• [SLOW TEST:6.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:41:30.879: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:41:30.908: INFO: Waiting up to 5m0s for pod "downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30" in namespace "projected-8884" to be "success or failure"
Nov  5 20:41:30.910: INFO: Pod "downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30": Phase="Pending", Reason="", readiness=false. Elapsed: 1.740574ms
Nov  5 20:41:32.913: INFO: Pod "downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004408117s
STEP: Saw pod success
Nov  5 20:41:32.913: INFO: Pod "downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30" satisfied condition "success or failure"
Nov  5 20:41:32.914: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30 container client-container: <nil>
STEP: delete the pod
Nov  5 20:41:32.929: INFO: Waiting for pod downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30 to disappear
Nov  5 20:41:32.932: INFO: Pod downwardapi-volume-059383de-1173-4b42-9cd6-44ed6c1f0f30 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:32.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8884" for this suite.
Nov  5 20:41:38.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:41:39.000: INFO: namespace projected-8884 deletion completed in 6.065528571s

• [SLOW TEST:8.121 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:41:39.000: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov  5 20:41:41.554: INFO: Successfully updated pod "annotationupdateee8ec33f-6254-407d-8237-8287c5f7478b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:41:43.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6475" for this suite.
Nov  5 20:42:05.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:42:05.634: INFO: namespace projected-6475 deletion completed in 22.063661573s

• [SLOW TEST:26.634 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:42:05.635: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  5 20:42:09.679: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:42:09.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2999" for this suite.
Nov  5 20:42:15.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:42:15.758: INFO: namespace container-runtime-2999 deletion completed in 6.068066594s

• [SLOW TEST:10.123 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:42:15.758: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  5 20:42:18.810: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:42:19.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1401" for this suite.
Nov  5 20:42:41.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:42:41.886: INFO: namespace replicaset-1401 deletion completed in 22.062307866s

• [SLOW TEST:26.128 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:42:41.886: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  5 20:42:45.931: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 20:42:45.933: INFO: Pod pod-with-prestop-http-hook still exists
Nov  5 20:42:47.933: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 20:42:47.936: INFO: Pod pod-with-prestop-http-hook still exists
Nov  5 20:42:49.933: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 20:42:49.936: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:42:49.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5928" for this suite.
Nov  5 20:43:11.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:43:12.022: INFO: namespace container-lifecycle-hook-5928 deletion completed in 22.069570617s

• [SLOW TEST:30.136 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:43:12.023: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-79fd91a5-9413-4c22-85ec-5688619576ec
STEP: Creating a pod to test consume configMaps
Nov  5 20:43:12.054: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12" in namespace "projected-470" to be "success or failure"
Nov  5 20:43:12.056: INFO: Pod "pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12": Phase="Pending", Reason="", readiness=false. Elapsed: 1.986643ms
Nov  5 20:43:14.059: INFO: Pod "pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004912282s
STEP: Saw pod success
Nov  5 20:43:14.059: INFO: Pod "pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12" satisfied condition "success or failure"
Nov  5 20:43:14.060: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 20:43:14.073: INFO: Waiting for pod pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12 to disappear
Nov  5 20:43:14.074: INFO: Pod pod-projected-configmaps-0ba4683c-e040-4988-b502-2d76722b9d12 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:43:14.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-470" for this suite.
Nov  5 20:43:20.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:43:20.199: INFO: namespace projected-470 deletion completed in 6.108925278s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:43:20.199: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  5 20:43:20.231: INFO: Waiting up to 5m0s for pod "pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741" in namespace "emptydir-5891" to be "success or failure"
Nov  5 20:43:20.235: INFO: Pod "pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005573ms
Nov  5 20:43:22.238: INFO: Pod "pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006975412s
Nov  5 20:43:24.241: INFO: Pod "pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00965472s
STEP: Saw pod success
Nov  5 20:43:24.241: INFO: Pod "pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741" satisfied condition "success or failure"
Nov  5 20:43:24.242: INFO: Trying to get logs from node k8s-node-1 pod pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741 container test-container: <nil>
STEP: delete the pod
Nov  5 20:43:24.255: INFO: Waiting for pod pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741 to disappear
Nov  5 20:43:24.257: INFO: Pod pod-a75a137d-7351-46c2-94d1-3fc6b7fe2741 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:43:24.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5891" for this suite.
Nov  5 20:43:30.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:43:30.326: INFO: namespace emptydir-5891 deletion completed in 6.065753944s

• [SLOW TEST:10.126 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:43:30.326: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:43:30.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5214" for this suite.
Nov  5 20:43:52.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:43:52.432: INFO: namespace pods-5214 deletion completed in 22.066448575s

• [SLOW TEST:22.106 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:43:52.432: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov  5 20:43:52.458: INFO: Waiting up to 5m0s for pod "downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89" in namespace "downward-api-4689" to be "success or failure"
Nov  5 20:43:52.460: INFO: Pod "downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89": Phase="Pending", Reason="", readiness=false. Elapsed: 1.899213ms
Nov  5 20:43:54.462: INFO: Pod "downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003978387s
STEP: Saw pod success
Nov  5 20:43:54.462: INFO: Pod "downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89" satisfied condition "success or failure"
Nov  5 20:43:54.464: INFO: Trying to get logs from node k8s-node-1 pod downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89 container dapi-container: <nil>
STEP: delete the pod
Nov  5 20:43:54.478: INFO: Waiting for pod downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89 to disappear
Nov  5 20:43:54.480: INFO: Pod downward-api-bbfa7cb7-4cab-4230-99b5-dd9fa5c7ea89 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:43:54.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4689" for this suite.
Nov  5 20:44:00.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:44:00.548: INFO: namespace downward-api-4689 deletion completed in 6.063823534s

• [SLOW TEST:8.116 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:44:00.548: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Nov  5 20:44:00.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 cluster-info'
Nov  5 20:44:00.695: INFO: stderr: ""
Nov  5 20:44:00.695: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:44:00.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6787" for this suite.
Nov  5 20:44:06.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:44:06.765: INFO: namespace kubectl-6787 deletion completed in 6.067058707s

• [SLOW TEST:6.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:44:06.765: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:44:06.798: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  5 20:44:06.803: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:06.806: INFO: Number of nodes with available pods: 0
Nov  5 20:44:06.806: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:44:07.809: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:07.811: INFO: Number of nodes with available pods: 1
Nov  5 20:44:07.811: INFO: Node k8s-node-2 is running more than one daemon pod
Nov  5 20:44:08.809: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:08.811: INFO: Number of nodes with available pods: 2
Nov  5 20:44:08.811: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 20:44:09.809: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:09.812: INFO: Number of nodes with available pods: 2
Nov  5 20:44:09.812: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 20:44:10.809: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:10.811: INFO: Number of nodes with available pods: 3
Nov  5 20:44:10.811: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  5 20:44:10.831: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:10.831: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:10.831: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:10.833: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:11.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:11.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:11.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:11.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:11.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:12.837: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:12.837: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:12.837: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:12.837: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:12.842: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:13.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:13.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:13.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:13.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:13.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:14.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:14.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:14.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:14.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:14.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:15.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:15.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:15.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:15.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:15.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:16.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:16.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:16.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:16.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:16.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:17.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:17.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:17.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:17.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:17.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:18.842: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:18.842: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:18.842: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:18.842: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:18.845: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:19.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:19.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:19.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:19.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:19.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:20.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:20.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:20.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:20.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:20.840: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:21.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:21.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:21.836: INFO: Wrong image for pod: daemon-set-klpdb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:21.836: INFO: Pod daemon-set-klpdb is not available
Nov  5 20:44:21.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:22.837: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:22.837: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:22.837: INFO: Pod daemon-set-vbdmk is not available
Nov  5 20:44:22.840: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:23.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:23.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:23.836: INFO: Pod daemon-set-vbdmk is not available
Nov  5 20:44:23.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:24.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:24.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:24.836: INFO: Pod daemon-set-vbdmk is not available
Nov  5 20:44:24.840: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:25.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:25.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:25.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:26.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:26.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:26.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:26.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:27.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:27.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:27.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:27.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:28.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:28.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:28.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:28.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:29.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:29.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:29.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:29.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:30.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:30.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:30.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:30.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:31.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:31.836: INFO: Wrong image for pod: daemon-set-kgxwg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:31.836: INFO: Pod daemon-set-kgxwg is not available
Nov  5 20:44:31.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:32.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:32.836: INFO: Pod daemon-set-v5bj7 is not available
Nov  5 20:44:32.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:33.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:33.836: INFO: Pod daemon-set-v5bj7 is not available
Nov  5 20:44:33.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:34.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:34.836: INFO: Pod daemon-set-v5bj7 is not available
Nov  5 20:44:34.840: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:35.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:35.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:36.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:36.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:37.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:37.836: INFO: Pod daemon-set-cg4d6 is not available
Nov  5 20:44:37.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:38.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:38.836: INFO: Pod daemon-set-cg4d6 is not available
Nov  5 20:44:38.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:39.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:39.836: INFO: Pod daemon-set-cg4d6 is not available
Nov  5 20:44:39.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:40.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:40.836: INFO: Pod daemon-set-cg4d6 is not available
Nov  5 20:44:40.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:41.836: INFO: Wrong image for pod: daemon-set-cg4d6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov  5 20:44:41.836: INFO: Pod daemon-set-cg4d6 is not available
Nov  5 20:44:41.838: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:42.836: INFO: Pod daemon-set-t98rq is not available
Nov  5 20:44:42.839: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  5 20:44:42.842: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:42.844: INFO: Number of nodes with available pods: 2
Nov  5 20:44:42.844: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:44:43.848: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:43.850: INFO: Number of nodes with available pods: 2
Nov  5 20:44:43.850: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:44:44.848: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:44.850: INFO: Number of nodes with available pods: 2
Nov  5 20:44:44.850: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:44:45.848: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:44:45.850: INFO: Number of nodes with available pods: 3
Nov  5 20:44:45.850: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9843, will wait for the garbage collector to delete the pods
Nov  5 20:44:45.915: INFO: Deleting DaemonSet.extensions daemon-set took: 4.201987ms
Nov  5 20:44:46.215: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.1945ms
Nov  5 20:44:52.818: INFO: Number of nodes with available pods: 0
Nov  5 20:44:52.818: INFO: Number of running nodes: 0, number of available pods: 0
Nov  5 20:44:52.820: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9843/daemonsets","resourceVersion":"5306"},"items":null}

Nov  5 20:44:52.821: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9843/pods","resourceVersion":"5306"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:44:52.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9843" for this suite.
Nov  5 20:44:58.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:44:58.899: INFO: namespace daemonsets-9843 deletion completed in 6.066471557s

• [SLOW TEST:52.135 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:44:58.900: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:44:58.931: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf" in namespace "downward-api-2851" to be "success or failure"
Nov  5 20:44:58.933: INFO: Pod "downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.981044ms
Nov  5 20:45:00.935: INFO: Pod "downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004707937s
STEP: Saw pod success
Nov  5 20:45:00.935: INFO: Pod "downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf" satisfied condition "success or failure"
Nov  5 20:45:00.937: INFO: Trying to get logs from node k8s-node-3 pod downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf container client-container: <nil>
STEP: delete the pod
Nov  5 20:45:00.949: INFO: Waiting for pod downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf to disappear
Nov  5 20:45:00.952: INFO: Pod downwardapi-volume-6af3f6a3-75e3-4d64-8fc7-bed0162cdecf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:00.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2851" for this suite.
Nov  5 20:45:06.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:45:07.019: INFO: namespace downward-api-2851 deletion completed in 6.064282725s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:45:07.019: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  5 20:45:13.104: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 245
	[quantile=0.9] = 42798
	[quantile=0.99] = 180412
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 206005
	[quantile=0.9] = 252331
	[quantile=0.99] = 266828
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 7
	[quantile=0.9] = 219770
	[quantile=0.99] = 219770
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 1971
	[quantile=0.9] = 220155
	[quantile=0.99] = 220155
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 6
	[quantile=0.99] = 23
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 25
	[quantile=0.99] = 47
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 16
	[quantile=0.9] = 24
	[quantile=0.99] = 36
For namespace_queue_latency_sum:
	[] = 410
For namespace_queue_latency_count:
	[] = 25
For namespace_retries:
	[] = 26
For namespace_work_duration:
	[quantile=0.5] = 134071
	[quantile=0.9] = 153830
	[quantile=0.99] = 240793
For namespace_work_duration_sum:
	[] = 3469079
For namespace_work_duration_count:
	[] = 25
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:13.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8857" for this suite.
Nov  5 20:45:19.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:45:19.174: INFO: namespace gc-8857 deletion completed in 6.066082774s

• [SLOW TEST:12.155 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:45:19.175: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-380e3799-f86b-4192-bd5e-d5d6ae41e4e7
STEP: Creating a pod to test consume secrets
Nov  5 20:45:19.204: INFO: Waiting up to 5m0s for pod "pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a" in namespace "secrets-3976" to be "success or failure"
Nov  5 20:45:19.206: INFO: Pod "pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.474181ms
Nov  5 20:45:21.209: INFO: Pod "pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005415325s
STEP: Saw pod success
Nov  5 20:45:21.209: INFO: Pod "pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a" satisfied condition "success or failure"
Nov  5 20:45:21.211: INFO: Trying to get logs from node k8s-node-1 pod pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a container secret-env-test: <nil>
STEP: delete the pod
Nov  5 20:45:21.227: INFO: Waiting for pod pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a to disappear
Nov  5 20:45:21.229: INFO: Pod pod-secrets-4f32756f-2adf-4cfa-9290-8e5ffeda6a9a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:21.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3976" for this suite.
Nov  5 20:45:27.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:45:27.303: INFO: namespace secrets-3976 deletion completed in 6.07112117s

• [SLOW TEST:8.128 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:45:27.303: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:31.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7331" for this suite.
Nov  5 20:45:37.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:45:37.422: INFO: namespace emptydir-wrapper-7331 deletion completed in 6.065745017s

• [SLOW TEST:10.119 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:45:37.422: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5f8b1b7f-0ff6-40ac-a3d2-70fa20d21efb
STEP: Creating a pod to test consume secrets
Nov  5 20:45:37.450: INFO: Waiting up to 5m0s for pod "pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c" in namespace "secrets-2126" to be "success or failure"
Nov  5 20:45:37.453: INFO: Pod "pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313ms
Nov  5 20:45:39.455: INFO: Pod "pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00504777s
STEP: Saw pod success
Nov  5 20:45:39.455: INFO: Pod "pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c" satisfied condition "success or failure"
Nov  5 20:45:39.460: INFO: Trying to get logs from node k8s-node-1 pod pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 20:45:39.475: INFO: Waiting for pod pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c to disappear
Nov  5 20:45:39.477: INFO: Pod pod-secrets-da5e5855-9261-4fd1-956a-e915ca36849c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:39.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2126" for this suite.
Nov  5 20:45:45.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:45:45.549: INFO: namespace secrets-2126 deletion completed in 6.068116294s

• [SLOW TEST:8.127 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:45:45.549: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Nov  5 20:45:45.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-1073'
Nov  5 20:45:45.788: INFO: stderr: ""
Nov  5 20:45:45.788: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Nov  5 20:45:46.791: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:45:46.791: INFO: Found 0 / 1
Nov  5 20:45:47.791: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:45:47.791: INFO: Found 1 / 1
Nov  5 20:45:47.791: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  5 20:45:47.793: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:45:47.793: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov  5 20:45:47.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 logs redis-master-k75fk redis-master --namespace=kubectl-1073'
Nov  5 20:45:47.888: INFO: stderr: ""
Nov  5 20:45:47.888: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Nov 20:45:46.674 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Nov 20:45:46.674 # Server started, Redis version 3.2.12\n1:M 05 Nov 20:45:46.674 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Nov 20:45:46.674 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov  5 20:45:47.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 log redis-master-k75fk redis-master --namespace=kubectl-1073 --tail=1'
Nov  5 20:45:47.979: INFO: stderr: ""
Nov  5 20:45:47.979: INFO: stdout: "1:M 05 Nov 20:45:46.674 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov  5 20:45:47.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 log redis-master-k75fk redis-master --namespace=kubectl-1073 --limit-bytes=1'
Nov  5 20:45:48.081: INFO: stderr: ""
Nov  5 20:45:48.081: INFO: stdout: " "
STEP: exposing timestamps
Nov  5 20:45:48.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 log redis-master-k75fk redis-master --namespace=kubectl-1073 --tail=1 --timestamps'
Nov  5 20:45:48.181: INFO: stderr: ""
Nov  5 20:45:48.181: INFO: stdout: "2019-11-05T20:45:46.675851824Z 1:M 05 Nov 20:45:46.674 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov  5 20:45:50.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 log redis-master-k75fk redis-master --namespace=kubectl-1073 --since=1s'
Nov  5 20:45:50.785: INFO: stderr: ""
Nov  5 20:45:50.785: INFO: stdout: ""
Nov  5 20:45:50.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 log redis-master-k75fk redis-master --namespace=kubectl-1073 --since=24h'
Nov  5 20:45:50.875: INFO: stderr: ""
Nov  5 20:45:50.875: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Nov 20:45:46.674 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Nov 20:45:46.674 # Server started, Redis version 3.2.12\n1:M 05 Nov 20:45:46.674 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Nov 20:45:46.674 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Nov  5 20:45:50.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-1073'
Nov  5 20:45:50.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 20:45:50.964: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov  5 20:45:50.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1073'
Nov  5 20:45:51.060: INFO: stderr: "No resources found.\n"
Nov  5 20:45:51.060: INFO: stdout: ""
Nov  5 20:45:51.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=nginx --namespace=kubectl-1073 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 20:45:51.136: INFO: stderr: ""
Nov  5 20:45:51.136: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:45:51.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1073" for this suite.
Nov  5 20:46:13.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:46:13.203: INFO: namespace kubectl-1073 deletion completed in 22.063478752s

• [SLOW TEST:27.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:46:13.203: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 20:46:13.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-2044'
Nov  5 20:46:13.327: INFO: stderr: ""
Nov  5 20:46:13.327: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov  5 20:46:18.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pod e2e-test-nginx-pod --namespace=kubectl-2044 -o json'
Nov  5 20:46:18.462: INFO: stderr: ""
Nov  5 20:46:18.462: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-11-05T20:46:13Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-2044\",\n        \"resourceVersion\": \"5999\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2044/pods/e2e-test-nginx-pod\",\n        \"uid\": \"493d59fd-ca01-4368-84c9-58f04b32970c\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hbcpp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-node-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hbcpp\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hbcpp\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-05T20:46:13Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-05T20:46:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-05T20:46:14Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-05T20:46:13Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://d6784bf0f75dee3ac6e815fa955b77f17260b2d320b474bd5d9681c8074bc3b1\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-05T20:46:14Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.40.3.111\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.117.18\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-05T20:46:13Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  5 20:46:18.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 replace -f - --namespace=kubectl-2044'
Nov  5 20:46:18.603: INFO: stderr: ""
Nov  5 20:46:18.603: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Nov  5 20:46:18.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete pods e2e-test-nginx-pod --namespace=kubectl-2044'
Nov  5 20:46:20.697: INFO: stderr: ""
Nov  5 20:46:20.697: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:46:20.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2044" for this suite.
Nov  5 20:46:26.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:46:26.771: INFO: namespace kubectl-2044 deletion completed in 6.070588943s

• [SLOW TEST:13.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:46:26.771: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  5 20:46:26.810: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:26.812: INFO: Number of nodes with available pods: 0
Nov  5 20:46:26.812: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:46:27.815: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:27.818: INFO: Number of nodes with available pods: 1
Nov  5 20:46:27.818: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 20:46:28.815: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:28.817: INFO: Number of nodes with available pods: 3
Nov  5 20:46:28.817: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  5 20:46:28.827: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:28.830: INFO: Number of nodes with available pods: 2
Nov  5 20:46:28.830: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 20:46:29.834: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:29.837: INFO: Number of nodes with available pods: 2
Nov  5 20:46:29.837: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 20:46:30.834: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 20:46:30.837: INFO: Number of nodes with available pods: 3
Nov  5 20:46:30.837: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9113, will wait for the garbage collector to delete the pods
Nov  5 20:46:30.897: INFO: Deleting DaemonSet.extensions daemon-set took: 4.938638ms
Nov  5 20:46:31.197: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.226977ms
Nov  5 20:46:42.800: INFO: Number of nodes with available pods: 0
Nov  5 20:46:42.800: INFO: Number of running nodes: 0, number of available pods: 0
Nov  5 20:46:42.802: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9113/daemonsets","resourceVersion":"6175"},"items":null}

Nov  5 20:46:42.803: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9113/pods","resourceVersion":"6175"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:46:42.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9113" for this suite.
Nov  5 20:46:48.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:46:48.878: INFO: namespace daemonsets-9113 deletion completed in 6.063756819s

• [SLOW TEST:22.107 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:46:48.879: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-98bbf6d8-441b-4b4b-86b4-288d7a02c25f
STEP: Creating a pod to test consume secrets
Nov  5 20:46:48.926: INFO: Waiting up to 5m0s for pod "pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911" in namespace "secrets-2967" to be "success or failure"
Nov  5 20:46:48.929: INFO: Pod "pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.798928ms
Nov  5 20:46:50.932: INFO: Pod "pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005733219s
STEP: Saw pod success
Nov  5 20:46:50.932: INFO: Pod "pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911" satisfied condition "success or failure"
Nov  5 20:46:50.934: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 20:46:50.947: INFO: Waiting for pod pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911 to disappear
Nov  5 20:46:50.949: INFO: Pod pod-secrets-9bb34eaa-ad54-43bf-b9fa-94f64edc8911 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:46:50.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2967" for this suite.
Nov  5 20:46:56.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:46:57.021: INFO: namespace secrets-2967 deletion completed in 6.069100624s
STEP: Destroying namespace "secret-namespace-3378" for this suite.
Nov  5 20:47:03.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:47:03.085: INFO: namespace secret-namespace-3378 deletion completed in 6.063897478s

• [SLOW TEST:14.206 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:47:03.085: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:47:03.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9730" for this suite.
Nov  5 20:47:09.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:47:09.197: INFO: namespace kubelet-test-9730 deletion completed in 6.070551335s

• [SLOW TEST:6.112 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:47:09.197: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-b92e8d44-c8fb-4443-b029-77268f6be218
STEP: Creating a pod to test consume secrets
Nov  5 20:47:09.228: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e" in namespace "projected-7421" to be "success or failure"
Nov  5 20:47:09.229: INFO: Pod "pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716808ms
Nov  5 20:47:11.232: INFO: Pod "pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004633274s
STEP: Saw pod success
Nov  5 20:47:11.232: INFO: Pod "pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e" satisfied condition "success or failure"
Nov  5 20:47:11.234: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  5 20:47:11.250: INFO: Waiting for pod pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e to disappear
Nov  5 20:47:11.252: INFO: Pod pod-projected-secrets-b9bdae1d-18ec-405d-a412-f8e913f9085e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:47:11.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7421" for this suite.
Nov  5 20:47:17.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:47:17.333: INFO: namespace projected-7421 deletion completed in 6.078496675s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:47:17.334: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6010
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov  5 20:47:17.366: INFO: Found 0 stateful pods, waiting for 3
Nov  5 20:47:27.369: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 20:47:27.369: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 20:47:27.369: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  5 20:47:27.389: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  5 20:47:37.414: INFO: Updating stateful set ss2
Nov  5 20:47:37.420: INFO: Waiting for Pod statefulset-6010/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Nov  5 20:47:47.456: INFO: Found 2 stateful pods, waiting for 3
Nov  5 20:47:57.460: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 20:47:57.460: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 20:47:57.460: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  5 20:47:57.480: INFO: Updating stateful set ss2
Nov  5 20:47:57.490: INFO: Waiting for Pod statefulset-6010/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov  5 20:48:07.511: INFO: Updating stateful set ss2
Nov  5 20:48:07.515: INFO: Waiting for StatefulSet statefulset-6010/ss2 to complete update
Nov  5 20:48:07.515: INFO: Waiting for Pod statefulset-6010/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov  5 20:48:17.520: INFO: Deleting all statefulset in ns statefulset-6010
Nov  5 20:48:17.522: INFO: Scaling statefulset ss2 to 0
Nov  5 20:48:27.531: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 20:48:27.533: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:48:27.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6010" for this suite.
Nov  5 20:48:33.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:48:33.615: INFO: namespace statefulset-6010 deletion completed in 6.071933535s

• [SLOW TEST:76.282 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:48:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7142
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  5 20:48:33.638: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  5 20:48:59.692: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.114.15 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 20:48:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 20:49:00.822: INFO: Found all expected endpoints: [netserver-0]
Nov  5 20:49:00.825: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.117.23 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 20:49:00.825: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 20:49:01.948: INFO: Found all expected endpoints: [netserver-1]
Nov  5 20:49:01.950: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.113.24 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7142 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 20:49:01.950: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 20:49:03.073: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:49:03.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7142" for this suite.
Nov  5 20:49:25.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:49:25.141: INFO: namespace pod-network-test-7142 deletion completed in 22.064712058s

• [SLOW TEST:51.526 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:49:25.142: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  5 20:49:29.204: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:29.207: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:31.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:31.209: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:33.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:33.210: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:35.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:35.210: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:37.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:37.210: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:39.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:39.209: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:41.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:41.210: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:43.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:43.210: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:45.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:45.209: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:47.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:47.209: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 20:49:49.207: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 20:49:49.209: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:49:49.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8852" for this suite.
Nov  5 20:50:11.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:50:11.279: INFO: namespace container-lifecycle-hook-8852 deletion completed in 22.066864774s

• [SLOW TEST:46.138 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:50:11.279: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 20:50:11.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-3758'
Nov  5 20:50:11.399: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  5 20:50:11.399: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Nov  5 20:50:13.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3758'
Nov  5 20:50:13.505: INFO: stderr: ""
Nov  5 20:50:13.505: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:50:13.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3758" for this suite.
Nov  5 20:50:19.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:50:19.574: INFO: namespace kubectl-3758 deletion completed in 6.066358102s

• [SLOW TEST:8.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:50:19.574: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  5 20:50:19.600: INFO: Waiting up to 5m0s for pod "pod-905c307e-d1ec-44ea-a16b-07e5a16d7093" in namespace "emptydir-2020" to be "success or failure"
Nov  5 20:50:19.602: INFO: Pod "pod-905c307e-d1ec-44ea-a16b-07e5a16d7093": Phase="Pending", Reason="", readiness=false. Elapsed: 1.89665ms
Nov  5 20:50:21.605: INFO: Pod "pod-905c307e-d1ec-44ea-a16b-07e5a16d7093": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005076315s
STEP: Saw pod success
Nov  5 20:50:21.605: INFO: Pod "pod-905c307e-d1ec-44ea-a16b-07e5a16d7093" satisfied condition "success or failure"
Nov  5 20:50:21.607: INFO: Trying to get logs from node k8s-node-2 pod pod-905c307e-d1ec-44ea-a16b-07e5a16d7093 container test-container: <nil>
STEP: delete the pod
Nov  5 20:50:21.621: INFO: Waiting for pod pod-905c307e-d1ec-44ea-a16b-07e5a16d7093 to disappear
Nov  5 20:50:21.622: INFO: Pod pod-905c307e-d1ec-44ea-a16b-07e5a16d7093 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:50:21.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2020" for this suite.
Nov  5 20:50:27.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:50:27.691: INFO: namespace emptydir-2020 deletion completed in 6.066412284s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:50:27.692: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:50:27.716: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:50:29.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2517" for this suite.
Nov  5 20:51:13.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:51:13.918: INFO: namespace pods-2517 deletion completed in 44.066670696s

• [SLOW TEST:46.227 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:51:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov  5 20:51:13.946: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 20:51:13.951: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 20:51:13.953: INFO: 
Logging pods the kubelet thinks is on node k8s-node-1 before test
Nov  5 20:51:13.958: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-txwxh from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 20:51:13.958: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 20:51:13.958: INFO: nodelocaldns-p82tq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 20:51:13.958: INFO: sonobuoy from sonobuoy started at 2019-11-05 20:38:44 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 20:51:13.958: INFO: nginx-proxy-k8s-node-1 from kube-system started at 2019-11-05 20:15:32 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 20:51:13.958: INFO: kube-proxy-cd9zn from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 20:51:13.958: INFO: calico-node-rksqz from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.958: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 20:51:13.958: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Nov  5 20:51:13.966: INFO: nginx-proxy-k8s-node-2 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 20:51:13.966: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-llxsl from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 20:51:13.966: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 20:51:13.966: INFO: nodelocaldns-4xvgq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 20:51:13.966: INFO: kube-proxy-9v9z4 from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 20:51:13.966: INFO: calico-node-fdvf2 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 20:51:13.966: INFO: calico-kube-controllers-587d9754b8-4slnw from kube-system started at 2019-11-05 20:15:50 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.966: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 20:51:13.966: INFO: 
Logging pods the kubelet thinks is on node k8s-node-3 before test
Nov  5 20:51:13.973: INFO: coredns-74c9d4d795-7xz2x from kube-system started at 2019-11-05 20:16:10 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container coredns ready: true, restart count 0
Nov  5 20:51:13.973: INFO: sonobuoy-e2e-job-af538b29db5041da from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container e2e ready: true, restart count 0
Nov  5 20:51:13.973: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 20:51:13.973: INFO: nginx-proxy-k8s-node-3 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 20:51:13.973: INFO: kube-proxy-rs4vx from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 20:51:13.973: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-r67ng from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 20:51:13.973: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 20:51:13.973: INFO: calico-node-tr8c7 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 20:51:13.973: INFO: nodelocaldns-rj2f2 from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 20:51:13.973: INFO: 	Container node-cache ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b35ad31f-f522-4013-89c1-0979a1c68856 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b35ad31f-f522-4013-89c1-0979a1c68856 off the node k8s-node-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b35ad31f-f522-4013-89c1-0979a1c68856
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:51:20.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4749" for this suite.
Nov  5 20:51:28.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:51:28.098: INFO: namespace sched-pred-4749 deletion completed in 8.071059s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:14.179 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:51:28.098: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-6mzt
STEP: Creating a pod to test atomic-volume-subpath
Nov  5 20:51:28.129: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6mzt" in namespace "subpath-3273" to be "success or failure"
Nov  5 20:51:28.132: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.544183ms
Nov  5 20:51:30.134: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 2.00487147s
Nov  5 20:51:32.137: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 4.007801367s
Nov  5 20:51:34.140: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 6.010692018s
Nov  5 20:51:36.143: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 8.013555311s
Nov  5 20:51:38.146: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 10.016741566s
Nov  5 20:51:40.149: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 12.01972429s
Nov  5 20:51:42.151: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 14.022441626s
Nov  5 20:51:44.154: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 16.025204273s
Nov  5 20:51:46.157: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 18.027972188s
Nov  5 20:51:48.160: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Running", Reason="", readiness=true. Elapsed: 20.030904328s
Nov  5 20:51:50.163: INFO: Pod "pod-subpath-test-configmap-6mzt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034192838s
STEP: Saw pod success
Nov  5 20:51:50.163: INFO: Pod "pod-subpath-test-configmap-6mzt" satisfied condition "success or failure"
Nov  5 20:51:50.165: INFO: Trying to get logs from node k8s-node-1 pod pod-subpath-test-configmap-6mzt container test-container-subpath-configmap-6mzt: <nil>
STEP: delete the pod
Nov  5 20:51:50.181: INFO: Waiting for pod pod-subpath-test-configmap-6mzt to disappear
Nov  5 20:51:50.183: INFO: Pod pod-subpath-test-configmap-6mzt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6mzt
Nov  5 20:51:50.183: INFO: Deleting pod "pod-subpath-test-configmap-6mzt" in namespace "subpath-3273"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:51:50.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3273" for this suite.
Nov  5 20:51:56.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:51:56.260: INFO: namespace subpath-3273 deletion completed in 6.072358678s

• [SLOW TEST:28.162 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:51:56.260: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 20:51:56.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8042'
Nov  5 20:51:56.381: INFO: stderr: ""
Nov  5 20:51:56.381: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Nov  5 20:51:56.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete pods e2e-test-nginx-pod --namespace=kubectl-8042'
Nov  5 20:52:12.720: INFO: stderr: ""
Nov  5 20:52:12.720: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:52:12.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8042" for this suite.
Nov  5 20:52:18.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:52:18.794: INFO: namespace kubectl-8042 deletion completed in 6.071061988s

• [SLOW TEST:22.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:52:18.794: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6539/secret-test-00e1d9a3-92cc-4780-9691-8b7ef6c28c4d
STEP: Creating a pod to test consume secrets
Nov  5 20:52:18.824: INFO: Waiting up to 5m0s for pod "pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb" in namespace "secrets-6539" to be "success or failure"
Nov  5 20:52:18.825: INFO: Pod "pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.400655ms
Nov  5 20:52:20.828: INFO: Pod "pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004266144s
STEP: Saw pod success
Nov  5 20:52:20.828: INFO: Pod "pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb" satisfied condition "success or failure"
Nov  5 20:52:20.830: INFO: Trying to get logs from node k8s-node-1 pod pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb container env-test: <nil>
STEP: delete the pod
Nov  5 20:52:20.843: INFO: Waiting for pod pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb to disappear
Nov  5 20:52:20.845: INFO: Pod pod-configmaps-51d969b3-009f-4604-8c82-1e86a2587cfb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:52:20.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6539" for this suite.
Nov  5 20:52:26.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:52:26.947: INFO: namespace secrets-6539 deletion completed in 6.100008839s

• [SLOW TEST:8.153 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:52:26.948: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-8af8f6e6-9fab-469d-9488-df2c0093a295
STEP: Creating secret with name s-test-opt-upd-07a806d6-d702-44b3-a404-7f0e31f288a7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8af8f6e6-9fab-469d-9488-df2c0093a295
STEP: Updating secret s-test-opt-upd-07a806d6-d702-44b3-a404-7f0e31f288a7
STEP: Creating secret with name s-test-opt-create-d2a47c1f-75ae-4ac1-9193-ef4ca81c7229
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:52:31.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1562" for this suite.
Nov  5 20:52:53.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:52:53.109: INFO: namespace secrets-1562 deletion completed in 22.068785471s

• [SLOW TEST:26.161 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:52:53.109: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  5 20:52:53.136: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:53:02.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8848" for this suite.
Nov  5 20:53:08.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:53:08.762: INFO: namespace pods-8848 deletion completed in 6.070887595s

• [SLOW TEST:15.653 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:53:08.763: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:53:12.808: INFO: Waiting up to 5m0s for pod "client-envvars-592c729c-b070-4291-8134-c96e30e7569e" in namespace "pods-2520" to be "success or failure"
Nov  5 20:53:12.811: INFO: Pod "client-envvars-592c729c-b070-4291-8134-c96e30e7569e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.875509ms
Nov  5 20:53:14.814: INFO: Pod "client-envvars-592c729c-b070-4291-8134-c96e30e7569e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00581987s
STEP: Saw pod success
Nov  5 20:53:14.814: INFO: Pod "client-envvars-592c729c-b070-4291-8134-c96e30e7569e" satisfied condition "success or failure"
Nov  5 20:53:14.816: INFO: Trying to get logs from node k8s-node-1 pod client-envvars-592c729c-b070-4291-8134-c96e30e7569e container env3cont: <nil>
STEP: delete the pod
Nov  5 20:53:14.831: INFO: Waiting for pod client-envvars-592c729c-b070-4291-8134-c96e30e7569e to disappear
Nov  5 20:53:14.833: INFO: Pod client-envvars-592c729c-b070-4291-8134-c96e30e7569e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:53:14.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2520" for this suite.
Nov  5 20:54:04.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:54:04.902: INFO: namespace pods-2520 deletion completed in 50.065549367s

• [SLOW TEST:56.139 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:54:04.902: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov  5 20:54:04.946: INFO: namespace kubectl-4510
Nov  5 20:54:04.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-4510'
Nov  5 20:54:05.140: INFO: stderr: ""
Nov  5 20:54:05.140: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  5 20:54:06.143: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:54:06.143: INFO: Found 0 / 1
Nov  5 20:54:07.143: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:54:07.143: INFO: Found 1 / 1
Nov  5 20:54:07.143: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  5 20:54:07.145: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 20:54:07.145: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 20:54:07.145: INFO: wait on redis-master startup in kubectl-4510 
Nov  5 20:54:07.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 logs redis-master-774lj redis-master --namespace=kubectl-4510'
Nov  5 20:54:07.244: INFO: stderr: ""
Nov  5 20:54:07.244: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 05 Nov 20:54:05.987 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Nov 20:54:05.987 # Server started, Redis version 3.2.12\n1:M 05 Nov 20:54:05.988 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Nov 20:54:05.988 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov  5 20:54:07.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4510'
Nov  5 20:54:07.343: INFO: stderr: ""
Nov  5 20:54:07.343: INFO: stdout: "service/rm2 exposed\n"
Nov  5 20:54:07.346: INFO: Service rm2 in namespace kubectl-4510 found.
STEP: exposing service
Nov  5 20:54:09.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4510'
Nov  5 20:54:09.439: INFO: stderr: ""
Nov  5 20:54:09.439: INFO: stdout: "service/rm3 exposed\n"
Nov  5 20:54:09.442: INFO: Service rm3 in namespace kubectl-4510 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:54:11.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4510" for this suite.
Nov  5 20:54:33.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:54:33.516: INFO: namespace kubectl-4510 deletion completed in 22.067362447s

• [SLOW TEST:28.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:54:33.517: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  5 20:54:33.543: INFO: Waiting up to 5m0s for pod "pod-d1661f8d-9908-43a8-b012-c64417912eb7" in namespace "emptydir-2092" to be "success or failure"
Nov  5 20:54:33.544: INFO: Pod "pod-d1661f8d-9908-43a8-b012-c64417912eb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.571236ms
Nov  5 20:54:35.548: INFO: Pod "pod-d1661f8d-9908-43a8-b012-c64417912eb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004691959s
STEP: Saw pod success
Nov  5 20:54:35.548: INFO: Pod "pod-d1661f8d-9908-43a8-b012-c64417912eb7" satisfied condition "success or failure"
Nov  5 20:54:35.550: INFO: Trying to get logs from node k8s-node-1 pod pod-d1661f8d-9908-43a8-b012-c64417912eb7 container test-container: <nil>
STEP: delete the pod
Nov  5 20:54:35.565: INFO: Waiting for pod pod-d1661f8d-9908-43a8-b012-c64417912eb7 to disappear
Nov  5 20:54:35.567: INFO: Pod pod-d1661f8d-9908-43a8-b012-c64417912eb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:54:35.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2092" for this suite.
Nov  5 20:54:41.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:54:41.643: INFO: namespace emptydir-2092 deletion completed in 6.07195424s

• [SLOW TEST:8.126 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:54:41.643: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:54:41.666: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  5 20:54:41.671: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  5 20:54:46.674: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  5 20:54:46.674: INFO: Creating deployment "test-rolling-update-deployment"
Nov  5 20:54:46.677: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  5 20:54:46.681: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  5 20:54:48.686: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  5 20:54:48.688: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov  5 20:54:48.695: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-9407,SelfLink:/apis/apps/v1/namespaces/deployment-9407/deployments/test-rolling-update-deployment,UID:226eae01-f609-4486-8738-8184af91bf2b,ResourceVersion:8312,Generation:1,CreationTimestamp:2019-11-05 20:54:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-05 20:54:46 +0000 UTC 2019-11-05 20:54:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-05 20:54:48 +0000 UTC 2019-11-05 20:54:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 20:54:48.697: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-9407,SelfLink:/apis/apps/v1/namespaces/deployment-9407/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:1d44c24c-2671-4a0d-9927-7c532d5e13ae,ResourceVersion:8301,Generation:1,CreationTimestamp:2019-11-05 20:54:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 226eae01-f609-4486-8738-8184af91bf2b 0xc00304b437 0xc00304b438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  5 20:54:48.697: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  5 20:54:48.697: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-9407,SelfLink:/apis/apps/v1/namespaces/deployment-9407/replicasets/test-rolling-update-controller,UID:ebdacff1-e16e-48b7-9ac3-11ef33373026,ResourceVersion:8310,Generation:2,CreationTimestamp:2019-11-05 20:54:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 226eae01-f609-4486-8738-8184af91bf2b 0xc00304b35f 0xc00304b370}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 20:54:48.700: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-s2chv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-s2chv,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-9407,SelfLink:/api/v1/namespaces/deployment-9407/pods/test-rolling-update-deployment-79f6b9d75c-s2chv,UID:abc80a15-d9f0-4510-8e9e-64b983f36095,ResourceVersion:8300,Generation:0,CreationTimestamp:2019-11-05 20:54:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 1d44c24c-2671-4a0d-9927-7c532d5e13ae 0xc00304bd67 0xc00304bd68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qzrb8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qzrb8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qzrb8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00304bde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00304be00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 20:54:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 20:54:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 20:54:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 20:54:46 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.32,StartTime:2019-11-05 20:54:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-05 20:54:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c02a954f54aa082392f27a3e73ed59fddfd7ef77bd3e979e103d2c835e9983cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:54:48.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9407" for this suite.
Nov  5 20:54:54.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:54:54.778: INFO: namespace deployment-9407 deletion completed in 6.075244914s

• [SLOW TEST:13.135 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:54:54.778: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:54:54.803: INFO: Creating ReplicaSet my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06
Nov  5 20:54:54.808: INFO: Pod name my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06: Found 0 pods out of 1
Nov  5 20:54:59.811: INFO: Pod name my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06: Found 1 pods out of 1
Nov  5 20:54:59.811: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06" is running
Nov  5 20:54:59.813: INFO: Pod "my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06-zhnj5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 20:54:54 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 20:54:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 20:54:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 20:54:54 +0000 UTC Reason: Message:}])
Nov  5 20:54:59.813: INFO: Trying to dial the pod
Nov  5 20:55:04.822: INFO: Controller my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06: Got expected result from replica 1 [my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06-zhnj5]: "my-hostname-basic-0f62e352-50d9-49af-bf7d-f520da0aaf06-zhnj5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:04.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1065" for this suite.
Nov  5 20:55:10.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:55:10.890: INFO: namespace replicaset-1065 deletion completed in 6.064650396s

• [SLOW TEST:16.112 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:55:10.890: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Nov  5 20:55:10.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-1396'
Nov  5 20:55:11.058: INFO: stderr: ""
Nov  5 20:55:11.058: INFO: stdout: "pod/pause created\n"
Nov  5 20:55:11.058: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  5 20:55:11.058: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1396" to be "running and ready"
Nov  5 20:55:11.061: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595643ms
Nov  5 20:55:13.064: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005218993s
Nov  5 20:55:13.064: INFO: Pod "pause" satisfied condition "running and ready"
Nov  5 20:55:13.064: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  5 20:55:13.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 label pods pause testing-label=testing-label-value --namespace=kubectl-1396'
Nov  5 20:55:13.148: INFO: stderr: ""
Nov  5 20:55:13.148: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  5 20:55:13.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pod pause -L testing-label --namespace=kubectl-1396'
Nov  5 20:55:13.232: INFO: stderr: ""
Nov  5 20:55:13.232: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  5 20:55:13.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 label pods pause testing-label- --namespace=kubectl-1396'
Nov  5 20:55:13.313: INFO: stderr: ""
Nov  5 20:55:13.313: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  5 20:55:13.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pod pause -L testing-label --namespace=kubectl-1396'
Nov  5 20:55:13.393: INFO: stderr: ""
Nov  5 20:55:13.393: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Nov  5 20:55:13.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-1396'
Nov  5 20:55:13.477: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 20:55:13.477: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  5 20:55:13.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=pause --no-headers --namespace=kubectl-1396'
Nov  5 20:55:13.573: INFO: stderr: "No resources found.\n"
Nov  5 20:55:13.574: INFO: stdout: ""
Nov  5 20:55:13.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=pause --namespace=kubectl-1396 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 20:55:13.655: INFO: stderr: ""
Nov  5 20:55:13.655: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:13.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1396" for this suite.
Nov  5 20:55:19.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:55:19.722: INFO: namespace kubectl-1396 deletion completed in 6.06369713s

• [SLOW TEST:8.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:55:19.722: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 20:55:19.759: INFO: (0) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 6.992238ms)
Nov  5 20:55:19.762: INFO: (1) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.63056ms)
Nov  5 20:55:19.765: INFO: (2) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.476935ms)
Nov  5 20:55:19.767: INFO: (3) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.632676ms)
Nov  5 20:55:19.770: INFO: (4) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.7687ms)
Nov  5 20:55:19.773: INFO: (5) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.520124ms)
Nov  5 20:55:19.775: INFO: (6) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.581668ms)
Nov  5 20:55:19.778: INFO: (7) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.456851ms)
Nov  5 20:55:19.780: INFO: (8) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.382417ms)
Nov  5 20:55:19.783: INFO: (9) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.560035ms)
Nov  5 20:55:19.785: INFO: (10) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.286952ms)
Nov  5 20:55:19.788: INFO: (11) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.689252ms)
Nov  5 20:55:19.790: INFO: (12) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.414592ms)
Nov  5 20:55:19.792: INFO: (13) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.301228ms)
Nov  5 20:55:19.795: INFO: (14) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.888434ms)
Nov  5 20:55:19.798: INFO: (15) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.465157ms)
Nov  5 20:55:19.800: INFO: (16) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.277917ms)
Nov  5 20:55:19.803: INFO: (17) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.407792ms)
Nov  5 20:55:19.805: INFO: (18) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.495265ms)
Nov  5 20:55:19.808: INFO: (19) /api/v1/nodes/k8s-node-1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.599811ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:19.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8628" for this suite.
Nov  5 20:55:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:55:25.875: INFO: namespace proxy-8628 deletion completed in 6.064098129s

• [SLOW TEST:6.153 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:55:25.875: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  5 20:55:27.915: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-243470310 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  5 20:55:32.993: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:32.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6850" for this suite.
Nov  5 20:55:39.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:55:39.061: INFO: namespace pods-6850 deletion completed in 6.063429913s

• [SLOW TEST:13.186 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:55:39.061: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3472
I1105 20:55:39.086165      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3472, replica count: 1
I1105 20:55:40.136509      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 20:55:41.136708      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 20:55:41.242: INFO: Created: latency-svc-j4dnh
Nov  5 20:55:41.246: INFO: Got endpoints: latency-svc-j4dnh [9.363046ms]
Nov  5 20:55:41.254: INFO: Created: latency-svc-qf5zc
Nov  5 20:55:41.258: INFO: Created: latency-svc-vtxw8
Nov  5 20:55:41.258: INFO: Got endpoints: latency-svc-qf5zc [12.274678ms]
Nov  5 20:55:41.262: INFO: Got endpoints: latency-svc-vtxw8 [15.110263ms]
Nov  5 20:55:41.264: INFO: Created: latency-svc-r9nqj
Nov  5 20:55:41.268: INFO: Got endpoints: latency-svc-r9nqj [21.345672ms]
Nov  5 20:55:41.269: INFO: Created: latency-svc-f4g2k
Nov  5 20:55:41.272: INFO: Created: latency-svc-kmk4p
Nov  5 20:55:41.272: INFO: Got endpoints: latency-svc-f4g2k [25.552434ms]
Nov  5 20:55:41.277: INFO: Created: latency-svc-f4lpd
Nov  5 20:55:41.277: INFO: Got endpoints: latency-svc-kmk4p [29.50493ms]
Nov  5 20:55:41.281: INFO: Got endpoints: latency-svc-f4lpd [33.326686ms]
Nov  5 20:55:41.284: INFO: Created: latency-svc-ckfn2
Nov  5 20:55:41.286: INFO: Got endpoints: latency-svc-ckfn2 [38.181186ms]
Nov  5 20:55:41.287: INFO: Created: latency-svc-7f275
Nov  5 20:55:41.291: INFO: Got endpoints: latency-svc-7f275 [42.47772ms]
Nov  5 20:55:41.291: INFO: Created: latency-svc-zpbg4
Nov  5 20:55:41.296: INFO: Got endpoints: latency-svc-zpbg4 [48.144655ms]
Nov  5 20:55:41.296: INFO: Created: latency-svc-24c8m
Nov  5 20:55:41.303: INFO: Created: latency-svc-h6whl
Nov  5 20:55:41.303: INFO: Got endpoints: latency-svc-24c8m [54.188798ms]
Nov  5 20:55:41.306: INFO: Got endpoints: latency-svc-h6whl [58.377344ms]
Nov  5 20:55:41.308: INFO: Created: latency-svc-9rs5p
Nov  5 20:55:41.310: INFO: Got endpoints: latency-svc-9rs5p [61.473349ms]
Nov  5 20:55:41.311: INFO: Created: latency-svc-t5m5v
Nov  5 20:55:41.314: INFO: Got endpoints: latency-svc-t5m5v [65.038921ms]
Nov  5 20:55:41.316: INFO: Created: latency-svc-fdmmn
Nov  5 20:55:41.319: INFO: Created: latency-svc-fqq59
Nov  5 20:55:41.320: INFO: Got endpoints: latency-svc-fdmmn [71.68133ms]
Nov  5 20:55:41.324: INFO: Created: latency-svc-mfw5s
Nov  5 20:55:41.325: INFO: Got endpoints: latency-svc-fqq59 [76.124121ms]
Nov  5 20:55:41.329: INFO: Got endpoints: latency-svc-mfw5s [70.782292ms]
Nov  5 20:55:41.331: INFO: Created: latency-svc-4gh8n
Nov  5 20:55:41.340: INFO: Got endpoints: latency-svc-4gh8n [78.456576ms]
Nov  5 20:55:41.344: INFO: Created: latency-svc-rks6v
Nov  5 20:55:41.349: INFO: Created: latency-svc-skwjs
Nov  5 20:55:41.350: INFO: Got endpoints: latency-svc-rks6v [82.130992ms]
Nov  5 20:55:41.353: INFO: Got endpoints: latency-svc-skwjs [80.904334ms]
Nov  5 20:55:41.356: INFO: Created: latency-svc-lrpx5
Nov  5 20:55:41.359: INFO: Got endpoints: latency-svc-lrpx5 [82.55822ms]
Nov  5 20:55:41.361: INFO: Created: latency-svc-q6sz8
Nov  5 20:55:41.364: INFO: Created: latency-svc-n7w4c
Nov  5 20:55:41.365: INFO: Got endpoints: latency-svc-q6sz8 [83.549646ms]
Nov  5 20:55:41.371: INFO: Got endpoints: latency-svc-n7w4c [84.595886ms]
Nov  5 20:55:41.372: INFO: Created: latency-svc-xvrj7
Nov  5 20:55:41.375: INFO: Got endpoints: latency-svc-xvrj7 [83.685129ms]
Nov  5 20:55:41.375: INFO: Created: latency-svc-jx4zs
Nov  5 20:55:41.380: INFO: Got endpoints: latency-svc-jx4zs [83.049132ms]
Nov  5 20:55:41.380: INFO: Created: latency-svc-6gtrx
Nov  5 20:55:41.381: INFO: Got endpoints: latency-svc-6gtrx [78.377246ms]
Nov  5 20:55:41.384: INFO: Created: latency-svc-6t82m
Nov  5 20:55:41.388: INFO: Got endpoints: latency-svc-6t82m [81.774505ms]
Nov  5 20:55:41.390: INFO: Created: latency-svc-zpdhf
Nov  5 20:55:41.394: INFO: Got endpoints: latency-svc-zpdhf [83.510131ms]
Nov  5 20:55:41.397: INFO: Created: latency-svc-97sjs
Nov  5 20:55:41.401: INFO: Created: latency-svc-9psb7
Nov  5 20:55:41.401: INFO: Got endpoints: latency-svc-97sjs [87.206151ms]
Nov  5 20:55:41.405: INFO: Got endpoints: latency-svc-9psb7 [84.223488ms]
Nov  5 20:55:41.406: INFO: Created: latency-svc-wqrpq
Nov  5 20:55:41.409: INFO: Got endpoints: latency-svc-wqrpq [83.731453ms]
Nov  5 20:55:41.409: INFO: Created: latency-svc-gwsdt
Nov  5 20:55:41.414: INFO: Got endpoints: latency-svc-gwsdt [84.540956ms]
Nov  5 20:55:41.415: INFO: Created: latency-svc-r87xh
Nov  5 20:55:41.420: INFO: Got endpoints: latency-svc-r87xh [79.57395ms]
Nov  5 20:55:41.420: INFO: Created: latency-svc-lm4k7
Nov  5 20:55:41.425: INFO: Created: latency-svc-77qgr
Nov  5 20:55:41.428: INFO: Created: latency-svc-f86dd
Nov  5 20:55:41.432: INFO: Created: latency-svc-6mnz6
Nov  5 20:55:41.436: INFO: Created: latency-svc-pbbmc
Nov  5 20:55:41.439: INFO: Created: latency-svc-pbrqh
Nov  5 20:55:41.443: INFO: Created: latency-svc-s6lnb
Nov  5 20:55:41.447: INFO: Created: latency-svc-xb2lm
Nov  5 20:55:41.447: INFO: Got endpoints: latency-svc-lm4k7 [96.920773ms]
Nov  5 20:55:41.450: INFO: Created: latency-svc-rcmqb
Nov  5 20:55:41.452: INFO: Created: latency-svc-dj6bm
Nov  5 20:55:41.455: INFO: Created: latency-svc-4mdwr
Nov  5 20:55:41.459: INFO: Created: latency-svc-njvj9
Nov  5 20:55:41.463: INFO: Created: latency-svc-78p65
Nov  5 20:55:41.468: INFO: Created: latency-svc-tgczf
Nov  5 20:55:41.470: INFO: Created: latency-svc-ptpc6
Nov  5 20:55:41.474: INFO: Created: latency-svc-vplgn
Nov  5 20:55:41.498: INFO: Got endpoints: latency-svc-77qgr [144.275949ms]
Nov  5 20:55:41.505: INFO: Created: latency-svc-m7wr7
Nov  5 20:55:41.546: INFO: Got endpoints: latency-svc-f86dd [186.513719ms]
Nov  5 20:55:41.551: INFO: Created: latency-svc-rngwd
Nov  5 20:55:41.596: INFO: Got endpoints: latency-svc-6mnz6 [231.819316ms]
Nov  5 20:55:41.602: INFO: Created: latency-svc-pbv86
Nov  5 20:55:41.647: INFO: Got endpoints: latency-svc-pbbmc [276.400271ms]
Nov  5 20:55:41.654: INFO: Created: latency-svc-fnk9b
Nov  5 20:55:41.697: INFO: Got endpoints: latency-svc-pbrqh [322.190888ms]
Nov  5 20:55:41.703: INFO: Created: latency-svc-r9vn7
Nov  5 20:55:41.746: INFO: Got endpoints: latency-svc-s6lnb [366.511379ms]
Nov  5 20:55:41.752: INFO: Created: latency-svc-df2ds
Nov  5 20:55:41.797: INFO: Got endpoints: latency-svc-xb2lm [415.858991ms]
Nov  5 20:55:41.803: INFO: Created: latency-svc-8jmt9
Nov  5 20:55:41.846: INFO: Got endpoints: latency-svc-rcmqb [458.459851ms]
Nov  5 20:55:41.852: INFO: Created: latency-svc-nd656
Nov  5 20:55:41.898: INFO: Got endpoints: latency-svc-dj6bm [504.022749ms]
Nov  5 20:55:41.904: INFO: Created: latency-svc-lhkdx
Nov  5 20:55:41.947: INFO: Got endpoints: latency-svc-4mdwr [545.858284ms]
Nov  5 20:55:41.953: INFO: Created: latency-svc-bsm78
Nov  5 20:55:41.997: INFO: Got endpoints: latency-svc-njvj9 [592.512144ms]
Nov  5 20:55:42.003: INFO: Created: latency-svc-wfb2f
Nov  5 20:55:42.046: INFO: Got endpoints: latency-svc-78p65 [637.818191ms]
Nov  5 20:55:42.054: INFO: Created: latency-svc-z6fbz
Nov  5 20:55:42.097: INFO: Got endpoints: latency-svc-tgczf [683.431619ms]
Nov  5 20:55:42.106: INFO: Created: latency-svc-4jp85
Nov  5 20:55:42.147: INFO: Got endpoints: latency-svc-ptpc6 [727.067026ms]
Nov  5 20:55:42.152: INFO: Created: latency-svc-b55pd
Nov  5 20:55:42.196: INFO: Got endpoints: latency-svc-vplgn [749.230501ms]
Nov  5 20:55:42.204: INFO: Created: latency-svc-8q82b
Nov  5 20:55:42.246: INFO: Got endpoints: latency-svc-m7wr7 [748.350624ms]
Nov  5 20:55:42.252: INFO: Created: latency-svc-79sqf
Nov  5 20:55:42.296: INFO: Got endpoints: latency-svc-rngwd [749.792522ms]
Nov  5 20:55:42.303: INFO: Created: latency-svc-bf76n
Nov  5 20:55:42.346: INFO: Got endpoints: latency-svc-pbv86 [749.679478ms]
Nov  5 20:55:42.352: INFO: Created: latency-svc-9hmtw
Nov  5 20:55:42.396: INFO: Got endpoints: latency-svc-fnk9b [748.623451ms]
Nov  5 20:55:42.402: INFO: Created: latency-svc-vtg5t
Nov  5 20:55:42.448: INFO: Got endpoints: latency-svc-r9vn7 [750.835782ms]
Nov  5 20:55:42.454: INFO: Created: latency-svc-jfs5h
Nov  5 20:55:42.496: INFO: Got endpoints: latency-svc-df2ds [749.988675ms]
Nov  5 20:55:42.501: INFO: Created: latency-svc-k5rnf
Nov  5 20:55:42.548: INFO: Got endpoints: latency-svc-8jmt9 [750.809449ms]
Nov  5 20:55:42.553: INFO: Created: latency-svc-2xm76
Nov  5 20:55:42.596: INFO: Got endpoints: latency-svc-nd656 [749.660033ms]
Nov  5 20:55:42.602: INFO: Created: latency-svc-58wv2
Nov  5 20:55:42.646: INFO: Got endpoints: latency-svc-lhkdx [748.043431ms]
Nov  5 20:55:42.651: INFO: Created: latency-svc-j89bt
Nov  5 20:55:42.696: INFO: Got endpoints: latency-svc-bsm78 [749.664662ms]
Nov  5 20:55:42.703: INFO: Created: latency-svc-bdb2l
Nov  5 20:55:42.746: INFO: Got endpoints: latency-svc-wfb2f [749.187982ms]
Nov  5 20:55:42.752: INFO: Created: latency-svc-t5xg2
Nov  5 20:55:42.797: INFO: Got endpoints: latency-svc-z6fbz [749.784748ms]
Nov  5 20:55:42.803: INFO: Created: latency-svc-nhsbt
Nov  5 20:55:42.847: INFO: Got endpoints: latency-svc-4jp85 [749.830542ms]
Nov  5 20:55:42.854: INFO: Created: latency-svc-bfwdb
Nov  5 20:55:42.898: INFO: Got endpoints: latency-svc-b55pd [750.95978ms]
Nov  5 20:55:42.903: INFO: Created: latency-svc-xvcjz
Nov  5 20:55:42.947: INFO: Got endpoints: latency-svc-8q82b [750.122285ms]
Nov  5 20:55:42.954: INFO: Created: latency-svc-rhjrt
Nov  5 20:55:42.996: INFO: Got endpoints: latency-svc-79sqf [750.27842ms]
Nov  5 20:55:43.002: INFO: Created: latency-svc-cgpm7
Nov  5 20:55:43.046: INFO: Got endpoints: latency-svc-bf76n [750.090161ms]
Nov  5 20:55:43.051: INFO: Created: latency-svc-2gqh8
Nov  5 20:55:43.096: INFO: Got endpoints: latency-svc-9hmtw [749.574082ms]
Nov  5 20:55:43.102: INFO: Created: latency-svc-rcjwb
Nov  5 20:55:43.146: INFO: Got endpoints: latency-svc-vtg5t [750.449231ms]
Nov  5 20:55:43.153: INFO: Created: latency-svc-hcqlm
Nov  5 20:55:43.196: INFO: Got endpoints: latency-svc-jfs5h [748.120867ms]
Nov  5 20:55:43.202: INFO: Created: latency-svc-qcqh5
Nov  5 20:55:43.247: INFO: Got endpoints: latency-svc-k5rnf [750.63189ms]
Nov  5 20:55:43.257: INFO: Created: latency-svc-pgfsw
Nov  5 20:55:43.296: INFO: Got endpoints: latency-svc-2xm76 [748.23714ms]
Nov  5 20:55:43.302: INFO: Created: latency-svc-g4frb
Nov  5 20:55:43.346: INFO: Got endpoints: latency-svc-58wv2 [750.057854ms]
Nov  5 20:55:43.353: INFO: Created: latency-svc-hg6wg
Nov  5 20:55:43.396: INFO: Got endpoints: latency-svc-j89bt [750.175697ms]
Nov  5 20:55:43.402: INFO: Created: latency-svc-spvkf
Nov  5 20:55:43.447: INFO: Got endpoints: latency-svc-bdb2l [750.294079ms]
Nov  5 20:55:43.454: INFO: Created: latency-svc-p4qsj
Nov  5 20:55:43.497: INFO: Got endpoints: latency-svc-t5xg2 [750.741871ms]
Nov  5 20:55:43.504: INFO: Created: latency-svc-dgcwf
Nov  5 20:55:43.546: INFO: Got endpoints: latency-svc-nhsbt [749.670944ms]
Nov  5 20:55:43.552: INFO: Created: latency-svc-7sxd4
Nov  5 20:55:43.597: INFO: Got endpoints: latency-svc-bfwdb [749.651819ms]
Nov  5 20:55:43.605: INFO: Created: latency-svc-qb7q4
Nov  5 20:55:43.647: INFO: Got endpoints: latency-svc-xvcjz [749.216372ms]
Nov  5 20:55:43.654: INFO: Created: latency-svc-4gz4v
Nov  5 20:55:43.696: INFO: Got endpoints: latency-svc-rhjrt [749.250378ms]
Nov  5 20:55:43.702: INFO: Created: latency-svc-sb4t6
Nov  5 20:55:43.747: INFO: Got endpoints: latency-svc-cgpm7 [750.636311ms]
Nov  5 20:55:43.754: INFO: Created: latency-svc-t9z4m
Nov  5 20:55:43.796: INFO: Got endpoints: latency-svc-2gqh8 [750.457481ms]
Nov  5 20:55:43.804: INFO: Created: latency-svc-dvvnj
Nov  5 20:55:43.847: INFO: Got endpoints: latency-svc-rcjwb [751.536757ms]
Nov  5 20:55:43.853: INFO: Created: latency-svc-hgjg6
Nov  5 20:55:43.897: INFO: Got endpoints: latency-svc-hcqlm [750.257602ms]
Nov  5 20:55:43.903: INFO: Created: latency-svc-f7k4w
Nov  5 20:55:43.947: INFO: Got endpoints: latency-svc-qcqh5 [751.317279ms]
Nov  5 20:55:43.953: INFO: Created: latency-svc-9nzrc
Nov  5 20:55:43.996: INFO: Got endpoints: latency-svc-pgfsw [749.193408ms]
Nov  5 20:55:44.002: INFO: Created: latency-svc-mrwkq
Nov  5 20:55:44.047: INFO: Got endpoints: latency-svc-g4frb [750.387805ms]
Nov  5 20:55:44.052: INFO: Created: latency-svc-nhmbj
Nov  5 20:55:44.097: INFO: Got endpoints: latency-svc-hg6wg [750.760875ms]
Nov  5 20:55:44.103: INFO: Created: latency-svc-v26md
Nov  5 20:55:44.146: INFO: Got endpoints: latency-svc-spvkf [749.723091ms]
Nov  5 20:55:44.152: INFO: Created: latency-svc-qvpm5
Nov  5 20:55:44.198: INFO: Got endpoints: latency-svc-p4qsj [750.957871ms]
Nov  5 20:55:44.203: INFO: Created: latency-svc-5pszk
Nov  5 20:55:44.246: INFO: Got endpoints: latency-svc-dgcwf [748.855967ms]
Nov  5 20:55:44.252: INFO: Created: latency-svc-hnrf7
Nov  5 20:55:44.297: INFO: Got endpoints: latency-svc-7sxd4 [750.931369ms]
Nov  5 20:55:44.303: INFO: Created: latency-svc-z9ftt
Nov  5 20:55:44.346: INFO: Got endpoints: latency-svc-qb7q4 [749.421363ms]
Nov  5 20:55:44.353: INFO: Created: latency-svc-n9vjf
Nov  5 20:55:44.396: INFO: Got endpoints: latency-svc-4gz4v [749.083675ms]
Nov  5 20:55:44.404: INFO: Created: latency-svc-kbdsq
Nov  5 20:55:44.448: INFO: Got endpoints: latency-svc-sb4t6 [751.729433ms]
Nov  5 20:55:44.453: INFO: Created: latency-svc-8h7vf
Nov  5 20:55:44.497: INFO: Got endpoints: latency-svc-t9z4m [750.022422ms]
Nov  5 20:55:44.503: INFO: Created: latency-svc-qt6zk
Nov  5 20:55:44.546: INFO: Got endpoints: latency-svc-dvvnj [750.005847ms]
Nov  5 20:55:44.556: INFO: Created: latency-svc-cdlr2
Nov  5 20:55:44.597: INFO: Got endpoints: latency-svc-hgjg6 [749.972432ms]
Nov  5 20:55:44.603: INFO: Created: latency-svc-qwh2b
Nov  5 20:55:44.646: INFO: Got endpoints: latency-svc-f7k4w [749.818328ms]
Nov  5 20:55:44.654: INFO: Created: latency-svc-bqvf2
Nov  5 20:55:44.696: INFO: Got endpoints: latency-svc-9nzrc [748.839451ms]
Nov  5 20:55:44.701: INFO: Created: latency-svc-xbd9p
Nov  5 20:55:44.746: INFO: Got endpoints: latency-svc-mrwkq [750.373767ms]
Nov  5 20:55:44.754: INFO: Created: latency-svc-hf9tz
Nov  5 20:55:44.797: INFO: Got endpoints: latency-svc-nhmbj [750.124301ms]
Nov  5 20:55:44.806: INFO: Created: latency-svc-wzd48
Nov  5 20:55:44.846: INFO: Got endpoints: latency-svc-v26md [749.081033ms]
Nov  5 20:55:44.852: INFO: Created: latency-svc-mjxdr
Nov  5 20:55:44.896: INFO: Got endpoints: latency-svc-qvpm5 [749.822611ms]
Nov  5 20:55:44.903: INFO: Created: latency-svc-6fhd5
Nov  5 20:55:44.946: INFO: Got endpoints: latency-svc-5pszk [748.583422ms]
Nov  5 20:55:44.951: INFO: Created: latency-svc-8cs6h
Nov  5 20:55:44.996: INFO: Got endpoints: latency-svc-hnrf7 [750.08851ms]
Nov  5 20:55:45.002: INFO: Created: latency-svc-4xms9
Nov  5 20:55:45.047: INFO: Got endpoints: latency-svc-z9ftt [749.429598ms]
Nov  5 20:55:45.052: INFO: Created: latency-svc-sfwqc
Nov  5 20:55:45.097: INFO: Got endpoints: latency-svc-n9vjf [750.428352ms]
Nov  5 20:55:45.103: INFO: Created: latency-svc-m67ff
Nov  5 20:55:45.149: INFO: Got endpoints: latency-svc-kbdsq [752.902586ms]
Nov  5 20:55:45.157: INFO: Created: latency-svc-dkpcl
Nov  5 20:55:45.196: INFO: Got endpoints: latency-svc-8h7vf [748.286507ms]
Nov  5 20:55:45.202: INFO: Created: latency-svc-2kxfl
Nov  5 20:55:45.247: INFO: Got endpoints: latency-svc-qt6zk [749.752641ms]
Nov  5 20:55:45.256: INFO: Created: latency-svc-56rqq
Nov  5 20:55:45.296: INFO: Got endpoints: latency-svc-cdlr2 [749.401084ms]
Nov  5 20:55:45.301: INFO: Created: latency-svc-n7gpw
Nov  5 20:55:45.346: INFO: Got endpoints: latency-svc-qwh2b [748.860562ms]
Nov  5 20:55:45.352: INFO: Created: latency-svc-jcbf2
Nov  5 20:55:45.397: INFO: Got endpoints: latency-svc-bqvf2 [750.204376ms]
Nov  5 20:55:45.402: INFO: Created: latency-svc-2fmw6
Nov  5 20:55:45.445: INFO: Got endpoints: latency-svc-xbd9p [749.119265ms]
Nov  5 20:55:45.452: INFO: Created: latency-svc-2lrrh
Nov  5 20:55:45.497: INFO: Got endpoints: latency-svc-hf9tz [750.195689ms]
Nov  5 20:55:45.503: INFO: Created: latency-svc-jxzm8
Nov  5 20:55:45.547: INFO: Got endpoints: latency-svc-wzd48 [750.215249ms]
Nov  5 20:55:45.552: INFO: Created: latency-svc-j6flw
Nov  5 20:55:45.597: INFO: Got endpoints: latency-svc-mjxdr [751.395298ms]
Nov  5 20:55:45.603: INFO: Created: latency-svc-p6h7p
Nov  5 20:55:45.646: INFO: Got endpoints: latency-svc-6fhd5 [750.520109ms]
Nov  5 20:55:45.653: INFO: Created: latency-svc-ddcg8
Nov  5 20:55:45.697: INFO: Got endpoints: latency-svc-8cs6h [750.411911ms]
Nov  5 20:55:45.703: INFO: Created: latency-svc-s6xdc
Nov  5 20:55:45.747: INFO: Got endpoints: latency-svc-4xms9 [750.539215ms]
Nov  5 20:55:45.753: INFO: Created: latency-svc-lrswd
Nov  5 20:55:45.796: INFO: Got endpoints: latency-svc-sfwqc [749.337052ms]
Nov  5 20:55:45.801: INFO: Created: latency-svc-cd6mk
Nov  5 20:55:45.846: INFO: Got endpoints: latency-svc-m67ff [749.016678ms]
Nov  5 20:55:45.852: INFO: Created: latency-svc-v4cfn
Nov  5 20:55:45.897: INFO: Got endpoints: latency-svc-dkpcl [747.667133ms]
Nov  5 20:55:45.903: INFO: Created: latency-svc-wthzr
Nov  5 20:55:45.946: INFO: Got endpoints: latency-svc-2kxfl [750.304343ms]
Nov  5 20:55:45.954: INFO: Created: latency-svc-ptbb7
Nov  5 20:55:45.997: INFO: Got endpoints: latency-svc-56rqq [749.910515ms]
Nov  5 20:55:46.004: INFO: Created: latency-svc-gg5gp
Nov  5 20:55:46.047: INFO: Got endpoints: latency-svc-n7gpw [751.076387ms]
Nov  5 20:55:46.055: INFO: Created: latency-svc-jsd8w
Nov  5 20:55:46.096: INFO: Got endpoints: latency-svc-jcbf2 [749.538646ms]
Nov  5 20:55:46.105: INFO: Created: latency-svc-nh6dj
Nov  5 20:55:46.147: INFO: Got endpoints: latency-svc-2fmw6 [749.955006ms]
Nov  5 20:55:46.152: INFO: Created: latency-svc-8fc5c
Nov  5 20:55:46.196: INFO: Got endpoints: latency-svc-2lrrh [750.503029ms]
Nov  5 20:55:46.201: INFO: Created: latency-svc-7bmtg
Nov  5 20:55:46.246: INFO: Got endpoints: latency-svc-jxzm8 [749.163721ms]
Nov  5 20:55:46.252: INFO: Created: latency-svc-drsgd
Nov  5 20:55:46.296: INFO: Got endpoints: latency-svc-j6flw [748.70921ms]
Nov  5 20:55:46.302: INFO: Created: latency-svc-zmh5w
Nov  5 20:55:46.347: INFO: Got endpoints: latency-svc-p6h7p [749.158608ms]
Nov  5 20:55:46.356: INFO: Created: latency-svc-2r2sv
Nov  5 20:55:46.396: INFO: Got endpoints: latency-svc-ddcg8 [749.96618ms]
Nov  5 20:55:46.402: INFO: Created: latency-svc-mmdqc
Nov  5 20:55:46.446: INFO: Got endpoints: latency-svc-s6xdc [749.135652ms]
Nov  5 20:55:46.452: INFO: Created: latency-svc-c6xnt
Nov  5 20:55:46.497: INFO: Got endpoints: latency-svc-lrswd [749.89111ms]
Nov  5 20:55:46.503: INFO: Created: latency-svc-hxdrf
Nov  5 20:55:46.547: INFO: Got endpoints: latency-svc-cd6mk [750.268816ms]
Nov  5 20:55:46.553: INFO: Created: latency-svc-5hbgf
Nov  5 20:55:46.597: INFO: Got endpoints: latency-svc-v4cfn [750.853887ms]
Nov  5 20:55:46.602: INFO: Created: latency-svc-wchvf
Nov  5 20:55:46.646: INFO: Got endpoints: latency-svc-wthzr [748.891298ms]
Nov  5 20:55:46.653: INFO: Created: latency-svc-lcgg7
Nov  5 20:55:46.697: INFO: Got endpoints: latency-svc-ptbb7 [750.844099ms]
Nov  5 20:55:46.703: INFO: Created: latency-svc-g5cvs
Nov  5 20:55:46.746: INFO: Got endpoints: latency-svc-gg5gp [749.058134ms]
Nov  5 20:55:46.754: INFO: Created: latency-svc-ldxrd
Nov  5 20:55:46.796: INFO: Got endpoints: latency-svc-jsd8w [749.374281ms]
Nov  5 20:55:46.805: INFO: Created: latency-svc-65d6d
Nov  5 20:55:46.846: INFO: Got endpoints: latency-svc-nh6dj [750.35529ms]
Nov  5 20:55:46.853: INFO: Created: latency-svc-qp99t
Nov  5 20:55:46.897: INFO: Got endpoints: latency-svc-8fc5c [749.894811ms]
Nov  5 20:55:46.904: INFO: Created: latency-svc-lbmrb
Nov  5 20:55:46.946: INFO: Got endpoints: latency-svc-7bmtg [750.23946ms]
Nov  5 20:55:46.952: INFO: Created: latency-svc-dfd5m
Nov  5 20:55:46.997: INFO: Got endpoints: latency-svc-drsgd [751.05104ms]
Nov  5 20:55:47.003: INFO: Created: latency-svc-hf7xf
Nov  5 20:55:47.047: INFO: Got endpoints: latency-svc-zmh5w [750.889853ms]
Nov  5 20:55:47.053: INFO: Created: latency-svc-6c6ld
Nov  5 20:55:47.097: INFO: Got endpoints: latency-svc-2r2sv [749.788869ms]
Nov  5 20:55:47.102: INFO: Created: latency-svc-xtds8
Nov  5 20:55:47.150: INFO: Got endpoints: latency-svc-mmdqc [753.777793ms]
Nov  5 20:55:47.157: INFO: Created: latency-svc-wjwr4
Nov  5 20:55:47.196: INFO: Got endpoints: latency-svc-c6xnt [750.333137ms]
Nov  5 20:55:47.203: INFO: Created: latency-svc-bqjc7
Nov  5 20:55:47.248: INFO: Got endpoints: latency-svc-hxdrf [751.666225ms]
Nov  5 20:55:47.255: INFO: Created: latency-svc-hdvr7
Nov  5 20:55:47.297: INFO: Got endpoints: latency-svc-5hbgf [750.451265ms]
Nov  5 20:55:47.306: INFO: Created: latency-svc-9895d
Nov  5 20:55:47.346: INFO: Got endpoints: latency-svc-wchvf [749.712282ms]
Nov  5 20:55:47.353: INFO: Created: latency-svc-9t8gz
Nov  5 20:55:47.397: INFO: Got endpoints: latency-svc-lcgg7 [750.797983ms]
Nov  5 20:55:47.403: INFO: Created: latency-svc-cxzkr
Nov  5 20:55:47.446: INFO: Got endpoints: latency-svc-g5cvs [748.781814ms]
Nov  5 20:55:47.469: INFO: Created: latency-svc-lvm4n
Nov  5 20:55:47.497: INFO: Got endpoints: latency-svc-ldxrd [750.653707ms]
Nov  5 20:55:47.503: INFO: Created: latency-svc-btjlc
Nov  5 20:55:47.548: INFO: Got endpoints: latency-svc-65d6d [751.350938ms]
Nov  5 20:55:47.554: INFO: Created: latency-svc-2lr9q
Nov  5 20:55:47.596: INFO: Got endpoints: latency-svc-qp99t [749.671893ms]
Nov  5 20:55:47.603: INFO: Created: latency-svc-9w2n5
Nov  5 20:55:47.646: INFO: Got endpoints: latency-svc-lbmrb [749.597018ms]
Nov  5 20:55:47.653: INFO: Created: latency-svc-rt7g9
Nov  5 20:55:47.696: INFO: Got endpoints: latency-svc-dfd5m [750.151812ms]
Nov  5 20:55:47.704: INFO: Created: latency-svc-spg8t
Nov  5 20:55:47.747: INFO: Got endpoints: latency-svc-hf7xf [749.837736ms]
Nov  5 20:55:47.753: INFO: Created: latency-svc-w2q4b
Nov  5 20:55:47.798: INFO: Got endpoints: latency-svc-6c6ld [750.855026ms]
Nov  5 20:55:47.805: INFO: Created: latency-svc-c9s4q
Nov  5 20:55:47.847: INFO: Got endpoints: latency-svc-xtds8 [750.490599ms]
Nov  5 20:55:47.855: INFO: Created: latency-svc-cjp44
Nov  5 20:55:47.898: INFO: Got endpoints: latency-svc-wjwr4 [747.629737ms]
Nov  5 20:55:47.904: INFO: Created: latency-svc-7bcnn
Nov  5 20:55:47.947: INFO: Got endpoints: latency-svc-bqjc7 [750.21691ms]
Nov  5 20:55:47.953: INFO: Created: latency-svc-5s8rp
Nov  5 20:55:47.996: INFO: Got endpoints: latency-svc-hdvr7 [747.242858ms]
Nov  5 20:55:48.003: INFO: Created: latency-svc-2t6h9
Nov  5 20:55:48.046: INFO: Got endpoints: latency-svc-9895d [749.139798ms]
Nov  5 20:55:48.055: INFO: Created: latency-svc-5np7v
Nov  5 20:55:48.096: INFO: Got endpoints: latency-svc-9t8gz [749.819238ms]
Nov  5 20:55:48.106: INFO: Created: latency-svc-g9gft
Nov  5 20:55:48.147: INFO: Got endpoints: latency-svc-cxzkr [750.410787ms]
Nov  5 20:55:48.154: INFO: Created: latency-svc-5gcr2
Nov  5 20:55:48.197: INFO: Got endpoints: latency-svc-lvm4n [751.269063ms]
Nov  5 20:55:48.203: INFO: Created: latency-svc-zjnkc
Nov  5 20:55:48.247: INFO: Got endpoints: latency-svc-btjlc [749.822503ms]
Nov  5 20:55:48.253: INFO: Created: latency-svc-whw9z
Nov  5 20:55:48.296: INFO: Got endpoints: latency-svc-2lr9q [747.966262ms]
Nov  5 20:55:48.301: INFO: Created: latency-svc-jl4vt
Nov  5 20:55:48.347: INFO: Got endpoints: latency-svc-9w2n5 [751.157832ms]
Nov  5 20:55:48.353: INFO: Created: latency-svc-rq4ss
Nov  5 20:55:48.395: INFO: Got endpoints: latency-svc-rt7g9 [749.015639ms]
Nov  5 20:55:48.402: INFO: Created: latency-svc-8vplg
Nov  5 20:55:48.446: INFO: Got endpoints: latency-svc-spg8t [750.041271ms]
Nov  5 20:55:48.453: INFO: Created: latency-svc-l4wtg
Nov  5 20:55:48.496: INFO: Got endpoints: latency-svc-w2q4b [748.927291ms]
Nov  5 20:55:48.504: INFO: Created: latency-svc-lfr4z
Nov  5 20:55:48.547: INFO: Got endpoints: latency-svc-c9s4q [748.910249ms]
Nov  5 20:55:48.552: INFO: Created: latency-svc-shhkz
Nov  5 20:55:48.596: INFO: Got endpoints: latency-svc-cjp44 [749.209303ms]
Nov  5 20:55:48.603: INFO: Created: latency-svc-m64nn
Nov  5 20:55:48.647: INFO: Got endpoints: latency-svc-7bcnn [748.621145ms]
Nov  5 20:55:48.651: INFO: Created: latency-svc-ds7wh
Nov  5 20:55:48.696: INFO: Got endpoints: latency-svc-5s8rp [749.844352ms]
Nov  5 20:55:48.702: INFO: Created: latency-svc-9x6sl
Nov  5 20:55:48.746: INFO: Got endpoints: latency-svc-2t6h9 [750.173272ms]
Nov  5 20:55:48.751: INFO: Created: latency-svc-qgjl8
Nov  5 20:55:48.797: INFO: Got endpoints: latency-svc-5np7v [751.022278ms]
Nov  5 20:55:48.803: INFO: Created: latency-svc-2zfvw
Nov  5 20:55:48.846: INFO: Got endpoints: latency-svc-g9gft [749.772709ms]
Nov  5 20:55:48.853: INFO: Created: latency-svc-ft6dv
Nov  5 20:55:48.898: INFO: Got endpoints: latency-svc-5gcr2 [750.607108ms]
Nov  5 20:55:48.903: INFO: Created: latency-svc-wq6bl
Nov  5 20:55:48.947: INFO: Got endpoints: latency-svc-zjnkc [749.44791ms]
Nov  5 20:55:48.952: INFO: Created: latency-svc-gkmhn
Nov  5 20:55:48.997: INFO: Got endpoints: latency-svc-whw9z [750.089253ms]
Nov  5 20:55:49.004: INFO: Created: latency-svc-c9vpx
Nov  5 20:55:49.046: INFO: Got endpoints: latency-svc-jl4vt [749.850129ms]
Nov  5 20:55:49.053: INFO: Created: latency-svc-9fndj
Nov  5 20:55:49.097: INFO: Got endpoints: latency-svc-rq4ss [750.130557ms]
Nov  5 20:55:49.146: INFO: Got endpoints: latency-svc-8vplg [750.716678ms]
Nov  5 20:55:49.196: INFO: Got endpoints: latency-svc-l4wtg [749.488003ms]
Nov  5 20:55:49.246: INFO: Got endpoints: latency-svc-lfr4z [749.999897ms]
Nov  5 20:55:49.296: INFO: Got endpoints: latency-svc-shhkz [749.340009ms]
Nov  5 20:55:49.348: INFO: Got endpoints: latency-svc-m64nn [751.262988ms]
Nov  5 20:55:49.397: INFO: Got endpoints: latency-svc-ds7wh [750.479043ms]
Nov  5 20:55:49.446: INFO: Got endpoints: latency-svc-9x6sl [749.235ms]
Nov  5 20:55:49.496: INFO: Got endpoints: latency-svc-qgjl8 [750.437659ms]
Nov  5 20:55:49.546: INFO: Got endpoints: latency-svc-2zfvw [748.71138ms]
Nov  5 20:55:49.596: INFO: Got endpoints: latency-svc-ft6dv [749.810356ms]
Nov  5 20:55:49.646: INFO: Got endpoints: latency-svc-wq6bl [747.854404ms]
Nov  5 20:55:49.696: INFO: Got endpoints: latency-svc-gkmhn [749.514075ms]
Nov  5 20:55:49.746: INFO: Got endpoints: latency-svc-c9vpx [749.540736ms]
Nov  5 20:55:49.796: INFO: Got endpoints: latency-svc-9fndj [750.390567ms]
Nov  5 20:55:49.796: INFO: Latencies: [12.274678ms 15.110263ms 21.345672ms 25.552434ms 29.50493ms 33.326686ms 38.181186ms 42.47772ms 48.144655ms 54.188798ms 58.377344ms 61.473349ms 65.038921ms 70.782292ms 71.68133ms 76.124121ms 78.377246ms 78.456576ms 79.57395ms 80.904334ms 81.774505ms 82.130992ms 82.55822ms 83.049132ms 83.510131ms 83.549646ms 83.685129ms 83.731453ms 84.223488ms 84.540956ms 84.595886ms 87.206151ms 96.920773ms 144.275949ms 186.513719ms 231.819316ms 276.400271ms 322.190888ms 366.511379ms 415.858991ms 458.459851ms 504.022749ms 545.858284ms 592.512144ms 637.818191ms 683.431619ms 727.067026ms 747.242858ms 747.629737ms 747.667133ms 747.854404ms 747.966262ms 748.043431ms 748.120867ms 748.23714ms 748.286507ms 748.350624ms 748.583422ms 748.621145ms 748.623451ms 748.70921ms 748.71138ms 748.781814ms 748.839451ms 748.855967ms 748.860562ms 748.891298ms 748.910249ms 748.927291ms 749.015639ms 749.016678ms 749.058134ms 749.081033ms 749.083675ms 749.119265ms 749.135652ms 749.139798ms 749.158608ms 749.163721ms 749.187982ms 749.193408ms 749.209303ms 749.216372ms 749.230501ms 749.235ms 749.250378ms 749.337052ms 749.340009ms 749.374281ms 749.401084ms 749.421363ms 749.429598ms 749.44791ms 749.488003ms 749.514075ms 749.538646ms 749.540736ms 749.574082ms 749.597018ms 749.651819ms 749.660033ms 749.664662ms 749.670944ms 749.671893ms 749.679478ms 749.712282ms 749.723091ms 749.752641ms 749.772709ms 749.784748ms 749.788869ms 749.792522ms 749.810356ms 749.818328ms 749.819238ms 749.822503ms 749.822611ms 749.830542ms 749.837736ms 749.844352ms 749.850129ms 749.89111ms 749.894811ms 749.910515ms 749.955006ms 749.96618ms 749.972432ms 749.988675ms 749.999897ms 750.005847ms 750.022422ms 750.041271ms 750.057854ms 750.08851ms 750.089253ms 750.090161ms 750.122285ms 750.124301ms 750.130557ms 750.151812ms 750.173272ms 750.175697ms 750.195689ms 750.204376ms 750.215249ms 750.21691ms 750.23946ms 750.257602ms 750.268816ms 750.27842ms 750.294079ms 750.304343ms 750.333137ms 750.35529ms 750.373767ms 750.387805ms 750.390567ms 750.410787ms 750.411911ms 750.428352ms 750.437659ms 750.449231ms 750.451265ms 750.457481ms 750.479043ms 750.490599ms 750.503029ms 750.520109ms 750.539215ms 750.607108ms 750.63189ms 750.636311ms 750.653707ms 750.716678ms 750.741871ms 750.760875ms 750.797983ms 750.809449ms 750.835782ms 750.844099ms 750.853887ms 750.855026ms 750.889853ms 750.931369ms 750.957871ms 750.95978ms 751.022278ms 751.05104ms 751.076387ms 751.157832ms 751.262988ms 751.269063ms 751.317279ms 751.350938ms 751.395298ms 751.536757ms 751.666225ms 751.729433ms 752.902586ms 753.777793ms]
Nov  5 20:55:49.796: INFO: 50 %ile: 749.660033ms
Nov  5 20:55:49.796: INFO: 90 %ile: 750.853887ms
Nov  5 20:55:49.796: INFO: 99 %ile: 752.902586ms
Nov  5 20:55:49.796: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:49.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3472" for this suite.
Nov  5 20:55:57.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:55:57.865: INFO: namespace svc-latency-3472 deletion completed in 8.065470459s

• [SLOW TEST:18.804 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:55:57.866: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:55:57.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a" in namespace "projected-429" to be "success or failure"
Nov  5 20:55:57.896: INFO: Pod "downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.274339ms
Nov  5 20:55:59.899: INFO: Pod "downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004624825s
STEP: Saw pod success
Nov  5 20:55:59.899: INFO: Pod "downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a" satisfied condition "success or failure"
Nov  5 20:55:59.900: INFO: Trying to get logs from node k8s-node-1 pod downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a container client-container: <nil>
STEP: delete the pod
Nov  5 20:55:59.915: INFO: Waiting for pod downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a to disappear
Nov  5 20:55:59.916: INFO: Pod downwardapi-volume-45ae56a6-a1b9-454c-b279-6e6ac751106a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:55:59.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-429" for this suite.
Nov  5 20:56:05.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:56:05.989: INFO: namespace projected-429 deletion completed in 6.068901899s

• [SLOW TEST:8.123 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:56:05.989: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:56:06.019: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef" in namespace "downward-api-7717" to be "success or failure"
Nov  5 20:56:06.021: INFO: Pod "downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef": Phase="Pending", Reason="", readiness=false. Elapsed: 1.897922ms
Nov  5 20:56:08.024: INFO: Pod "downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005078788s
STEP: Saw pod success
Nov  5 20:56:08.024: INFO: Pod "downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef" satisfied condition "success or failure"
Nov  5 20:56:08.026: INFO: Trying to get logs from node k8s-node-3 pod downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef container client-container: <nil>
STEP: delete the pod
Nov  5 20:56:08.046: INFO: Waiting for pod downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef to disappear
Nov  5 20:56:08.048: INFO: Pod downwardapi-volume-98db72ee-8d97-4c20-b36f-f0fb5d4dfcef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:56:08.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7717" for this suite.
Nov  5 20:56:14.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:56:14.116: INFO: namespace downward-api-7717 deletion completed in 6.065417032s

• [SLOW TEST:8.127 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:56:14.116: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:56:17.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7913" for this suite.
Nov  5 20:56:39.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:56:39.229: INFO: namespace replication-controller-7913 deletion completed in 22.064296957s

• [SLOW TEST:25.113 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:56:39.230: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 20:56:39.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4074'
Nov  5 20:56:39.346: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  5 20:56:39.346: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov  5 20:56:39.349: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  5 20:56:39.355: INFO: scanned /root for discovery docs: <nil>
Nov  5 20:56:39.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4074'
Nov  5 20:56:55.106: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  5 20:56:55.106: INFO: stdout: "Created e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760\nScaling up e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov  5 20:56:55.106: INFO: stdout: "Created e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760\nScaling up e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov  5 20:56:55.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4074'
Nov  5 20:56:55.190: INFO: stderr: ""
Nov  5 20:56:55.190: INFO: stdout: "e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760-8b764 "
Nov  5 20:56:55.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760-8b764 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4074'
Nov  5 20:56:55.277: INFO: stderr: ""
Nov  5 20:56:55.277: INFO: stdout: "true"
Nov  5 20:56:55.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760-8b764 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4074'
Nov  5 20:56:55.362: INFO: stderr: ""
Nov  5 20:56:55.362: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Nov  5 20:56:55.362: INFO: e2e-test-nginx-rc-51054edd25c90b9b0c3d9fef3c1ef760-8b764 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Nov  5 20:56:55.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete rc e2e-test-nginx-rc --namespace=kubectl-4074'
Nov  5 20:56:55.453: INFO: stderr: ""
Nov  5 20:56:55.453: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:56:55.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4074" for this suite.
Nov  5 20:57:17.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:57:17.526: INFO: namespace kubectl-4074 deletion completed in 22.069030917s

• [SLOW TEST:38.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:57:17.526: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Nov  5 20:57:17.553: INFO: Waiting up to 5m0s for pod "client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd" in namespace "containers-6169" to be "success or failure"
Nov  5 20:57:17.555: INFO: Pod "client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.760375ms
Nov  5 20:57:19.558: INFO: Pod "client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004788187s
Nov  5 20:57:21.561: INFO: Pod "client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007186437s
STEP: Saw pod success
Nov  5 20:57:21.561: INFO: Pod "client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd" satisfied condition "success or failure"
Nov  5 20:57:21.562: INFO: Trying to get logs from node k8s-node-1 pod client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd container test-container: <nil>
STEP: delete the pod
Nov  5 20:57:21.574: INFO: Waiting for pod client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd to disappear
Nov  5 20:57:21.576: INFO: Pod client-containers-94c94fd4-f35c-4390-abfe-b9313b3ea7fd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:57:21.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6169" for this suite.
Nov  5 20:57:27.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:57:27.646: INFO: namespace containers-6169 deletion completed in 6.066554994s

• [SLOW TEST:10.119 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:57:27.646: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8992.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8992.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8992.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8992.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 20:57:39.700: INFO: DNS probes using dns-8992/dns-test-67745866-5c98-4eaf-a74f-31c39f0fd2ac succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:57:39.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8992" for this suite.
Nov  5 20:57:45.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:57:45.776: INFO: namespace dns-8992 deletion completed in 6.066949788s

• [SLOW TEST:18.131 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:57:45.777: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-944.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-944.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 20:57:59.832: INFO: DNS probes using dns-944/dns-test-81496c53-a293-4ac5-a8ed-835de69b28cd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:57:59.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-944" for this suite.
Nov  5 20:58:05.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:58:05.909: INFO: namespace dns-944 deletion completed in 6.067050111s

• [SLOW TEST:20.132 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:58:05.909: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  5 20:58:15.999: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 535
	[quantile=0.9] = 199230
	[quantile=0.99] = 914068
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 207134
	[quantile=0.9] = 596621
	[quantile=0.99] = 914166
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 17
	[quantile=0.99] = 17
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 215080
	[quantile=0.9] = 221029
	[quantile=0.99] = 221029
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 6
	[quantile=0.99] = 20
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 10
	[quantile=0.9] = 20
	[quantile=0.99] = 44
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 14
	[quantile=0.9] = 25
	[quantile=0.99] = 33
For namespace_queue_latency_sum:
	[] = 1697
For namespace_queue_latency_count:
	[] = 105
For namespace_retries:
	[] = 106
For namespace_work_duration:
	[quantile=0.5] = 118971
	[quantile=0.9] = 178868
	[quantile=0.99] = 2862211
For namespace_work_duration_sum:
	[] = 17022094
For namespace_work_duration_count:
	[] = 105
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:58:15.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8467" for this suite.
Nov  5 20:58:22.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:58:22.070: INFO: namespace gc-8467 deletion completed in 6.068495993s

• [SLOW TEST:16.161 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:58:22.070: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 20:58:22.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e" in namespace "downward-api-6807" to be "success or failure"
Nov  5 20:58:22.102: INFO: Pod "downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.734481ms
Nov  5 20:58:24.105: INFO: Pod "downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004655609s
STEP: Saw pod success
Nov  5 20:58:24.105: INFO: Pod "downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e" satisfied condition "success or failure"
Nov  5 20:58:24.107: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e container client-container: <nil>
STEP: delete the pod
Nov  5 20:58:24.127: INFO: Waiting for pod downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e to disappear
Nov  5 20:58:24.129: INFO: Pod downwardapi-volume-c89807da-791f-4379-babf-089c6584f13e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:58:24.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6807" for this suite.
Nov  5 20:58:30.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:58:30.221: INFO: namespace downward-api-6807 deletion completed in 6.089307869s

• [SLOW TEST:8.150 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:58:30.221: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov  5 20:58:30.255: INFO: PodSpec: initContainers in spec.initContainers
Nov  5 20:59:17.543: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-be754ad0-55b1-4e2e-86ac-8d87caffcb3b", GenerateName:"", Namespace:"init-container-6839", SelfLink:"/api/v1/namespaces/init-container-6839/pods/pod-init-be754ad0-55b1-4e2e-86ac-8d87caffcb3b", UID:"026d0f83-e428-49e9-9c68-5f462bb8eac5", ResourceVersion:"10985", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708584310, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"255784560"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qz54g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0027bb6c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz54g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz54g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qz54g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0028a91e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0029bd140), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028a9270)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028a9290)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0028a9298), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0028a929c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708584310, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708584310, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708584310, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708584310, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.3.111", PodIP:"10.233.117.43", StartTime:(*v1.Time)(0xc001fbec80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00094d180)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00094d260)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://100985463e4ec52fa7e97565112a75d40afdb3d61e72a4f073afa76281b9e223"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fbed20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001fbed00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:59:17.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6839" for this suite.
Nov  5 20:59:39.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:59:39.625: INFO: namespace init-container-6839 deletion completed in 22.067224223s

• [SLOW TEST:69.404 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:59:39.625: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-1cebc72e-249b-41c6-943b-1c82d1b4f97e
STEP: Creating secret with name secret-projected-all-test-volume-106f29d5-94d3-4ba9-9904-2bf822e1d6a7
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  5 20:59:39.659: INFO: Waiting up to 5m0s for pod "projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3" in namespace "projected-7959" to be "success or failure"
Nov  5 20:59:39.662: INFO: Pod "projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.959443ms
Nov  5 20:59:41.665: INFO: Pod "projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006093198s
Nov  5 20:59:43.668: INFO: Pod "projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008958933s
STEP: Saw pod success
Nov  5 20:59:43.668: INFO: Pod "projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3" satisfied condition "success or failure"
Nov  5 20:59:43.670: INFO: Trying to get logs from node k8s-node-2 pod projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  5 20:59:43.683: INFO: Waiting for pod projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3 to disappear
Nov  5 20:59:43.685: INFO: Pod projected-volume-ed1710c8-d8b8-4ef3-9b86-ebd98fd916f3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 20:59:43.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7959" for this suite.
Nov  5 20:59:49.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 20:59:49.751: INFO: namespace projected-7959 deletion completed in 6.062776557s

• [SLOW TEST:10.126 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 20:59:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j2ckl in namespace proxy-6475
I1105 20:59:49.788146      17 runners.go:180] Created replication controller with name: proxy-service-j2ckl, namespace: proxy-6475, replica count: 1
I1105 20:59:50.838576      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 20:59:51.838755      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 20:59:52.838926      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:53.839101      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:54.839285      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:55.839463      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:56.839644      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:57.839830      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1105 20:59:58.839989      17 runners.go:180] proxy-service-j2ckl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 20:59:58.842: INFO: setup took 9.065786908s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  5 20:59:58.850: INFO: (0) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 8.010588ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.520902ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 8.566388ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.486636ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.101792ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 8.142363ms)
Nov  5 20:59:58.851: INFO: (0) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 8.407618ms)
Nov  5 20:59:58.852: INFO: (0) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 9.272549ms)
Nov  5 20:59:58.856: INFO: (0) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 13.104753ms)
Nov  5 20:59:58.856: INFO: (0) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 12.454058ms)
Nov  5 20:59:58.856: INFO: (0) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 12.390743ms)
Nov  5 20:59:58.860: INFO: (0) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 16.35338ms)
Nov  5 20:59:58.861: INFO: (0) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 17.107435ms)
Nov  5 20:59:58.861: INFO: (0) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 17.462144ms)
Nov  5 20:59:58.862: INFO: (0) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 19.123685ms)
Nov  5 20:59:58.864: INFO: (0) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 21.54811ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.122854ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 7.214387ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 7.187491ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.442361ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 8.039499ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 7.335108ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.312352ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.329726ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 7.399273ms)
Nov  5 20:59:58.872: INFO: (1) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 7.467423ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.321968ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.114266ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.493662ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.334558ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 8.407719ms)
Nov  5 20:59:58.873: INFO: (1) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.715505ms)
Nov  5 20:59:58.876: INFO: (2) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 2.514955ms)
Nov  5 20:59:58.877: INFO: (2) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 3.354167ms)
Nov  5 20:59:58.877: INFO: (2) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 3.337937ms)
Nov  5 20:59:58.877: INFO: (2) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 3.640102ms)
Nov  5 20:59:58.879: INFO: (2) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 4.546967ms)
Nov  5 20:59:58.879: INFO: (2) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 4.956648ms)
Nov  5 20:59:58.879: INFO: (2) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 4.731259ms)
Nov  5 20:59:58.879: INFO: (2) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.26991ms)
Nov  5 20:59:58.880: INFO: (2) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 5.753239ms)
Nov  5 20:59:58.880: INFO: (2) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 5.920704ms)
Nov  5 20:59:58.881: INFO: (2) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 6.447101ms)
Nov  5 20:59:58.882: INFO: (2) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 7.75392ms)
Nov  5 20:59:58.882: INFO: (2) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.523143ms)
Nov  5 20:59:58.882: INFO: (2) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.924504ms)
Nov  5 20:59:58.882: INFO: (2) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 6.958384ms)
Nov  5 20:59:58.882: INFO: (2) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 7.23589ms)
Nov  5 20:59:58.885: INFO: (3) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 2.79287ms)
Nov  5 20:59:58.888: INFO: (3) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 4.949103ms)
Nov  5 20:59:58.888: INFO: (3) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 5.050671ms)
Nov  5 20:59:58.888: INFO: (3) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.291666ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 4.901789ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 5.416488ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 6.832537ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.218281ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.216006ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 5.838863ms)
Nov  5 20:59:58.889: INFO: (3) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.638544ms)
Nov  5 20:59:58.891: INFO: (3) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 7.329709ms)
Nov  5 20:59:58.891: INFO: (3) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.51309ms)
Nov  5 20:59:58.891: INFO: (3) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.375291ms)
Nov  5 20:59:58.891: INFO: (3) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.124247ms)
Nov  5 20:59:58.891: INFO: (3) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.044322ms)
Nov  5 20:59:58.894: INFO: (4) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 3.25156ms)
Nov  5 20:59:58.895: INFO: (4) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 3.296403ms)
Nov  5 20:59:58.895: INFO: (4) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 3.379838ms)
Nov  5 20:59:58.895: INFO: (4) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 3.585085ms)
Nov  5 20:59:58.896: INFO: (4) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 4.883208ms)
Nov  5 20:59:58.896: INFO: (4) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 4.799002ms)
Nov  5 20:59:58.896: INFO: (4) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 5.034136ms)
Nov  5 20:59:58.897: INFO: (4) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 5.290132ms)
Nov  5 20:59:58.897: INFO: (4) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 5.454032ms)
Nov  5 20:59:58.897: INFO: (4) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 5.604713ms)
Nov  5 20:59:58.897: INFO: (4) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.667114ms)
Nov  5 20:59:58.898: INFO: (4) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 6.78522ms)
Nov  5 20:59:58.899: INFO: (4) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 7.404427ms)
Nov  5 20:59:58.899: INFO: (4) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 7.137131ms)
Nov  5 20:59:58.899: INFO: (4) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.777559ms)
Nov  5 20:59:58.899: INFO: (4) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 7.713605ms)
Nov  5 20:59:58.906: INFO: (5) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 6.529463ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.822874ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 8.172096ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 8.280094ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 8.376241ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 8.419976ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 8.717412ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 8.489444ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 8.684406ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 8.957653ms)
Nov  5 20:59:58.908: INFO: (5) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 8.644257ms)
Nov  5 20:59:58.910: INFO: (5) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 10.405063ms)
Nov  5 20:59:58.910: INFO: (5) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 10.528396ms)
Nov  5 20:59:58.910: INFO: (5) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 10.490677ms)
Nov  5 20:59:58.910: INFO: (5) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 10.776053ms)
Nov  5 20:59:58.911: INFO: (5) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 10.821716ms)
Nov  5 20:59:58.914: INFO: (6) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 3.642563ms)
Nov  5 20:59:58.915: INFO: (6) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 3.801905ms)
Nov  5 20:59:58.917: INFO: (6) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 5.025289ms)
Nov  5 20:59:58.917: INFO: (6) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.347367ms)
Nov  5 20:59:58.917: INFO: (6) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 6.554773ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 6.436554ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.280539ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 6.404185ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.164041ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 6.501136ms)
Nov  5 20:59:58.918: INFO: (6) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.369947ms)
Nov  5 20:59:58.924: INFO: (6) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 13.378891ms)
Nov  5 20:59:58.926: INFO: (6) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 14.744618ms)
Nov  5 20:59:58.926: INFO: (6) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 14.680287ms)
Nov  5 20:59:58.926: INFO: (6) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 15.198099ms)
Nov  5 20:59:58.926: INFO: (6) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 14.920944ms)
Nov  5 20:59:58.932: INFO: (7) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.68399ms)
Nov  5 20:59:58.932: INFO: (7) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 6.288835ms)
Nov  5 20:59:58.933: INFO: (7) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.081691ms)
Nov  5 20:59:58.933: INFO: (7) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 6.66187ms)
Nov  5 20:59:58.933: INFO: (7) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 6.772094ms)
Nov  5 20:59:58.933: INFO: (7) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.28153ms)
Nov  5 20:59:58.933: INFO: (7) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.352645ms)
Nov  5 20:59:58.934: INFO: (7) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 6.983644ms)
Nov  5 20:59:58.934: INFO: (7) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 7.458694ms)
Nov  5 20:59:58.934: INFO: (7) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 7.45855ms)
Nov  5 20:59:58.934: INFO: (7) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.816904ms)
Nov  5 20:59:58.935: INFO: (7) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 7.878478ms)
Nov  5 20:59:58.935: INFO: (7) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.012629ms)
Nov  5 20:59:58.935: INFO: (7) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 8.629905ms)
Nov  5 20:59:58.935: INFO: (7) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.915789ms)
Nov  5 20:59:58.936: INFO: (7) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 9.351243ms)
Nov  5 20:59:58.945: INFO: (8) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.53206ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 8.977927ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 9.90564ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 9.417639ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 9.512621ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 10.180454ms)
Nov  5 20:59:58.946: INFO: (8) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 9.45677ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 9.878643ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 10.36999ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 9.576215ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 9.896203ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 9.505206ms)
Nov  5 20:59:58.947: INFO: (8) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 10.709386ms)
Nov  5 20:59:58.949: INFO: (8) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 11.922999ms)
Nov  5 20:59:58.949: INFO: (8) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 12.201344ms)
Nov  5 20:59:58.949: INFO: (8) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 12.524183ms)
Nov  5 20:59:58.958: INFO: (9) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 7.799167ms)
Nov  5 20:59:58.958: INFO: (9) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.797161ms)
Nov  5 20:59:58.958: INFO: (9) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 7.245191ms)
Nov  5 20:59:58.958: INFO: (9) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 7.547244ms)
Nov  5 20:59:58.958: INFO: (9) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 8.307837ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.738608ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 8.896675ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.831258ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.906366ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 8.213268ms)
Nov  5 20:59:58.959: INFO: (9) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 9.64331ms)
Nov  5 20:59:58.960: INFO: (9) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 9.576438ms)
Nov  5 20:59:58.961: INFO: (9) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 10.855006ms)
Nov  5 20:59:58.961: INFO: (9) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 10.994288ms)
Nov  5 20:59:58.961: INFO: (9) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 11.793139ms)
Nov  5 20:59:58.962: INFO: (9) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 11.89823ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 5.363282ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.1817ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 5.883956ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.12348ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 6.225834ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 6.544936ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 6.690722ms)
Nov  5 20:59:58.968: INFO: (10) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.857557ms)
Nov  5 20:59:58.969: INFO: (10) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.870628ms)
Nov  5 20:59:58.969: INFO: (10) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 7.287904ms)
Nov  5 20:59:58.970: INFO: (10) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.858028ms)
Nov  5 20:59:58.970: INFO: (10) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.094307ms)
Nov  5 20:59:58.970: INFO: (10) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.353358ms)
Nov  5 20:59:58.970: INFO: (10) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.358033ms)
Nov  5 20:59:58.971: INFO: (10) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.368014ms)
Nov  5 20:59:58.971: INFO: (10) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.5383ms)
Nov  5 20:59:58.974: INFO: (11) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 3.029367ms)
Nov  5 20:59:58.975: INFO: (11) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 3.049477ms)
Nov  5 20:59:58.975: INFO: (11) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 3.368779ms)
Nov  5 20:59:58.978: INFO: (11) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 6.181295ms)
Nov  5 20:59:58.978: INFO: (11) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.959675ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.944561ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 7.892216ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 7.707407ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 7.091909ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.208347ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.156983ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.245644ms)
Nov  5 20:59:58.979: INFO: (11) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 7.381613ms)
Nov  5 20:59:58.981: INFO: (11) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 8.183019ms)
Nov  5 20:59:58.981: INFO: (11) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.415333ms)
Nov  5 20:59:58.981: INFO: (11) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 9.047457ms)
Nov  5 20:59:58.984: INFO: (12) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 3.634213ms)
Nov  5 20:59:58.984: INFO: (12) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 3.023746ms)
Nov  5 20:59:58.988: INFO: (12) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 6.854591ms)
Nov  5 20:59:58.988: INFO: (12) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.429821ms)
Nov  5 20:59:58.988: INFO: (12) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.215773ms)
Nov  5 20:59:58.988: INFO: (12) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 6.993304ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 7.302244ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 7.097501ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 7.083387ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.169785ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 7.324104ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.54832ms)
Nov  5 20:59:58.989: INFO: (12) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 7.278861ms)
Nov  5 20:59:58.990: INFO: (12) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.458106ms)
Nov  5 20:59:58.990: INFO: (12) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.954703ms)
Nov  5 20:59:58.990: INFO: (12) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.724874ms)
Nov  5 20:59:58.993: INFO: (13) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 2.705237ms)
Nov  5 20:59:58.994: INFO: (13) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 3.39815ms)
Nov  5 20:59:58.995: INFO: (13) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 4.873627ms)
Nov  5 20:59:58.996: INFO: (13) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 4.140108ms)
Nov  5 20:59:58.996: INFO: (13) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 6.376057ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.361423ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.054483ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 5.895838ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 5.627598ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.54297ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 7.412175ms)
Nov  5 20:59:58.997: INFO: (13) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 6.047046ms)
Nov  5 20:59:58.998: INFO: (13) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 6.470763ms)
Nov  5 20:59:58.998: INFO: (13) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.329998ms)
Nov  5 20:59:58.999: INFO: (13) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.295668ms)
Nov  5 20:59:58.999: INFO: (13) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.227461ms)
Nov  5 20:59:59.002: INFO: (14) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 3.35113ms)
Nov  5 20:59:59.007: INFO: (14) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.808202ms)
Nov  5 20:59:59.008: INFO: (14) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 8.190941ms)
Nov  5 20:59:59.008: INFO: (14) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.910525ms)
Nov  5 20:59:59.009: INFO: (14) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.918399ms)
Nov  5 20:59:59.009: INFO: (14) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 9.253513ms)
Nov  5 20:59:59.009: INFO: (14) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 9.208311ms)
Nov  5 20:59:59.009: INFO: (14) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 9.616465ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 9.673717ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 10.053068ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 10.141758ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 10.217605ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 10.794618ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 10.604713ms)
Nov  5 20:59:59.010: INFO: (14) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 10.372008ms)
Nov  5 20:59:59.011: INFO: (14) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 10.866129ms)
Nov  5 20:59:59.018: INFO: (15) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 7.27471ms)
Nov  5 20:59:59.018: INFO: (15) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 5.882186ms)
Nov  5 20:59:59.018: INFO: (15) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 6.77634ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.001462ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 7.311702ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.947722ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.460397ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 7.487006ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 8.169615ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 8.620866ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 8.326145ms)
Nov  5 20:59:59.019: INFO: (15) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 8.561456ms)
Nov  5 20:59:59.020: INFO: (15) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 9.146271ms)
Nov  5 20:59:59.021: INFO: (15) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.990289ms)
Nov  5 20:59:59.021: INFO: (15) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.962045ms)
Nov  5 20:59:59.021: INFO: (15) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 9.296522ms)
Nov  5 20:59:59.028: INFO: (16) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.827522ms)
Nov  5 20:59:59.028: INFO: (16) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.597512ms)
Nov  5 20:59:59.028: INFO: (16) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 6.66195ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 7.712418ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 6.604947ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 6.844297ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 7.630786ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.622244ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.582616ms)
Nov  5 20:59:59.029: INFO: (16) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.685824ms)
Nov  5 20:59:59.030: INFO: (16) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 7.312407ms)
Nov  5 20:59:59.030: INFO: (16) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 7.924163ms)
Nov  5 20:59:59.031: INFO: (16) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.996005ms)
Nov  5 20:59:59.031: INFO: (16) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 8.601552ms)
Nov  5 20:59:59.031: INFO: (16) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.730075ms)
Nov  5 20:59:59.031: INFO: (16) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 9.348063ms)
Nov  5 20:59:59.034: INFO: (17) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 2.848691ms)
Nov  5 20:59:59.035: INFO: (17) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 3.504811ms)
Nov  5 20:59:59.035: INFO: (17) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 3.827706ms)
Nov  5 20:59:59.035: INFO: (17) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 4.660741ms)
Nov  5 20:59:59.036: INFO: (17) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 4.352745ms)
Nov  5 20:59:59.036: INFO: (17) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 4.625932ms)
Nov  5 20:59:59.036: INFO: (17) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 4.796785ms)
Nov  5 20:59:59.037: INFO: (17) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 5.978194ms)
Nov  5 20:59:59.037: INFO: (17) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 5.113001ms)
Nov  5 20:59:59.037: INFO: (17) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 5.256258ms)
Nov  5 20:59:59.037: INFO: (17) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 5.386228ms)
Nov  5 20:59:59.038: INFO: (17) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.199714ms)
Nov  5 20:59:59.038: INFO: (17) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 5.899656ms)
Nov  5 20:59:59.039: INFO: (17) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 6.961841ms)
Nov  5 20:59:59.039: INFO: (17) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 6.883028ms)
Nov  5 20:59:59.039: INFO: (17) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 7.098609ms)
Nov  5 20:59:59.041: INFO: (18) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 2.356766ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 5.675744ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 5.616054ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.424629ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 5.30187ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 5.838151ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 5.822184ms)
Nov  5 20:59:59.046: INFO: (18) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 6.918346ms)
Nov  5 20:59:59.047: INFO: (18) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 7.513977ms)
Nov  5 20:59:59.047: INFO: (18) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 6.378657ms)
Nov  5 20:59:59.048: INFO: (18) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 7.054599ms)
Nov  5 20:59:59.048: INFO: (18) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.061541ms)
Nov  5 20:59:59.048: INFO: (18) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.370195ms)
Nov  5 20:59:59.048: INFO: (18) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.00663ms)
Nov  5 20:59:59.048: INFO: (18) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 8.25417ms)
Nov  5 20:59:59.049: INFO: (18) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 9.450348ms)
Nov  5 20:59:59.056: INFO: (19) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn/proxy/rewriteme">test</a> (200; 5.650254ms)
Nov  5 20:59:59.056: INFO: (19) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:443/proxy/tlsrewritem... (200; 6.258065ms)
Nov  5 20:59:59.056: INFO: (19) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname2/proxy/: bar (200; 6.579306ms)
Nov  5 20:59:59.056: INFO: (19) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">... (200; 5.620209ms)
Nov  5 20:59:59.056: INFO: (19) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.480367ms)
Nov  5 20:59:59.057: INFO: (19) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:460/proxy/: tls baz (200; 6.901642ms)
Nov  5 20:59:59.057: INFO: (19) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/: <a href="/api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:1080/proxy/rewriteme">test<... (200; 6.091745ms)
Nov  5 20:59:59.057: INFO: (19) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 5.928352ms)
Nov  5 20:59:59.057: INFO: (19) /api/v1/namespaces/proxy-6475/pods/proxy-service-j2ckl-jbdjn:160/proxy/: foo (200; 6.8783ms)
Nov  5 20:59:59.058: INFO: (19) /api/v1/namespaces/proxy-6475/pods/https:proxy-service-j2ckl-jbdjn:462/proxy/: tls qux (200; 8.053762ms)
Nov  5 20:59:59.058: INFO: (19) /api/v1/namespaces/proxy-6475/pods/http:proxy-service-j2ckl-jbdjn:162/proxy/: bar (200; 6.958101ms)
Nov  5 20:59:59.058: INFO: (19) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname2/proxy/: tls qux (200; 8.028684ms)
Nov  5 20:59:59.059: INFO: (19) /api/v1/namespaces/proxy-6475/services/http:proxy-service-j2ckl:portname1/proxy/: foo (200; 8.438593ms)
Nov  5 20:59:59.059: INFO: (19) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname2/proxy/: bar (200; 8.677693ms)
Nov  5 20:59:59.059: INFO: (19) /api/v1/namespaces/proxy-6475/services/https:proxy-service-j2ckl:tlsportname1/proxy/: tls baz (200; 8.60866ms)
Nov  5 20:59:59.059: INFO: (19) /api/v1/namespaces/proxy-6475/services/proxy-service-j2ckl:portname1/proxy/: foo (200; 7.991262ms)
STEP: deleting ReplicationController proxy-service-j2ckl in namespace proxy-6475, will wait for the garbage collector to delete the pods
Nov  5 20:59:59.116: INFO: Deleting ReplicationController proxy-service-j2ckl took: 4.68228ms
Nov  5 20:59:59.416: INFO: Terminating ReplicationController proxy-service-j2ckl pods took: 300.192542ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:00:00.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6475" for this suite.
Nov  5 21:00:06.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:00:06.989: INFO: namespace proxy-6475 deletion completed in 6.070066089s

• [SLOW TEST:17.238 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:00:06.990: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-lsq6
STEP: Creating a pod to test atomic-volume-subpath
Nov  5 21:00:07.023: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-lsq6" in namespace "subpath-8522" to be "success or failure"
Nov  5 21:00:07.024: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.665156ms
Nov  5 21:00:09.027: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 2.004422906s
Nov  5 21:00:11.030: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007066808s
Nov  5 21:00:13.032: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 6.009200564s
Nov  5 21:00:15.034: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 8.011597093s
Nov  5 21:00:17.036: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 10.013765226s
Nov  5 21:00:19.039: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 12.016018734s
Nov  5 21:00:21.041: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 14.018428246s
Nov  5 21:00:23.043: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 16.020514008s
Nov  5 21:00:25.046: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 18.023108085s
Nov  5 21:00:27.048: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Running", Reason="", readiness=true. Elapsed: 20.025268914s
Nov  5 21:00:29.050: INFO: Pod "pod-subpath-test-projected-lsq6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.027485192s
STEP: Saw pod success
Nov  5 21:00:29.050: INFO: Pod "pod-subpath-test-projected-lsq6" satisfied condition "success or failure"
Nov  5 21:00:29.052: INFO: Trying to get logs from node k8s-node-2 pod pod-subpath-test-projected-lsq6 container test-container-subpath-projected-lsq6: <nil>
STEP: delete the pod
Nov  5 21:00:29.065: INFO: Waiting for pod pod-subpath-test-projected-lsq6 to disappear
Nov  5 21:00:29.067: INFO: Pod pod-subpath-test-projected-lsq6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-lsq6
Nov  5 21:00:29.067: INFO: Deleting pod "pod-subpath-test-projected-lsq6" in namespace "subpath-8522"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:00:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8522" for this suite.
Nov  5 21:00:35.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:00:35.144: INFO: namespace subpath-8522 deletion completed in 6.07162601s

• [SLOW TEST:28.155 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:00:35.144: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:00:35.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2749" for this suite.
Nov  5 21:00:41.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:00:41.239: INFO: namespace services-2749 deletion completed in 6.064228699s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.094 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:00:41.239: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3449
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  5 21:00:41.262: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  5 21:01:05.324: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.113.46:8080/dial?request=hostName&protocol=http&host=10.233.113.45&port=8080&tries=1'] Namespace:pod-network-test-3449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:01:05.324: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:01:05.458: INFO: Waiting for endpoints: map[]
Nov  5 21:01:05.461: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.113.46:8080/dial?request=hostName&protocol=http&host=10.233.114.21&port=8080&tries=1'] Namespace:pod-network-test-3449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:01:05.461: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:01:05.596: INFO: Waiting for endpoints: map[]
Nov  5 21:01:05.599: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.113.46:8080/dial?request=hostName&protocol=http&host=10.233.117.45&port=8080&tries=1'] Namespace:pod-network-test-3449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:01:05.599: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:01:05.724: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:01:05.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3449" for this suite.
Nov  5 21:01:27.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:01:27.797: INFO: namespace pod-network-test-3449 deletion completed in 22.069137049s

• [SLOW TEST:46.558 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:01:27.798: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Nov  5 21:01:27.827: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2145" to be "success or failure"
Nov  5 21:01:27.830: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.587004ms
Nov  5 21:01:29.833: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005385206s
STEP: Saw pod success
Nov  5 21:01:29.833: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  5 21:01:29.835: INFO: Trying to get logs from node k8s-node-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  5 21:01:29.852: INFO: Waiting for pod pod-host-path-test to disappear
Nov  5 21:01:29.857: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:01:29.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2145" for this suite.
Nov  5 21:01:35.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:01:35.927: INFO: namespace hostpath-2145 deletion completed in 6.065832997s

• [SLOW TEST:8.129 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:01:35.927: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-d8789c70-c6b5-4829-8755-546b12deb8f6 in namespace container-probe-8396
Nov  5 21:01:37.958: INFO: Started pod busybox-d8789c70-c6b5-4829-8755-546b12deb8f6 in namespace container-probe-8396
STEP: checking the pod's current state and verifying that restartCount is present
Nov  5 21:01:37.959: INFO: Initial restart count of pod busybox-d8789c70-c6b5-4829-8755-546b12deb8f6 is 0
Nov  5 21:02:28.032: INFO: Restart count of pod container-probe-8396/busybox-d8789c70-c6b5-4829-8755-546b12deb8f6 is now 1 (50.072564975s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:02:28.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8396" for this suite.
Nov  5 21:02:34.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:02:34.109: INFO: namespace container-probe-8396 deletion completed in 6.066414057s

• [SLOW TEST:58.182 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:02:34.109: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:02:34.142: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:02:35.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2879" for this suite.
Nov  5 21:02:41.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:02:41.289: INFO: namespace custom-resource-definition-2879 deletion completed in 6.078035842s

• [SLOW TEST:7.180 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:02:41.290: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:02:41.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7" in namespace "projected-5014" to be "success or failure"
Nov  5 21:02:41.319: INFO: Pod "downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.636955ms
Nov  5 21:02:43.322: INFO: Pod "downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004460219s
STEP: Saw pod success
Nov  5 21:02:43.322: INFO: Pod "downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7" satisfied condition "success or failure"
Nov  5 21:02:43.324: INFO: Trying to get logs from node k8s-node-1 pod downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7 container client-container: <nil>
STEP: delete the pod
Nov  5 21:02:43.346: INFO: Waiting for pod downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7 to disappear
Nov  5 21:02:43.348: INFO: Pod downwardapi-volume-5177fe0b-adab-4d5f-8033-7d34e73d1ef7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:02:43.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5014" for this suite.
Nov  5 21:02:49.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:02:49.419: INFO: namespace projected-5014 deletion completed in 6.066724171s

• [SLOW TEST:8.129 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:02:49.419: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-15eca753-9ece-4738-9eb8-c3e284798ac1
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:02:49.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8669" for this suite.
Nov  5 21:02:55.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:02:55.524: INFO: namespace configmap-8669 deletion completed in 6.07475141s

• [SLOW TEST:6.106 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:02:55.525: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Nov  5 21:02:55.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 api-versions'
Nov  5 21:02:55.634: INFO: stderr: ""
Nov  5 21:02:55.634: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:02:55.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8788" for this suite.
Nov  5 21:03:01.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:01.707: INFO: namespace kubectl-8788 deletion completed in 6.070028557s

• [SLOW TEST:6.183 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:01.708: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  5 21:03:04.252: INFO: Successfully updated pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b"
Nov  5 21:03:04.252: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b" in namespace "pods-8370" to be "terminated due to deadline exceeded"
Nov  5 21:03:04.254: INFO: Pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b": Phase="Running", Reason="", readiness=true. Elapsed: 2.050529ms
Nov  5 21:03:06.257: INFO: Pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b": Phase="Running", Reason="", readiness=true. Elapsed: 2.004867914s
Nov  5 21:03:08.260: INFO: Pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007844784s
Nov  5 21:03:08.260: INFO: Pod "pod-update-activedeadlineseconds-523204c7-6246-40df-a331-203a5b61039b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:03:08.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8370" for this suite.
Nov  5 21:03:14.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:14.344: INFO: namespace pods-8370 deletion completed in 6.080633947s

• [SLOW TEST:12.637 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:14.344: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov  5 21:03:24.406: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 535
	[quantile=0.9] = 199230
	[quantile=0.99] = 914068
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 213691
	[quantile=0.9] = 596621
	[quantile=0.99] = 914166
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 17
	[quantile=0.99] = 17
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 215080
	[quantile=0.9] = 221029
	[quantile=0.99] = 221029
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 6
	[quantile=0.99] = 19
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 11
	[quantile=0.9] = 20
	[quantile=0.99] = 45
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 13
	[quantile=0.9] = 27
	[quantile=0.99] = 33
For namespace_queue_latency_sum:
	[] = 1953
For namespace_queue_latency_count:
	[] = 122
For namespace_retries:
	[] = 124
For namespace_work_duration:
	[quantile=0.5] = 140198
	[quantile=0.9] = 188053
	[quantile=0.99] = 2862211
For namespace_work_duration_sum:
	[] = 19767006
For namespace_work_duration_count:
	[] = 122
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:03:24.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-941" for this suite.
Nov  5 21:03:30.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:30.475: INFO: namespace gc-941 deletion completed in 6.066392672s

• [SLOW TEST:16.131 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:30.475: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:03:35.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3533" for this suite.
Nov  5 21:03:42.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:42.144: INFO: namespace watch-3533 deletion completed in 6.163653801s

• [SLOW TEST:11.669 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:42.145: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:03:42.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 version'
Nov  5 21:03:42.242: INFO: stderr: ""
Nov  5 21:03:42.243: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:03:42.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-150" for this suite.
Nov  5 21:03:48.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:48.313: INFO: namespace kubectl-150 deletion completed in 6.066528978s

• [SLOW TEST:6.168 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:48.313: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-ba8a543b-66bb-475e-a3c8-0b9848cb69e8
STEP: Creating a pod to test consume configMaps
Nov  5 21:03:48.342: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c" in namespace "projected-2356" to be "success or failure"
Nov  5 21:03:48.344: INFO: Pod "pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.680451ms
Nov  5 21:03:50.347: INFO: Pod "pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0046576s
STEP: Saw pod success
Nov  5 21:03:50.347: INFO: Pod "pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c" satisfied condition "success or failure"
Nov  5 21:03:50.349: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:03:50.362: INFO: Waiting for pod pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c to disappear
Nov  5 21:03:50.364: INFO: Pod pod-projected-configmaps-2714fce6-c2be-4ff8-b939-95e089aba26c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:03:50.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2356" for this suite.
Nov  5 21:03:56.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:03:56.432: INFO: namespace projected-2356 deletion completed in 6.064627541s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:03:56.432: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1ccf8f83-5a7f-4919-84aa-123385086e1d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1ccf8f83-5a7f-4919-84aa-123385086e1d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:04:00.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1580" for this suite.
Nov  5 21:04:22.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:04:22.567: INFO: namespace projected-1580 deletion completed in 22.066241527s

• [SLOW TEST:26.135 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:04:22.567: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  5 21:04:22.825: INFO: Pod name wrapped-volume-race-effff833-e4b0-43a9-8acc-4168cd537e79: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-effff833-e4b0-43a9-8acc-4168cd537e79 in namespace emptydir-wrapper-3889, will wait for the garbage collector to delete the pods
Nov  5 21:04:36.942: INFO: Deleting ReplicationController wrapped-volume-race-effff833-e4b0-43a9-8acc-4168cd537e79 took: 5.079006ms
Nov  5 21:04:37.243: INFO: Terminating ReplicationController wrapped-volume-race-effff833-e4b0-43a9-8acc-4168cd537e79 pods took: 300.21645ms
STEP: Creating RC which spawns configmap-volume pods
Nov  5 21:05:13.454: INFO: Pod name wrapped-volume-race-c2a742ce-3872-4271-93ef-0cd031af773e: Found 0 pods out of 5
Nov  5 21:05:18.459: INFO: Pod name wrapped-volume-race-c2a742ce-3872-4271-93ef-0cd031af773e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c2a742ce-3872-4271-93ef-0cd031af773e in namespace emptydir-wrapper-3889, will wait for the garbage collector to delete the pods
Nov  5 21:05:30.530: INFO: Deleting ReplicationController wrapped-volume-race-c2a742ce-3872-4271-93ef-0cd031af773e took: 4.767698ms
Nov  5 21:05:30.830: INFO: Terminating ReplicationController wrapped-volume-race-c2a742ce-3872-4271-93ef-0cd031af773e pods took: 300.203948ms
STEP: Creating RC which spawns configmap-volume pods
Nov  5 21:06:12.743: INFO: Pod name wrapped-volume-race-f1d4dae5-ed38-4c39-944f-7772c20bc6a9: Found 0 pods out of 5
Nov  5 21:06:17.749: INFO: Pod name wrapped-volume-race-f1d4dae5-ed38-4c39-944f-7772c20bc6a9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f1d4dae5-ed38-4c39-944f-7772c20bc6a9 in namespace emptydir-wrapper-3889, will wait for the garbage collector to delete the pods
Nov  5 21:06:27.823: INFO: Deleting ReplicationController wrapped-volume-race-f1d4dae5-ed38-4c39-944f-7772c20bc6a9 took: 5.687119ms
Nov  5 21:06:28.123: INFO: Terminating ReplicationController wrapped-volume-race-f1d4dae5-ed38-4c39-944f-7772c20bc6a9 pods took: 300.243607ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:13.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3889" for this suite.
Nov  5 21:07:19.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:07:19.370: INFO: namespace emptydir-wrapper-3889 deletion completed in 6.069574627s

• [SLOW TEST:176.803 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:07:19.370: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:07:19.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac" in namespace "downward-api-1537" to be "success or failure"
Nov  5 21:07:19.398: INFO: Pod "downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.779026ms
Nov  5 21:07:21.401: INFO: Pod "downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004664254s
STEP: Saw pod success
Nov  5 21:07:21.401: INFO: Pod "downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac" satisfied condition "success or failure"
Nov  5 21:07:21.403: INFO: Trying to get logs from node k8s-node-1 pod downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac container client-container: <nil>
STEP: delete the pod
Nov  5 21:07:21.415: INFO: Waiting for pod downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac to disappear
Nov  5 21:07:21.417: INFO: Pod downwardapi-volume-169f9216-e40a-4222-9ce1-cb0abcd6e5ac no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:21.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1537" for this suite.
Nov  5 21:07:27.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:07:27.485: INFO: namespace downward-api-1537 deletion completed in 6.065199239s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:07:27.486: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  5 21:07:27.511: INFO: Waiting up to 5m0s for pod "pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1" in namespace "emptydir-5416" to be "success or failure"
Nov  5 21:07:27.513: INFO: Pod "pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.16191ms
Nov  5 21:07:29.515: INFO: Pod "pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004894569s
STEP: Saw pod success
Nov  5 21:07:29.516: INFO: Pod "pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1" satisfied condition "success or failure"
Nov  5 21:07:29.517: INFO: Trying to get logs from node k8s-node-2 pod pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1 container test-container: <nil>
STEP: delete the pod
Nov  5 21:07:29.530: INFO: Waiting for pod pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1 to disappear
Nov  5 21:07:29.532: INFO: Pod pod-8e287a86-bc8d-43f1-ac3f-8492aff6caa1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:29.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5416" for this suite.
Nov  5 21:07:35.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:07:35.608: INFO: namespace emptydir-5416 deletion completed in 6.073964054s

• [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:07:35.609: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-f4a472b4-daab-436b-a12c-a52d28526b69
STEP: Creating a pod to test consume configMaps
Nov  5 21:07:35.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d" in namespace "configmap-3463" to be "success or failure"
Nov  5 21:07:35.644: INFO: Pod "pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.736863ms
Nov  5 21:07:37.647: INFO: Pod "pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004541305s
STEP: Saw pod success
Nov  5 21:07:37.647: INFO: Pod "pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d" satisfied condition "success or failure"
Nov  5 21:07:37.649: INFO: Trying to get logs from node k8s-node-1 pod pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:07:37.662: INFO: Waiting for pod pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d to disappear
Nov  5 21:07:37.664: INFO: Pod pod-configmaps-3be7877c-daeb-4efa-893a-b3fadcb3597d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:37.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3463" for this suite.
Nov  5 21:07:43.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:07:43.733: INFO: namespace configmap-3463 deletion completed in 6.066075351s

• [SLOW TEST:8.124 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:07:43.733: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-c2ba8939-4420-401f-8b8a-b746f47c79e1
STEP: Creating a pod to test consume configMaps
Nov  5 21:07:43.763: INFO: Waiting up to 5m0s for pod "pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936" in namespace "configmap-7336" to be "success or failure"
Nov  5 21:07:43.765: INFO: Pod "pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936": Phase="Pending", Reason="", readiness=false. Elapsed: 1.861337ms
Nov  5 21:07:45.768: INFO: Pod "pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005023197s
STEP: Saw pod success
Nov  5 21:07:45.768: INFO: Pod "pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936" satisfied condition "success or failure"
Nov  5 21:07:45.770: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:07:45.783: INFO: Waiting for pod pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936 to disappear
Nov  5 21:07:45.785: INFO: Pod pod-configmaps-e5d86161-1cf1-4d08-a009-e591c4974936 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:45.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7336" for this suite.
Nov  5 21:07:51.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:07:51.855: INFO: namespace configmap-7336 deletion completed in 6.067354504s

• [SLOW TEST:8.122 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:07:51.855: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov  5 21:07:51.879: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:07:55.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5128" for this suite.
Nov  5 21:08:17.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:08:17.925: INFO: namespace init-container-5128 deletion completed in 22.064730409s

• [SLOW TEST:26.069 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:08:17.925: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov  5 21:08:17.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-2966'
Nov  5 21:08:18.201: INFO: stderr: ""
Nov  5 21:08:18.201: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  5 21:08:19.205: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:08:19.205: INFO: Found 0 / 1
Nov  5 21:08:20.204: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:08:20.204: INFO: Found 1 / 1
Nov  5 21:08:20.204: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  5 21:08:20.206: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:08:20.206: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 21:08:20.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 patch pod redis-master-hk7f7 --namespace=kubectl-2966 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  5 21:08:20.291: INFO: stderr: ""
Nov  5 21:08:20.291: INFO: stdout: "pod/redis-master-hk7f7 patched\n"
STEP: checking annotations
Nov  5 21:08:20.293: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:08:20.293: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:08:20.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2966" for this suite.
Nov  5 21:08:42.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:08:42.364: INFO: namespace kubectl-2966 deletion completed in 22.068420808s

• [SLOW TEST:24.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:08:42.365: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-a928a1c5-e4c9-433f-b620-4746a85620e9
STEP: Creating a pod to test consume configMaps
Nov  5 21:08:42.394: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7" in namespace "projected-6223" to be "success or failure"
Nov  5 21:08:42.396: INFO: Pod "pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.931582ms
Nov  5 21:08:44.399: INFO: Pod "pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004416064s
STEP: Saw pod success
Nov  5 21:08:44.399: INFO: Pod "pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7" satisfied condition "success or failure"
Nov  5 21:08:44.401: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:08:44.421: INFO: Waiting for pod pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7 to disappear
Nov  5 21:08:44.423: INFO: Pod pod-projected-configmaps-78f5d3d2-1a26-438a-bda4-203596f538c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:08:44.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6223" for this suite.
Nov  5 21:08:50.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:08:50.498: INFO: namespace projected-6223 deletion completed in 6.072699654s

• [SLOW TEST:8.134 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:08:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  5 21:08:50.539: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:50.542: INFO: Number of nodes with available pods: 0
Nov  5 21:08:50.542: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:08:51.546: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:51.548: INFO: Number of nodes with available pods: 0
Nov  5 21:08:51.548: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:08:52.546: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:52.548: INFO: Number of nodes with available pods: 3
Nov  5 21:08:52.548: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  5 21:08:52.558: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:52.560: INFO: Number of nodes with available pods: 2
Nov  5 21:08:52.560: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:53.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:53.566: INFO: Number of nodes with available pods: 2
Nov  5 21:08:53.566: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:54.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:54.567: INFO: Number of nodes with available pods: 2
Nov  5 21:08:54.567: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:55.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:55.566: INFO: Number of nodes with available pods: 2
Nov  5 21:08:55.566: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:56.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:56.566: INFO: Number of nodes with available pods: 2
Nov  5 21:08:56.566: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:57.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:57.567: INFO: Number of nodes with available pods: 2
Nov  5 21:08:57.567: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:58.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:58.567: INFO: Number of nodes with available pods: 2
Nov  5 21:08:58.567: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:08:59.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:08:59.567: INFO: Number of nodes with available pods: 2
Nov  5 21:08:59.567: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:09:00.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:09:00.567: INFO: Number of nodes with available pods: 2
Nov  5 21:09:00.567: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:09:01.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:09:01.566: INFO: Number of nodes with available pods: 2
Nov  5 21:09:01.566: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:09:02.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:09:02.566: INFO: Number of nodes with available pods: 2
Nov  5 21:09:02.566: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:09:03.565: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:09:03.568: INFO: Number of nodes with available pods: 2
Nov  5 21:09:03.568: INFO: Node k8s-node-3 is running more than one daemon pod
Nov  5 21:09:04.564: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:09:04.567: INFO: Number of nodes with available pods: 3
Nov  5 21:09:04.567: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8671, will wait for the garbage collector to delete the pods
Nov  5 21:09:04.625: INFO: Deleting DaemonSet.extensions daemon-set took: 4.552066ms
Nov  5 21:09:04.925: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.225523ms
Nov  5 21:09:12.828: INFO: Number of nodes with available pods: 0
Nov  5 21:09:12.828: INFO: Number of running nodes: 0, number of available pods: 0
Nov  5 21:09:12.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8671/daemonsets","resourceVersion":"14177"},"items":null}

Nov  5 21:09:12.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8671/pods","resourceVersion":"14177"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:12.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8671" for this suite.
Nov  5 21:09:18.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:18.908: INFO: namespace daemonsets-8671 deletion completed in 6.064984794s

• [SLOW TEST:28.409 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:18.908: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Nov  5 21:09:19.451: INFO: created pod pod-service-account-defaultsa
Nov  5 21:09:19.451: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  5 21:09:19.453: INFO: created pod pod-service-account-mountsa
Nov  5 21:09:19.453: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  5 21:09:19.459: INFO: created pod pod-service-account-nomountsa
Nov  5 21:09:19.459: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  5 21:09:19.463: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  5 21:09:19.463: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  5 21:09:19.468: INFO: created pod pod-service-account-mountsa-mountspec
Nov  5 21:09:19.468: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  5 21:09:19.475: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  5 21:09:19.475: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  5 21:09:19.480: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  5 21:09:19.480: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  5 21:09:19.484: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  5 21:09:19.484: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  5 21:09:19.492: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  5 21:09:19.492: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:19.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-509" for this suite.
Nov  5 21:09:25.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:25.576: INFO: namespace svcaccounts-509 deletion completed in 6.078118399s

• [SLOW TEST:6.668 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:25.576: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-935/configmap-test-fbe6e1b8-8e56-4e65-9788-8f55fa40f77f
STEP: Creating a pod to test consume configMaps
Nov  5 21:09:25.657: INFO: Waiting up to 5m0s for pod "pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f" in namespace "configmap-935" to be "success or failure"
Nov  5 21:09:25.658: INFO: Pod "pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.61468ms
Nov  5 21:09:27.661: INFO: Pod "pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004330208s
STEP: Saw pod success
Nov  5 21:09:27.661: INFO: Pod "pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f" satisfied condition "success or failure"
Nov  5 21:09:27.663: INFO: Trying to get logs from node k8s-node-1 pod pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f container env-test: <nil>
STEP: delete the pod
Nov  5 21:09:27.675: INFO: Waiting for pod pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f to disappear
Nov  5 21:09:27.677: INFO: Pod pod-configmaps-eb1adbd0-d564-4d62-a064-c8ea6577e50f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:27.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-935" for this suite.
Nov  5 21:09:33.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:33.750: INFO: namespace configmap-935 deletion completed in 6.069706059s

• [SLOW TEST:8.174 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:33.750: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov  5 21:09:33.782: INFO: Waiting up to 5m0s for pod "downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca" in namespace "downward-api-8119" to be "success or failure"
Nov  5 21:09:33.785: INFO: Pod "downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca": Phase="Pending", Reason="", readiness=false. Elapsed: 3.235843ms
Nov  5 21:09:35.788: INFO: Pod "downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006205394s
STEP: Saw pod success
Nov  5 21:09:35.788: INFO: Pod "downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca" satisfied condition "success or failure"
Nov  5 21:09:35.791: INFO: Trying to get logs from node k8s-node-2 pod downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:09:35.809: INFO: Waiting for pod downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca to disappear
Nov  5 21:09:35.811: INFO: Pod downward-api-c663be97-aa0a-4247-93c0-2df0bb2eecca no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:35.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8119" for this suite.
Nov  5 21:09:41.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:41.882: INFO: namespace downward-api-8119 deletion completed in 6.066722207s

• [SLOW TEST:8.132 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:41.882: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  5 21:09:41.908: INFO: Waiting up to 5m0s for pod "pod-b180eda5-276c-4f5c-bb53-30c8f398b34c" in namespace "emptydir-574" to be "success or failure"
Nov  5 21:09:41.910: INFO: Pod "pod-b180eda5-276c-4f5c-bb53-30c8f398b34c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.160531ms
Nov  5 21:09:43.913: INFO: Pod "pod-b180eda5-276c-4f5c-bb53-30c8f398b34c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00489611s
STEP: Saw pod success
Nov  5 21:09:43.913: INFO: Pod "pod-b180eda5-276c-4f5c-bb53-30c8f398b34c" satisfied condition "success or failure"
Nov  5 21:09:43.914: INFO: Trying to get logs from node k8s-node-1 pod pod-b180eda5-276c-4f5c-bb53-30c8f398b34c container test-container: <nil>
STEP: delete the pod
Nov  5 21:09:43.926: INFO: Waiting for pod pod-b180eda5-276c-4f5c-bb53-30c8f398b34c to disappear
Nov  5 21:09:43.928: INFO: Pod pod-b180eda5-276c-4f5c-bb53-30c8f398b34c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:43.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-574" for this suite.
Nov  5 21:09:49.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:49.997: INFO: namespace emptydir-574 deletion completed in 6.065716442s

• [SLOW TEST:8.115 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:49.997: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:09:50.020: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  5 21:09:52.041: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:09:53.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3966" for this suite.
Nov  5 21:09:59.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:09:59.116: INFO: namespace replication-controller-3966 deletion completed in 6.066638205s

• [SLOW TEST:9.119 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:09:59.117: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  5 21:10:01.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec pod-sharedvolume-2cc6ecee-b318-48b6-88cd-c70d9dd3a5ec -c busybox-main-container --namespace=emptydir-3043 -- cat /usr/share/volumeshare/shareddata.txt'
Nov  5 21:10:01.360: INFO: stderr: ""
Nov  5 21:10:01.360: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:10:01.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3043" for this suite.
Nov  5 21:10:07.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:10:07.432: INFO: namespace emptydir-3043 deletion completed in 6.068940236s

• [SLOW TEST:8.316 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:10:07.433: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:10:07.464: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  5 21:10:12.467: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  5 21:10:12.467: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  5 21:10:14.470: INFO: Creating deployment "test-rollover-deployment"
Nov  5 21:10:14.475: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  5 21:10:16.479: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  5 21:10:16.484: INFO: Ensure that both replica sets have 1 created replica
Nov  5 21:10:16.488: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  5 21:10:16.492: INFO: Updating deployment test-rollover-deployment
Nov  5 21:10:16.492: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  5 21:10:18.496: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  5 21:10:18.500: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  5 21:10:18.504: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 21:10:18.504: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585017, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:10:20.509: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 21:10:20.509: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585017, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:10:22.509: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 21:10:22.509: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585017, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:10:24.509: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 21:10:24.509: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585017, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:10:26.508: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 21:10:26.509: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585017, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585014, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:10:28.508: INFO: 
Nov  5 21:10:28.508: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov  5 21:10:28.514: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3602,SelfLink:/apis/apps/v1/namespaces/deployment-3602/deployments/test-rollover-deployment,UID:429ae5c5-b2e3-46ca-8d07-69be12156e49,ResourceVersion:14827,Generation:2,CreationTimestamp:2019-11-05 21:10:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-05 21:10:14 +0000 UTC 2019-11-05 21:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-05 21:10:27 +0000 UTC 2019-11-05 21:10:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 21:10:28.517: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-3602,SelfLink:/apis/apps/v1/namespaces/deployment-3602/replicasets/test-rollover-deployment-854595fc44,UID:25a35def-8ec6-4da2-a634-f5666ffa3852,ResourceVersion:14817,Generation:2,CreationTimestamp:2019-11-05 21:10:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429ae5c5-b2e3-46ca-8d07-69be12156e49 0xc0032e8107 0xc0032e8108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  5 21:10:28.517: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  5 21:10:28.517: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3602,SelfLink:/apis/apps/v1/namespaces/deployment-3602/replicasets/test-rollover-controller,UID:e3830be9-aca4-44a1-97bc-45318579e1ce,ResourceVersion:14826,Generation:2,CreationTimestamp:2019-11-05 21:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429ae5c5-b2e3-46ca-8d07-69be12156e49 0xc0032e8037 0xc0032e8038}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:10:28.517: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-3602,SelfLink:/apis/apps/v1/namespaces/deployment-3602/replicasets/test-rollover-deployment-9b8b997cf,UID:0cb9c9db-fdd7-492e-b6d0-ffea5a46685a,ResourceVersion:14777,Generation:2,CreationTimestamp:2019-11-05 21:10:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 429ae5c5-b2e3-46ca-8d07-69be12156e49 0xc0032e81d0 0xc0032e81d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:10:28.519: INFO: Pod "test-rollover-deployment-854595fc44-8gf9b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-8gf9b,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-3602,SelfLink:/api/v1/namespaces/deployment-3602/pods/test-rollover-deployment-854595fc44-8gf9b,UID:b58d1293-b84e-4eff-ab2f-2ceb83acebd8,ResourceVersion:14795,Generation:0,CreationTimestamp:2019-11-05 21:10:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 25a35def-8ec6-4da2-a634-f5666ffa3852 0xc002873dd7 0xc002873dd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lzrtg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lzrtg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lzrtg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002873e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002873e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:10:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:10:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:10:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:10:16 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.78,StartTime:2019-11-05 21:10:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-05 21:10:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bdd360fd95960b85e817905f8c0bf68d18cb890c69a425db644696ffb7bb30fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:10:28.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3602" for this suite.
Nov  5 21:10:34.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:10:34.595: INFO: namespace deployment-3602 deletion completed in 6.072043061s

• [SLOW TEST:27.162 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:10:34.595: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-4b541074-367e-47a6-8e87-b1d4547a4fba
STEP: Creating a pod to test consume configMaps
Nov  5 21:10:34.628: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a" in namespace "projected-4633" to be "success or failure"
Nov  5 21:10:34.632: INFO: Pod "pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.340373ms
Nov  5 21:10:36.634: INFO: Pod "pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005819166s
STEP: Saw pod success
Nov  5 21:10:36.634: INFO: Pod "pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a" satisfied condition "success or failure"
Nov  5 21:10:36.636: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:10:36.648: INFO: Waiting for pod pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a to disappear
Nov  5 21:10:36.650: INFO: Pod pod-projected-configmaps-88fcbe86-facf-46c3-856c-c8402d0b186a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:10:36.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4633" for this suite.
Nov  5 21:10:42.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:10:42.724: INFO: namespace projected-4633 deletion completed in 6.069830408s

• [SLOW TEST:8.129 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:10:42.724: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  5 21:10:48.779: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:48.779: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:48.906: INFO: Exec stderr: ""
Nov  5 21:10:48.906: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:48.906: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.030: INFO: Exec stderr: ""
Nov  5 21:10:49.030: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.030: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.150: INFO: Exec stderr: ""
Nov  5 21:10:49.150: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.150: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.268: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  5 21:10:49.268: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.268: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.384: INFO: Exec stderr: ""
Nov  5 21:10:49.384: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.384: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.506: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  5 21:10:49.506: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.506: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.634: INFO: Exec stderr: ""
Nov  5 21:10:49.634: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.634: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.756: INFO: Exec stderr: ""
Nov  5 21:10:49.756: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.756: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:49.879: INFO: Exec stderr: ""
Nov  5 21:10:49.879: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7267 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:10:49.879: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:10:50.002: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:10:50.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7267" for this suite.
Nov  5 21:11:28.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:11:28.072: INFO: namespace e2e-kubelet-etc-hosts-7267 deletion completed in 38.066884795s

• [SLOW TEST:45.348 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:11:28.073: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:11:28.105: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2" in namespace "projected-311" to be "success or failure"
Nov  5 21:11:28.106: INFO: Pod "downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.670164ms
Nov  5 21:11:30.109: INFO: Pod "downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004466069s
STEP: Saw pod success
Nov  5 21:11:30.109: INFO: Pod "downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2" satisfied condition "success or failure"
Nov  5 21:11:30.111: INFO: Trying to get logs from node k8s-node-3 pod downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2 container client-container: <nil>
STEP: delete the pod
Nov  5 21:11:30.128: INFO: Waiting for pod downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2 to disappear
Nov  5 21:11:30.130: INFO: Pod downwardapi-volume-a4b928f1-e075-44e9-8bd6-9a9824b78af2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:11:30.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-311" for this suite.
Nov  5 21:11:36.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:11:36.201: INFO: namespace projected-311 deletion completed in 6.067401635s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:11:36.202: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov  5 21:11:36.223: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Nov  5 21:11:36.641: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  5 21:11:38.669: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:40.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:42.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:44.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:46.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:48.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708585096, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 21:11:51.598: INFO: Waited 921.915539ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:11:51.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1267" for this suite.
Nov  5 21:11:58.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:11:58.198: INFO: namespace aggregator-1267 deletion completed in 6.162598439s

• [SLOW TEST:21.996 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:11:58.198: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2011
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2011
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2011
Nov  5 21:11:58.242: INFO: Found 0 stateful pods, waiting for 1
Nov  5 21:12:08.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  5 21:12:08.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:12:08.460: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:12:08.460: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:12:08.460: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:12:08.463: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  5 21:12:18.466: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:12:18.466: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:12:18.474: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999568s
Nov  5 21:12:19.477: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997815025s
Nov  5 21:12:20.480: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994681178s
Nov  5 21:12:21.484: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991633399s
Nov  5 21:12:22.487: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988063181s
Nov  5 21:12:23.490: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985002217s
Nov  5 21:12:24.493: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982319873s
Nov  5 21:12:25.496: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979381402s
Nov  5 21:12:26.499: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976040038s
Nov  5 21:12:27.503: INFO: Verifying statefulset ss doesn't scale past 1 for another 972.763183ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2011
Nov  5 21:12:28.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:12:28.711: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:12:28.711: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:12:28.711: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:12:28.715: INFO: Found 1 stateful pods, waiting for 3
Nov  5 21:12:38.719: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:12:38.719: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:12:38.719: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  5 21:12:38.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:12:38.933: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:12:38.933: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:12:38.933: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:12:38.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:12:39.139: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:12:39.139: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:12:39.139: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:12:39.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:12:39.396: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:12:39.396: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:12:39.396: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:12:39.396: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:12:39.399: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  5 21:12:49.404: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:12:49.404: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:12:49.404: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:12:49.418: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999748s
Nov  5 21:12:50.421: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990747933s
Nov  5 21:12:51.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987363381s
Nov  5 21:12:52.428: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984161247s
Nov  5 21:12:53.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980559872s
Nov  5 21:12:54.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977265085s
Nov  5 21:12:55.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973666402s
Nov  5 21:12:56.442: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970525613s
Nov  5 21:12:57.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967022542s
Nov  5 21:12:58.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.63087ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2011
Nov  5 21:12:59.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:12:59.664: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:12:59.664: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:12:59.664: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:12:59.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:12:59.888: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:12:59.888: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:12:59.888: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:12:59.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-2011 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:13:00.096: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:13:00.096: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:13:00.096: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:13:00.096: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov  5 21:13:30.113: INFO: Deleting all statefulset in ns statefulset-2011
Nov  5 21:13:30.115: INFO: Scaling statefulset ss to 0
Nov  5 21:13:30.121: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:13:30.122: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:13:30.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2011" for this suite.
Nov  5 21:13:36.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:13:36.202: INFO: namespace statefulset-2011 deletion completed in 6.069409921s

• [SLOW TEST:98.004 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:13:36.202: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-d5ed0e1a-6023-4703-8347-1c68ec08b3e8
STEP: Creating a pod to test consume configMaps
Nov  5 21:13:36.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4" in namespace "configmap-9965" to be "success or failure"
Nov  5 21:13:36.234: INFO: Pod "pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710418ms
Nov  5 21:13:38.237: INFO: Pod "pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005970565s
STEP: Saw pod success
Nov  5 21:13:38.237: INFO: Pod "pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4" satisfied condition "success or failure"
Nov  5 21:13:38.239: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:13:38.253: INFO: Waiting for pod pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4 to disappear
Nov  5 21:13:38.255: INFO: Pod pod-configmaps-298ca386-c7d4-44c3-be64-c1c120a36fb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:13:38.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9965" for this suite.
Nov  5 21:13:44.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:13:44.323: INFO: namespace configmap-9965 deletion completed in 6.064981686s

• [SLOW TEST:8.121 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:13:44.323: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  5 21:13:44.350: INFO: Waiting up to 5m0s for pod "pod-e5dc7768-8b07-4d55-a4be-3f57c5617942" in namespace "emptydir-1022" to be "success or failure"
Nov  5 21:13:44.352: INFO: Pod "pod-e5dc7768-8b07-4d55-a4be-3f57c5617942": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143512ms
Nov  5 21:13:46.355: INFO: Pod "pod-e5dc7768-8b07-4d55-a4be-3f57c5617942": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005133605s
STEP: Saw pod success
Nov  5 21:13:46.355: INFO: Pod "pod-e5dc7768-8b07-4d55-a4be-3f57c5617942" satisfied condition "success or failure"
Nov  5 21:13:46.357: INFO: Trying to get logs from node k8s-node-1 pod pod-e5dc7768-8b07-4d55-a4be-3f57c5617942 container test-container: <nil>
STEP: delete the pod
Nov  5 21:13:46.372: INFO: Waiting for pod pod-e5dc7768-8b07-4d55-a4be-3f57c5617942 to disappear
Nov  5 21:13:46.375: INFO: Pod pod-e5dc7768-8b07-4d55-a4be-3f57c5617942 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:13:46.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1022" for this suite.
Nov  5 21:13:52.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:13:52.447: INFO: namespace emptydir-1022 deletion completed in 6.065872231s

• [SLOW TEST:8.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:13:52.447: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:13:52.483: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  5 21:13:52.489: INFO: Number of nodes with available pods: 0
Nov  5 21:13:52.489: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  5 21:13:52.501: INFO: Number of nodes with available pods: 0
Nov  5 21:13:52.501: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:53.504: INFO: Number of nodes with available pods: 0
Nov  5 21:13:53.504: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:54.504: INFO: Number of nodes with available pods: 1
Nov  5 21:13:54.504: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  5 21:13:54.513: INFO: Number of nodes with available pods: 1
Nov  5 21:13:54.513: INFO: Number of running nodes: 0, number of available pods: 1
Nov  5 21:13:55.516: INFO: Number of nodes with available pods: 0
Nov  5 21:13:55.516: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  5 21:13:55.521: INFO: Number of nodes with available pods: 0
Nov  5 21:13:55.521: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:56.524: INFO: Number of nodes with available pods: 0
Nov  5 21:13:56.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:57.524: INFO: Number of nodes with available pods: 0
Nov  5 21:13:57.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:58.524: INFO: Number of nodes with available pods: 0
Nov  5 21:13:58.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:13:59.524: INFO: Number of nodes with available pods: 0
Nov  5 21:13:59.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:00.524: INFO: Number of nodes with available pods: 0
Nov  5 21:14:00.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:01.524: INFO: Number of nodes with available pods: 0
Nov  5 21:14:01.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:02.524: INFO: Number of nodes with available pods: 0
Nov  5 21:14:02.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:03.524: INFO: Number of nodes with available pods: 0
Nov  5 21:14:03.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:04.524: INFO: Number of nodes with available pods: 0
Nov  5 21:14:04.524: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:14:05.524: INFO: Number of nodes with available pods: 1
Nov  5 21:14:05.524: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-457, will wait for the garbage collector to delete the pods
Nov  5 21:14:05.585: INFO: Deleting DaemonSet.extensions daemon-set took: 5.098717ms
Nov  5 21:14:05.885: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.262252ms
Nov  5 21:14:12.791: INFO: Number of nodes with available pods: 0
Nov  5 21:14:12.791: INFO: Number of running nodes: 0, number of available pods: 0
Nov  5 21:14:12.793: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-457/daemonsets","resourceVersion":"15879"},"items":null}

Nov  5 21:14:12.795: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-457/pods","resourceVersion":"15879"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:14:12.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-457" for this suite.
Nov  5 21:14:18.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:14:18.883: INFO: namespace daemonsets-457 deletion completed in 6.06965602s

• [SLOW TEST:26.436 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:14:18.884: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f
Nov  5 21:14:18.911: INFO: Pod name my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f: Found 0 pods out of 1
Nov  5 21:14:23.914: INFO: Pod name my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f: Found 1 pods out of 1
Nov  5 21:14:23.914: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f" are running
Nov  5 21:14:23.916: INFO: Pod "my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f-t2hvr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 21:14:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 21:14:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 21:14:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-05 21:14:18 +0000 UTC Reason: Message:}])
Nov  5 21:14:23.916: INFO: Trying to dial the pod
Nov  5 21:14:28.924: INFO: Controller my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f: Got expected result from replica 1 [my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f-t2hvr]: "my-hostname-basic-55065bb0-9dc7-449a-8c64-d16c9716622f-t2hvr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:14:28.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6665" for this suite.
Nov  5 21:14:34.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:14:34.996: INFO: namespace replication-controller-6665 deletion completed in 6.068797011s

• [SLOW TEST:16.112 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:14:34.997: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:14:37.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2934" for this suite.
Nov  5 21:15:23.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:15:23.108: INFO: namespace kubelet-test-2934 deletion completed in 46.064324945s

• [SLOW TEST:48.111 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:15:23.108: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-998132b4-9ee1-4f2b-97ec-340f05705845
STEP: Creating a pod to test consume configMaps
Nov  5 21:15:23.150: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6" in namespace "projected-6999" to be "success or failure"
Nov  5 21:15:23.152: INFO: Pod "pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.788078ms
Nov  5 21:15:25.155: INFO: Pod "pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004854s
STEP: Saw pod success
Nov  5 21:15:25.155: INFO: Pod "pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6" satisfied condition "success or failure"
Nov  5 21:15:25.157: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:15:25.172: INFO: Waiting for pod pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6 to disappear
Nov  5 21:15:25.175: INFO: Pod pod-projected-configmaps-6a33025d-8c24-4bd3-bc4c-e57effb29dd6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:15:25.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6999" for this suite.
Nov  5 21:15:31.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:15:31.240: INFO: namespace projected-6999 deletion completed in 6.062867873s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:15:31.240: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5aaf16d4-9c5c-4ee4-8554-88cf9e90026e
STEP: Creating a pod to test consume configMaps
Nov  5 21:15:31.268: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e" in namespace "projected-1559" to be "success or failure"
Nov  5 21:15:31.271: INFO: Pod "pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.758006ms
Nov  5 21:15:33.274: INFO: Pod "pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005795943s
STEP: Saw pod success
Nov  5 21:15:33.274: INFO: Pod "pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e" satisfied condition "success or failure"
Nov  5 21:15:33.275: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:15:33.290: INFO: Waiting for pod pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e to disappear
Nov  5 21:15:33.292: INFO: Pod pod-projected-configmaps-65b2d7c0-0309-4251-8e6c-f77c3aba600e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:15:33.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1559" for this suite.
Nov  5 21:15:39.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:15:39.360: INFO: namespace projected-1559 deletion completed in 6.065746485s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:15:39.361: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:15:39.388: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3" in namespace "downward-api-4679" to be "success or failure"
Nov  5 21:15:39.389: INFO: Pod "downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.555662ms
Nov  5 21:15:41.392: INFO: Pod "downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00448799s
STEP: Saw pod success
Nov  5 21:15:41.392: INFO: Pod "downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3" satisfied condition "success or failure"
Nov  5 21:15:41.395: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3 container client-container: <nil>
STEP: delete the pod
Nov  5 21:15:41.408: INFO: Waiting for pod downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3 to disappear
Nov  5 21:15:41.410: INFO: Pod downwardapi-volume-1e8dcbb4-430e-4acd-b06e-294139da5eb3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:15:41.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4679" for this suite.
Nov  5 21:15:47.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:15:47.486: INFO: namespace downward-api-4679 deletion completed in 6.072571943s

• [SLOW TEST:8.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:15:47.486: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  5 21:15:50.028: INFO: Successfully updated pod "pod-update-b2dcc021-16cf-4957-bd23-5e5f72b3e1bd"
STEP: verifying the updated pod is in kubernetes
Nov  5 21:15:50.034: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:15:50.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7267" for this suite.
Nov  5 21:16:12.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:16:12.109: INFO: namespace pods-7267 deletion completed in 22.070863739s

• [SLOW TEST:24.623 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:16:12.109: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Nov  5 21:16:12.131: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-243470310 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:16:12.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3626" for this suite.
Nov  5 21:16:18.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:16:18.282: INFO: namespace kubectl-3626 deletion completed in 6.068743973s

• [SLOW TEST:6.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:16:18.282: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  5 21:16:22.329: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:22.331: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:24.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:24.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:26.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:26.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:28.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:28.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:30.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:30.335: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:32.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:32.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:34.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:34.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:36.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:36.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:38.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:38.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:40.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:40.334: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 21:16:42.331: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 21:16:42.334: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:16:42.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9830" for this suite.
Nov  5 21:17:04.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:17:04.411: INFO: namespace container-lifecycle-hook-9830 deletion completed in 22.067259022s

• [SLOW TEST:46.129 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:17:04.412: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov  5 21:17:04.441: INFO: Waiting up to 5m0s for pod "downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a" in namespace "downward-api-6849" to be "success or failure"
Nov  5 21:17:04.443: INFO: Pod "downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.616363ms
Nov  5 21:17:06.446: INFO: Pod "downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005237999s
STEP: Saw pod success
Nov  5 21:17:06.446: INFO: Pod "downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a" satisfied condition "success or failure"
Nov  5 21:17:06.448: INFO: Trying to get logs from node k8s-node-2 pod downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:17:06.463: INFO: Waiting for pod downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a to disappear
Nov  5 21:17:06.465: INFO: Pod downward-api-791a7ef2-cbc2-44c6-b1e8-7d317066862a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:17:06.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6849" for this suite.
Nov  5 21:17:12.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:17:12.534: INFO: namespace downward-api-6849 deletion completed in 6.06539597s

• [SLOW TEST:8.122 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:17:12.534: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Nov  5 21:17:12.562: INFO: Waiting up to 5m0s for pod "var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89" in namespace "var-expansion-4472" to be "success or failure"
Nov  5 21:17:12.566: INFO: Pod "var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89": Phase="Pending", Reason="", readiness=false. Elapsed: 3.241076ms
Nov  5 21:17:14.568: INFO: Pod "var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006041115s
STEP: Saw pod success
Nov  5 21:17:14.568: INFO: Pod "var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89" satisfied condition "success or failure"
Nov  5 21:17:14.570: INFO: Trying to get logs from node k8s-node-1 pod var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89 container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:17:14.585: INFO: Waiting for pod var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89 to disappear
Nov  5 21:17:14.587: INFO: Pod var-expansion-7be75a3a-23c4-4a89-9ad1-5644e766be89 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:17:14.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4472" for this suite.
Nov  5 21:17:20.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:17:20.655: INFO: namespace var-expansion-4472 deletion completed in 6.064689234s

• [SLOW TEST:8.121 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:17:20.655: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Nov  5 21:17:22.690: INFO: Pod pod-hostip-f57452d3-7df5-4d38-bbbd-19efc16d5eda has hostIP: 10.40.3.112
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:17:22.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9865" for this suite.
Nov  5 21:17:44.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:17:44.766: INFO: namespace pods-9865 deletion completed in 22.07261305s

• [SLOW TEST:24.110 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:17:44.766: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  5 21:17:44.795: INFO: Waiting up to 5m0s for pod "pod-70775009-4f53-41df-9a3f-acee76dafac8" in namespace "emptydir-2758" to be "success or failure"
Nov  5 21:17:44.797: INFO: Pod "pod-70775009-4f53-41df-9a3f-acee76dafac8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.966465ms
Nov  5 21:17:46.799: INFO: Pod "pod-70775009-4f53-41df-9a3f-acee76dafac8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004370847s
STEP: Saw pod success
Nov  5 21:17:46.799: INFO: Pod "pod-70775009-4f53-41df-9a3f-acee76dafac8" satisfied condition "success or failure"
Nov  5 21:17:46.801: INFO: Trying to get logs from node k8s-node-1 pod pod-70775009-4f53-41df-9a3f-acee76dafac8 container test-container: <nil>
STEP: delete the pod
Nov  5 21:17:46.815: INFO: Waiting for pod pod-70775009-4f53-41df-9a3f-acee76dafac8 to disappear
Nov  5 21:17:46.817: INFO: Pod pod-70775009-4f53-41df-9a3f-acee76dafac8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:17:46.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2758" for this suite.
Nov  5 21:17:52.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:17:52.890: INFO: namespace emptydir-2758 deletion completed in 6.069883623s

• [SLOW TEST:8.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:17:52.891: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1aa0fc1e-d615-4bd2-abf8-3921bbf2d81c
STEP: Creating a pod to test consume secrets
Nov  5 21:17:52.921: INFO: Waiting up to 5m0s for pod "pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69" in namespace "secrets-9476" to be "success or failure"
Nov  5 21:17:52.925: INFO: Pod "pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021635ms
Nov  5 21:17:54.927: INFO: Pod "pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006786237s
STEP: Saw pod success
Nov  5 21:17:54.928: INFO: Pod "pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69" satisfied condition "success or failure"
Nov  5 21:17:54.929: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:17:54.943: INFO: Waiting for pod pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69 to disappear
Nov  5 21:17:54.945: INFO: Pod pod-secrets-7b55e8bc-1bfb-4ba0-a545-9a3c59ae3b69 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:17:54.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9476" for this suite.
Nov  5 21:18:00.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:18:01.016: INFO: namespace secrets-9476 deletion completed in 6.067841102s

• [SLOW TEST:8.125 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:18:01.016: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-8334
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8334 to expose endpoints map[]
Nov  5 21:18:01.049: INFO: successfully validated that service endpoint-test2 in namespace services-8334 exposes endpoints map[] (2.317567ms elapsed)
STEP: Creating pod pod1 in namespace services-8334
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8334 to expose endpoints map[pod1:[80]]
Nov  5 21:18:03.070: INFO: successfully validated that service endpoint-test2 in namespace services-8334 exposes endpoints map[pod1:[80]] (2.015074365s elapsed)
STEP: Creating pod pod2 in namespace services-8334
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8334 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  5 21:18:04.087: INFO: successfully validated that service endpoint-test2 in namespace services-8334 exposes endpoints map[pod1:[80] pod2:[80]] (1.013312608s elapsed)
STEP: Deleting pod pod1 in namespace services-8334
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8334 to expose endpoints map[pod2:[80]]
Nov  5 21:18:04.096: INFO: successfully validated that service endpoint-test2 in namespace services-8334 exposes endpoints map[pod2:[80]] (4.62276ms elapsed)
STEP: Deleting pod pod2 in namespace services-8334
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8334 to expose endpoints map[]
Nov  5 21:18:04.104: INFO: successfully validated that service endpoint-test2 in namespace services-8334 exposes endpoints map[] (2.803637ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:18:04.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8334" for this suite.
Nov  5 21:18:26.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:18:26.190: INFO: namespace services-8334 deletion completed in 22.069514673s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:25.174 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:18:26.190: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9818
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov  5 21:18:26.227: INFO: Found 0 stateful pods, waiting for 3
Nov  5 21:18:36.231: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:18:36.231: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:18:36.231: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:18:36.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-9818 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:18:36.507: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:18:36.508: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:18:36.508: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  5 21:18:46.556: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  5 21:18:56.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-9818 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:18:56.785: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:18:56.785: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:18:56.785: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:19:16.799: INFO: Waiting for StatefulSet statefulset-9818/ss2 to complete update
Nov  5 21:19:16.799: INFO: Waiting for Pod statefulset-9818/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Nov  5 21:19:26.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-9818 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:19:27.007: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:19:27.007: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:19:27.007: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:19:37.032: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  5 21:19:47.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-9818 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:19:47.262: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:19:47.262: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:19:47.262: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:20:07.276: INFO: Waiting for StatefulSet statefulset-9818/ss2 to complete update
Nov  5 21:20:07.276: INFO: Waiting for Pod statefulset-9818/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov  5 21:20:17.281: INFO: Deleting all statefulset in ns statefulset-9818
Nov  5 21:20:17.283: INFO: Scaling statefulset ss2 to 0
Nov  5 21:20:37.295: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:20:37.297: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:20:37.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9818" for this suite.
Nov  5 21:20:43.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:20:43.381: INFO: namespace statefulset-9818 deletion completed in 6.069855136s

• [SLOW TEST:137.191 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:20:43.381: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  5 21:20:45.418: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:20:45.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4299" for this suite.
Nov  5 21:20:51.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:20:51.498: INFO: namespace container-runtime-4299 deletion completed in 6.069245157s

• [SLOW TEST:8.117 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:20:51.498: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  5 21:20:51.525: INFO: Waiting up to 5m0s for pod "pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876" in namespace "emptydir-997" to be "success or failure"
Nov  5 21:20:51.527: INFO: Pod "pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179365ms
Nov  5 21:20:53.530: INFO: Pod "pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004894354s
STEP: Saw pod success
Nov  5 21:20:53.530: INFO: Pod "pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876" satisfied condition "success or failure"
Nov  5 21:20:53.532: INFO: Trying to get logs from node k8s-node-1 pod pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876 container test-container: <nil>
STEP: delete the pod
Nov  5 21:20:53.546: INFO: Waiting for pod pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876 to disappear
Nov  5 21:20:53.548: INFO: Pod pod-b4febb7a-e0d7-46ca-8f8f-f0ee8dfca876 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:20:53.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-997" for this suite.
Nov  5 21:20:59.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:20:59.620: INFO: namespace emptydir-997 deletion completed in 6.068410285s

• [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:20:59.620: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-e6c1176c-1fb6-4ab7-b817-b57a13d8f4bd
STEP: Creating a pod to test consume secrets
Nov  5 21:20:59.651: INFO: Waiting up to 5m0s for pod "pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0" in namespace "secrets-8122" to be "success or failure"
Nov  5 21:20:59.652: INFO: Pod "pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.680904ms
Nov  5 21:21:01.656: INFO: Pod "pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004901129s
STEP: Saw pod success
Nov  5 21:21:01.656: INFO: Pod "pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0" satisfied condition "success or failure"
Nov  5 21:21:01.658: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:21:01.673: INFO: Waiting for pod pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0 to disappear
Nov  5 21:21:01.675: INFO: Pod pod-secrets-66421c6d-189d-41ae-bc48-b70aa0fa6aa0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:01.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8122" for this suite.
Nov  5 21:21:07.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:07.745: INFO: namespace secrets-8122 deletion completed in 6.067250077s

• [SLOW TEST:8.124 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:07.745: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Nov  5 21:21:07.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 --namespace=kubectl-8911 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  5 21:21:09.609: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  5 21:21:09.609: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:11.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8911" for this suite.
Nov  5 21:21:17.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:17.686: INFO: namespace kubectl-8911 deletion completed in 6.06925117s

• [SLOW TEST:9.941 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:17.686: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:21:17.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d" in namespace "downward-api-3330" to be "success or failure"
Nov  5 21:21:17.717: INFO: Pod "downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.198548ms
Nov  5 21:21:19.719: INFO: Pod "downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004870573s
STEP: Saw pod success
Nov  5 21:21:19.719: INFO: Pod "downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d" satisfied condition "success or failure"
Nov  5 21:21:19.721: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d container client-container: <nil>
STEP: delete the pod
Nov  5 21:21:19.734: INFO: Waiting for pod downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d to disappear
Nov  5 21:21:19.736: INFO: Pod downwardapi-volume-8e5881ae-6ac8-441e-9166-290b428cd79d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:19.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3330" for this suite.
Nov  5 21:21:25.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:25.805: INFO: namespace downward-api-3330 deletion completed in 6.0661397s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:25.806: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  5 21:21:25.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7790,SelfLink:/api/v1/namespaces/watch-7790/configmaps/e2e-watch-test-resource-version,UID:8c814465-f5c8-4b5f-98d1-e53e2e256096,ResourceVersion:17828,Generation:0,CreationTimestamp:2019-11-05 21:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  5 21:21:25.840: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7790,SelfLink:/api/v1/namespaces/watch-7790/configmaps/e2e-watch-test-resource-version,UID:8c814465-f5c8-4b5f-98d1-e53e2e256096,ResourceVersion:17829,Generation:0,CreationTimestamp:2019-11-05 21:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:25.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7790" for this suite.
Nov  5 21:21:31.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:31.913: INFO: namespace watch-7790 deletion completed in 6.070355486s

• [SLOW TEST:6.108 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:31.914: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 21:21:33.958: INFO: DNS probes using dns-test-d1405e9f-c7d7-4c16-ba08-1edd5581da7f succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 21:21:37.985: INFO: File wheezy_udp@dns-test-service-3.dns-1353.svc.cluster.local from pod  dns-1353/dns-test-b3d75b0f-8ac6-4fbd-9e50-e27c840c0ed6 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  5 21:21:37.988: INFO: File jessie_udp@dns-test-service-3.dns-1353.svc.cluster.local from pod  dns-1353/dns-test-b3d75b0f-8ac6-4fbd-9e50-e27c840c0ed6 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  5 21:21:37.988: INFO: Lookups using dns-1353/dns-test-b3d75b0f-8ac6-4fbd-9e50-e27c840c0ed6 failed for: [wheezy_udp@dns-test-service-3.dns-1353.svc.cluster.local jessie_udp@dns-test-service-3.dns-1353.svc.cluster.local]

Nov  5 21:21:42.994: INFO: DNS probes using dns-test-b3d75b0f-8ac6-4fbd-9e50-e27c840c0ed6 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1353.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1353.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 21:21:45.041: INFO: DNS probes using dns-test-f1059099-7a47-4688-93b7-255625e83987 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:45.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1353" for this suite.
Nov  5 21:21:51.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:51.136: INFO: namespace dns-1353 deletion completed in 6.070728884s

• [SLOW TEST:19.223 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:51.137: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 21:21:51.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-264'
Nov  5 21:21:51.246: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  5 21:21:51.246: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Nov  5 21:21:51.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete jobs e2e-test-nginx-job --namespace=kubectl-264'
Nov  5 21:21:51.340: INFO: stderr: ""
Nov  5 21:21:51.340: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:21:51.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-264" for this suite.
Nov  5 21:21:57.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:21:57.411: INFO: namespace kubectl-264 deletion completed in 6.068122435s

• [SLOW TEST:6.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:21:57.411: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:21:57.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-8066'
Nov  5 21:21:57.646: INFO: stderr: ""
Nov  5 21:21:57.646: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  5 21:21:57.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-8066'
Nov  5 21:21:57.788: INFO: stderr: ""
Nov  5 21:21:57.788: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  5 21:21:58.791: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:21:58.791: INFO: Found 0 / 1
Nov  5 21:21:59.790: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:21:59.791: INFO: Found 1 / 1
Nov  5 21:21:59.791: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  5 21:21:59.792: INFO: Selector matched 1 pods for map[app:redis]
Nov  5 21:21:59.792: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 21:21:59.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 describe pod redis-master-8lkfb --namespace=kubectl-8066'
Nov  5 21:21:59.889: INFO: stderr: ""
Nov  5 21:21:59.889: INFO: stdout: "Name:           redis-master-8lkfb\nNamespace:      kubectl-8066\nPriority:       0\nNode:           k8s-node-1/10.40.3.111\nStart Time:     Tue, 05 Nov 2019 21:21:57 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.233.117.98\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1a247f3b0c6b37800d71dc15077e129836d67d3f23fa4503cebc225140c92272\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 05 Nov 2019 21:21:58 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xs85d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-xs85d:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-xs85d\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                 Message\n  ----    ------     ----  ----                 -------\n  Normal  Scheduled  2s    default-scheduler    Successfully assigned kubectl-8066/redis-master-8lkfb to k8s-node-1\n  Normal  Pulled     1s    kubelet, k8s-node-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, k8s-node-1  Created container redis-master\n  Normal  Started    1s    kubelet, k8s-node-1  Started container redis-master\n"
Nov  5 21:21:59.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 describe rc redis-master --namespace=kubectl-8066'
Nov  5 21:21:59.992: INFO: stderr: ""
Nov  5 21:21:59.992: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8066\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-8lkfb\n"
Nov  5 21:21:59.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 describe service redis-master --namespace=kubectl-8066'
Nov  5 21:22:00.086: INFO: stderr: ""
Nov  5 21:22:00.086: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8066\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.233.50.151\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.117.98:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  5 21:22:00.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 describe node k8s-master'
Nov  5 21:22:00.198: INFO: stderr: ""
Nov  5 21:22:00.198: INFO: stdout: "Name:               k8s-master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-master\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 05 Nov 2019 20:14:25 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 05 Nov 2019 20:15:37 +0000   Tue, 05 Nov 2019 20:15:37 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 05 Nov 2019 21:21:51 +0000   Tue, 05 Nov 2019 20:14:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 05 Nov 2019 21:21:51 +0000   Tue, 05 Nov 2019 20:14:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 05 Nov 2019 21:21:51 +0000   Tue, 05 Nov 2019 20:14:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 05 Nov 2019 21:21:51 +0000   Tue, 05 Nov 2019 20:15:26 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.40.3.110\n  Hostname:    k8s-master\nCapacity:\n cpu:                4\n ephemeral-storage:  20469Mi\n hugepages-2Mi:      0\n memory:             8009200Ki\n pods:               110\nAllocatable:\n cpu:                3800m\n ephemeral-storage:  19316971898\n hugepages-2Mi:      0\n memory:             7406800Ki\n pods:               110\nSystem Info:\n Machine ID:                 d32ae9c97510467c86102394700948df\n System UUID:                664E2C42-108B-BDA5-798F-9EF96BC4009D\n Boot ID:                    003ad44f-1e85-4040-90df-c7ef962c91a5\n Kernel Version:             3.10.0-957.21.3.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.7\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nPodCIDR:                     10.233.64.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-58z8r                                          150m (3%)     300m (7%)   64M (0%)         500M (6%)      66m\n  kube-system                coredns-74c9d4d795-wxqp4                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     65m\n  kube-system                dns-autoscaler-7d95989447-tgcbh                            20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         65m\n  kube-system                kube-apiserver-k8s-master                                  250m (6%)     0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-controller-manager-k8s-master                         200m (5%)     0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-proxy-nj5qj                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                kube-scheduler-k8s-master                                  100m (2%)     0 (0%)      0 (0%)           0 (0%)         67m\n  kube-system                nodelocaldns-7mwdf                                         100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     65m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-7jfl7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests        Limits\n  --------           --------        ------\n  cpu                920m (24%)      300m (7%)\n  memory             221286400 (2%)  856515840 (11%)\n  ephemeral-storage  0 (0%)          0 (0%)\nEvents:              <none>\n"
Nov  5 21:22:00.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 describe namespace kubectl-8066'
Nov  5 21:22:00.287: INFO: stderr: ""
Nov  5 21:22:00.287: INFO: stdout: "Name:         kubectl-8066\nLabels:       e2e-framework=kubectl\n              e2e-run=e5580e23-ecb8-43ac-b56b-b62a0cdda1af\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:22:00.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8066" for this suite.
Nov  5 21:22:22.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:22:22.357: INFO: namespace kubectl-8066 deletion completed in 22.06588281s

• [SLOW TEST:24.946 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:22:22.357: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Nov  5 21:22:22.384: INFO: Waiting up to 5m0s for pod "var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad" in namespace "var-expansion-8503" to be "success or failure"
Nov  5 21:22:22.386: INFO: Pod "var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798829ms
Nov  5 21:22:24.389: INFO: Pod "var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005039577s
STEP: Saw pod success
Nov  5 21:22:24.389: INFO: Pod "var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad" satisfied condition "success or failure"
Nov  5 21:22:24.391: INFO: Trying to get logs from node k8s-node-2 pod var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:22:24.404: INFO: Waiting for pod var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad to disappear
Nov  5 21:22:24.406: INFO: Pod var-expansion-869239f1-65f3-4982-b92c-0fac255cd7ad no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:22:24.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8503" for this suite.
Nov  5 21:22:30.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:22:30.476: INFO: namespace var-expansion-8503 deletion completed in 6.066764329s

• [SLOW TEST:8.119 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:22:30.477: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:22:30.515: INFO: Create a RollingUpdate DaemonSet
Nov  5 21:22:30.518: INFO: Check that daemon pods launch on every node of the cluster
Nov  5 21:22:30.521: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:30.523: INFO: Number of nodes with available pods: 0
Nov  5 21:22:30.523: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:22:31.526: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:31.529: INFO: Number of nodes with available pods: 0
Nov  5 21:22:31.529: INFO: Node k8s-node-1 is running more than one daemon pod
Nov  5 21:22:32.527: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:32.529: INFO: Number of nodes with available pods: 3
Nov  5 21:22:32.529: INFO: Number of running nodes: 3, number of available pods: 3
Nov  5 21:22:32.529: INFO: Update the DaemonSet to trigger a rollout
Nov  5 21:22:32.534: INFO: Updating DaemonSet daemon-set
Nov  5 21:22:43.547: INFO: Roll back the DaemonSet before rollout is complete
Nov  5 21:22:43.553: INFO: Updating DaemonSet daemon-set
Nov  5 21:22:43.553: INFO: Make sure DaemonSet rollback is complete
Nov  5 21:22:43.556: INFO: Wrong image for pod: daemon-set-j5l87. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov  5 21:22:43.556: INFO: Pod daemon-set-j5l87 is not available
Nov  5 21:22:43.559: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:44.562: INFO: Wrong image for pod: daemon-set-j5l87. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov  5 21:22:44.562: INFO: Pod daemon-set-j5l87 is not available
Nov  5 21:22:44.565: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:45.562: INFO: Wrong image for pod: daemon-set-j5l87. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov  5 21:22:45.562: INFO: Pod daemon-set-j5l87 is not available
Nov  5 21:22:45.566: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 21:22:46.562: INFO: Pod daemon-set-msk87 is not available
Nov  5 21:22:46.566: INFO: DaemonSet pods can't tolerate node k8s-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6030, will wait for the garbage collector to delete the pods
Nov  5 21:22:46.627: INFO: Deleting DaemonSet.extensions daemon-set took: 4.653811ms
Nov  5 21:22:46.927: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.21537ms
Nov  5 21:22:52.830: INFO: Number of nodes with available pods: 0
Nov  5 21:22:52.830: INFO: Number of running nodes: 0, number of available pods: 0
Nov  5 21:22:52.832: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6030/daemonsets","resourceVersion":"18375"},"items":null}

Nov  5 21:22:52.833: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6030/pods","resourceVersion":"18375"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:22:52.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6030" for this suite.
Nov  5 21:22:58.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:22:58.916: INFO: namespace daemonsets-6030 deletion completed in 6.070163858s

• [SLOW TEST:28.439 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:22:58.917: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov  5 21:23:01.466: INFO: Successfully updated pod "annotationupdate6a597ecc-ca5c-4d73-8cfd-872a0d06e30d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:23:03.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8071" for this suite.
Nov  5 21:23:25.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:23:25.552: INFO: namespace downward-api-8071 deletion completed in 22.068196617s

• [SLOW TEST:26.636 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:23:25.553: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7483aae8-ef01-4e00-81cd-becb3c7af934
STEP: Creating a pod to test consume configMaps
Nov  5 21:23:25.586: INFO: Waiting up to 5m0s for pod "pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628" in namespace "configmap-3476" to be "success or failure"
Nov  5 21:23:25.588: INFO: Pod "pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253709ms
Nov  5 21:23:27.591: INFO: Pod "pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005182943s
STEP: Saw pod success
Nov  5 21:23:27.591: INFO: Pod "pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628" satisfied condition "success or failure"
Nov  5 21:23:27.593: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:23:27.606: INFO: Waiting for pod pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628 to disappear
Nov  5 21:23:27.608: INFO: Pod pod-configmaps-71151fcc-e262-4065-9fc2-8ed1a1fe4628 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:23:27.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3476" for this suite.
Nov  5 21:23:33.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:23:33.681: INFO: namespace configmap-3476 deletion completed in 6.069272905s

• [SLOW TEST:8.128 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:23:33.681: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov  5 21:23:33.704: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 21:23:33.709: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 21:23:33.711: INFO: 
Logging pods the kubelet thinks is on node k8s-node-1 before test
Nov  5 21:23:33.716: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-txwxh from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:23:33.716: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 21:23:33.716: INFO: nginx-proxy-k8s-node-1 from kube-system started at 2019-11-05 20:15:32 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:23:33.716: INFO: kube-proxy-cd9zn from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:23:33.716: INFO: calico-node-rksqz from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:23:33.716: INFO: nodelocaldns-p82tq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:23:33.716: INFO: sonobuoy from sonobuoy started at 2019-11-05 20:38:44 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.716: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 21:23:33.716: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Nov  5 21:23:33.721: INFO: nginx-proxy-k8s-node-2 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:23:33.721: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-llxsl from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:23:33.721: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 21:23:33.721: INFO: kube-proxy-9v9z4 from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:23:33.721: INFO: calico-node-fdvf2 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:23:33.721: INFO: calico-kube-controllers-587d9754b8-4slnw from kube-system started at 2019-11-05 20:15:50 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 21:23:33.721: INFO: nodelocaldns-4xvgq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.721: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:23:33.721: INFO: 
Logging pods the kubelet thinks is on node k8s-node-3 before test
Nov  5 21:23:33.728: INFO: calico-node-tr8c7 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:23:33.728: INFO: nodelocaldns-rj2f2 from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:23:33.728: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-r67ng from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:23:33.728: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 21:23:33.728: INFO: sonobuoy-e2e-job-af538b29db5041da from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container e2e ready: true, restart count 0
Nov  5 21:23:33.728: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:23:33.728: INFO: nginx-proxy-k8s-node-3 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:23:33.728: INFO: kube-proxy-rs4vx from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:23:33.728: INFO: coredns-74c9d4d795-7xz2x from kube-system started at 2019-11-05 20:16:10 +0000 UTC (1 container statuses recorded)
Nov  5 21:23:33.728: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d4612c87ba7a83], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:23:34.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4764" for this suite.
Nov  5 21:23:40.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:23:40.818: INFO: namespace sched-pred-4764 deletion completed in 6.068856611s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.138 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:23:40.819: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-hmsr
STEP: Creating a pod to test atomic-volume-subpath
Nov  5 21:23:40.852: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hmsr" in namespace "subpath-8010" to be "success or failure"
Nov  5 21:23:40.854: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735955ms
Nov  5 21:23:42.858: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 2.00614078s
Nov  5 21:23:44.861: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 4.008859366s
Nov  5 21:23:46.863: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 6.011724521s
Nov  5 21:23:48.866: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 8.0144433s
Nov  5 21:23:50.869: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 10.017675676s
Nov  5 21:23:52.872: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 12.020585681s
Nov  5 21:23:54.876: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 14.023815587s
Nov  5 21:23:56.878: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 16.026551509s
Nov  5 21:23:58.881: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 18.02945874s
Nov  5 21:24:00.884: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Running", Reason="", readiness=true. Elapsed: 20.032143339s
Nov  5 21:24:02.887: INFO: Pod "pod-subpath-test-downwardapi-hmsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035327336s
STEP: Saw pod success
Nov  5 21:24:02.887: INFO: Pod "pod-subpath-test-downwardapi-hmsr" satisfied condition "success or failure"
Nov  5 21:24:02.889: INFO: Trying to get logs from node k8s-node-1 pod pod-subpath-test-downwardapi-hmsr container test-container-subpath-downwardapi-hmsr: <nil>
STEP: delete the pod
Nov  5 21:24:02.904: INFO: Waiting for pod pod-subpath-test-downwardapi-hmsr to disappear
Nov  5 21:24:02.906: INFO: Pod pod-subpath-test-downwardapi-hmsr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hmsr
Nov  5 21:24:02.906: INFO: Deleting pod "pod-subpath-test-downwardapi-hmsr" in namespace "subpath-8010"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:24:02.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8010" for this suite.
Nov  5 21:24:08.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:24:08.977: INFO: namespace subpath-8010 deletion completed in 6.066308285s

• [SLOW TEST:28.158 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:24:08.977: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov  5 21:24:08.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-6864'
Nov  5 21:24:09.144: INFO: stderr: ""
Nov  5 21:24:09.144: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 21:24:09.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6864'
Nov  5 21:24:09.232: INFO: stderr: ""
Nov  5 21:24:09.232: INFO: stdout: "update-demo-nautilus-lt7fp update-demo-nautilus-x27qq "
Nov  5 21:24:09.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-lt7fp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6864'
Nov  5 21:24:09.313: INFO: stderr: ""
Nov  5 21:24:09.313: INFO: stdout: ""
Nov  5 21:24:09.313: INFO: update-demo-nautilus-lt7fp is created but not running
Nov  5 21:24:14.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6864'
Nov  5 21:24:14.405: INFO: stderr: ""
Nov  5 21:24:14.405: INFO: stdout: "update-demo-nautilus-lt7fp update-demo-nautilus-x27qq "
Nov  5 21:24:14.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-lt7fp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6864'
Nov  5 21:24:14.484: INFO: stderr: ""
Nov  5 21:24:14.484: INFO: stdout: "true"
Nov  5 21:24:14.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-lt7fp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6864'
Nov  5 21:24:14.562: INFO: stderr: ""
Nov  5 21:24:14.562: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:24:14.562: INFO: validating pod update-demo-nautilus-lt7fp
Nov  5 21:24:14.565: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:24:14.565: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:24:14.565: INFO: update-demo-nautilus-lt7fp is verified up and running
Nov  5 21:24:14.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-x27qq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6864'
Nov  5 21:24:14.649: INFO: stderr: ""
Nov  5 21:24:14.649: INFO: stdout: "true"
Nov  5 21:24:14.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-x27qq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6864'
Nov  5 21:24:14.730: INFO: stderr: ""
Nov  5 21:24:14.730: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:24:14.730: INFO: validating pod update-demo-nautilus-x27qq
Nov  5 21:24:14.734: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:24:14.734: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:24:14.734: INFO: update-demo-nautilus-x27qq is verified up and running
STEP: using delete to clean up resources
Nov  5 21:24:14.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-6864'
Nov  5 21:24:14.818: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:24:14.818: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  5 21:24:14.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6864'
Nov  5 21:24:14.902: INFO: stderr: "No resources found.\n"
Nov  5 21:24:14.902: INFO: stdout: ""
Nov  5 21:24:14.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=update-demo --namespace=kubectl-6864 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 21:24:14.983: INFO: stderr: ""
Nov  5 21:24:14.983: INFO: stdout: "update-demo-nautilus-lt7fp\nupdate-demo-nautilus-x27qq\n"
Nov  5 21:24:15.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6864'
Nov  5 21:24:15.578: INFO: stderr: "No resources found.\n"
Nov  5 21:24:15.578: INFO: stdout: ""
Nov  5 21:24:15.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=update-demo --namespace=kubectl-6864 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 21:24:15.667: INFO: stderr: ""
Nov  5 21:24:15.667: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:24:15.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6864" for this suite.
Nov  5 21:24:37.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:24:37.737: INFO: namespace kubectl-6864 deletion completed in 22.066251568s

• [SLOW TEST:28.760 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:24:37.737: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:24:37.771: INFO: (0) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 6.217172ms)
Nov  5 21:24:37.774: INFO: (1) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.935086ms)
Nov  5 21:24:37.777: INFO: (2) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.619483ms)
Nov  5 21:24:37.779: INFO: (3) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.458643ms)
Nov  5 21:24:37.782: INFO: (4) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.87987ms)
Nov  5 21:24:37.785: INFO: (5) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.69497ms)
Nov  5 21:24:37.787: INFO: (6) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.64268ms)
Nov  5 21:24:37.790: INFO: (7) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.592259ms)
Nov  5 21:24:37.793: INFO: (8) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.616119ms)
Nov  5 21:24:37.795: INFO: (9) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.468093ms)
Nov  5 21:24:37.798: INFO: (10) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.696966ms)
Nov  5 21:24:37.800: INFO: (11) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.421894ms)
Nov  5 21:24:37.803: INFO: (12) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.370966ms)
Nov  5 21:24:37.805: INFO: (13) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.354137ms)
Nov  5 21:24:37.808: INFO: (14) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.498893ms)
Nov  5 21:24:37.810: INFO: (15) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.425682ms)
Nov  5 21:24:37.813: INFO: (16) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.502647ms)
Nov  5 21:24:37.815: INFO: (17) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.607212ms)
Nov  5 21:24:37.818: INFO: (18) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.524604ms)
Nov  5 21:24:37.820: INFO: (19) /api/v1/nodes/k8s-node-1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="boot.log-20191104">boo... (200; 2.395213ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:24:37.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5057" for this suite.
Nov  5 21:24:43.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:24:43.892: INFO: namespace proxy-5057 deletion completed in 6.069269631s

• [SLOW TEST:6.155 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:24:43.893: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-8046f4b6-a8f0-4273-889a-5b9bb59826a0
STEP: Creating a pod to test consume configMaps
Nov  5 21:24:43.927: INFO: Waiting up to 5m0s for pod "pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6" in namespace "configmap-4783" to be "success or failure"
Nov  5 21:24:43.931: INFO: Pod "pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050722ms
Nov  5 21:24:45.934: INFO: Pod "pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006784132s
STEP: Saw pod success
Nov  5 21:24:45.934: INFO: Pod "pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6" satisfied condition "success or failure"
Nov  5 21:24:45.936: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:24:45.954: INFO: Waiting for pod pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6 to disappear
Nov  5 21:24:45.955: INFO: Pod pod-configmaps-ded07b96-f078-43bf-b387-3691e60153b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:24:45.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4783" for this suite.
Nov  5 21:24:51.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:24:52.032: INFO: namespace configmap-4783 deletion completed in 6.072661353s

• [SLOW TEST:8.139 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:24:52.032: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:24:52.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b" in namespace "projected-9928" to be "success or failure"
Nov  5 21:24:52.065: INFO: Pod "downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878437ms
Nov  5 21:24:54.068: INFO: Pod "downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005909522s
STEP: Saw pod success
Nov  5 21:24:54.068: INFO: Pod "downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b" satisfied condition "success or failure"
Nov  5 21:24:54.070: INFO: Trying to get logs from node k8s-node-1 pod downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b container client-container: <nil>
STEP: delete the pod
Nov  5 21:24:54.083: INFO: Waiting for pod downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b to disappear
Nov  5 21:24:54.085: INFO: Pod downwardapi-volume-685d88f4-2a99-4f1c-ba3b-850a48f4075b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:24:54.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9928" for this suite.
Nov  5 21:25:00.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:25:00.156: INFO: namespace projected-9928 deletion completed in 6.06795545s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:25:00.156: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2434
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  5 21:25:00.193: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  5 21:25:22.254: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.117.104:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2434 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:25:22.254: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:25:22.377: INFO: Found all expected endpoints: [netserver-0]
Nov  5 21:25:22.380: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.114.33:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2434 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:25:22.380: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:25:22.506: INFO: Found all expected endpoints: [netserver-1]
Nov  5 21:25:22.509: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.113.88:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2434 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:25:22.509: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:25:22.627: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:25:22.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2434" for this suite.
Nov  5 21:25:44.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:25:44.709: INFO: namespace pod-network-test-2434 deletion completed in 22.077581728s

• [SLOW TEST:44.552 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:25:44.709: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-905943a7-c860-48a6-8d04-b4a9a4ecc8c2 in namespace container-probe-5933
Nov  5 21:25:46.749: INFO: Started pod test-webserver-905943a7-c860-48a6-8d04-b4a9a4ecc8c2 in namespace container-probe-5933
STEP: checking the pod's current state and verifying that restartCount is present
Nov  5 21:25:46.750: INFO: Initial restart count of pod test-webserver-905943a7-c860-48a6-8d04-b4a9a4ecc8c2 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:29:47.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5933" for this suite.
Nov  5 21:29:53.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:29:53.191: INFO: namespace container-probe-5933 deletion completed in 6.063283759s

• [SLOW TEST:248.482 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:29:53.191: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  5 21:29:53.218: INFO: Waiting up to 5m0s for pod "pod-4d49bf74-8fcf-4638-964e-39876de63d10" in namespace "emptydir-7776" to be "success or failure"
Nov  5 21:29:53.220: INFO: Pod "pod-4d49bf74-8fcf-4638-964e-39876de63d10": Phase="Pending", Reason="", readiness=false. Elapsed: 1.427454ms
Nov  5 21:29:55.223: INFO: Pod "pod-4d49bf74-8fcf-4638-964e-39876de63d10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004668278s
STEP: Saw pod success
Nov  5 21:29:55.223: INFO: Pod "pod-4d49bf74-8fcf-4638-964e-39876de63d10" satisfied condition "success or failure"
Nov  5 21:29:55.225: INFO: Trying to get logs from node k8s-node-1 pod pod-4d49bf74-8fcf-4638-964e-39876de63d10 container test-container: <nil>
STEP: delete the pod
Nov  5 21:29:55.242: INFO: Waiting for pod pod-4d49bf74-8fcf-4638-964e-39876de63d10 to disappear
Nov  5 21:29:55.244: INFO: Pod pod-4d49bf74-8fcf-4638-964e-39876de63d10 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:29:55.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7776" for this suite.
Nov  5 21:30:01.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:30:01.314: INFO: namespace emptydir-7776 deletion completed in 6.066139199s

• [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:30:01.314: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  5 21:30:01.340: INFO: Waiting up to 5m0s for pod "pod-90a29e00-f2de-439c-a626-6013fa1a20d9" in namespace "emptydir-1893" to be "success or failure"
Nov  5 21:30:01.343: INFO: Pod "pod-90a29e00-f2de-439c-a626-6013fa1a20d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.733648ms
Nov  5 21:30:03.347: INFO: Pod "pod-90a29e00-f2de-439c-a626-6013fa1a20d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006777547s
STEP: Saw pod success
Nov  5 21:30:03.347: INFO: Pod "pod-90a29e00-f2de-439c-a626-6013fa1a20d9" satisfied condition "success or failure"
Nov  5 21:30:03.349: INFO: Trying to get logs from node k8s-node-2 pod pod-90a29e00-f2de-439c-a626-6013fa1a20d9 container test-container: <nil>
STEP: delete the pod
Nov  5 21:30:03.363: INFO: Waiting for pod pod-90a29e00-f2de-439c-a626-6013fa1a20d9 to disappear
Nov  5 21:30:03.365: INFO: Pod pod-90a29e00-f2de-439c-a626-6013fa1a20d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:30:03.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1893" for this suite.
Nov  5 21:30:09.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:30:09.433: INFO: namespace emptydir-1893 deletion completed in 6.065426807s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:30:09.434: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-0edbf8fa-07c5-4bfc-a988-9e1cd198d8b0 in namespace container-probe-2510
Nov  5 21:30:11.468: INFO: Started pod busybox-0edbf8fa-07c5-4bfc-a988-9e1cd198d8b0 in namespace container-probe-2510
STEP: checking the pod's current state and verifying that restartCount is present
Nov  5 21:30:11.469: INFO: Initial restart count of pod busybox-0edbf8fa-07c5-4bfc-a988-9e1cd198d8b0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:11.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2510" for this suite.
Nov  5 21:34:17.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:34:17.889: INFO: namespace container-probe-2510 deletion completed in 6.063704833s

• [SLOW TEST:248.456 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:34:17.890: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:34:17.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d" in namespace "projected-6699" to be "success or failure"
Nov  5 21:34:17.917: INFO: Pod "downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.671798ms
Nov  5 21:34:19.920: INFO: Pod "downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004394102s
STEP: Saw pod success
Nov  5 21:34:19.920: INFO: Pod "downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d" satisfied condition "success or failure"
Nov  5 21:34:19.921: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d container client-container: <nil>
STEP: delete the pod
Nov  5 21:34:19.934: INFO: Waiting for pod downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d to disappear
Nov  5 21:34:19.936: INFO: Pod downwardapi-volume-e1d79dbb-e57d-4491-83b6-66b45ace0c8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:19.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6699" for this suite.
Nov  5 21:34:25.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:34:26.006: INFO: namespace projected-6699 deletion completed in 6.066623729s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:34:26.007: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:34:26.032: INFO: Creating deployment "test-recreate-deployment"
Nov  5 21:34:26.035: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  5 21:34:26.039: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  5 21:34:28.045: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  5 21:34:28.047: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  5 21:34:28.070: INFO: Updating deployment test-recreate-deployment
Nov  5 21:34:28.070: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov  5 21:34:28.118: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-662,SelfLink:/apis/apps/v1/namespaces/deployment-662/deployments/test-recreate-deployment,UID:0f910b06-99e4-42f2-b62e-fb8dcf600a7f,ResourceVersion:20349,Generation:2,CreationTimestamp:2019-11-05 21:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-11-05 21:34:28 +0000 UTC 2019-11-05 21:34:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-11-05 21:34:28 +0000 UTC 2019-11-05 21:34:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov  5 21:34:28.120: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-662,SelfLink:/apis/apps/v1/namespaces/deployment-662/replicasets/test-recreate-deployment-5c8c9cc69d,UID:ca9076fe-e17e-47cc-8494-fdfe046f0e73,ResourceVersion:20347,Generation:1,CreationTimestamp:2019-11-05 21:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0f910b06-99e4-42f2-b62e-fb8dcf600a7f 0xc002486bd7 0xc002486bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:34:28.120: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  5 21:34:28.120: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-662,SelfLink:/apis/apps/v1/namespaces/deployment-662/replicasets/test-recreate-deployment-6df85df6b9,UID:e473a481-5a65-4ee0-beef-462e68f5c3e2,ResourceVersion:20336,Generation:2,CreationTimestamp:2019-11-05 21:34:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0f910b06-99e4-42f2-b62e-fb8dcf600a7f 0xc002486ca7 0xc002486ca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:34:28.123: INFO: Pod "test-recreate-deployment-5c8c9cc69d-lpcrm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-lpcrm,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-662,SelfLink:/api/v1/namespaces/deployment-662/pods/test-recreate-deployment-5c8c9cc69d-lpcrm,UID:e5232eba-f779-4987-a417-fb807806f36b,ResourceVersion:20348,Generation:0,CreationTimestamp:2019-11-05 21:34:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d ca9076fe-e17e-47cc-8494-fdfe046f0e73 0xc00278ccb7 0xc00278ccb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mcq8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mcq8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-mcq8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00278cd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00278cd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:34:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:34:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:34:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:34:28 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:34:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:28.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-662" for this suite.
Nov  5 21:34:34.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:34:34.199: INFO: namespace deployment-662 deletion completed in 6.073157211s

• [SLOW TEST:8.192 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:34:34.199: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:38.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1913" for this suite.
Nov  5 21:34:44.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:34:44.301: INFO: namespace kubelet-test-1913 deletion completed in 6.066660173s

• [SLOW TEST:10.102 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:34:44.302: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-e29083e1-2586-4310-bd43-67d930b85e36
STEP: Creating a pod to test consume secrets
Nov  5 21:34:44.333: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275" in namespace "projected-9387" to be "success or failure"
Nov  5 21:34:44.335: INFO: Pod "pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143146ms
Nov  5 21:34:46.338: INFO: Pod "pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005279966s
STEP: Saw pod success
Nov  5 21:34:46.338: INFO: Pod "pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275" satisfied condition "success or failure"
Nov  5 21:34:46.340: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:34:46.356: INFO: Waiting for pod pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275 to disappear
Nov  5 21:34:46.358: INFO: Pod pod-projected-secrets-48adccf1-f11d-4213-ac2f-e3e0d07c7275 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:46.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9387" for this suite.
Nov  5 21:34:52.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:34:52.429: INFO: namespace projected-9387 deletion completed in 6.06805662s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:34:52.430: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov  5 21:34:54.976: INFO: Successfully updated pod "labelsupdate3cd3265f-1659-4bc9-8a53-9b27f524cf94"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:34:58.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9451" for this suite.
Nov  5 21:35:21.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:35:21.074: INFO: namespace downward-api-9451 deletion completed in 22.071781431s

• [SLOW TEST:28.645 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:35:21.074: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-3ac3c623-b04a-42d0-bc6a-fa57c0aa5810 in namespace container-probe-5149
Nov  5 21:35:25.107: INFO: Started pod liveness-3ac3c623-b04a-42d0-bc6a-fa57c0aa5810 in namespace container-probe-5149
STEP: checking the pod's current state and verifying that restartCount is present
Nov  5 21:35:25.109: INFO: Initial restart count of pod liveness-3ac3c623-b04a-42d0-bc6a-fa57c0aa5810 is 0
Nov  5 21:35:47.143: INFO: Restart count of pod container-probe-5149/liveness-3ac3c623-b04a-42d0-bc6a-fa57c0aa5810 is now 1 (22.034746025s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:35:47.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5149" for this suite.
Nov  5 21:35:53.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:35:53.221: INFO: namespace container-probe-5149 deletion completed in 6.066936655s

• [SLOW TEST:32.147 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:35:53.222: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:35:53.245: INFO: Creating deployment "nginx-deployment"
Nov  5 21:35:53.247: INFO: Waiting for observed generation 1
Nov  5 21:35:55.252: INFO: Waiting for all required pods to come up
Nov  5 21:35:55.255: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  5 21:35:55.255: INFO: Waiting for deployment "nginx-deployment" to complete
Nov  5 21:35:55.259: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov  5 21:35:55.264: INFO: Updating deployment nginx-deployment
Nov  5 21:35:55.264: INFO: Waiting for observed generation 2
Nov  5 21:35:57.271: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  5 21:35:57.273: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  5 21:35:57.275: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  5 21:35:57.281: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  5 21:35:57.281: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  5 21:35:57.283: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  5 21:35:57.287: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov  5 21:35:57.287: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov  5 21:35:57.296: INFO: Updating deployment nginx-deployment
Nov  5 21:35:57.296: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov  5 21:35:57.302: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  5 21:35:59.318: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov  5 21:35:59.322: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1297,SelfLink:/apis/apps/v1/namespaces/deployment-1297/deployments/nginx-deployment,UID:3a17d754-f8b5-40e4-abc6-9575791ce9bb,ResourceVersion:21033,Generation:3,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-11-05 21:35:57 +0000 UTC 2019-11-05 21:35:57 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-11-05 21:35:57 +0000 UTC 2019-11-05 21:35:53 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov  5 21:35:59.325: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-1297,SelfLink:/apis/apps/v1/namespaces/deployment-1297/replicasets/nginx-deployment-55fb7cb77f,UID:e496490e-8758-47d7-8e29-ca232ec351bb,ResourceVersion:21031,Generation:3,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3a17d754-f8b5-40e4-abc6-9575791ce9bb 0xc000742e87 0xc000742e88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:35:59.325: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov  5 21:35:59.325: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-1297,SelfLink:/apis/apps/v1/namespaces/deployment-1297/replicasets/nginx-deployment-7b8c6f4498,UID:585b5bdd-80ce-4545-aa6c-3ee28b6d5e11,ResourceVersion:21018,Generation:3,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3a17d754-f8b5-40e4-abc6-9575791ce9bb 0xc000742f57 0xc000742f58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov  5 21:35:59.330: INFO: Pod "nginx-deployment-55fb7cb77f-2c7dg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2c7dg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-2c7dg,UID:50613f2f-198c-4d1c-a99a-627734f0a4fa,ResourceVersion:21084,Generation:0,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c227 0xc002f2c228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2c2a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2c2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:10.233.114.38,StartTime:2019-11-05 21:35:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.330: INFO: Pod "nginx-deployment-55fb7cb77f-4tv7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4tv7f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-4tv7f,UID:4d49b13f-4009-4849-a387-15ccd9bd9b74,ResourceVersion:21022,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c3d0 0xc002f2c3d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2c450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2c470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.330: INFO: Pod "nginx-deployment-55fb7cb77f-55r8f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-55r8f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-55r8f,UID:8d52fe52-3bc0-4913-86f1-c45db516bc4f,ResourceVersion:21155,Generation:0,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c540 0xc002f2c541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2c5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2c5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:10.233.113.101,StartTime:2019-11-05 21:35:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.330: INFO: Pod "nginx-deployment-55fb7cb77f-77lh9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-77lh9,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-77lh9,UID:046b383f-b5c7-44fd-acfb-220c3049e967,ResourceVersion:21109,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c6d0 0xc002f2c6d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2c760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2c780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-8msn6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8msn6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-8msn6,UID:1b3e4374-7c21-4246-8409-575e57157391,ResourceVersion:21028,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c860 0xc002f2c861}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2c8e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2c900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-bp7hn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bp7hn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-bp7hn,UID:eb719ccf-da97-4a88-88bd-0c87dff39897,ResourceVersion:20950,Generation:0,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2c9e0 0xc002f2c9e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2ca60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2ca80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:10.233.113.100,StartTime:2019-11-05 21:35:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-c5tpf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-c5tpf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-c5tpf,UID:db934d67-4193-4530-8895-22ce9866e291,ResourceVersion:21046,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2cb70 0xc002f2cb71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2cc00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2cc20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-dvpmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dvpmc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-dvpmc,UID:8ef95968-862e-4ad9-acdc-186bde1f8fbb,ResourceVersion:20947,Generation:0,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2ccf0 0xc002f2ccf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2cd80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2cda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.113,StartTime:2019-11-05 21:35:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-hdwfh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hdwfh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-hdwfh,UID:64ce6b72-5894-44da-a8c7-5e3df92b6418,ResourceVersion:21071,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2ce90 0xc002f2ce91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2cf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2cf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.331: INFO: Pod "nginx-deployment-55fb7cb77f-k5vcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-k5vcp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-k5vcp,UID:3c8cbb13-6c45-4af2-bc6c-95cea74c17c6,ResourceVersion:21037,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2d010 0xc002f2d011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-55fb7cb77f-nkzbd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nkzbd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-nkzbd,UID:a6095da5-4c91-4bae-bf51-e3ffde3590d0,ResourceVersion:21002,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2d190 0xc002f2d191}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-55fb7cb77f-qlwss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qlwss,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-qlwss,UID:85e18685-390f-4584-a112-5cf869817031,ResourceVersion:20966,Generation:0,CreationTimestamp:2019-11-05 21:35:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2d300 0xc002f2d301}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d3a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:10.233.114.37,StartTime:2019-11-05 21:35:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-55fb7cb77f-sf2fv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sf2fv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-55fb7cb77f-sf2fv,UID:7f030a77-3859-4d0d-a1bd-7f258fdc0043,ResourceVersion:21072,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e496490e-8758-47d7-8e29-ca232ec351bb 0xc002f2d490 0xc002f2d491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-7b8c6f4498-2tplx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2tplx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-2tplx,UID:ff79d138-e004-4920-ab7e-307c295e949d,ResourceVersion:20826,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2d610 0xc002f2d611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:10.233.114.36,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://effe619d2ab8f12be16c97687eda709eec8b22bb6bde48617d3491475cc006b3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-7b8c6f4498-4s8q7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4s8q7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-4s8q7,UID:7aca7a80-16c0-40be-9bf5-49cd21ce0bd2,ResourceVersion:21073,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2d770 0xc002f2d771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-7b8c6f4498-5vrls" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5vrls,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-5vrls,UID:15768034-b309-4f05-b930-5af947de1bfe,ResourceVersion:20835,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2d8c0 0xc002f2d8c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2d930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2d950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.111,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://da3a6db329bff50b7bc242f8d470212f3743c34892af6de421224a15c9af9046}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.332: INFO: Pod "nginx-deployment-7b8c6f4498-b8qvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-b8qvv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-b8qvv,UID:06fe83eb-2fad-461d-bb19-bbd68f8f1adf,ResourceVersion:21064,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2da20 0xc002f2da21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2da90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2dab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-cz9g7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cz9g7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-cz9g7,UID:69e8bbb0-d395-4994-ab26-373d5c24037a,ResourceVersion:20829,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2db70 0xc002f2db71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2dbe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2dc00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:10.233.114.34,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0230dbc53544e6ad1068d80f9b35dc4d5c6af9d5144e2e661fd3d915c8d5da4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-d67bs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d67bs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-d67bs,UID:00011922-1414-463a-bf93-9069a814baae,ResourceVersion:21004,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2dcd0 0xc002f2dcd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2dd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2dd60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-ggb7k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ggb7k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-ggb7k,UID:bb6c683d-b7dc-4971-8ae9-b58c1fcc59c1,ResourceVersion:20830,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2de40 0xc002f2de41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f2deb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f2ded0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.110,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6f7be94b8e690e9095116a2c269463d95b37bce7f3acb965140d8055e6d4e511}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-hnnnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hnnnn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-hnnnn,UID:9b390e78-e5ca-4820-914f-295f0db5c929,ResourceVersion:21012,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc002f2dfa0 0xc002f2dfa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-hqpsv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hqpsv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-hqpsv,UID:babfc953-cdbe-4906-8466-b89d55ec40ee,ResourceVersion:20994,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a0f0 0xc00336a0f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-k4z9t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k4z9t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-k4z9t,UID:cfd5a14e-7b30-4651-a5f6-572712d382f4,ResourceVersion:21051,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a240 0xc00336a241}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.333: INFO: Pod "nginx-deployment-7b8c6f4498-qf98b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qf98b,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-qf98b,UID:fed0eb5d-d0c9-4471-ad53-3b2a05400c81,ResourceVersion:21053,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a390 0xc00336a391}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-qtqvc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qtqvc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-qtqvc,UID:cecacc5d-490e-4d0f-9003-bca7e7b3776d,ResourceVersion:20851,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a4e0 0xc00336a4e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:10.233.113.99,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e189d9f87513a472adf915482de22ff9bedef0c4ab6cd63b03d30ed7f24fa820}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-rb8jw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rb8jw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-rb8jw,UID:586eddf0-bc32-4f80-bdf5-3cf39c75485b,ResourceVersion:20848,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a640 0xc00336a641}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:10.233.113.97,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ef8ef9b3ac0e805eefbc0c3f90c7b8846caeb7ce864cbd783925e049000bda24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-rdjt4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rdjt4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-rdjt4,UID:070165dd-d5ba-40ae-b96d-53163d8a6559,ResourceVersion:21023,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a7c0 0xc00336a7c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-rph9w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rph9w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-rph9w,UID:18f9b178-4de6-4365-8bbf-b6e5fb020158,ResourceVersion:21088,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336a920 0xc00336a921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336a9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336a9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-t87ht" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-t87ht,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-t87ht,UID:ebb67237-72c3-4d59-9209-794603c2c403,ResourceVersion:21029,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336aa80 0xc00336aa81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336aaf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336ab10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.334: INFO: Pod "nginx-deployment-7b8c6f4498-tg4cp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tg4cp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-tg4cp,UID:9fe4ebcb-cb59-472b-899d-63bb65a3b486,ResourceVersion:20839,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336abd0 0xc00336abd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336ac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336ac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.112,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2620bff5c24ee712026f6b98714cc68056986823425ddb13b463df6e17cb8ada}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.335: INFO: Pod "nginx-deployment-7b8c6f4498-v2227" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-v2227,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-v2227,UID:99009657-ed4f-4324-a2d0-6ede76090ef6,ResourceVersion:20842,Generation:0,CreationTimestamp:2019-11-05 21:35:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336ad30 0xc00336ad31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336ada0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336adc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:53 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.112,PodIP:10.233.113.98,StartTime:2019-11-05 21:35:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:35:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2a4539c5729a99c731927744ce03e276acb5d480d50b9247988d0a071a29f753}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.335: INFO: Pod "nginx-deployment-7b8c6f4498-vp8wh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vp8wh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-vp8wh,UID:1706296f-1d6d-4424-a162-6cdda788432b,ResourceVersion:21034,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336ae90 0xc00336ae91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336af00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336af20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.113,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:35:59.335: INFO: Pod "nginx-deployment-7b8c6f4498-xsv9p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xsv9p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1297,SelfLink:/api/v1/namespaces/deployment-1297/pods/nginx-deployment-7b8c6f4498-xsv9p,UID:595c4ea3-5d96-4d50-8012-ced156047ad9,ResourceVersion:21040,Generation:0,CreationTimestamp:2019-11-05 21:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 585b5bdd-80ce-4545-aa6c-3ee28b6d5e11 0xc00336afe0 0xc00336afe1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6bt8c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bt8c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6bt8c true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00336b050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00336b070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:35:57 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:,StartTime:2019-11-05 21:35:57 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:35:59.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1297" for this suite.
Nov  5 21:36:07.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:36:07.410: INFO: namespace deployment-1297 deletion completed in 8.071108251s

• [SLOW TEST:14.188 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:36:07.411: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4439, will wait for the garbage collector to delete the pods
Nov  5 21:36:09.495: INFO: Deleting Job.batch foo took: 4.973873ms
Nov  5 21:36:09.596: INFO: Terminating Job.batch foo pods took: 100.181764ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:36:43.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4439" for this suite.
Nov  5 21:36:49.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:36:49.569: INFO: namespace job-4439 deletion completed in 6.068650639s

• [SLOW TEST:42.159 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:36:49.569: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ca4b92fd-ea8f-45eb-b7da-bb8c75aebc0e
STEP: Creating a pod to test consume secrets
Nov  5 21:36:49.599: INFO: Waiting up to 5m0s for pod "pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3" in namespace "secrets-2249" to be "success or failure"
Nov  5 21:36:49.604: INFO: Pod "pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.715303ms
Nov  5 21:36:51.607: INFO: Pod "pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007987774s
STEP: Saw pod success
Nov  5 21:36:51.607: INFO: Pod "pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3" satisfied condition "success or failure"
Nov  5 21:36:51.609: INFO: Trying to get logs from node k8s-node-2 pod pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:36:51.626: INFO: Waiting for pod pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3 to disappear
Nov  5 21:36:51.629: INFO: Pod pod-secrets-76b3050e-82bd-4a9e-9076-e4e8eb65bac3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:36:51.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2249" for this suite.
Nov  5 21:36:57.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:36:57.698: INFO: namespace secrets-2249 deletion completed in 6.066402583s

• [SLOW TEST:8.129 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:36:57.699: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:37:57.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7092" for this suite.
Nov  5 21:38:19.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:38:19.801: INFO: namespace container-probe-7092 deletion completed in 22.068653359s

• [SLOW TEST:82.102 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:38:19.801: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  5 21:38:19.828: INFO: Waiting up to 5m0s for pod "pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb" in namespace "emptydir-9451" to be "success or failure"
Nov  5 21:38:19.830: INFO: Pod "pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.710362ms
Nov  5 21:38:21.833: INFO: Pod "pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004156428s
STEP: Saw pod success
Nov  5 21:38:21.833: INFO: Pod "pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb" satisfied condition "success or failure"
Nov  5 21:38:21.834: INFO: Trying to get logs from node k8s-node-2 pod pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb container test-container: <nil>
STEP: delete the pod
Nov  5 21:38:21.846: INFO: Waiting for pod pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb to disappear
Nov  5 21:38:21.848: INFO: Pod pod-98f544cf-28e3-40ea-8fc3-82f60f43ddfb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:38:21.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9451" for this suite.
Nov  5 21:38:27.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:38:27.918: INFO: namespace emptydir-9451 deletion completed in 6.067081873s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:38:27.919: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov  5 21:38:27.942: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 21:38:27.948: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 21:38:27.949: INFO: 
Logging pods the kubelet thinks is on node k8s-node-1 before test
Nov  5 21:38:27.954: INFO: nginx-proxy-k8s-node-1 from kube-system started at 2019-11-05 20:15:32 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.954: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:38:27.954: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-txwxh from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:38:27.954: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:38:27.954: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 21:38:27.954: INFO: kube-proxy-cd9zn from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.954: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:38:27.954: INFO: calico-node-rksqz from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.954: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:38:27.955: INFO: nodelocaldns-p82tq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.955: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:38:27.955: INFO: sonobuoy from sonobuoy started at 2019-11-05 20:38:44 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.955: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 21:38:27.955: INFO: 
Logging pods the kubelet thinks is on node k8s-node-2 before test
Nov  5 21:38:27.960: INFO: kube-proxy-9v9z4 from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:38:27.960: INFO: calico-kube-controllers-587d9754b8-4slnw from kube-system started at 2019-11-05 20:15:50 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 21:38:27.960: INFO: nginx-proxy-k8s-node-2 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:38:27.960: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-llxsl from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:38:27.960: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 21:38:27.960: INFO: calico-node-fdvf2 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:38:27.960: INFO: nodelocaldns-4xvgq from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.960: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:38:27.960: INFO: 
Logging pods the kubelet thinks is on node k8s-node-3 before test
Nov  5 21:38:27.969: INFO: nginx-proxy-k8s-node-3 from kube-system started at 2019-11-05 20:15:33 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov  5 21:38:27.969: INFO: kube-proxy-rs4vx from kube-system started at 2019-11-05 20:14:59 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  5 21:38:27.969: INFO: coredns-74c9d4d795-7xz2x from kube-system started at 2019-11-05 20:16:10 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container coredns ready: true, restart count 0
Nov  5 21:38:27.969: INFO: sonobuoy-e2e-job-af538b29db5041da from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container e2e ready: true, restart count 0
Nov  5 21:38:27.969: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:38:27.969: INFO: nodelocaldns-rj2f2 from kube-system started at 2019-11-05 20:16:11 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container node-cache ready: true, restart count 0
Nov  5 21:38:27.969: INFO: calico-node-tr8c7 from kube-system started at 2019-11-05 20:15:19 +0000 UTC (1 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container calico-node ready: true, restart count 1
Nov  5 21:38:27.969: INFO: sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-r67ng from sonobuoy started at 2019-11-05 20:38:50 +0000 UTC (2 container statuses recorded)
Nov  5 21:38:27.969: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 21:38:27.969: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node k8s-node-1
STEP: verifying the node has the label node k8s-node-2
STEP: verifying the node has the label node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod calico-kube-controllers-587d9754b8-4slnw requesting resource cpu=30m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod calico-node-fdvf2 requesting resource cpu=150m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod calico-node-rksqz requesting resource cpu=150m on Node k8s-node-1
Nov  5 21:38:28.016: INFO: Pod calico-node-tr8c7 requesting resource cpu=150m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod coredns-74c9d4d795-7xz2x requesting resource cpu=100m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod kube-proxy-9v9z4 requesting resource cpu=0m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod kube-proxy-cd9zn requesting resource cpu=0m on Node k8s-node-1
Nov  5 21:38:28.016: INFO: Pod kube-proxy-rs4vx requesting resource cpu=0m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod nginx-proxy-k8s-node-1 requesting resource cpu=25m on Node k8s-node-1
Nov  5 21:38:28.016: INFO: Pod nginx-proxy-k8s-node-2 requesting resource cpu=25m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod nginx-proxy-k8s-node-3 requesting resource cpu=25m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod nodelocaldns-4xvgq requesting resource cpu=100m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod nodelocaldns-p82tq requesting resource cpu=100m on Node k8s-node-1
Nov  5 21:38:28.016: INFO: Pod nodelocaldns-rj2f2 requesting resource cpu=100m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-node-1
Nov  5 21:38:28.016: INFO: Pod sonobuoy-e2e-job-af538b29db5041da requesting resource cpu=0m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-llxsl requesting resource cpu=0m on Node k8s-node-2
Nov  5 21:38:28.016: INFO: Pod sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-r67ng requesting resource cpu=0m on Node k8s-node-3
Nov  5 21:38:28.016: INFO: Pod sonobuoy-systemd-logs-daemon-set-1acb19ab444e4b7c-txwxh requesting resource cpu=0m on Node k8s-node-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e.15d461fcbf3000b0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4645/filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e to k8s-node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e.15d461fcee54685a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e.15d461fcefa48ea5], Reason = [Created], Message = [Created container filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e.15d461fcf7177903], Reason = [Started], Message = [Started container filler-pod-79b78a0f-25b6-47f1-8172-a77c7a71e11e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584.15d461fcbf9c1e40], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4645/filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584 to k8s-node-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584.15d461fcedda9cd5], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584.15d461fd31faf236], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584.15d461fd33d92479], Reason = [Created], Message = [Created container filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584.15d461fd3acca78d], Reason = [Started], Message = [Started container filler-pod-8db5b2ff-26ce-4e02-9b50-136cbd886584]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177.15d461fcbfa13278], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4645/filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177 to k8s-node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177.15d461fced21b758], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177.15d461fceec1a14f], Reason = [Created], Message = [Created container filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177.15d461fcf66b0395], Reason = [Started], Message = [Started container filler-pod-f7ae8474-fc90-4bc5-8077-11b5eb8c3177]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d461fdaf05b6ad], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-node-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:38:33.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4645" for this suite.
Nov  5 21:38:39.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:38:39.156: INFO: namespace sched-pred-4645 deletion completed in 6.064098204s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.238 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:38:39.157: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2019
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  5 21:38:39.179: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  5 21:39:03.240: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.114.47:8080/dial?request=hostName&protocol=udp&host=10.233.114.46&port=8081&tries=1'] Namespace:pod-network-test-2019 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:39:03.240: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:39:03.370: INFO: Waiting for endpoints: map[]
Nov  5 21:39:03.372: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.114.47:8080/dial?request=hostName&protocol=udp&host=10.233.117.125&port=8081&tries=1'] Namespace:pod-network-test-2019 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:39:03.372: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:39:03.503: INFO: Waiting for endpoints: map[]
Nov  5 21:39:03.505: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.114.47:8080/dial?request=hostName&protocol=udp&host=10.233.113.112&port=8081&tries=1'] Namespace:pod-network-test-2019 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  5 21:39:03.505: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
Nov  5 21:39:03.632: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:39:03.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2019" for this suite.
Nov  5 21:39:25.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:39:25.706: INFO: namespace pod-network-test-2019 deletion completed in 22.071049835s

• [SLOW TEST:46.549 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:39:25.706: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  5 21:39:25.733: INFO: Waiting up to 5m0s for pod "pod-91530a0d-ef91-4ade-aa14-54a565ba19de" in namespace "emptydir-530" to be "success or failure"
Nov  5 21:39:25.735: INFO: Pod "pod-91530a0d-ef91-4ade-aa14-54a565ba19de": Phase="Pending", Reason="", readiness=false. Elapsed: 1.649012ms
Nov  5 21:39:27.738: INFO: Pod "pod-91530a0d-ef91-4ade-aa14-54a565ba19de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004743498s
STEP: Saw pod success
Nov  5 21:39:27.738: INFO: Pod "pod-91530a0d-ef91-4ade-aa14-54a565ba19de" satisfied condition "success or failure"
Nov  5 21:39:27.740: INFO: Trying to get logs from node k8s-node-1 pod pod-91530a0d-ef91-4ade-aa14-54a565ba19de container test-container: <nil>
STEP: delete the pod
Nov  5 21:39:27.752: INFO: Waiting for pod pod-91530a0d-ef91-4ade-aa14-54a565ba19de to disappear
Nov  5 21:39:27.754: INFO: Pod pod-91530a0d-ef91-4ade-aa14-54a565ba19de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:39:27.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-530" for this suite.
Nov  5 21:39:33.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:39:33.825: INFO: namespace emptydir-530 deletion completed in 6.068309187s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:39:33.825: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:39:33.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80" in namespace "downward-api-8271" to be "success or failure"
Nov  5 21:39:33.854: INFO: Pod "downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637307ms
Nov  5 21:39:35.856: INFO: Pod "downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003931363s
STEP: Saw pod success
Nov  5 21:39:35.856: INFO: Pod "downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80" satisfied condition "success or failure"
Nov  5 21:39:35.858: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80 container client-container: <nil>
STEP: delete the pod
Nov  5 21:39:35.871: INFO: Waiting for pod downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80 to disappear
Nov  5 21:39:35.873: INFO: Pod downwardapi-volume-25244d8d-5c02-45bb-be8c-720c5130eb80 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:39:35.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8271" for this suite.
Nov  5 21:39:41.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:39:41.951: INFO: namespace downward-api-8271 deletion completed in 6.074832509s

• [SLOW TEST:8.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:39:41.951: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-248.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-248.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-248.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-248.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-248.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 168.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.168_udp@PTR;check="$$(dig +tcp +noall +answer +search 168.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.168_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-248.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-248.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-248.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-248.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-248.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-248.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-248.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 168.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.168_udp@PTR;check="$$(dig +tcp +noall +answer +search 168.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.168_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  5 21:39:44.010: INFO: Unable to read wheezy_udp@dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.013: INFO: Unable to read wheezy_tcp@dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.017: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.020: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.038: INFO: Unable to read jessie_udp@dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.042: INFO: Unable to read jessie_tcp@dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.045: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.048: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local from pod dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae: the server could not find the requested resource (get pods dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae)
Nov  5 21:39:44.065: INFO: Lookups using dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae failed for: [wheezy_udp@dns-test-service.dns-248.svc.cluster.local wheezy_tcp@dns-test-service.dns-248.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local jessie_udp@dns-test-service.dns-248.svc.cluster.local jessie_tcp@dns-test-service.dns-248.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-248.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-248.svc.cluster.local]

Nov  5 21:39:49.112: INFO: DNS probes using dns-248/dns-test-655632f6-8f89-4925-bbcb-4c4faf8547ae succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:39:49.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-248" for this suite.
Nov  5 21:39:55.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:39:55.289: INFO: namespace dns-248 deletion completed in 6.132980609s

• [SLOW TEST:13.338 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:39:55.290: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-ttsc
STEP: Creating a pod to test atomic-volume-subpath
Nov  5 21:39:55.319: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ttsc" in namespace "subpath-2390" to be "success or failure"
Nov  5 21:39:55.322: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.543786ms
Nov  5 21:39:57.325: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 2.005351644s
Nov  5 21:39:59.327: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 4.008084842s
Nov  5 21:40:01.330: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 6.010896143s
Nov  5 21:40:03.333: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 8.013835263s
Nov  5 21:40:05.336: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 10.016687645s
Nov  5 21:40:07.339: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 12.019525476s
Nov  5 21:40:09.342: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 14.022362358s
Nov  5 21:40:11.345: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 16.025231396s
Nov  5 21:40:13.347: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 18.028028021s
Nov  5 21:40:15.350: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Running", Reason="", readiness=true. Elapsed: 20.030745516s
Nov  5 21:40:17.353: INFO: Pod "pod-subpath-test-configmap-ttsc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033681506s
STEP: Saw pod success
Nov  5 21:40:17.353: INFO: Pod "pod-subpath-test-configmap-ttsc" satisfied condition "success or failure"
Nov  5 21:40:17.355: INFO: Trying to get logs from node k8s-node-2 pod pod-subpath-test-configmap-ttsc container test-container-subpath-configmap-ttsc: <nil>
STEP: delete the pod
Nov  5 21:40:17.368: INFO: Waiting for pod pod-subpath-test-configmap-ttsc to disappear
Nov  5 21:40:17.372: INFO: Pod pod-subpath-test-configmap-ttsc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ttsc
Nov  5 21:40:17.372: INFO: Deleting pod "pod-subpath-test-configmap-ttsc" in namespace "subpath-2390"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:40:17.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2390" for this suite.
Nov  5 21:40:23.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:40:23.442: INFO: namespace subpath-2390 deletion completed in 6.06523062s

• [SLOW TEST:28.152 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:40:23.442: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:40:47.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8879" for this suite.
Nov  5 21:40:53.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:40:53.600: INFO: namespace namespaces-8879 deletion completed in 6.065330162s
STEP: Destroying namespace "nsdeletetest-1640" for this suite.
Nov  5 21:40:53.601: INFO: Namespace nsdeletetest-1640 was already deleted
STEP: Destroying namespace "nsdeletetest-4509" for this suite.
Nov  5 21:40:59.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:40:59.669: INFO: namespace nsdeletetest-4509 deletion completed in 6.067214912s

• [SLOW TEST:36.227 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:40:59.669: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-bace9695-7145-41df-bbff-6dfbc26afc35 in namespace container-probe-589
Nov  5 21:41:01.703: INFO: Started pod liveness-bace9695-7145-41df-bbff-6dfbc26afc35 in namespace container-probe-589
STEP: checking the pod's current state and verifying that restartCount is present
Nov  5 21:41:01.705: INFO: Initial restart count of pod liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is 0
Nov  5 21:41:21.735: INFO: Restart count of pod container-probe-589/liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is now 1 (20.029417028s elapsed)
Nov  5 21:41:41.761: INFO: Restart count of pod container-probe-589/liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is now 2 (40.055504444s elapsed)
Nov  5 21:42:01.789: INFO: Restart count of pod container-probe-589/liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is now 3 (1m0.083644434s elapsed)
Nov  5 21:42:21.816: INFO: Restart count of pod container-probe-589/liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is now 4 (1m20.111003608s elapsed)
Nov  5 21:43:27.908: INFO: Restart count of pod container-probe-589/liveness-bace9695-7145-41df-bbff-6dfbc26afc35 is now 5 (2m26.203072307s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:43:27.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-589" for this suite.
Nov  5 21:43:33.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:43:33.981: INFO: namespace container-probe-589 deletion completed in 6.064137967s

• [SLOW TEST:154.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:43:33.981: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 21:43:34.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4755'
Nov  5 21:43:34.135: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  5 21:43:34.135: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov  5 21:43:34.141: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-g8gn4]
Nov  5 21:43:34.141: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-g8gn4" in namespace "kubectl-4755" to be "running and ready"
Nov  5 21:43:34.142: INFO: Pod "e2e-test-nginx-rc-g8gn4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.67492ms
Nov  5 21:43:36.145: INFO: Pod "e2e-test-nginx-rc-g8gn4": Phase="Running", Reason="", readiness=true. Elapsed: 2.004410518s
Nov  5 21:43:36.145: INFO: Pod "e2e-test-nginx-rc-g8gn4" satisfied condition "running and ready"
Nov  5 21:43:36.145: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-g8gn4]
Nov  5 21:43:36.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 logs rc/e2e-test-nginx-rc --namespace=kubectl-4755'
Nov  5 21:43:36.250: INFO: stderr: ""
Nov  5 21:43:36.250: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Nov  5 21:43:36.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete rc e2e-test-nginx-rc --namespace=kubectl-4755'
Nov  5 21:43:36.336: INFO: stderr: ""
Nov  5 21:43:36.336: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:43:36.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4755" for this suite.
Nov  5 21:43:58.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:43:58.409: INFO: namespace kubectl-4755 deletion completed in 22.069084024s

• [SLOW TEST:24.428 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:43:58.410: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov  5 21:44:00.956: INFO: Successfully updated pod "labelsupdate133bcbb7-1a5c-4e69-89fb-813aad4e768d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:44:04.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9990" for this suite.
Nov  5 21:44:26.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:44:27.047: INFO: namespace projected-9990 deletion completed in 22.06218246s

• [SLOW TEST:28.638 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:44:27.047: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:44:53.080: INFO: Container started at 2019-11-05 21:44:27 +0000 UTC, pod became ready at 2019-11-05 21:44:51 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:44:53.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2923" for this suite.
Nov  5 21:45:15.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:45:15.155: INFO: namespace container-probe-2923 deletion completed in 22.072397825s

• [SLOW TEST:48.108 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:45:15.156: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov  5 21:45:15.181: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:45:17.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9980" for this suite.
Nov  5 21:45:23.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:45:24.047: INFO: namespace init-container-9980 deletion completed in 6.069783918s

• [SLOW TEST:8.892 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:45:24.048: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:45:24.071: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:45:26.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4244" for this suite.
Nov  5 21:46:04.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:46:04.162: INFO: namespace pods-4244 deletion completed in 38.065881852s

• [SLOW TEST:40.114 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:46:04.163: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-93ab098f-0481-4df6-8284-c3fc09a0b0b5
STEP: Creating configMap with name cm-test-opt-upd-eb47e5f1-c43f-478d-9ae2-521d40b28787
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-93ab098f-0481-4df6-8284-c3fc09a0b0b5
STEP: Updating configmap cm-test-opt-upd-eb47e5f1-c43f-478d-9ae2-521d40b28787
STEP: Creating configMap with name cm-test-opt-create-fcee74c1-35bf-473a-a0f7-111c002e7436
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:47:36.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3933" for this suite.
Nov  5 21:47:58.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:47:58.708: INFO: namespace projected-3933 deletion completed in 22.070871463s

• [SLOW TEST:114.545 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:47:58.708: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-8446
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8446
STEP: Deleting pre-stop pod
Nov  5 21:48:11.777: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:48:11.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8446" for this suite.
Nov  5 21:48:49.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:48:49.848: INFO: namespace prestop-8446 deletion completed in 38.06485008s

• [SLOW TEST:51.139 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:48:49.848: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov  5 21:48:49.870: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:48:53.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1004" for this suite.
Nov  5 21:48:59.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:48:59.601: INFO: namespace init-container-1004 deletion completed in 6.068188911s

• [SLOW TEST:9.753 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:48:59.601: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov  5 21:48:59.627: INFO: Waiting up to 5m0s for pod "downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9" in namespace "downward-api-8339" to be "success or failure"
Nov  5 21:48:59.629: INFO: Pod "downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040661ms
Nov  5 21:49:01.632: INFO: Pod "downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005079528s
STEP: Saw pod success
Nov  5 21:49:01.632: INFO: Pod "downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9" satisfied condition "success or failure"
Nov  5 21:49:01.634: INFO: Trying to get logs from node k8s-node-1 pod downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9 container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:49:01.653: INFO: Waiting for pod downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9 to disappear
Nov  5 21:49:01.655: INFO: Pod downward-api-55f5d040-7ac3-46b0-bd86-07af384e8ff9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:49:01.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8339" for this suite.
Nov  5 21:49:07.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:49:07.722: INFO: namespace downward-api-8339 deletion completed in 6.063796003s

• [SLOW TEST:8.121 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:49:07.722: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-7bb1fba9-5f37-497f-a294-6bdc9f230385
STEP: Creating a pod to test consume secrets
Nov  5 21:49:07.751: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31" in namespace "projected-491" to be "success or failure"
Nov  5 21:49:07.755: INFO: Pod "pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.631287ms
Nov  5 21:49:09.757: INFO: Pod "pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005985401s
STEP: Saw pod success
Nov  5 21:49:09.757: INFO: Pod "pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31" satisfied condition "success or failure"
Nov  5 21:49:09.759: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31 container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:49:09.773: INFO: Waiting for pod pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31 to disappear
Nov  5 21:49:09.775: INFO: Pod pod-projected-secrets-85bfce7f-d2e9-450a-8df0-a2acd6628d31 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:49:09.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-491" for this suite.
Nov  5 21:49:15.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:49:15.843: INFO: namespace projected-491 deletion completed in 6.064699455s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:49:15.843: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Nov  5 21:49:15.870: INFO: Waiting up to 5m0s for pod "client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390" in namespace "containers-534" to be "success or failure"
Nov  5 21:49:15.872: INFO: Pod "client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02701ms
Nov  5 21:49:17.875: INFO: Pod "client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004907117s
Nov  5 21:49:19.878: INFO: Pod "client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007713047s
STEP: Saw pod success
Nov  5 21:49:19.878: INFO: Pod "client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390" satisfied condition "success or failure"
Nov  5 21:49:19.880: INFO: Trying to get logs from node k8s-node-2 pod client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390 container test-container: <nil>
STEP: delete the pod
Nov  5 21:49:19.892: INFO: Waiting for pod client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390 to disappear
Nov  5 21:49:19.895: INFO: Pod client-containers-34fad98d-d3d0-4eaa-a027-77f1bf88a390 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:49:19.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-534" for this suite.
Nov  5 21:49:25.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:49:25.964: INFO: namespace containers-534 deletion completed in 6.066345489s

• [SLOW TEST:10.121 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:49:25.965: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:49:28.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7062" for this suite.
Nov  5 21:50:06.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:50:06.076: INFO: namespace kubelet-test-7062 deletion completed in 38.066835659s

• [SLOW TEST:40.111 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:50:06.076: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-ea64c7ec-7c8e-49cc-bd9c-568489ee6c2e
STEP: Creating configMap with name cm-test-opt-upd-19d9cf1f-bb83-4695-9ac0-525777e0313c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ea64c7ec-7c8e-49cc-bd9c-568489ee6c2e
STEP: Updating configmap cm-test-opt-upd-19d9cf1f-bb83-4695-9ac0-525777e0313c
STEP: Creating configMap with name cm-test-opt-create-27a2c1c6-cb3f-47af-b78d-f78fb75a70b0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:50:10.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3412" for this suite.
Nov  5 21:50:32.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:50:32.240: INFO: namespace configmap-3412 deletion completed in 22.066164408s

• [SLOW TEST:26.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:50:32.241: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Nov  5 21:50:32.265: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  5 21:50:32.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:32.415: INFO: stderr: ""
Nov  5 21:50:32.415: INFO: stdout: "service/redis-slave created\n"
Nov  5 21:50:32.416: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  5 21:50:32.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:32.590: INFO: stderr: ""
Nov  5 21:50:32.590: INFO: stdout: "service/redis-master created\n"
Nov  5 21:50:32.590: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  5 21:50:32.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:32.761: INFO: stderr: ""
Nov  5 21:50:32.761: INFO: stdout: "service/frontend created\n"
Nov  5 21:50:32.761: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  5 21:50:32.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:32.975: INFO: stderr: ""
Nov  5 21:50:32.975: INFO: stdout: "deployment.apps/frontend created\n"
Nov  5 21:50:32.975: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  5 21:50:32.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:33.131: INFO: stderr: ""
Nov  5 21:50:33.131: INFO: stdout: "deployment.apps/redis-master created\n"
Nov  5 21:50:33.131: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  5 21:50:33.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-226'
Nov  5 21:50:33.274: INFO: stderr: ""
Nov  5 21:50:33.274: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov  5 21:50:33.274: INFO: Waiting for all frontend pods to be Running.
Nov  5 21:50:53.325: INFO: Waiting for frontend to serve content.
Nov  5 21:50:54.343: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Nov  5 21:50:59.359: INFO: Trying to add a new entry to the guestbook.
Nov  5 21:50:59.368: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  5 21:50:59.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.476: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.476: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  5 21:50:59.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.584: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.584: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  5 21:50:59.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.685: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.685: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  5 21:50:59.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.786: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.786: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  5 21:50:59.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.867: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  5 21:50:59.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-226'
Nov  5 21:50:59.948: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:50:59.948: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:50:59.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-226" for this suite.
Nov  5 21:51:43.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:51:44.015: INFO: namespace kubectl-226 deletion completed in 44.063582778s

• [SLOW TEST:71.774 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:51:44.015: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Nov  5 21:51:44.042: INFO: Waiting up to 5m0s for pod "var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2" in namespace "var-expansion-5264" to be "success or failure"
Nov  5 21:51:44.044: INFO: Pod "var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031382ms
Nov  5 21:51:46.047: INFO: Pod "var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004774488s
STEP: Saw pod success
Nov  5 21:51:46.047: INFO: Pod "var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2" satisfied condition "success or failure"
Nov  5 21:51:46.048: INFO: Trying to get logs from node k8s-node-1 pod var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2 container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:51:46.061: INFO: Waiting for pod var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2 to disappear
Nov  5 21:51:46.063: INFO: Pod var-expansion-9cb22a41-140e-43a3-b92e-32bdc7a256f2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:51:46.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5264" for this suite.
Nov  5 21:51:52.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:51:52.136: INFO: namespace var-expansion-5264 deletion completed in 6.069150624s

• [SLOW TEST:8.121 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:51:52.136: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  5 21:51:52.164: INFO: Waiting up to 5m0s for pod "pod-720a1778-895a-44b0-9d75-2e0e67220a38" in namespace "emptydir-3309" to be "success or failure"
Nov  5 21:51:52.166: INFO: Pod "pod-720a1778-895a-44b0-9d75-2e0e67220a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1.663815ms
Nov  5 21:51:54.169: INFO: Pod "pod-720a1778-895a-44b0-9d75-2e0e67220a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004412609s
Nov  5 21:51:56.171: INFO: Pod "pod-720a1778-895a-44b0-9d75-2e0e67220a38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007205214s
STEP: Saw pod success
Nov  5 21:51:56.172: INFO: Pod "pod-720a1778-895a-44b0-9d75-2e0e67220a38" satisfied condition "success or failure"
Nov  5 21:51:56.173: INFO: Trying to get logs from node k8s-node-2 pod pod-720a1778-895a-44b0-9d75-2e0e67220a38 container test-container: <nil>
STEP: delete the pod
Nov  5 21:51:56.186: INFO: Waiting for pod pod-720a1778-895a-44b0-9d75-2e0e67220a38 to disappear
Nov  5 21:51:56.188: INFO: Pod pod-720a1778-895a-44b0-9d75-2e0e67220a38 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:51:56.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3309" for this suite.
Nov  5 21:52:02.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:52:02.257: INFO: namespace emptydir-3309 deletion completed in 6.065475534s

• [SLOW TEST:10.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:52:02.257: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  5 21:52:02.286: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  5 21:52:07.289: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:52:08.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3830" for this suite.
Nov  5 21:52:14.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:52:14.368: INFO: namespace replication-controller-3830 deletion completed in 6.06595979s

• [SLOW TEST:12.111 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:52:14.368: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov  5 21:52:14.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-4944'
Nov  5 21:52:14.544: INFO: stderr: ""
Nov  5 21:52:14.544: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 21:52:14.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:14.641: INFO: stderr: ""
Nov  5 21:52:14.641: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-h8nll "
Nov  5 21:52:14.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:14.728: INFO: stderr: ""
Nov  5 21:52:14.728: INFO: stdout: ""
Nov  5 21:52:14.728: INFO: update-demo-nautilus-47mts is created but not running
Nov  5 21:52:19.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:19.815: INFO: stderr: ""
Nov  5 21:52:19.816: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-h8nll "
Nov  5 21:52:19.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:19.897: INFO: stderr: ""
Nov  5 21:52:19.897: INFO: stdout: "true"
Nov  5 21:52:19.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:19.974: INFO: stderr: ""
Nov  5 21:52:19.974: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:19.974: INFO: validating pod update-demo-nautilus-47mts
Nov  5 21:52:19.978: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:19.978: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:19.978: INFO: update-demo-nautilus-47mts is verified up and running
Nov  5 21:52:19.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-h8nll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:20.061: INFO: stderr: ""
Nov  5 21:52:20.061: INFO: stdout: "true"
Nov  5 21:52:20.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-h8nll -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:20.141: INFO: stderr: ""
Nov  5 21:52:20.141: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:20.141: INFO: validating pod update-demo-nautilus-h8nll
Nov  5 21:52:20.145: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:20.145: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:20.145: INFO: update-demo-nautilus-h8nll is verified up and running
STEP: scaling down the replication controller
Nov  5 21:52:20.147: INFO: scanned /root for discovery docs: <nil>
Nov  5 21:52:20.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4944'
Nov  5 21:52:21.258: INFO: stderr: ""
Nov  5 21:52:21.258: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 21:52:21.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:21.340: INFO: stderr: ""
Nov  5 21:52:21.340: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-h8nll "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  5 21:52:26.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:26.430: INFO: stderr: ""
Nov  5 21:52:26.430: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-h8nll "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  5 21:52:31.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:31.521: INFO: stderr: ""
Nov  5 21:52:31.521: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-h8nll "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  5 21:52:36.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:36.607: INFO: stderr: ""
Nov  5 21:52:36.608: INFO: stdout: "update-demo-nautilus-47mts "
Nov  5 21:52:36.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:36.689: INFO: stderr: ""
Nov  5 21:52:36.689: INFO: stdout: "true"
Nov  5 21:52:36.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:36.774: INFO: stderr: ""
Nov  5 21:52:36.774: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:36.774: INFO: validating pod update-demo-nautilus-47mts
Nov  5 21:52:36.776: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:36.776: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:36.776: INFO: update-demo-nautilus-47mts is verified up and running
STEP: scaling up the replication controller
Nov  5 21:52:36.778: INFO: scanned /root for discovery docs: <nil>
Nov  5 21:52:36.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4944'
Nov  5 21:52:37.878: INFO: stderr: ""
Nov  5 21:52:37.878: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 21:52:37.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:37.962: INFO: stderr: ""
Nov  5 21:52:37.962: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-5qtpp "
Nov  5 21:52:37.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:38.048: INFO: stderr: ""
Nov  5 21:52:38.048: INFO: stdout: "true"
Nov  5 21:52:38.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:38.129: INFO: stderr: ""
Nov  5 21:52:38.129: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:38.129: INFO: validating pod update-demo-nautilus-47mts
Nov  5 21:52:38.132: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:38.132: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:38.132: INFO: update-demo-nautilus-47mts is verified up and running
Nov  5 21:52:38.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-5qtpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:38.213: INFO: stderr: ""
Nov  5 21:52:38.213: INFO: stdout: ""
Nov  5 21:52:38.213: INFO: update-demo-nautilus-5qtpp is created but not running
Nov  5 21:52:43.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4944'
Nov  5 21:52:43.296: INFO: stderr: ""
Nov  5 21:52:43.296: INFO: stdout: "update-demo-nautilus-47mts update-demo-nautilus-5qtpp "
Nov  5 21:52:43.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:43.378: INFO: stderr: ""
Nov  5 21:52:43.378: INFO: stdout: "true"
Nov  5 21:52:43.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-47mts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:43.460: INFO: stderr: ""
Nov  5 21:52:43.460: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:43.460: INFO: validating pod update-demo-nautilus-47mts
Nov  5 21:52:43.463: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:43.463: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:43.463: INFO: update-demo-nautilus-47mts is verified up and running
Nov  5 21:52:43.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-5qtpp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:43.545: INFO: stderr: ""
Nov  5 21:52:43.545: INFO: stdout: "true"
Nov  5 21:52:43.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-5qtpp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4944'
Nov  5 21:52:43.623: INFO: stderr: ""
Nov  5 21:52:43.623: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:52:43.623: INFO: validating pod update-demo-nautilus-5qtpp
Nov  5 21:52:43.627: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:52:43.627: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:52:43.627: INFO: update-demo-nautilus-5qtpp is verified up and running
STEP: using delete to clean up resources
Nov  5 21:52:43.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete --grace-period=0 --force -f - --namespace=kubectl-4944'
Nov  5 21:52:43.716: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 21:52:43.716: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  5 21:52:43.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4944'
Nov  5 21:52:43.805: INFO: stderr: "No resources found.\n"
Nov  5 21:52:43.805: INFO: stdout: ""
Nov  5 21:52:43.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=update-demo --namespace=kubectl-4944 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 21:52:43.888: INFO: stderr: ""
Nov  5 21:52:43.888: INFO: stdout: "update-demo-nautilus-47mts\nupdate-demo-nautilus-5qtpp\n"
Nov  5 21:52:44.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4944'
Nov  5 21:52:44.476: INFO: stderr: "No resources found.\n"
Nov  5 21:52:44.476: INFO: stdout: ""
Nov  5 21:52:44.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -l name=update-demo --namespace=kubectl-4944 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 21:52:44.561: INFO: stderr: ""
Nov  5 21:52:44.561: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:52:44.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4944" for this suite.
Nov  5 21:52:50.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:52:50.633: INFO: namespace kubectl-4944 deletion completed in 6.069321804s

• [SLOW TEST:36.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:52:50.634: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:52:50.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a" in namespace "downward-api-709" to be "success or failure"
Nov  5 21:52:50.663: INFO: Pod "downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.648894ms
Nov  5 21:52:52.666: INFO: Pod "downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004616284s
STEP: Saw pod success
Nov  5 21:52:52.666: INFO: Pod "downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a" satisfied condition "success or failure"
Nov  5 21:52:52.668: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a container client-container: <nil>
STEP: delete the pod
Nov  5 21:52:52.683: INFO: Waiting for pod downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a to disappear
Nov  5 21:52:52.684: INFO: Pod downwardapi-volume-16a776a5-7418-4b30-9946-7288c222e11a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:52:52.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-709" for this suite.
Nov  5 21:52:58.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:52:58.761: INFO: namespace downward-api-709 deletion completed in 6.073634334s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:52:58.762: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-484
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-484
STEP: Creating statefulset with conflicting port in namespace statefulset-484
STEP: Waiting until pod test-pod will start running in namespace statefulset-484
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-484
Nov  5 21:53:02.817: INFO: Observed stateful pod in namespace: statefulset-484, name: ss-0, uid: 6e7a145f-25cd-4a89-ab3d-24f5f6456435, status phase: Pending. Waiting for statefulset controller to delete.
Nov  5 21:53:03.007: INFO: Observed stateful pod in namespace: statefulset-484, name: ss-0, uid: 6e7a145f-25cd-4a89-ab3d-24f5f6456435, status phase: Failed. Waiting for statefulset controller to delete.
Nov  5 21:53:03.012: INFO: Observed stateful pod in namespace: statefulset-484, name: ss-0, uid: 6e7a145f-25cd-4a89-ab3d-24f5f6456435, status phase: Failed. Waiting for statefulset controller to delete.
Nov  5 21:53:03.014: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-484
STEP: Removing pod with conflicting port in namespace statefulset-484
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-484 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov  5 21:53:07.030: INFO: Deleting all statefulset in ns statefulset-484
Nov  5 21:53:07.031: INFO: Scaling statefulset ss to 0
Nov  5 21:53:17.041: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:53:17.044: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:53:17.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-484" for this suite.
Nov  5 21:53:23.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:53:23.134: INFO: namespace statefulset-484 deletion completed in 6.071823618s

• [SLOW TEST:24.372 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:53:23.134: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:53:25.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4540" for this suite.
Nov  5 21:54:15.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:54:15.250: INFO: namespace kubelet-test-4540 deletion completed in 50.071373881s

• [SLOW TEST:52.116 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:54:15.250: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-7121
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7121 to expose endpoints map[]
Nov  5 21:54:15.282: INFO: Get endpoints failed (1.975105ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  5 21:54:16.285: INFO: successfully validated that service multi-endpoint-test in namespace services-7121 exposes endpoints map[] (1.004639904s elapsed)
STEP: Creating pod pod1 in namespace services-7121
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7121 to expose endpoints map[pod1:[100]]
Nov  5 21:54:17.298: INFO: successfully validated that service multi-endpoint-test in namespace services-7121 exposes endpoints map[pod1:[100]] (1.00878357s elapsed)
STEP: Creating pod pod2 in namespace services-7121
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7121 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  5 21:54:19.321: INFO: successfully validated that service multi-endpoint-test in namespace services-7121 exposes endpoints map[pod1:[100] pod2:[101]] (2.019854088s elapsed)
STEP: Deleting pod pod1 in namespace services-7121
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7121 to expose endpoints map[pod2:[101]]
Nov  5 21:54:20.334: INFO: successfully validated that service multi-endpoint-test in namespace services-7121 exposes endpoints map[pod2:[101]] (1.009448741s elapsed)
STEP: Deleting pod pod2 in namespace services-7121
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7121 to expose endpoints map[]
Nov  5 21:54:21.341: INFO: successfully validated that service multi-endpoint-test in namespace services-7121 exposes endpoints map[] (1.00407824s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:54:21.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7121" for this suite.
Nov  5 21:54:43.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:54:43.428: INFO: namespace services-7121 deletion completed in 22.06862709s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:28.178 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:54:43.428: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Nov  5 21:54:43.454: INFO: Waiting up to 5m0s for pod "client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4" in namespace "containers-141" to be "success or failure"
Nov  5 21:54:43.456: INFO: Pod "client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.995085ms
Nov  5 21:54:45.458: INFO: Pod "client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004848605s
STEP: Saw pod success
Nov  5 21:54:45.458: INFO: Pod "client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4" satisfied condition "success or failure"
Nov  5 21:54:45.460: INFO: Trying to get logs from node k8s-node-2 pod client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4 container test-container: <nil>
STEP: delete the pod
Nov  5 21:54:45.477: INFO: Waiting for pod client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4 to disappear
Nov  5 21:54:45.479: INFO: Pod client-containers-513056a6-4b9c-48ab-b1ee-30f5be3a55b4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:54:45.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-141" for this suite.
Nov  5 21:54:51.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:54:51.560: INFO: namespace containers-141 deletion completed in 6.077288537s

• [SLOW TEST:8.132 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:54:51.560: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-eae76c55-f785-4a31-9379-972903f30ee2
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:54:51.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7404" for this suite.
Nov  5 21:54:57.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:54:57.664: INFO: namespace secrets-7404 deletion completed in 6.069780633s

• [SLOW TEST:6.104 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:54:57.665: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 21:54:57.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073" in namespace "downward-api-3966" to be "success or failure"
Nov  5 21:54:57.695: INFO: Pod "downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073": Phase="Pending", Reason="", readiness=false. Elapsed: 1.800852ms
Nov  5 21:54:59.697: INFO: Pod "downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004270526s
STEP: Saw pod success
Nov  5 21:54:59.697: INFO: Pod "downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073" satisfied condition "success or failure"
Nov  5 21:54:59.699: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073 container client-container: <nil>
STEP: delete the pod
Nov  5 21:54:59.713: INFO: Waiting for pod downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073 to disappear
Nov  5 21:54:59.715: INFO: Pod downwardapi-volume-26f0499b-a9e1-4ead-a676-d74acef24073 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:54:59.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3966" for this suite.
Nov  5 21:55:05.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:55:05.785: INFO: namespace downward-api-3966 deletion completed in 6.067316111s

• [SLOW TEST:8.121 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:55:05.786: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-9241aad5-30c4-42f7-acab-e86f9fad8b44
STEP: Creating a pod to test consume configMaps
Nov  5 21:55:05.817: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce" in namespace "projected-8209" to be "success or failure"
Nov  5 21:55:05.819: INFO: Pod "pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce": Phase="Pending", Reason="", readiness=false. Elapsed: 1.906655ms
Nov  5 21:55:07.822: INFO: Pod "pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004874571s
STEP: Saw pod success
Nov  5 21:55:07.822: INFO: Pod "pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce" satisfied condition "success or failure"
Nov  5 21:55:07.824: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 21:55:07.836: INFO: Waiting for pod pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce to disappear
Nov  5 21:55:07.839: INFO: Pod pod-projected-configmaps-aaaab13b-b9f2-4c04-ab27-74b1945471ce no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:55:07.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8209" for this suite.
Nov  5 21:55:13.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:55:13.911: INFO: namespace projected-8209 deletion completed in 6.068577763s

• [SLOW TEST:8.125 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:55:13.911: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-109a06c1-7246-4d8d-9e36-42764e9d32fb
STEP: Creating a pod to test consume secrets
Nov  5 21:55:13.943: INFO: Waiting up to 5m0s for pod "pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a" in namespace "secrets-9169" to be "success or failure"
Nov  5 21:55:13.945: INFO: Pod "pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.813253ms
Nov  5 21:55:15.948: INFO: Pod "pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004442539s
STEP: Saw pod success
Nov  5 21:55:15.948: INFO: Pod "pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a" satisfied condition "success or failure"
Nov  5 21:55:15.950: INFO: Trying to get logs from node k8s-node-1 pod pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a container secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:55:15.964: INFO: Waiting for pod pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a to disappear
Nov  5 21:55:15.966: INFO: Pod pod-secrets-88f93745-e5b2-40fa-b9aa-40036cfafa3a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:55:15.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9169" for this suite.
Nov  5 21:55:21.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:55:22.034: INFO: namespace secrets-9169 deletion completed in 6.066030977s

• [SLOW TEST:8.123 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:55:22.035: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov  5 21:56:02.110: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 321
	[quantile=0.99] = 547
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 11061
	[quantile=0.9] = 208583
	[quantile=0.99] = 212786
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 4
	[quantile=0.99] = 4
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 237289
	[quantile=0.9] = 237289
	[quantile=0.99] = 237289
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 6
	[quantile=0.99] = 19
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 22
	[quantile=0.99] = 41
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 21
	[quantile=0.99] = 41
For namespace_queue_latency_sum:
	[] = 4687
For namespace_queue_latency_count:
	[] = 301
For namespace_retries:
	[] = 306
For namespace_work_duration:
	[quantile=0.5] = 116513
	[quantile=0.9] = 172028
	[quantile=0.99] = 241810
For namespace_work_duration_sum:
	[] = 46371582
For namespace_work_duration_count:
	[] = 301
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:02.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8255" for this suite.
Nov  5 21:56:08.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:56:08.184: INFO: namespace gc-8255 deletion completed in 6.070851528s

• [SLOW TEST:46.150 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:56:08.185: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  5 21:56:08.214: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8309,SelfLink:/api/v1/namespaces/watch-8309/configmaps/e2e-watch-test-watch-closed,UID:f3736b82-5b30-48d2-862c-b476fe92f74b,ResourceVersion:26322,Generation:0,CreationTimestamp:2019-11-05 21:56:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  5 21:56:08.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8309,SelfLink:/api/v1/namespaces/watch-8309/configmaps/e2e-watch-test-watch-closed,UID:f3736b82-5b30-48d2-862c-b476fe92f74b,ResourceVersion:26323,Generation:0,CreationTimestamp:2019-11-05 21:56:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  5 21:56:08.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8309,SelfLink:/api/v1/namespaces/watch-8309/configmaps/e2e-watch-test-watch-closed,UID:f3736b82-5b30-48d2-862c-b476fe92f74b,ResourceVersion:26324,Generation:0,CreationTimestamp:2019-11-05 21:56:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  5 21:56:08.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8309,SelfLink:/api/v1/namespaces/watch-8309/configmaps/e2e-watch-test-watch-closed,UID:f3736b82-5b30-48d2-862c-b476fe92f74b,ResourceVersion:26325,Generation:0,CreationTimestamp:2019-11-05 21:56:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:08.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8309" for this suite.
Nov  5 21:56:14.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:56:14.294: INFO: namespace watch-8309 deletion completed in 6.067078925s

• [SLOW TEST:6.110 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:56:14.295: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  5 21:56:16.333: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:16.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2171" for this suite.
Nov  5 21:56:22.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:56:22.411: INFO: namespace container-runtime-2171 deletion completed in 6.066156576s

• [SLOW TEST:8.116 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:56:22.411: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-6e56f12b-fea5-4fae-867c-8f3d0f1a80f2
STEP: Creating secret with name s-test-opt-upd-2ae372ad-9762-4aaf-ab68-4b2fd2b987fd
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6e56f12b-fea5-4fae-867c-8f3d0f1a80f2
STEP: Updating secret s-test-opt-upd-2ae372ad-9762-4aaf-ab68-4b2fd2b987fd
STEP: Creating secret with name s-test-opt-create-89a3b081-e9fe-405d-b9a1-e58ef317ecb8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:26.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7659" for this suite.
Nov  5 21:56:48.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:56:48.575: INFO: namespace projected-7659 deletion completed in 22.069955203s

• [SLOW TEST:26.164 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:56:48.576: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Nov  5 21:56:49.650: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 321
	[quantile=0.99] = 547
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 11372
	[quantile=0.9] = 208912
	[quantile=0.99] = 212786
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 4
	[quantile=0.99] = 4
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 237289
	[quantile=0.9] = 237289
	[quantile=0.99] = 237289
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 3
	[quantile=0.9] = 6
	[quantile=0.99] = 18
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 22
	[quantile=0.99] = 40
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 21
	[quantile=0.99] = 28
For namespace_queue_latency_sum:
	[] = 4768
For namespace_queue_latency_count:
	[] = 306
For namespace_retries:
	[] = 311
For namespace_work_duration:
	[quantile=0.5] = 116513
	[quantile=0.9] = 172813
	[quantile=0.99] = 479770
For namespace_work_duration_sum:
	[] = 47409613
For namespace_work_duration_count:
	[] = 306
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:49.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8898" for this suite.
Nov  5 21:56:55.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:56:55.724: INFO: namespace gc-8898 deletion completed in 6.070510029s

• [SLOW TEST:7.148 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:56:55.724: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-7bc98398-7eb8-4e24-aa50-0819fcf2e68a
STEP: Creating a pod to test consume secrets
Nov  5 21:56:55.755: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4" in namespace "projected-5860" to be "success or failure"
Nov  5 21:56:55.758: INFO: Pod "pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.722866ms
Nov  5 21:56:57.760: INFO: Pod "pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005253603s
STEP: Saw pod success
Nov  5 21:56:57.761: INFO: Pod "pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4" satisfied condition "success or failure"
Nov  5 21:56:57.763: INFO: Trying to get logs from node k8s-node-2 pod pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  5 21:56:57.777: INFO: Waiting for pod pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4 to disappear
Nov  5 21:56:57.779: INFO: Pod pod-projected-secrets-bfea5d33-7242-4656-aee2-625963c750c4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:56:57.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5860" for this suite.
Nov  5 21:57:03.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:57:03.850: INFO: namespace projected-5860 deletion completed in 6.067873731s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:57:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6703
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-6703
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6703
Nov  5 21:57:03.881: INFO: Found 0 stateful pods, waiting for 1
Nov  5 21:57:13.884: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  5 21:57:13.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:57:14.146: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:57:14.147: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:57:14.147: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:57:14.150: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  5 21:57:24.153: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:57:24.153: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:57:24.163: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Nov  5 21:57:24.163: INFO: ss-0  k8s-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  }]
Nov  5 21:57:24.163: INFO: 
Nov  5 21:57:24.163: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  5 21:57:25.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996016034s
Nov  5 21:57:26.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992670396s
Nov  5 21:57:27.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989790327s
Nov  5 21:57:28.176: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986400405s
Nov  5 21:57:29.180: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983133442s
Nov  5 21:57:30.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979548872s
Nov  5 21:57:31.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976087978s
Nov  5 21:57:32.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972808139s
Nov  5 21:57:33.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.364145ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6703
Nov  5 21:57:34.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:57:34.401: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov  5 21:57:34.401: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:57:34.401: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:57:34.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:57:34.609: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  5 21:57:34.609: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:57:34.609: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:57:34.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  5 21:57:34.831: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  5 21:57:34.831: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  5 21:57:34.831: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  5 21:57:34.834: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov  5 21:57:44.838: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:57:44.838: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 21:57:44.838: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  5 21:57:44.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:57:45.053: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:57:45.054: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:57:45.054: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:57:45.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:57:45.274: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:57:45.274: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:57:45.275: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:57:45.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 exec --namespace=statefulset-6703 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  5 21:57:45.504: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov  5 21:57:45.505: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  5 21:57:45.505: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  5 21:57:45.505: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:57:45.507: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  5 21:57:55.513: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:57:55.513: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:57:55.513: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 21:57:55.522: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Nov  5 21:57:55.522: INFO: ss-0  k8s-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  }]
Nov  5 21:57:55.522: INFO: ss-1  k8s-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  }]
Nov  5 21:57:55.522: INFO: ss-2  k8s-node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  }]
Nov  5 21:57:55.522: INFO: 
Nov  5 21:57:55.522: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  5 21:57:56.524: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Nov  5 21:57:56.524: INFO: ss-0  k8s-node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:03 +0000 UTC  }]
Nov  5 21:57:56.525: INFO: ss-1  k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  }]
Nov  5 21:57:56.525: INFO: ss-2  k8s-node-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:57:24 +0000 UTC  }]
Nov  5 21:57:56.525: INFO: 
Nov  5 21:57:56.525: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  5 21:57:57.528: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.993812751s
Nov  5 21:57:58.531: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.990687173s
Nov  5 21:57:59.534: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.987709154s
Nov  5 21:58:00.536: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.98484449s
Nov  5 21:58:01.539: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.981934008s
Nov  5 21:58:02.542: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.979051721s
Nov  5 21:58:03.545: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.976146719s
Nov  5 21:58:04.548: INFO: Verifying statefulset ss doesn't scale past 0 for another 973.535541ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6703
Nov  5 21:58:05.551: INFO: Scaling statefulset ss to 0
Nov  5 21:58:05.558: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov  5 21:58:05.559: INFO: Deleting all statefulset in ns statefulset-6703
Nov  5 21:58:05.561: INFO: Scaling statefulset ss to 0
Nov  5 21:58:05.566: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 21:58:05.568: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:58:05.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6703" for this suite.
Nov  5 21:58:11.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:58:11.655: INFO: namespace statefulset-6703 deletion completed in 6.072337531s

• [SLOW TEST:67.805 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:58:11.656: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Nov  5 21:58:11.684: INFO: Waiting up to 5m0s for pod "client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5" in namespace "containers-266" to be "success or failure"
Nov  5 21:58:11.687: INFO: Pod "client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07324ms
Nov  5 21:58:13.689: INFO: Pod "client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004989837s
STEP: Saw pod success
Nov  5 21:58:13.689: INFO: Pod "client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5" satisfied condition "success or failure"
Nov  5 21:58:13.691: INFO: Trying to get logs from node k8s-node-2 pod client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5 container test-container: <nil>
STEP: delete the pod
Nov  5 21:58:13.709: INFO: Waiting for pod client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5 to disappear
Nov  5 21:58:13.712: INFO: Pod client-containers-9901c424-5823-499c-a540-3b1d5a3f0ca5 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:58:13.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-266" for this suite.
Nov  5 21:58:19.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:58:19.782: INFO: namespace containers-266 deletion completed in 6.065264166s

• [SLOW TEST:8.126 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:58:19.782: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  5 21:58:23.817: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-fc82bf91-c62a-4be6-9096-cbc73377cbb2,GenerateName:,Namespace:events-5551,SelfLink:/api/v1/namespaces/events-5551/pods/send-events-fc82bf91-c62a-4be6-9096-cbc73377cbb2,UID:03a0f9ae-8fbc-405b-941f-7b5ff9e3deac,ResourceVersion:27014,Generation:0,CreationTimestamp:2019-11-05 21:58:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 805277556,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cbwbm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cbwbm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-cbwbm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003390a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003390a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:58:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:58:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:58:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:58:19 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.155,StartTime:2019-11-05 21:58:19 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-11-05 21:58:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://c57b2a22c1408c86f64003e474545c9a2c521bf66fc3eb0b38615096c8de1186}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov  5 21:58:25.821: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  5 21:58:27.824: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:58:27.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5551" for this suite.
Nov  5 21:59:05.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:59:05.900: INFO: namespace events-5551 deletion completed in 38.068717073s

• [SLOW TEST:46.118 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:59:05.901: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-fcd33064-b6d5-43f3-8f0b-59e67f25464e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-fcd33064-b6d5-43f3-8f0b-59e67f25464e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:59:09.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5027" for this suite.
Nov  5 21:59:31.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:59:32.039: INFO: namespace configmap-5027 deletion completed in 22.072009222s

• [SLOW TEST:26.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:59:32.039: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 21:59:32.070: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  5 21:59:37.073: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  5 21:59:37.073: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov  5 21:59:37.098: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6577,SelfLink:/apis/apps/v1/namespaces/deployment-6577/deployments/test-cleanup-deployment,UID:bfc098d1-acb1-47c7-8e7d-e047d06cb95d,ResourceVersion:27236,Generation:1,CreationTimestamp:2019-11-05 21:59:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov  5 21:59:37.102: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-6577,SelfLink:/apis/apps/v1/namespaces/deployment-6577/replicasets/test-cleanup-deployment-55bbcbc84c,UID:5e929b25-ce22-4132-8645-26b57e40e307,ResourceVersion:27238,Generation:1,CreationTimestamp:2019-11-05 21:59:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment bfc098d1-acb1-47c7-8e7d-e047d06cb95d 0xc0026dac17 0xc0026dac18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  5 21:59:37.102: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  5 21:59:37.102: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-6577,SelfLink:/apis/apps/v1/namespaces/deployment-6577/replicasets/test-cleanup-controller,UID:a88367a1-5b51-4cd8-bdc4-16d3317b72a6,ResourceVersion:27237,Generation:1,CreationTimestamp:2019-11-05 21:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment bfc098d1-acb1-47c7-8e7d-e047d06cb95d 0xc0026dab47 0xc0026dab48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  5 21:59:37.107: INFO: Pod "test-cleanup-controller-8qxw5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-8qxw5,GenerateName:test-cleanup-controller-,Namespace:deployment-6577,SelfLink:/api/v1/namespaces/deployment-6577/pods/test-cleanup-controller-8qxw5,UID:58521dae-bffc-4c83-9c91-f7ab0c043398,ResourceVersion:27226,Generation:0,CreationTimestamp:2019-11-05 21:59:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller a88367a1-5b51-4cd8-bdc4-16d3317b72a6 0xc00304b337 0xc00304b338}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8h7sz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8h7sz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8h7sz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00304b3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00304b3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:59:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:59:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:59:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:59:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.3.111,PodIP:10.233.117.156,StartTime:2019-11-05 21:59:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-05 21:59:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5b0919fd614bffaf0b7d0695d71ab15a86b7edd6a795ec73627ee22758223282}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  5 21:59:37.108: INFO: Pod "test-cleanup-deployment-55bbcbc84c-g46bl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-g46bl,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-6577,SelfLink:/api/v1/namespaces/deployment-6577/pods/test-cleanup-deployment-55bbcbc84c-g46bl,UID:50435142-ea46-46ad-b930-c746fc7231da,ResourceVersion:27242,Generation:0,CreationTimestamp:2019-11-05 21:59:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 5e929b25-ce22-4132-8645-26b57e40e307 0xc00304b4b7 0xc00304b4b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8h7sz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8h7sz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8h7sz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00304b530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00304b550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-05 21:59:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:59:37.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6577" for this suite.
Nov  5 21:59:43.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:59:43.180: INFO: namespace deployment-6577 deletion completed in 6.067481878s

• [SLOW TEST:11.141 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:59:43.180: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov  5 21:59:43.209: INFO: Waiting up to 5m0s for pod "downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4" in namespace "downward-api-6686" to be "success or failure"
Nov  5 21:59:43.213: INFO: Pod "downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471736ms
Nov  5 21:59:45.216: INFO: Pod "downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006333448s
Nov  5 21:59:47.219: INFO: Pod "downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009261717s
STEP: Saw pod success
Nov  5 21:59:47.219: INFO: Pod "downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4" satisfied condition "success or failure"
Nov  5 21:59:47.220: INFO: Trying to get logs from node k8s-node-3 pod downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4 container dapi-container: <nil>
STEP: delete the pod
Nov  5 21:59:47.237: INFO: Waiting for pod downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4 to disappear
Nov  5 21:59:47.238: INFO: Pod downward-api-31d2ceca-8f15-49c9-97ec-1af68ec90ec4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 21:59:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6686" for this suite.
Nov  5 21:59:53.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 21:59:53.312: INFO: namespace downward-api-6686 deletion completed in 6.070163882s

• [SLOW TEST:10.131 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 21:59:53.312: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Nov  5 21:59:53.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 create -f - --namespace=kubectl-4095'
Nov  5 21:59:53.481: INFO: stderr: ""
Nov  5 21:59:53.481: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 21:59:53.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4095'
Nov  5 21:59:53.569: INFO: stderr: ""
Nov  5 21:59:53.569: INFO: stdout: "update-demo-nautilus-fch4h update-demo-nautilus-j62qh "
Nov  5 21:59:53.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-fch4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 21:59:53.649: INFO: stderr: ""
Nov  5 21:59:53.649: INFO: stdout: ""
Nov  5 21:59:53.649: INFO: update-demo-nautilus-fch4h is created but not running
Nov  5 21:59:58.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4095'
Nov  5 21:59:58.738: INFO: stderr: ""
Nov  5 21:59:58.738: INFO: stdout: "update-demo-nautilus-fch4h update-demo-nautilus-j62qh "
Nov  5 21:59:58.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-fch4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 21:59:58.820: INFO: stderr: ""
Nov  5 21:59:58.820: INFO: stdout: "true"
Nov  5 21:59:58.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-fch4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 21:59:58.898: INFO: stderr: ""
Nov  5 21:59:58.898: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:59:58.898: INFO: validating pod update-demo-nautilus-fch4h
Nov  5 21:59:58.902: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:59:58.902: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:59:58.902: INFO: update-demo-nautilus-fch4h is verified up and running
Nov  5 21:59:58.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-j62qh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 21:59:58.986: INFO: stderr: ""
Nov  5 21:59:58.986: INFO: stdout: "true"
Nov  5 21:59:58.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-nautilus-j62qh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 21:59:59.068: INFO: stderr: ""
Nov  5 21:59:59.069: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  5 21:59:59.069: INFO: validating pod update-demo-nautilus-j62qh
Nov  5 21:59:59.072: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 21:59:59.072: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 21:59:59.072: INFO: update-demo-nautilus-j62qh is verified up and running
STEP: rolling-update to new replication controller
Nov  5 21:59:59.074: INFO: scanned /root for discovery docs: <nil>
Nov  5 21:59:59.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4095'
Nov  5 22:00:21.372: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  5 22:00:21.372: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  5 22:00:21.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4095'
Nov  5 22:00:21.463: INFO: stderr: ""
Nov  5 22:00:21.463: INFO: stdout: "update-demo-kitten-dgl95 update-demo-kitten-zhgkn update-demo-nautilus-fch4h "
STEP: Replicas for name=update-demo: expected=2 actual=3
Nov  5 22:00:26.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4095'
Nov  5 22:00:26.546: INFO: stderr: ""
Nov  5 22:00:26.546: INFO: stdout: "update-demo-kitten-dgl95 update-demo-kitten-zhgkn "
Nov  5 22:00:26.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-kitten-dgl95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 22:00:26.631: INFO: stderr: ""
Nov  5 22:00:26.631: INFO: stdout: "true"
Nov  5 22:00:26.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-kitten-dgl95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 22:00:26.710: INFO: stderr: ""
Nov  5 22:00:26.710: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  5 22:00:26.710: INFO: validating pod update-demo-kitten-dgl95
Nov  5 22:00:26.714: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  5 22:00:26.714: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  5 22:00:26.714: INFO: update-demo-kitten-dgl95 is verified up and running
Nov  5 22:00:26.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-kitten-zhgkn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 22:00:26.803: INFO: stderr: ""
Nov  5 22:00:26.803: INFO: stdout: "true"
Nov  5 22:00:26.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 get pods update-demo-kitten-zhgkn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4095'
Nov  5 22:00:26.882: INFO: stderr: ""
Nov  5 22:00:26.882: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  5 22:00:26.882: INFO: validating pod update-demo-kitten-zhgkn
Nov  5 22:00:26.886: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  5 22:00:26.886: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  5 22:00:26.886: INFO: update-demo-kitten-zhgkn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:00:26.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4095" for this suite.
Nov  5 22:00:48.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:00:48.957: INFO: namespace kubectl-4095 deletion completed in 22.06763727s

• [SLOW TEST:55.644 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:00:48.957: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-h4hq
STEP: Creating a pod to test atomic-volume-subpath
Nov  5 22:00:48.991: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-h4hq" in namespace "subpath-7011" to be "success or failure"
Nov  5 22:00:48.993: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Pending", Reason="", readiness=false. Elapsed: 1.867284ms
Nov  5 22:00:50.996: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 2.004575653s
Nov  5 22:00:53.000: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 4.00876299s
Nov  5 22:00:55.003: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 6.011457874s
Nov  5 22:00:57.006: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 8.01441987s
Nov  5 22:00:59.008: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 10.017069716s
Nov  5 22:01:01.011: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 12.02002072s
Nov  5 22:01:03.014: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 14.022666106s
Nov  5 22:01:05.017: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 16.026101302s
Nov  5 22:01:07.020: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 18.028949978s
Nov  5 22:01:09.023: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Running", Reason="", readiness=true. Elapsed: 20.031781654s
Nov  5 22:01:11.026: INFO: Pod "pod-subpath-test-secret-h4hq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.034587991s
STEP: Saw pod success
Nov  5 22:01:11.026: INFO: Pod "pod-subpath-test-secret-h4hq" satisfied condition "success or failure"
Nov  5 22:01:11.027: INFO: Trying to get logs from node k8s-node-2 pod pod-subpath-test-secret-h4hq container test-container-subpath-secret-h4hq: <nil>
STEP: delete the pod
Nov  5 22:01:11.042: INFO: Waiting for pod pod-subpath-test-secret-h4hq to disappear
Nov  5 22:01:11.044: INFO: Pod pod-subpath-test-secret-h4hq no longer exists
STEP: Deleting pod pod-subpath-test-secret-h4hq
Nov  5 22:01:11.044: INFO: Deleting pod "pod-subpath-test-secret-h4hq" in namespace "subpath-7011"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:01:11.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7011" for this suite.
Nov  5 22:01:17.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:01:17.114: INFO: namespace subpath-7011 deletion completed in 6.065246934s

• [SLOW TEST:28.157 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:01:17.114: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  5 22:01:19.656: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-190 pod-service-account-0bfb4bd2-e165-430f-a167-f399583e5c97 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  5 22:01:19.860: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-190 pod-service-account-0bfb4bd2-e165-430f-a167-f399583e5c97 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  5 22:01:20.074: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-190 pod-service-account-0bfb4bd2-e165-430f-a167-f399583e5c97 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:01:20.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-190" for this suite.
Nov  5 22:01:26.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:01:26.365: INFO: namespace svcaccounts-190 deletion completed in 6.065427127s

• [SLOW TEST:9.251 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:01:26.365: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  5 22:01:26.392: INFO: Waiting up to 5m0s for pod "pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb" in namespace "emptydir-2767" to be "success or failure"
Nov  5 22:01:26.394: INFO: Pod "pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.292717ms
Nov  5 22:01:28.397: INFO: Pod "pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005693822s
STEP: Saw pod success
Nov  5 22:01:28.397: INFO: Pod "pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb" satisfied condition "success or failure"
Nov  5 22:01:28.400: INFO: Trying to get logs from node k8s-node-2 pod pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb container test-container: <nil>
STEP: delete the pod
Nov  5 22:01:28.415: INFO: Waiting for pod pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb to disappear
Nov  5 22:01:28.417: INFO: Pod pod-79a2fc86-1b38-4e90-9a2f-140fe281c4cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:01:28.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2767" for this suite.
Nov  5 22:01:34.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:01:34.485: INFO: namespace emptydir-2767 deletion completed in 6.06457502s

• [SLOW TEST:8.120 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:01:34.485: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  5 22:01:34.514: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27822,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  5 22:01:34.515: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27822,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  5 22:01:44.520: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27842,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  5 22:01:44.520: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27842,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  5 22:01:54.525: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27862,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  5 22:01:54.526: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27862,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  5 22:02:04.531: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27882,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  5 22:02:04.531: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-a,UID:f290f397-901d-4919-a138-b32f79d3c6aa,ResourceVersion:27882,Generation:0,CreationTimestamp:2019-11-05 22:01:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  5 22:02:14.536: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-b,UID:06576381-d2d0-4d32-977c-21c9af80aeb5,ResourceVersion:27902,Generation:0,CreationTimestamp:2019-11-05 22:02:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  5 22:02:14.536: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-b,UID:06576381-d2d0-4d32-977c-21c9af80aeb5,ResourceVersion:27902,Generation:0,CreationTimestamp:2019-11-05 22:02:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  5 22:02:24.541: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-b,UID:06576381-d2d0-4d32-977c-21c9af80aeb5,ResourceVersion:27922,Generation:0,CreationTimestamp:2019-11-05 22:02:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  5 22:02:24.541: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3416,SelfLink:/api/v1/namespaces/watch-3416/configmaps/e2e-watch-test-configmap-b,UID:06576381-d2d0-4d32-977c-21c9af80aeb5,ResourceVersion:27922,Generation:0,CreationTimestamp:2019-11-05 22:02:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:02:34.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3416" for this suite.
Nov  5 22:02:40.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:02:40.610: INFO: namespace watch-3416 deletion completed in 6.06457991s

• [SLOW TEST:66.125 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:02:40.610: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  5 22:02:42.646: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:02:42.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9509" for this suite.
Nov  5 22:02:48.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:02:48.736: INFO: namespace container-runtime-9509 deletion completed in 6.07525326s

• [SLOW TEST:8.126 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:02:48.736: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-6fab8747-3963-47b9-a5de-a31f321252d2
STEP: Creating a pod to test consume configMaps
Nov  5 22:02:48.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f" in namespace "configmap-5992" to be "success or failure"
Nov  5 22:02:48.776: INFO: Pod "pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.659486ms
Nov  5 22:02:50.778: INFO: Pod "pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003692944s
STEP: Saw pod success
Nov  5 22:02:50.778: INFO: Pod "pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f" satisfied condition "success or failure"
Nov  5 22:02:50.780: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f container configmap-volume-test: <nil>
STEP: delete the pod
Nov  5 22:02:50.792: INFO: Waiting for pod pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f to disappear
Nov  5 22:02:50.794: INFO: Pod pod-configmaps-251fdfe2-8beb-46f2-b7b8-b1271c0e9d7f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:02:50.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5992" for this suite.
Nov  5 22:02:56.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:02:56.863: INFO: namespace configmap-5992 deletion completed in 6.065493378s

• [SLOW TEST:8.127 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:02:56.864: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:03:19.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4563" for this suite.
Nov  5 22:03:25.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:03:25.084: INFO: namespace container-runtime-4563 deletion completed in 6.067326877s

• [SLOW TEST:28.220 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:03:25.084: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov  5 22:03:25.121: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a8fb925a-8497-4cfb-a653-ce966792d482", Controller:(*bool)(0xc0029ab3ca), BlockOwnerDeletion:(*bool)(0xc0029ab3cb)}}
Nov  5 22:03:25.125: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"65d6807f-192b-4380-b184-928b136b3548", Controller:(*bool)(0xc00348d826), BlockOwnerDeletion:(*bool)(0xc00348d827)}}
Nov  5 22:03:25.130: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d3897b99-86df-406d-b80f-e8c0ebc9bb8c", Controller:(*bool)(0xc00348d9d6), BlockOwnerDeletion:(*bool)(0xc00348d9d7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:03:30.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5711" for this suite.
Nov  5 22:03:36.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:03:36.211: INFO: namespace gc-5711 deletion completed in 6.069421599s

• [SLOW TEST:11.127 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:03:36.211: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-d8deeb1e-aad3-408c-9c04-03a36ab0df12
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:03:38.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7713" for this suite.
Nov  5 22:04:00.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:00.351: INFO: namespace configmap-7713 deletion completed in 22.080660214s

• [SLOW TEST:24.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:00.351: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  5 22:04:00.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28367,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  5 22:04:00.393: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28368,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  5 22:04:00.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28369,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  5 22:04:10.410: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28390,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  5 22:04:10.410: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28391,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  5 22:04:10.410: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-558,SelfLink:/api/v1/namespaces/watch-558/configmaps/e2e-watch-test-label-changed,UID:64bb06cf-7d6b-4500-8e72-1d2e3afbe513,ResourceVersion:28392,Generation:0,CreationTimestamp:2019-11-05 22:04:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:10.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-558" for this suite.
Nov  5 22:04:16.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:16.480: INFO: namespace watch-558 deletion completed in 6.066870224s

• [SLOW TEST:16.128 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:16.480: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov  5 22:04:16.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670" in namespace "projected-9557" to be "success or failure"
Nov  5 22:04:16.510: INFO: Pod "downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670": Phase="Pending", Reason="", readiness=false. Elapsed: 1.636845ms
Nov  5 22:04:18.512: INFO: Pod "downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004014974s
STEP: Saw pod success
Nov  5 22:04:18.512: INFO: Pod "downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670" satisfied condition "success or failure"
Nov  5 22:04:18.514: INFO: Trying to get logs from node k8s-node-2 pod downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670 container client-container: <nil>
STEP: delete the pod
Nov  5 22:04:18.528: INFO: Waiting for pod downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670 to disappear
Nov  5 22:04:18.529: INFO: Pod downwardapi-volume-ed650eda-5fc9-4059-a860-34df69f7c670 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:18.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9557" for this suite.
Nov  5 22:04:24.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:24.598: INFO: namespace projected-9557 deletion completed in 6.065279652s

• [SLOW TEST:8.118 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:24.598: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  5 22:04:24.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2505'
Nov  5 22:04:24.716: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  5 22:04:24.716: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Nov  5 22:04:24.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-243470310 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2505'
Nov  5 22:04:24.821: INFO: stderr: ""
Nov  5 22:04:24.821: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:24.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2505" for this suite.
Nov  5 22:04:30.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:30.892: INFO: namespace kubectl-2505 deletion completed in 6.067478608s

• [SLOW TEST:6.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:30.893: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:36.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2096" for this suite.
Nov  5 22:04:42.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:43.042: INFO: namespace namespaces-2096 deletion completed in 6.065174392s
STEP: Destroying namespace "nsdeletetest-4378" for this suite.
Nov  5 22:04:43.044: INFO: Namespace nsdeletetest-4378 was already deleted
STEP: Destroying namespace "nsdeletetest-6399" for this suite.
Nov  5 22:04:49.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:49.113: INFO: namespace nsdeletetest-6399 deletion completed in 6.069061447s

• [SLOW TEST:18.221 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:49.113: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9759/configmap-test-1752574d-57d5-4579-9f1b-5effe815447b
STEP: Creating a pod to test consume configMaps
Nov  5 22:04:49.147: INFO: Waiting up to 5m0s for pod "pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2" in namespace "configmap-9759" to be "success or failure"
Nov  5 22:04:49.149: INFO: Pod "pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.704796ms
Nov  5 22:04:51.153: INFO: Pod "pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00568153s
STEP: Saw pod success
Nov  5 22:04:51.153: INFO: Pod "pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2" satisfied condition "success or failure"
Nov  5 22:04:51.157: INFO: Trying to get logs from node k8s-node-2 pod pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2 container env-test: <nil>
STEP: delete the pod
Nov  5 22:04:51.174: INFO: Waiting for pod pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2 to disappear
Nov  5 22:04:51.176: INFO: Pod pod-configmaps-eb6759b1-914b-4fca-a3f6-edf7d889d1b2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:51.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9759" for this suite.
Nov  5 22:04:57.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:04:57.252: INFO: namespace configmap-9759 deletion completed in 6.073236242s

• [SLOW TEST:8.139 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov  5 22:04:57.253: INFO: >>> kubeConfig: /tmp/kubeconfig-243470310
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-6ea21cce-d8a5-46b3-9db2-024e290f3343
STEP: Creating a pod to test consume secrets
Nov  5 22:04:57.286: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc" in namespace "projected-4704" to be "success or failure"
Nov  5 22:04:57.288: INFO: Pod "pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.001188ms
Nov  5 22:04:59.293: INFO: Pod "pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007562414s
STEP: Saw pod success
Nov  5 22:04:59.293: INFO: Pod "pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc" satisfied condition "success or failure"
Nov  5 22:04:59.295: INFO: Trying to get logs from node k8s-node-1 pod pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  5 22:04:59.311: INFO: Waiting for pod pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc to disappear
Nov  5 22:04:59.312: INFO: Pod pod-projected-secrets-db32e116-cc56-4c27-8bfe-c16c3f8545bc no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov  5 22:04:59.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4704" for this suite.
Nov  5 22:05:05.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  5 22:05:05.386: INFO: namespace projected-4704 deletion completed in 6.06964092s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSNov  5 22:05:05.386: INFO: Running AfterSuite actions on all nodes
Nov  5 22:05:05.386: INFO: Running AfterSuite actions on node 1
Nov  5 22:05:05.386: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5138.190 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h25m39.71849542s
Test Suite Passed
