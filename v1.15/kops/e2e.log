I0909 23:24:29.059044      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-004522922
I0909 23:24:29.059165      15 e2e.go:241] Starting e2e run "b17a4653-0b9a-4070-8a69-59385bdc6848" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1568071467 - Will randomize all specs
Will run 215 of 4413 specs

Sep  9 23:24:29.253: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:24:29.255: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  9 23:24:29.266: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  9 23:24:29.287: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  9 23:24:29.287: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep  9 23:24:29.287: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  9 23:24:29.292: INFO: e2e test version: v1.15.3
Sep  9 23:24:29.293: INFO: kube-apiserver version: v1.15.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:24:29.294: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
Sep  9 23:24:29.313: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-dc866e64-23a9-46c9-a142-b0ba124a853f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:24:29.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9352" for this suite.
Sep  9 23:24:35.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:24:35.380: INFO: namespace secrets-9352 deletion completed in 6.063493303s

• [SLOW TEST:6.086 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:24:35.381: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5d66ef34-e8ae-4a22-ad5d-dedaa1df1f91
STEP: Creating a pod to test consume secrets
Sep  9 23:24:35.404: INFO: Waiting up to 5m0s for pod "pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8" in namespace "secrets-57" to be "success or failure"
Sep  9 23:24:35.406: INFO: Pod "pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.924937ms
Sep  9 23:24:37.408: INFO: Pod "pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00400703s
Sep  9 23:24:39.410: INFO: Pod "pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006270975s
STEP: Saw pod success
Sep  9 23:24:39.411: INFO: Pod "pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8" satisfied condition "success or failure"
Sep  9 23:24:39.412: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8 container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:24:39.436: INFO: Waiting for pod pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8 to disappear
Sep  9 23:24:39.437: INFO: Pod pod-secrets-2efd20ea-027d-44da-a638-35ff833d60c8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:24:39.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-57" for this suite.
Sep  9 23:24:45.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:24:45.498: INFO: namespace secrets-57 deletion completed in 6.059161078s

• [SLOW TEST:10.118 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:24:45.498: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  9 23:24:45.519: INFO: Waiting up to 5m0s for pod "pod-9caa9740-cb27-49d6-984c-b4de31efe2a8" in namespace "emptydir-6571" to be "success or failure"
Sep  9 23:24:45.523: INFO: Pod "pod-9caa9740-cb27-49d6-984c-b4de31efe2a8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.69884ms
Sep  9 23:24:47.526: INFO: Pod "pod-9caa9740-cb27-49d6-984c-b4de31efe2a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006384191s
Sep  9 23:24:49.528: INFO: Pod "pod-9caa9740-cb27-49d6-984c-b4de31efe2a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008642267s
STEP: Saw pod success
Sep  9 23:24:49.528: INFO: Pod "pod-9caa9740-cb27-49d6-984c-b4de31efe2a8" satisfied condition "success or failure"
Sep  9 23:24:49.530: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-9caa9740-cb27-49d6-984c-b4de31efe2a8 container test-container: <nil>
STEP: delete the pod
Sep  9 23:24:49.549: INFO: Waiting for pod pod-9caa9740-cb27-49d6-984c-b4de31efe2a8 to disappear
Sep  9 23:24:49.551: INFO: Pod pod-9caa9740-cb27-49d6-984c-b4de31efe2a8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:24:49.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6571" for this suite.
Sep  9 23:24:55.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:24:55.639: INFO: namespace emptydir-6571 deletion completed in 6.085569783s

• [SLOW TEST:10.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:24:55.639: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  9 23:24:55.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2" in namespace "downward-api-1812" to be "success or failure"
Sep  9 23:24:55.664: INFO: Pod "downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126538ms
Sep  9 23:24:57.666: INFO: Pod "downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00449889s
STEP: Saw pod success
Sep  9 23:24:57.666: INFO: Pod "downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2" satisfied condition "success or failure"
Sep  9 23:24:57.669: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2 container client-container: <nil>
STEP: delete the pod
Sep  9 23:24:57.692: INFO: Waiting for pod downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2 to disappear
Sep  9 23:24:57.695: INFO: Pod downwardapi-volume-af20814e-b32c-4257-9887-21d6c5149dd2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:24:57.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1812" for this suite.
Sep  9 23:25:03.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:25:03.768: INFO: namespace downward-api-1812 deletion completed in 6.069311636s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:25:03.768: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3594
I0909 23:25:03.788714      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3594, replica count: 1
I0909 23:25:04.839211      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 23:25:05.839464      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0909 23:25:06.839706      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  9 23:25:06.948: INFO: Created: latency-svc-9h2xg
Sep  9 23:25:06.950: INFO: Got endpoints: latency-svc-9h2xg [10.206037ms]
Sep  9 23:25:06.968: INFO: Created: latency-svc-wqhwg
Sep  9 23:25:06.972: INFO: Got endpoints: latency-svc-wqhwg [21.865192ms]
Sep  9 23:25:06.974: INFO: Created: latency-svc-4jvwv
Sep  9 23:25:06.980: INFO: Created: latency-svc-j9jsk
Sep  9 23:25:06.990: INFO: Created: latency-svc-hf59h
Sep  9 23:25:06.991: INFO: Got endpoints: latency-svc-4jvwv [39.929601ms]
Sep  9 23:25:06.992: INFO: Got endpoints: latency-svc-j9jsk [40.906395ms]
Sep  9 23:25:07.000: INFO: Got endpoints: latency-svc-hf59h [50.227266ms]
Sep  9 23:25:07.002: INFO: Created: latency-svc-7j8zc
Sep  9 23:25:07.009: INFO: Created: latency-svc-mh8f8
Sep  9 23:25:07.010: INFO: Got endpoints: latency-svc-7j8zc [59.357147ms]
Sep  9 23:25:07.016: INFO: Created: latency-svc-w6n6l
Sep  9 23:25:07.018: INFO: Got endpoints: latency-svc-mh8f8 [67.21713ms]
Sep  9 23:25:07.022: INFO: Got endpoints: latency-svc-w6n6l [71.024166ms]
Sep  9 23:25:07.025: INFO: Created: latency-svc-hswgl
Sep  9 23:25:07.027: INFO: Got endpoints: latency-svc-hswgl [76.598165ms]
Sep  9 23:25:07.044: INFO: Created: latency-svc-l55pg
Sep  9 23:25:07.048: INFO: Got endpoints: latency-svc-l55pg [97.2476ms]
Sep  9 23:25:07.054: INFO: Created: latency-svc-mhvhc
Sep  9 23:25:07.056: INFO: Got endpoints: latency-svc-mhvhc [105.464194ms]
Sep  9 23:25:07.060: INFO: Created: latency-svc-vtvhb
Sep  9 23:25:07.067: INFO: Got endpoints: latency-svc-vtvhb [115.897746ms]
Sep  9 23:25:07.068: INFO: Created: latency-svc-5t6sz
Sep  9 23:25:07.075: INFO: Got endpoints: latency-svc-5t6sz [124.155048ms]
Sep  9 23:25:07.080: INFO: Created: latency-svc-xf7hf
Sep  9 23:25:07.084: INFO: Got endpoints: latency-svc-xf7hf [132.989315ms]
Sep  9 23:25:07.085: INFO: Created: latency-svc-bgpnh
Sep  9 23:25:07.097: INFO: Got endpoints: latency-svc-bgpnh [145.744986ms]
Sep  9 23:25:07.105: INFO: Created: latency-svc-hk49g
Sep  9 23:25:07.111: INFO: Created: latency-svc-m2l5p
Sep  9 23:25:07.112: INFO: Got endpoints: latency-svc-hk49g [159.938715ms]
Sep  9 23:25:07.120: INFO: Created: latency-svc-fnbvt
Sep  9 23:25:07.121: INFO: Got endpoints: latency-svc-m2l5p [148.649792ms]
Sep  9 23:25:07.129: INFO: Got endpoints: latency-svc-fnbvt [137.9196ms]
Sep  9 23:25:07.130: INFO: Created: latency-svc-fp8vk
Sep  9 23:25:07.138: INFO: Got endpoints: latency-svc-fp8vk [146.249165ms]
Sep  9 23:25:07.141: INFO: Created: latency-svc-rwz5b
Sep  9 23:25:07.147: INFO: Got endpoints: latency-svc-rwz5b [146.281306ms]
Sep  9 23:25:07.149: INFO: Created: latency-svc-96fg2
Sep  9 23:25:07.152: INFO: Got endpoints: latency-svc-96fg2 [142.247541ms]
Sep  9 23:25:07.158: INFO: Created: latency-svc-g68v7
Sep  9 23:25:07.163: INFO: Got endpoints: latency-svc-g68v7 [145.475172ms]
Sep  9 23:25:07.178: INFO: Created: latency-svc-fr5tl
Sep  9 23:25:07.188: INFO: Created: latency-svc-b2jkp
Sep  9 23:25:07.188: INFO: Got endpoints: latency-svc-fr5tl [166.652299ms]
Sep  9 23:25:07.195: INFO: Created: latency-svc-f68fr
Sep  9 23:25:07.195: INFO: Got endpoints: latency-svc-b2jkp [167.263389ms]
Sep  9 23:25:07.205: INFO: Got endpoints: latency-svc-f68fr [157.056783ms]
Sep  9 23:25:07.209: INFO: Created: latency-svc-4zrdl
Sep  9 23:25:07.216: INFO: Created: latency-svc-bg2fb
Sep  9 23:25:07.219: INFO: Got endpoints: latency-svc-4zrdl [162.295817ms]
Sep  9 23:25:07.219: INFO: Got endpoints: latency-svc-bg2fb [152.042454ms]
Sep  9 23:25:07.231: INFO: Created: latency-svc-rhfxv
Sep  9 23:25:07.241: INFO: Got endpoints: latency-svc-rhfxv [165.135427ms]
Sep  9 23:25:07.241: INFO: Created: latency-svc-8nv59
Sep  9 23:25:07.243: INFO: Got endpoints: latency-svc-8nv59 [158.468684ms]
Sep  9 23:25:07.249: INFO: Created: latency-svc-pkrv6
Sep  9 23:25:07.255: INFO: Got endpoints: latency-svc-pkrv6 [157.792872ms]
Sep  9 23:25:07.258: INFO: Created: latency-svc-67h6c
Sep  9 23:25:07.260: INFO: Got endpoints: latency-svc-67h6c [17.205077ms]
Sep  9 23:25:07.265: INFO: Created: latency-svc-m6rcf
Sep  9 23:25:07.274: INFO: Got endpoints: latency-svc-m6rcf [162.029691ms]
Sep  9 23:25:07.277: INFO: Created: latency-svc-k69w5
Sep  9 23:25:07.280: INFO: Got endpoints: latency-svc-k69w5 [158.908771ms]
Sep  9 23:25:07.285: INFO: Created: latency-svc-79ljc
Sep  9 23:25:07.292: INFO: Got endpoints: latency-svc-79ljc [162.689879ms]
Sep  9 23:25:07.293: INFO: Created: latency-svc-n9mfz
Sep  9 23:25:07.300: INFO: Got endpoints: latency-svc-n9mfz [161.794871ms]
Sep  9 23:25:07.302: INFO: Created: latency-svc-97szk
Sep  9 23:25:07.308: INFO: Got endpoints: latency-svc-97szk [160.762669ms]
Sep  9 23:25:07.326: INFO: Created: latency-svc-s25dr
Sep  9 23:25:07.334: INFO: Got endpoints: latency-svc-s25dr [181.861937ms]
Sep  9 23:25:07.336: INFO: Created: latency-svc-6q2bb
Sep  9 23:25:07.343: INFO: Created: latency-svc-69g7m
Sep  9 23:25:07.352: INFO: Got endpoints: latency-svc-6q2bb [188.910122ms]
Sep  9 23:25:07.353: INFO: Created: latency-svc-qfzhp
Sep  9 23:25:07.361: INFO: Created: latency-svc-rm4wn
Sep  9 23:25:07.371: INFO: Created: latency-svc-cwht2
Sep  9 23:25:07.380: INFO: Created: latency-svc-lf7xd
Sep  9 23:25:07.386: INFO: Created: latency-svc-gqvwb
Sep  9 23:25:07.392: INFO: Created: latency-svc-w7cdm
Sep  9 23:25:07.398: INFO: Created: latency-svc-snl7l
Sep  9 23:25:07.401: INFO: Got endpoints: latency-svc-69g7m [212.175791ms]
Sep  9 23:25:07.408: INFO: Created: latency-svc-pdfhp
Sep  9 23:25:07.433: INFO: Created: latency-svc-qdnks
Sep  9 23:25:07.440: INFO: Created: latency-svc-9lvqx
Sep  9 23:25:07.448: INFO: Created: latency-svc-c4clf
Sep  9 23:25:07.449: INFO: Got endpoints: latency-svc-qfzhp [253.571694ms]
Sep  9 23:25:07.457: INFO: Created: latency-svc-92xn8
Sep  9 23:25:07.463: INFO: Created: latency-svc-5rq9k
Sep  9 23:25:07.470: INFO: Created: latency-svc-9k8n6
Sep  9 23:25:07.488: INFO: Created: latency-svc-gg9qc
Sep  9 23:25:07.499: INFO: Got endpoints: latency-svc-rm4wn [294.057958ms]
Sep  9 23:25:07.507: INFO: Created: latency-svc-phn4s
Sep  9 23:25:07.511: INFO: Created: latency-svc-gq6ff
Sep  9 23:25:07.550: INFO: Got endpoints: latency-svc-cwht2 [331.620488ms]
Sep  9 23:25:07.560: INFO: Created: latency-svc-4wjlj
Sep  9 23:25:07.601: INFO: Got endpoints: latency-svc-lf7xd [381.896506ms]
Sep  9 23:25:07.613: INFO: Created: latency-svc-vn95w
Sep  9 23:25:07.651: INFO: Got endpoints: latency-svc-gqvwb [410.166476ms]
Sep  9 23:25:07.663: INFO: Created: latency-svc-v2ctw
Sep  9 23:25:07.699: INFO: Got endpoints: latency-svc-w7cdm [443.787344ms]
Sep  9 23:25:07.709: INFO: Created: latency-svc-grl6h
Sep  9 23:25:07.748: INFO: Got endpoints: latency-svc-snl7l [487.663484ms]
Sep  9 23:25:07.757: INFO: Created: latency-svc-tls84
Sep  9 23:25:07.809: INFO: Got endpoints: latency-svc-pdfhp [535.600977ms]
Sep  9 23:25:07.820: INFO: Created: latency-svc-r5d9c
Sep  9 23:25:07.848: INFO: Got endpoints: latency-svc-qdnks [568.470149ms]
Sep  9 23:25:07.860: INFO: Created: latency-svc-7md5t
Sep  9 23:25:07.902: INFO: Got endpoints: latency-svc-9lvqx [609.590763ms]
Sep  9 23:25:07.912: INFO: Created: latency-svc-fmm6c
Sep  9 23:25:07.955: INFO: Got endpoints: latency-svc-c4clf [655.006526ms]
Sep  9 23:25:07.968: INFO: Created: latency-svc-85vd7
Sep  9 23:25:07.997: INFO: Got endpoints: latency-svc-92xn8 [689.668686ms]
Sep  9 23:25:08.008: INFO: Created: latency-svc-wsntn
Sep  9 23:25:08.048: INFO: Got endpoints: latency-svc-5rq9k [714.414097ms]
Sep  9 23:25:08.065: INFO: Created: latency-svc-qg5fm
Sep  9 23:25:08.099: INFO: Got endpoints: latency-svc-9k8n6 [745.870303ms]
Sep  9 23:25:08.107: INFO: Created: latency-svc-2wfss
Sep  9 23:25:08.147: INFO: Got endpoints: latency-svc-gg9qc [746.341401ms]
Sep  9 23:25:08.156: INFO: Created: latency-svc-t9lrq
Sep  9 23:25:08.199: INFO: Got endpoints: latency-svc-phn4s [750.550996ms]
Sep  9 23:25:08.219: INFO: Created: latency-svc-dx9qg
Sep  9 23:25:08.251: INFO: Got endpoints: latency-svc-gq6ff [751.339735ms]
Sep  9 23:25:08.259: INFO: Created: latency-svc-nqkrr
Sep  9 23:25:08.303: INFO: Got endpoints: latency-svc-4wjlj [752.47569ms]
Sep  9 23:25:08.313: INFO: Created: latency-svc-ttlvb
Sep  9 23:25:08.348: INFO: Got endpoints: latency-svc-vn95w [747.230445ms]
Sep  9 23:25:08.358: INFO: Created: latency-svc-nbnl7
Sep  9 23:25:08.399: INFO: Got endpoints: latency-svc-v2ctw [747.708626ms]
Sep  9 23:25:08.409: INFO: Created: latency-svc-d9gn4
Sep  9 23:25:08.449: INFO: Got endpoints: latency-svc-grl6h [749.161663ms]
Sep  9 23:25:08.457: INFO: Created: latency-svc-tggfl
Sep  9 23:25:08.501: INFO: Got endpoints: latency-svc-tls84 [752.28369ms]
Sep  9 23:25:08.508: INFO: Created: latency-svc-wmkb4
Sep  9 23:25:08.547: INFO: Got endpoints: latency-svc-r5d9c [737.948156ms]
Sep  9 23:25:08.557: INFO: Created: latency-svc-dzpp9
Sep  9 23:25:08.599: INFO: Got endpoints: latency-svc-7md5t [750.489771ms]
Sep  9 23:25:08.613: INFO: Created: latency-svc-mhzbr
Sep  9 23:25:08.650: INFO: Got endpoints: latency-svc-fmm6c [746.819224ms]
Sep  9 23:25:08.658: INFO: Created: latency-svc-gnpl7
Sep  9 23:25:08.699: INFO: Got endpoints: latency-svc-85vd7 [743.599147ms]
Sep  9 23:25:08.707: INFO: Created: latency-svc-j9lcp
Sep  9 23:25:08.748: INFO: Got endpoints: latency-svc-wsntn [750.558821ms]
Sep  9 23:25:08.759: INFO: Created: latency-svc-g9q7g
Sep  9 23:25:08.798: INFO: Got endpoints: latency-svc-qg5fm [749.040656ms]
Sep  9 23:25:08.819: INFO: Created: latency-svc-t84lm
Sep  9 23:25:08.855: INFO: Got endpoints: latency-svc-2wfss [756.391146ms]
Sep  9 23:25:08.878: INFO: Created: latency-svc-2gqtg
Sep  9 23:25:08.916: INFO: Got endpoints: latency-svc-t9lrq [768.017187ms]
Sep  9 23:25:08.940: INFO: Created: latency-svc-d7hxk
Sep  9 23:25:08.951: INFO: Got endpoints: latency-svc-dx9qg [751.479479ms]
Sep  9 23:25:08.961: INFO: Created: latency-svc-xhpbt
Sep  9 23:25:09.000: INFO: Got endpoints: latency-svc-nqkrr [749.45882ms]
Sep  9 23:25:09.020: INFO: Created: latency-svc-4fq9x
Sep  9 23:25:09.049: INFO: Got endpoints: latency-svc-ttlvb [745.694329ms]
Sep  9 23:25:09.065: INFO: Created: latency-svc-sfs2s
Sep  9 23:25:09.099: INFO: Got endpoints: latency-svc-nbnl7 [750.316183ms]
Sep  9 23:25:09.110: INFO: Created: latency-svc-m7v7l
Sep  9 23:25:09.149: INFO: Got endpoints: latency-svc-d9gn4 [749.847994ms]
Sep  9 23:25:09.157: INFO: Created: latency-svc-qnz9j
Sep  9 23:25:09.198: INFO: Got endpoints: latency-svc-tggfl [749.630216ms]
Sep  9 23:25:09.210: INFO: Created: latency-svc-k5trd
Sep  9 23:25:09.249: INFO: Got endpoints: latency-svc-wmkb4 [748.262111ms]
Sep  9 23:25:09.258: INFO: Created: latency-svc-4m5tv
Sep  9 23:25:09.298: INFO: Got endpoints: latency-svc-dzpp9 [750.709179ms]
Sep  9 23:25:09.307: INFO: Created: latency-svc-q4m22
Sep  9 23:25:09.350: INFO: Got endpoints: latency-svc-mhzbr [751.672313ms]
Sep  9 23:25:09.360: INFO: Created: latency-svc-8nzcz
Sep  9 23:25:09.398: INFO: Got endpoints: latency-svc-gnpl7 [748.055972ms]
Sep  9 23:25:09.408: INFO: Created: latency-svc-bklqh
Sep  9 23:25:09.449: INFO: Got endpoints: latency-svc-j9lcp [750.254852ms]
Sep  9 23:25:09.459: INFO: Created: latency-svc-gtzk4
Sep  9 23:25:09.498: INFO: Got endpoints: latency-svc-g9q7g [749.8264ms]
Sep  9 23:25:09.507: INFO: Created: latency-svc-7lxv7
Sep  9 23:25:09.553: INFO: Got endpoints: latency-svc-t84lm [755.204882ms]
Sep  9 23:25:09.568: INFO: Created: latency-svc-m4l75
Sep  9 23:25:09.599: INFO: Got endpoints: latency-svc-2gqtg [743.662178ms]
Sep  9 23:25:09.607: INFO: Created: latency-svc-rl6wp
Sep  9 23:25:09.649: INFO: Got endpoints: latency-svc-d7hxk [732.686678ms]
Sep  9 23:25:09.657: INFO: Created: latency-svc-wglt6
Sep  9 23:25:09.700: INFO: Got endpoints: latency-svc-xhpbt [748.877553ms]
Sep  9 23:25:09.710: INFO: Created: latency-svc-f89zg
Sep  9 23:25:09.748: INFO: Got endpoints: latency-svc-4fq9x [747.925934ms]
Sep  9 23:25:09.760: INFO: Created: latency-svc-h6jd8
Sep  9 23:25:09.805: INFO: Got endpoints: latency-svc-sfs2s [755.756084ms]
Sep  9 23:25:09.826: INFO: Created: latency-svc-j8j7x
Sep  9 23:25:09.852: INFO: Got endpoints: latency-svc-m7v7l [752.651335ms]
Sep  9 23:25:09.889: INFO: Created: latency-svc-4h4nb
Sep  9 23:25:09.898: INFO: Got endpoints: latency-svc-qnz9j [749.490768ms]
Sep  9 23:25:09.908: INFO: Created: latency-svc-vb2vc
Sep  9 23:25:09.955: INFO: Got endpoints: latency-svc-k5trd [756.334065ms]
Sep  9 23:25:09.970: INFO: Created: latency-svc-vx54l
Sep  9 23:25:09.998: INFO: Got endpoints: latency-svc-4m5tv [749.206863ms]
Sep  9 23:25:10.004: INFO: Created: latency-svc-7qj42
Sep  9 23:25:10.047: INFO: Got endpoints: latency-svc-q4m22 [749.084867ms]
Sep  9 23:25:10.055: INFO: Created: latency-svc-ldg4s
Sep  9 23:25:10.097: INFO: Got endpoints: latency-svc-8nzcz [746.933448ms]
Sep  9 23:25:10.104: INFO: Created: latency-svc-hs7wl
Sep  9 23:25:10.153: INFO: Got endpoints: latency-svc-bklqh [755.021461ms]
Sep  9 23:25:10.161: INFO: Created: latency-svc-zwgr8
Sep  9 23:25:10.198: INFO: Got endpoints: latency-svc-gtzk4 [748.438494ms]
Sep  9 23:25:10.206: INFO: Created: latency-svc-kpk7c
Sep  9 23:25:10.250: INFO: Got endpoints: latency-svc-7lxv7 [751.501184ms]
Sep  9 23:25:10.257: INFO: Created: latency-svc-2987f
Sep  9 23:25:10.298: INFO: Got endpoints: latency-svc-m4l75 [744.964494ms]
Sep  9 23:25:10.305: INFO: Created: latency-svc-v64m4
Sep  9 23:25:10.348: INFO: Got endpoints: latency-svc-rl6wp [748.765585ms]
Sep  9 23:25:10.356: INFO: Created: latency-svc-nqkpd
Sep  9 23:25:10.398: INFO: Got endpoints: latency-svc-wglt6 [749.756777ms]
Sep  9 23:25:10.407: INFO: Created: latency-svc-wh2j5
Sep  9 23:25:10.448: INFO: Got endpoints: latency-svc-f89zg [748.222009ms]
Sep  9 23:25:10.458: INFO: Created: latency-svc-xps2h
Sep  9 23:25:10.498: INFO: Got endpoints: latency-svc-h6jd8 [749.240482ms]
Sep  9 23:25:10.504: INFO: Created: latency-svc-sxgnw
Sep  9 23:25:10.548: INFO: Got endpoints: latency-svc-j8j7x [742.59141ms]
Sep  9 23:25:10.553: INFO: Created: latency-svc-gfjtd
Sep  9 23:25:10.598: INFO: Got endpoints: latency-svc-4h4nb [744.769048ms]
Sep  9 23:25:10.604: INFO: Created: latency-svc-r6jm4
Sep  9 23:25:10.648: INFO: Got endpoints: latency-svc-vb2vc [749.805538ms]
Sep  9 23:25:10.656: INFO: Created: latency-svc-6pp56
Sep  9 23:25:10.698: INFO: Got endpoints: latency-svc-vx54l [742.955157ms]
Sep  9 23:25:10.707: INFO: Created: latency-svc-cmqhh
Sep  9 23:25:10.750: INFO: Got endpoints: latency-svc-7qj42 [751.27423ms]
Sep  9 23:25:10.764: INFO: Created: latency-svc-nkxg9
Sep  9 23:25:10.798: INFO: Got endpoints: latency-svc-ldg4s [750.175365ms]
Sep  9 23:25:10.805: INFO: Created: latency-svc-46gq8
Sep  9 23:25:10.848: INFO: Got endpoints: latency-svc-hs7wl [750.139567ms]
Sep  9 23:25:10.855: INFO: Created: latency-svc-n2g7b
Sep  9 23:25:10.897: INFO: Got endpoints: latency-svc-zwgr8 [743.812536ms]
Sep  9 23:25:10.904: INFO: Created: latency-svc-k6w5z
Sep  9 23:25:10.949: INFO: Got endpoints: latency-svc-kpk7c [750.366257ms]
Sep  9 23:25:10.958: INFO: Created: latency-svc-qbrgq
Sep  9 23:25:10.998: INFO: Got endpoints: latency-svc-2987f [747.902291ms]
Sep  9 23:25:11.006: INFO: Created: latency-svc-5d2gn
Sep  9 23:25:11.053: INFO: Got endpoints: latency-svc-v64m4 [755.077629ms]
Sep  9 23:25:11.070: INFO: Created: latency-svc-zg2bh
Sep  9 23:25:11.099: INFO: Got endpoints: latency-svc-nqkpd [750.580497ms]
Sep  9 23:25:11.108: INFO: Created: latency-svc-5tqc5
Sep  9 23:25:11.149: INFO: Got endpoints: latency-svc-wh2j5 [748.872067ms]
Sep  9 23:25:11.163: INFO: Created: latency-svc-cv6qc
Sep  9 23:25:11.199: INFO: Got endpoints: latency-svc-xps2h [750.553966ms]
Sep  9 23:25:11.206: INFO: Created: latency-svc-vkwg5
Sep  9 23:25:11.249: INFO: Got endpoints: latency-svc-sxgnw [751.056911ms]
Sep  9 23:25:11.259: INFO: Created: latency-svc-fzpfs
Sep  9 23:25:11.299: INFO: Got endpoints: latency-svc-gfjtd [751.133822ms]
Sep  9 23:25:11.308: INFO: Created: latency-svc-pgz2c
Sep  9 23:25:11.352: INFO: Got endpoints: latency-svc-r6jm4 [754.887497ms]
Sep  9 23:25:11.359: INFO: Created: latency-svc-d9l7g
Sep  9 23:25:11.398: INFO: Got endpoints: latency-svc-6pp56 [749.728876ms]
Sep  9 23:25:11.414: INFO: Created: latency-svc-pgchp
Sep  9 23:25:11.450: INFO: Got endpoints: latency-svc-cmqhh [752.561387ms]
Sep  9 23:25:11.464: INFO: Created: latency-svc-767p9
Sep  9 23:25:11.502: INFO: Got endpoints: latency-svc-nkxg9 [750.66819ms]
Sep  9 23:25:11.515: INFO: Created: latency-svc-mdgjc
Sep  9 23:25:11.549: INFO: Got endpoints: latency-svc-46gq8 [750.934104ms]
Sep  9 23:25:11.568: INFO: Created: latency-svc-t9tdr
Sep  9 23:25:11.599: INFO: Got endpoints: latency-svc-n2g7b [751.588692ms]
Sep  9 23:25:11.611: INFO: Created: latency-svc-rj4d7
Sep  9 23:25:11.650: INFO: Got endpoints: latency-svc-k6w5z [751.953695ms]
Sep  9 23:25:11.662: INFO: Created: latency-svc-cwc89
Sep  9 23:25:11.699: INFO: Got endpoints: latency-svc-qbrgq [750.185809ms]
Sep  9 23:25:11.719: INFO: Created: latency-svc-8czkf
Sep  9 23:25:11.749: INFO: Got endpoints: latency-svc-5d2gn [750.939973ms]
Sep  9 23:25:11.758: INFO: Created: latency-svc-74dwm
Sep  9 23:25:11.800: INFO: Got endpoints: latency-svc-zg2bh [747.124725ms]
Sep  9 23:25:11.810: INFO: Created: latency-svc-2vbl7
Sep  9 23:25:11.849: INFO: Got endpoints: latency-svc-5tqc5 [750.432048ms]
Sep  9 23:25:11.862: INFO: Created: latency-svc-dpvqf
Sep  9 23:25:11.900: INFO: Got endpoints: latency-svc-cv6qc [750.077522ms]
Sep  9 23:25:11.911: INFO: Created: latency-svc-g46xt
Sep  9 23:25:11.949: INFO: Got endpoints: latency-svc-vkwg5 [749.55905ms]
Sep  9 23:25:11.956: INFO: Created: latency-svc-9w6k4
Sep  9 23:25:12.000: INFO: Got endpoints: latency-svc-fzpfs [750.712238ms]
Sep  9 23:25:12.010: INFO: Created: latency-svc-lhkkd
Sep  9 23:25:12.049: INFO: Got endpoints: latency-svc-pgz2c [750.508283ms]
Sep  9 23:25:12.064: INFO: Created: latency-svc-q4qfs
Sep  9 23:25:12.101: INFO: Got endpoints: latency-svc-d9l7g [748.05791ms]
Sep  9 23:25:12.109: INFO: Created: latency-svc-jr954
Sep  9 23:25:12.150: INFO: Got endpoints: latency-svc-pgchp [752.394351ms]
Sep  9 23:25:12.162: INFO: Created: latency-svc-k4xkw
Sep  9 23:25:12.199: INFO: Got endpoints: latency-svc-767p9 [748.876171ms]
Sep  9 23:25:12.207: INFO: Created: latency-svc-nw7gf
Sep  9 23:25:12.248: INFO: Got endpoints: latency-svc-mdgjc [746.455693ms]
Sep  9 23:25:12.259: INFO: Created: latency-svc-xdmjj
Sep  9 23:25:12.301: INFO: Got endpoints: latency-svc-t9tdr [751.943486ms]
Sep  9 23:25:12.317: INFO: Created: latency-svc-srtdb
Sep  9 23:25:12.350: INFO: Got endpoints: latency-svc-rj4d7 [750.345336ms]
Sep  9 23:25:12.365: INFO: Created: latency-svc-pf2fs
Sep  9 23:25:12.403: INFO: Got endpoints: latency-svc-cwc89 [752.69737ms]
Sep  9 23:25:12.417: INFO: Created: latency-svc-pq4zx
Sep  9 23:25:12.453: INFO: Got endpoints: latency-svc-8czkf [754.027782ms]
Sep  9 23:25:12.466: INFO: Created: latency-svc-wbcpt
Sep  9 23:25:12.501: INFO: Got endpoints: latency-svc-74dwm [751.942107ms]
Sep  9 23:25:12.518: INFO: Created: latency-svc-mtd7z
Sep  9 23:25:12.550: INFO: Got endpoints: latency-svc-2vbl7 [749.952918ms]
Sep  9 23:25:12.563: INFO: Created: latency-svc-m7629
Sep  9 23:25:12.599: INFO: Got endpoints: latency-svc-dpvqf [750.049864ms]
Sep  9 23:25:12.608: INFO: Created: latency-svc-gwc7n
Sep  9 23:25:12.650: INFO: Got endpoints: latency-svc-g46xt [749.513468ms]
Sep  9 23:25:12.658: INFO: Created: latency-svc-w5cm9
Sep  9 23:25:12.698: INFO: Got endpoints: latency-svc-9w6k4 [749.345911ms]
Sep  9 23:25:12.709: INFO: Created: latency-svc-rxdp2
Sep  9 23:25:12.750: INFO: Got endpoints: latency-svc-lhkkd [749.897915ms]
Sep  9 23:25:12.776: INFO: Created: latency-svc-g49rg
Sep  9 23:25:12.801: INFO: Got endpoints: latency-svc-q4qfs [751.497706ms]
Sep  9 23:25:12.811: INFO: Created: latency-svc-69nwp
Sep  9 23:25:12.849: INFO: Got endpoints: latency-svc-jr954 [748.740985ms]
Sep  9 23:25:12.859: INFO: Created: latency-svc-nkf79
Sep  9 23:25:12.901: INFO: Got endpoints: latency-svc-k4xkw [750.781635ms]
Sep  9 23:25:12.956: INFO: Created: latency-svc-2qzbl
Sep  9 23:25:12.959: INFO: Got endpoints: latency-svc-nw7gf [759.908519ms]
Sep  9 23:25:12.982: INFO: Created: latency-svc-tncrh
Sep  9 23:25:13.012: INFO: Got endpoints: latency-svc-xdmjj [763.876334ms]
Sep  9 23:25:13.024: INFO: Created: latency-svc-bkfbd
Sep  9 23:25:13.049: INFO: Got endpoints: latency-svc-srtdb [747.979192ms]
Sep  9 23:25:13.069: INFO: Created: latency-svc-bpgqh
Sep  9 23:25:13.098: INFO: Got endpoints: latency-svc-pf2fs [748.264478ms]
Sep  9 23:25:13.107: INFO: Created: latency-svc-p79t7
Sep  9 23:25:13.149: INFO: Got endpoints: latency-svc-pq4zx [745.929837ms]
Sep  9 23:25:13.158: INFO: Created: latency-svc-f6j2s
Sep  9 23:25:13.199: INFO: Got endpoints: latency-svc-wbcpt [745.83779ms]
Sep  9 23:25:13.207: INFO: Created: latency-svc-nwwq7
Sep  9 23:25:13.249: INFO: Got endpoints: latency-svc-mtd7z [747.890326ms]
Sep  9 23:25:13.265: INFO: Created: latency-svc-4n5sr
Sep  9 23:25:13.301: INFO: Got endpoints: latency-svc-m7629 [750.314089ms]
Sep  9 23:25:13.308: INFO: Created: latency-svc-z557h
Sep  9 23:25:13.348: INFO: Got endpoints: latency-svc-gwc7n [749.087124ms]
Sep  9 23:25:13.357: INFO: Created: latency-svc-kl42t
Sep  9 23:25:13.401: INFO: Got endpoints: latency-svc-w5cm9 [751.545412ms]
Sep  9 23:25:13.411: INFO: Created: latency-svc-cdjkn
Sep  9 23:25:13.453: INFO: Got endpoints: latency-svc-rxdp2 [755.166491ms]
Sep  9 23:25:13.472: INFO: Created: latency-svc-5vnj5
Sep  9 23:25:13.499: INFO: Got endpoints: latency-svc-g49rg [748.36807ms]
Sep  9 23:25:13.511: INFO: Created: latency-svc-n5pvg
Sep  9 23:25:13.551: INFO: Got endpoints: latency-svc-69nwp [749.214903ms]
Sep  9 23:25:13.561: INFO: Created: latency-svc-mkbtj
Sep  9 23:25:13.603: INFO: Got endpoints: latency-svc-nkf79 [753.034332ms]
Sep  9 23:25:13.619: INFO: Created: latency-svc-s584d
Sep  9 23:25:13.653: INFO: Got endpoints: latency-svc-2qzbl [751.358626ms]
Sep  9 23:25:13.662: INFO: Created: latency-svc-jj8b7
Sep  9 23:25:13.699: INFO: Got endpoints: latency-svc-tncrh [740.056453ms]
Sep  9 23:25:13.708: INFO: Created: latency-svc-45tp5
Sep  9 23:25:13.751: INFO: Got endpoints: latency-svc-bkfbd [738.932375ms]
Sep  9 23:25:13.769: INFO: Created: latency-svc-w2gws
Sep  9 23:25:13.800: INFO: Got endpoints: latency-svc-bpgqh [750.883402ms]
Sep  9 23:25:13.832: INFO: Created: latency-svc-q9zzf
Sep  9 23:25:13.849: INFO: Got endpoints: latency-svc-p79t7 [750.919502ms]
Sep  9 23:25:13.868: INFO: Created: latency-svc-xv25j
Sep  9 23:25:13.899: INFO: Got endpoints: latency-svc-f6j2s [749.478327ms]
Sep  9 23:25:13.909: INFO: Created: latency-svc-7xlb8
Sep  9 23:25:13.950: INFO: Got endpoints: latency-svc-nwwq7 [750.496124ms]
Sep  9 23:25:13.967: INFO: Created: latency-svc-998ch
Sep  9 23:25:13.999: INFO: Got endpoints: latency-svc-4n5sr [744.781699ms]
Sep  9 23:25:14.011: INFO: Created: latency-svc-mtnmt
Sep  9 23:25:14.048: INFO: Got endpoints: latency-svc-z557h [747.238467ms]
Sep  9 23:25:14.057: INFO: Created: latency-svc-rxghj
Sep  9 23:25:14.099: INFO: Got endpoints: latency-svc-kl42t [750.87148ms]
Sep  9 23:25:14.117: INFO: Created: latency-svc-5sjdw
Sep  9 23:25:14.149: INFO: Got endpoints: latency-svc-cdjkn [747.713857ms]
Sep  9 23:25:14.157: INFO: Created: latency-svc-dbtcl
Sep  9 23:25:14.200: INFO: Got endpoints: latency-svc-5vnj5 [746.606099ms]
Sep  9 23:25:14.211: INFO: Created: latency-svc-b2jl4
Sep  9 23:25:14.250: INFO: Got endpoints: latency-svc-n5pvg [750.78066ms]
Sep  9 23:25:14.259: INFO: Created: latency-svc-dpkt9
Sep  9 23:25:14.301: INFO: Got endpoints: latency-svc-mkbtj [750.542911ms]
Sep  9 23:25:14.325: INFO: Created: latency-svc-hwnd6
Sep  9 23:25:14.361: INFO: Got endpoints: latency-svc-s584d [756.808319ms]
Sep  9 23:25:14.379: INFO: Created: latency-svc-thz5d
Sep  9 23:25:14.400: INFO: Got endpoints: latency-svc-jj8b7 [746.814126ms]
Sep  9 23:25:14.412: INFO: Created: latency-svc-mxbrv
Sep  9 23:25:14.448: INFO: Got endpoints: latency-svc-45tp5 [748.718654ms]
Sep  9 23:25:14.460: INFO: Created: latency-svc-vxf6z
Sep  9 23:25:14.501: INFO: Got endpoints: latency-svc-w2gws [749.745506ms]
Sep  9 23:25:14.521: INFO: Created: latency-svc-mhh8x
Sep  9 23:25:14.549: INFO: Got endpoints: latency-svc-q9zzf [749.030391ms]
Sep  9 23:25:14.558: INFO: Created: latency-svc-nxz7d
Sep  9 23:25:14.599: INFO: Got endpoints: latency-svc-xv25j [739.381886ms]
Sep  9 23:25:14.609: INFO: Created: latency-svc-8cpkf
Sep  9 23:25:14.649: INFO: Got endpoints: latency-svc-7xlb8 [749.992834ms]
Sep  9 23:25:14.658: INFO: Created: latency-svc-vjgf5
Sep  9 23:25:14.699: INFO: Got endpoints: latency-svc-998ch [749.235079ms]
Sep  9 23:25:14.708: INFO: Created: latency-svc-42c6r
Sep  9 23:25:14.748: INFO: Got endpoints: latency-svc-mtnmt [746.974517ms]
Sep  9 23:25:14.758: INFO: Created: latency-svc-mdjbn
Sep  9 23:25:14.799: INFO: Got endpoints: latency-svc-rxghj [751.106249ms]
Sep  9 23:25:14.848: INFO: Got endpoints: latency-svc-5sjdw [748.912668ms]
Sep  9 23:25:14.902: INFO: Got endpoints: latency-svc-dbtcl [752.577739ms]
Sep  9 23:25:14.953: INFO: Got endpoints: latency-svc-b2jl4 [753.233381ms]
Sep  9 23:25:15.002: INFO: Got endpoints: latency-svc-dpkt9 [751.939617ms]
Sep  9 23:25:15.050: INFO: Got endpoints: latency-svc-hwnd6 [749.153205ms]
Sep  9 23:25:15.101: INFO: Got endpoints: latency-svc-thz5d [740.031529ms]
Sep  9 23:25:15.149: INFO: Got endpoints: latency-svc-mxbrv [749.225621ms]
Sep  9 23:25:15.201: INFO: Got endpoints: latency-svc-vxf6z [753.154486ms]
Sep  9 23:25:15.248: INFO: Got endpoints: latency-svc-mhh8x [746.797802ms]
Sep  9 23:25:15.298: INFO: Got endpoints: latency-svc-nxz7d [749.132494ms]
Sep  9 23:25:15.357: INFO: Got endpoints: latency-svc-8cpkf [758.11128ms]
Sep  9 23:25:15.398: INFO: Got endpoints: latency-svc-vjgf5 [747.95438ms]
Sep  9 23:25:15.448: INFO: Got endpoints: latency-svc-42c6r [749.15681ms]
Sep  9 23:25:15.498: INFO: Got endpoints: latency-svc-mdjbn [749.192198ms]
Sep  9 23:25:15.498: INFO: Latencies: [17.205077ms 21.865192ms 39.929601ms 40.906395ms 50.227266ms 59.357147ms 67.21713ms 71.024166ms 76.598165ms 97.2476ms 105.464194ms 115.897746ms 124.155048ms 132.989315ms 137.9196ms 142.247541ms 145.475172ms 145.744986ms 146.249165ms 146.281306ms 148.649792ms 152.042454ms 157.056783ms 157.792872ms 158.468684ms 158.908771ms 159.938715ms 160.762669ms 161.794871ms 162.029691ms 162.295817ms 162.689879ms 165.135427ms 166.652299ms 167.263389ms 181.861937ms 188.910122ms 212.175791ms 253.571694ms 294.057958ms 331.620488ms 381.896506ms 410.166476ms 443.787344ms 487.663484ms 535.600977ms 568.470149ms 609.590763ms 655.006526ms 689.668686ms 714.414097ms 732.686678ms 737.948156ms 738.932375ms 739.381886ms 740.031529ms 740.056453ms 742.59141ms 742.955157ms 743.599147ms 743.662178ms 743.812536ms 744.769048ms 744.781699ms 744.964494ms 745.694329ms 745.83779ms 745.870303ms 745.929837ms 746.341401ms 746.455693ms 746.606099ms 746.797802ms 746.814126ms 746.819224ms 746.933448ms 746.974517ms 747.124725ms 747.230445ms 747.238467ms 747.708626ms 747.713857ms 747.890326ms 747.902291ms 747.925934ms 747.95438ms 747.979192ms 748.055972ms 748.05791ms 748.222009ms 748.262111ms 748.264478ms 748.36807ms 748.438494ms 748.718654ms 748.740985ms 748.765585ms 748.872067ms 748.876171ms 748.877553ms 748.912668ms 749.030391ms 749.040656ms 749.084867ms 749.087124ms 749.132494ms 749.153205ms 749.15681ms 749.161663ms 749.192198ms 749.206863ms 749.214903ms 749.225621ms 749.235079ms 749.240482ms 749.345911ms 749.45882ms 749.478327ms 749.490768ms 749.513468ms 749.55905ms 749.630216ms 749.728876ms 749.745506ms 749.756777ms 749.805538ms 749.8264ms 749.847994ms 749.897915ms 749.952918ms 749.992834ms 750.049864ms 750.077522ms 750.139567ms 750.175365ms 750.185809ms 750.254852ms 750.314089ms 750.316183ms 750.345336ms 750.366257ms 750.432048ms 750.489771ms 750.496124ms 750.508283ms 750.542911ms 750.550996ms 750.553966ms 750.558821ms 750.580497ms 750.66819ms 750.709179ms 750.712238ms 750.78066ms 750.781635ms 750.87148ms 750.883402ms 750.919502ms 750.934104ms 750.939973ms 751.056911ms 751.106249ms 751.133822ms 751.27423ms 751.339735ms 751.358626ms 751.479479ms 751.497706ms 751.501184ms 751.545412ms 751.588692ms 751.672313ms 751.939617ms 751.942107ms 751.943486ms 751.953695ms 752.28369ms 752.394351ms 752.47569ms 752.561387ms 752.577739ms 752.651335ms 752.69737ms 753.034332ms 753.154486ms 753.233381ms 754.027782ms 754.887497ms 755.021461ms 755.077629ms 755.166491ms 755.204882ms 755.756084ms 756.334065ms 756.391146ms 756.808319ms 758.11128ms 759.908519ms 763.876334ms 768.017187ms]
Sep  9 23:25:15.499: INFO: 50 %ile: 748.912668ms
Sep  9 23:25:15.499: INFO: 90 %ile: 752.577739ms
Sep  9 23:25:15.499: INFO: 99 %ile: 763.876334ms
Sep  9 23:25:15.499: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:25:15.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3594" for this suite.
Sep  9 23:25:31.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:25:31.575: INFO: namespace svc-latency-3594 deletion completed in 16.072812896s

• [SLOW TEST:27.807 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:25:31.575: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  9 23:25:37.625: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 23:25:37.628: INFO: Pod pod-with-poststart-http-hook still exists
Sep  9 23:25:39.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 23:25:39.630: INFO: Pod pod-with-poststart-http-hook still exists
Sep  9 23:25:41.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  9 23:25:41.630: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:25:41.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4450" for this suite.
Sep  9 23:26:03.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:26:03.697: INFO: namespace container-lifecycle-hook-4450 deletion completed in 22.065420648s

• [SLOW TEST:32.122 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:26:03.697: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  9 23:26:03.720: INFO: Waiting up to 5m0s for pod "pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600" in namespace "emptydir-2751" to be "success or failure"
Sep  9 23:26:03.724: INFO: Pod "pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600": Phase="Pending", Reason="", readiness=false. Elapsed: 3.867371ms
Sep  9 23:26:05.727: INFO: Pod "pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006277477s
Sep  9 23:26:07.729: INFO: Pod "pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008953709s
STEP: Saw pod success
Sep  9 23:26:07.730: INFO: Pod "pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600" satisfied condition "success or failure"
Sep  9 23:26:07.731: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600 container test-container: <nil>
STEP: delete the pod
Sep  9 23:26:07.743: INFO: Waiting for pod pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600 to disappear
Sep  9 23:26:07.744: INFO: Pod pod-dae3d5f9-6e9b-48d8-8178-3f7a10475600 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:26:07.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2751" for this suite.
Sep  9 23:26:13.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:26:13.814: INFO: namespace emptydir-2751 deletion completed in 6.067772752s

• [SLOW TEST:10.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:26:13.814: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  9 23:26:13.840: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2309,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 23:26:13.840: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2309,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  9 23:26:23.845: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2325,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  9 23:26:23.845: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2325,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  9 23:26:33.849: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2341,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 23:26:33.849: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2341,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  9 23:26:43.853: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2356,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 23:26:43.853: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-a,UID:b5bc669a-8446-41c2-88ea-2f79be8ccb0b,ResourceVersion:2356,Generation:0,CreationTimestamp:2019-09-09 23:26:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  9 23:26:53.857: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-b,UID:6a2a5fec-61ea-43a7-9988-101a54e870e3,ResourceVersion:2372,Generation:0,CreationTimestamp:2019-09-09 23:26:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 23:26:53.858: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-b,UID:6a2a5fec-61ea-43a7-9988-101a54e870e3,ResourceVersion:2372,Generation:0,CreationTimestamp:2019-09-09 23:26:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  9 23:27:03.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-b,UID:6a2a5fec-61ea-43a7-9988-101a54e870e3,ResourceVersion:2387,Generation:0,CreationTimestamp:2019-09-09 23:26:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 23:27:03.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5809,SelfLink:/api/v1/namespaces/watch-5809/configmaps/e2e-watch-test-configmap-b,UID:6a2a5fec-61ea-43a7-9988-101a54e870e3,ResourceVersion:2387,Generation:0,CreationTimestamp:2019-09-09 23:26:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:27:13.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5809" for this suite.
Sep  9 23:27:19.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:27:19.945: INFO: namespace watch-5809 deletion completed in 6.079739018s

• [SLOW TEST:66.130 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:27:19.945: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-7fcl
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 23:27:19.973: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-7fcl" in namespace "subpath-4535" to be "success or failure"
Sep  9 23:27:19.976: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.018511ms
Sep  9 23:27:21.978: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005048036s
Sep  9 23:27:23.980: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 4.00755268s
Sep  9 23:27:25.983: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 6.010020418s
Sep  9 23:27:27.985: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 8.012477995s
Sep  9 23:27:29.988: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 10.014720752s
Sep  9 23:27:31.990: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.016740922s
Sep  9 23:27:33.992: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 14.019306713s
Sep  9 23:27:35.995: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 16.021815828s
Sep  9 23:27:37.997: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 18.024131896s
Sep  9 23:27:40.000: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 20.026773516s
Sep  9 23:27:42.002: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Running", Reason="", readiness=true. Elapsed: 22.028945793s
Sep  9 23:27:44.004: INFO: Pod "pod-subpath-test-secret-7fcl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.031500622s
STEP: Saw pod success
Sep  9 23:27:44.004: INFO: Pod "pod-subpath-test-secret-7fcl" satisfied condition "success or failure"
Sep  9 23:27:44.006: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-subpath-test-secret-7fcl container test-container-subpath-secret-7fcl: <nil>
STEP: delete the pod
Sep  9 23:27:44.018: INFO: Waiting for pod pod-subpath-test-secret-7fcl to disappear
Sep  9 23:27:44.019: INFO: Pod pod-subpath-test-secret-7fcl no longer exists
STEP: Deleting pod pod-subpath-test-secret-7fcl
Sep  9 23:27:44.019: INFO: Deleting pod "pod-subpath-test-secret-7fcl" in namespace "subpath-4535"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:27:44.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4535" for this suite.
Sep  9 23:27:50.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:27:50.099: INFO: namespace subpath-4535 deletion completed in 6.075623535s

• [SLOW TEST:30.153 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:27:50.099: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-83e238d1-3763-4f20-a4f3-8dd350d2904e
STEP: Creating a pod to test consume secrets
Sep  9 23:27:50.124: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605" in namespace "projected-8892" to be "success or failure"
Sep  9 23:27:50.126: INFO: Pod "pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605": Phase="Pending", Reason="", readiness=false. Elapsed: 1.712042ms
Sep  9 23:27:52.129: INFO: Pod "pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00459513s
STEP: Saw pod success
Sep  9 23:27:52.129: INFO: Pod "pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605" satisfied condition "success or failure"
Sep  9 23:27:52.131: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:27:52.145: INFO: Waiting for pod pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605 to disappear
Sep  9 23:27:52.146: INFO: Pod pod-projected-secrets-fc1ac6cf-a098-4ca8-9e89-6bd9b5958605 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:27:52.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8892" for this suite.
Sep  9 23:27:58.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:27:58.229: INFO: namespace projected-8892 deletion completed in 6.080110739s

• [SLOW TEST:8.130 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:27:58.229: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-0add5af4-5f22-4a30-ae72-9b652a619599
STEP: Creating a pod to test consume configMaps
Sep  9 23:27:58.254: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445" in namespace "projected-9446" to be "success or failure"
Sep  9 23:27:58.257: INFO: Pod "pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878596ms
Sep  9 23:28:00.259: INFO: Pod "pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005281629s
STEP: Saw pod success
Sep  9 23:28:00.260: INFO: Pod "pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445" satisfied condition "success or failure"
Sep  9 23:28:00.261: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 23:28:00.273: INFO: Waiting for pod pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445 to disappear
Sep  9 23:28:00.275: INFO: Pod pod-projected-configmaps-ac8d9544-13ba-46ce-b0ee-c6f428584445 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:00.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9446" for this suite.
Sep  9 23:28:06.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:06.343: INFO: namespace projected-9446 deletion completed in 6.066308265s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:06.343: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep  9 23:28:06.367: INFO: Waiting up to 5m0s for pod "var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d" in namespace "var-expansion-2279" to be "success or failure"
Sep  9 23:28:06.371: INFO: Pod "var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.993029ms
Sep  9 23:28:08.374: INFO: Pod "var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007076605s
Sep  9 23:28:10.376: INFO: Pod "var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009400264s
STEP: Saw pod success
Sep  9 23:28:10.376: INFO: Pod "var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d" satisfied condition "success or failure"
Sep  9 23:28:10.378: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d container dapi-container: <nil>
STEP: delete the pod
Sep  9 23:28:10.390: INFO: Waiting for pod var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d to disappear
Sep  9 23:28:10.392: INFO: Pod var-expansion-1087564a-924c-4ff3-93e4-6e94c633700d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:10.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2279" for this suite.
Sep  9 23:28:16.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:16.473: INFO: namespace var-expansion-2279 deletion completed in 6.078896819s

• [SLOW TEST:10.130 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:16.474: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  9 23:28:16.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07" in namespace "projected-6231" to be "success or failure"
Sep  9 23:28:16.500: INFO: Pod "downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.715625ms
Sep  9 23:28:18.503: INFO: Pod "downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07": Phase="Running", Reason="", readiness=true. Elapsed: 2.005660217s
Sep  9 23:28:20.505: INFO: Pod "downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008336598s
STEP: Saw pod success
Sep  9 23:28:20.505: INFO: Pod "downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07" satisfied condition "success or failure"
Sep  9 23:28:20.507: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07 container client-container: <nil>
STEP: delete the pod
Sep  9 23:28:20.520: INFO: Waiting for pod downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07 to disappear
Sep  9 23:28:20.522: INFO: Pod downwardapi-volume-3c56f763-94e1-4f31-b9b8-f08f4cbf7f07 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:20.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6231" for this suite.
Sep  9 23:28:26.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:26.585: INFO: namespace projected-6231 deletion completed in 6.061303842s

• [SLOW TEST:10.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:26.585: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  9 23:28:26.603: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5885" for this suite.
Sep  9 23:28:35.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:35.701: INFO: namespace init-container-5885 deletion completed in 6.058587494s

• [SLOW TEST:9.116 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:35.702: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-06c7b458-32d5-4b6b-a68d-0a28e0a02102
STEP: Creating a pod to test consume configMaps
Sep  9 23:28:35.723: INFO: Waiting up to 5m0s for pod "pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe" in namespace "configmap-4745" to be "success or failure"
Sep  9 23:28:35.725: INFO: Pod "pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.99873ms
Sep  9 23:28:37.728: INFO: Pod "pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004305705s
STEP: Saw pod success
Sep  9 23:28:37.728: INFO: Pod "pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe" satisfied condition "success or failure"
Sep  9 23:28:37.729: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 23:28:37.740: INFO: Waiting for pod pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe to disappear
Sep  9 23:28:37.742: INFO: Pod pod-configmaps-095aa33b-420a-4841-8a9c-2fb25f0d6cfe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4745" for this suite.
Sep  9 23:28:43.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:43.807: INFO: namespace configmap-4745 deletion completed in 6.063458825s

• [SLOW TEST:8.106 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:43.808: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:28:43.826: INFO: Creating deployment "test-recreate-deployment"
Sep  9 23:28:43.829: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  9 23:28:43.837: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep  9 23:28:45.841: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  9 23:28:45.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703668523, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703668523, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703668523, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703668523, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:28:47.844: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  9 23:28:47.848: INFO: Updating deployment test-recreate-deployment
Sep  9 23:28:47.848: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  9 23:28:47.901: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6639,SelfLink:/apis/apps/v1/namespaces/deployment-6639/deployments/test-recreate-deployment,UID:ab73df49-3476-424d-9c21-4b7c58814ba7,ResourceVersion:2688,Generation:2,CreationTimestamp:2019-09-09 23:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-09 23:28:47 +0000 UTC 2019-09-09 23:28:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-09 23:28:47 +0000 UTC 2019-09-09 23:28:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  9 23:28:47.905: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-6639,SelfLink:/apis/apps/v1/namespaces/deployment-6639/replicasets/test-recreate-deployment-5c8c9cc69d,UID:773d54bd-1323-433e-9227-b48c313598cb,ResourceVersion:2686,Generation:1,CreationTimestamp:2019-09-09 23:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ab73df49-3476-424d-9c21-4b7c58814ba7 0xc002b94b87 0xc002b94b88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 23:28:47.905: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  9 23:28:47.905: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-6639,SelfLink:/apis/apps/v1/namespaces/deployment-6639/replicasets/test-recreate-deployment-6df85df6b9,UID:f330afcb-ee00-46e0-8f0e-5d9633f8579b,ResourceVersion:2679,Generation:2,CreationTimestamp:2019-09-09 23:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ab73df49-3476-424d-9c21-4b7c58814ba7 0xc002b94c47 0xc002b94c48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 23:28:47.906: INFO: Pod "test-recreate-deployment-5c8c9cc69d-5t5vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-5t5vg,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-6639,SelfLink:/api/v1/namespaces/deployment-6639/pods/test-recreate-deployment-5c8c9cc69d-5t5vg,UID:712be25a-970a-4b82-bdcb-63a38ea6250f,ResourceVersion:2687,Generation:0,CreationTimestamp:2019-09-09 23:28:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 773d54bd-1323-433e-9227-b48c313598cb 0xc002b95527 0xc002b95528}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-454kz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-454kz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-454kz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b95590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b955b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:28:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:28:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:28:47 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:,StartTime:2019-09-09 23:28:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:47.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6639" for this suite.
Sep  9 23:28:53.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:28:53.971: INFO: namespace deployment-6639 deletion completed in 6.062115222s

• [SLOW TEST:10.163 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:28:53.971: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep  9 23:28:53.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-2968'
Sep  9 23:28:54.325: INFO: stderr: ""
Sep  9 23:28:54.325: INFO: stdout: "pod/pause created\n"
Sep  9 23:28:54.325: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  9 23:28:54.325: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2968" to be "running and ready"
Sep  9 23:28:54.328: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.5704ms
Sep  9 23:28:56.331: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006509846s
Sep  9 23:28:56.331: INFO: Pod "pause" satisfied condition "running and ready"
Sep  9 23:28:56.331: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  9 23:28:56.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 label pods pause testing-label=testing-label-value --namespace=kubectl-2968'
Sep  9 23:28:56.400: INFO: stderr: ""
Sep  9 23:28:56.400: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  9 23:28:56.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pod pause -L testing-label --namespace=kubectl-2968'
Sep  9 23:28:56.465: INFO: stderr: ""
Sep  9 23:28:56.465: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  9 23:28:56.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 label pods pause testing-label- --namespace=kubectl-2968'
Sep  9 23:28:56.535: INFO: stderr: ""
Sep  9 23:28:56.535: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  9 23:28:56.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pod pause -L testing-label --namespace=kubectl-2968'
Sep  9 23:28:56.598: INFO: stderr: ""
Sep  9 23:28:56.598: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep  9 23:28:56.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-2968'
Sep  9 23:28:56.674: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 23:28:56.674: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  9 23:28:56.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get rc,svc -l name=pause --no-headers --namespace=kubectl-2968'
Sep  9 23:28:56.742: INFO: stderr: "No resources found.\n"
Sep  9 23:28:56.742: INFO: stdout: ""
Sep  9 23:28:56.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -l name=pause --namespace=kubectl-2968 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 23:28:56.810: INFO: stderr: ""
Sep  9 23:28:56.810: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:28:56.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2968" for this suite.
Sep  9 23:29:02.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:29:02.874: INFO: namespace kubectl-2968 deletion completed in 6.061262133s

• [SLOW TEST:8.903 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:29:02.875: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:29:07.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8017" for this suite.
Sep  9 23:29:29.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:29:29.980: INFO: namespace replication-controller-8017 deletion completed in 22.066774351s

• [SLOW TEST:27.106 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:29:29.980: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-4bf8b4c1-d5a7-419d-8bde-517510e08f38
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:29:32.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2115" for this suite.
Sep  9 23:29:54.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:29:54.095: INFO: namespace configmap-2115 deletion completed in 22.065408937s

• [SLOW TEST:24.115 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:29:54.095: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  9 23:29:57.130: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:29:57.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4778" for this suite.
Sep  9 23:30:03.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:30:03.208: INFO: namespace container-runtime-4778 deletion completed in 6.064093684s

• [SLOW TEST:9.113 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:30:03.209: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 23:30:03.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4163'
Sep  9 23:30:03.301: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 23:30:03.301: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep  9 23:30:03.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4163'
Sep  9 23:30:03.381: INFO: stderr: ""
Sep  9 23:30:03.381: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:30:03.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4163" for this suite.
Sep  9 23:30:09.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:30:09.444: INFO: namespace kubectl-4163 deletion completed in 6.06008622s

• [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:30:09.444: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  9 23:30:11.983: INFO: Successfully updated pod "labelsupdate39917db5-2989-400d-adc2-6cd69caccc78"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:30:16.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9603" for this suite.
Sep  9 23:30:38.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:30:38.064: INFO: namespace downward-api-9603 deletion completed in 22.060720007s

• [SLOW TEST:28.621 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:30:38.065: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  9 23:30:38.091: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc" in namespace "projected-7709" to be "success or failure"
Sep  9 23:30:38.093: INFO: Pod "downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359893ms
Sep  9 23:30:40.095: INFO: Pod "downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00457993s
STEP: Saw pod success
Sep  9 23:30:40.095: INFO: Pod "downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc" satisfied condition "success or failure"
Sep  9 23:30:40.097: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc container client-container: <nil>
STEP: delete the pod
Sep  9 23:30:40.110: INFO: Waiting for pod downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc to disappear
Sep  9 23:30:40.111: INFO: Pod downwardapi-volume-dc3db558-32a0-4c52-9f6c-b2bbba894ddc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:30:40.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7709" for this suite.
Sep  9 23:30:46.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:30:46.174: INFO: namespace projected-7709 deletion completed in 6.060824865s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:30:46.174: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep  9 23:30:48.206: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:30:48.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1393" for this suite.
Sep  9 23:30:54.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:30:54.279: INFO: namespace container-runtime-1393 deletion completed in 6.062851703s

• [SLOW TEST:8.105 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:30:54.279: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6842
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 23:30:54.298: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 23:31:18.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6842 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:31:18.358: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:31:18.448: INFO: Found all expected endpoints: [netserver-0]
Sep  9 23:31:18.449: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.20:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6842 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:31:18.450: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:31:18.539: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:31:18.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6842" for this suite.
Sep  9 23:31:40.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:31:40.603: INFO: namespace pod-network-test-6842 deletion completed in 22.061143817s

• [SLOW TEST:46.324 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:31:40.603: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:32:06.633: INFO: Container started at 2019-09-09 23:31:42 +0000 UTC, pod became ready at 2019-09-09 23:32:05 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:32:06.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3035" for this suite.
Sep  9 23:32:28.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:32:28.707: INFO: namespace container-probe-3035 deletion completed in 22.07134566s

• [SLOW TEST:48.103 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:32:28.707: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  9 23:32:28.729: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e" in namespace "projected-3495" to be "success or failure"
Sep  9 23:32:28.732: INFO: Pod "downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.534469ms
Sep  9 23:32:30.734: INFO: Pod "downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005186362s
STEP: Saw pod success
Sep  9 23:32:30.735: INFO: Pod "downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e" satisfied condition "success or failure"
Sep  9 23:32:30.736: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e container client-container: <nil>
STEP: delete the pod
Sep  9 23:32:30.749: INFO: Waiting for pod downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e to disappear
Sep  9 23:32:30.752: INFO: Pod downwardapi-volume-fbc0ddd3-fcc9-4854-9e11-00ec183c7b2e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:32:30.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3495" for this suite.
Sep  9 23:32:36.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:32:36.813: INFO: namespace projected-3495 deletion completed in 6.059297612s

• [SLOW TEST:8.106 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:32:36.814: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep  9 23:32:42.849: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0909 23:32:42.849568      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:32:42.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1227" for this suite.
Sep  9 23:32:48.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:32:48.929: INFO: namespace gc-1227 deletion completed in 6.077552947s

• [SLOW TEST:12.115 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:32:48.929: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  9 23:32:48.954: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  9 23:32:53.956: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:32:53.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9730" for this suite.
Sep  9 23:32:59.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:33:00.038: INFO: namespace replication-controller-9730 deletion completed in 6.068321991s

• [SLOW TEST:11.109 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:33:00.038: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep  9 23:33:00.055: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-004522922 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:33:00.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3113" for this suite.
Sep  9 23:33:06.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:33:06.179: INFO: namespace kubectl-3113 deletion completed in 6.063105143s

• [SLOW TEST:6.141 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:33:06.180: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4676
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep  9 23:33:06.209: INFO: Found 0 stateful pods, waiting for 3
Sep  9 23:33:16.214: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:33:16.214: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:33:16.214: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  9 23:33:16.234: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  9 23:33:26.259: INFO: Updating stateful set ss2
Sep  9 23:33:26.263: INFO: Waiting for Pod statefulset-4676/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep  9 23:33:36.316: INFO: Found 1 stateful pods, waiting for 3
Sep  9 23:33:46.319: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:33:46.319: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:33:46.319: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  9 23:33:46.340: INFO: Updating stateful set ss2
Sep  9 23:33:46.345: INFO: Waiting for Pod statefulset-4676/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  9 23:33:56.349: INFO: Waiting for Pod statefulset-4676/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep  9 23:34:06.364: INFO: Updating stateful set ss2
Sep  9 23:34:06.372: INFO: Waiting for StatefulSet statefulset-4676/ss2 to complete update
Sep  9 23:34:06.372: INFO: Waiting for Pod statefulset-4676/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  9 23:34:16.377: INFO: Deleting all statefulset in ns statefulset-4676
Sep  9 23:34:16.379: INFO: Scaling statefulset ss2 to 0
Sep  9 23:34:46.390: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 23:34:46.391: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:34:46.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4676" for this suite.
Sep  9 23:34:52.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:34:52.467: INFO: namespace statefulset-4676 deletion completed in 6.066208614s

• [SLOW TEST:106.288 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:34:52.468: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:34:52.486: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:34:53.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2185" for this suite.
Sep  9 23:34:59.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:34:59.582: INFO: namespace custom-resource-definition-2185 deletion completed in 6.059917825s

• [SLOW TEST:7.114 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:34:59.582: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep  9 23:34:59.600: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:35:02.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3220" for this suite.
Sep  9 23:35:08.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:35:08.738: INFO: namespace init-container-3220 deletion completed in 6.058950937s

• [SLOW TEST:9.155 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:35:08.738: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a5c4d8c1-9dc6-47b5-aa61-aa30d56b0f0d
STEP: Creating a pod to test consume configMaps
Sep  9 23:35:08.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31" in namespace "configmap-4615" to be "success or failure"
Sep  9 23:35:08.782: INFO: Pod "pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123767ms
Sep  9 23:35:10.785: INFO: Pod "pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005393449s
STEP: Saw pod success
Sep  9 23:35:10.785: INFO: Pod "pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31" satisfied condition "success or failure"
Sep  9 23:35:10.786: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 23:35:10.798: INFO: Waiting for pod pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31 to disappear
Sep  9 23:35:10.801: INFO: Pod pod-configmaps-7361d8e3-e28c-4eea-96d8-b26d3a6ede31 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:35:10.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4615" for this suite.
Sep  9 23:35:16.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:35:16.867: INFO: namespace configmap-4615 deletion completed in 6.064384189s

• [SLOW TEST:8.129 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:35:16.867: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-dwzd
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 23:35:16.892: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dwzd" in namespace "subpath-532" to be "success or failure"
Sep  9 23:35:16.894: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.36657ms
Sep  9 23:35:18.896: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 2.004668437s
Sep  9 23:35:20.899: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 4.007156078s
Sep  9 23:35:22.902: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 6.010296166s
Sep  9 23:35:24.905: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 8.013212529s
Sep  9 23:35:26.907: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 10.015437446s
Sep  9 23:35:28.909: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 12.017645925s
Sep  9 23:35:30.912: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 14.020167052s
Sep  9 23:35:32.915: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 16.022714551s
Sep  9 23:35:34.917: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 18.025173682s
Sep  9 23:35:36.919: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Running", Reason="", readiness=true. Elapsed: 20.027463044s
Sep  9 23:35:38.921: INFO: Pod "pod-subpath-test-projected-dwzd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.029597983s
STEP: Saw pod success
Sep  9 23:35:38.921: INFO: Pod "pod-subpath-test-projected-dwzd" satisfied condition "success or failure"
Sep  9 23:35:38.923: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-subpath-test-projected-dwzd container test-container-subpath-projected-dwzd: <nil>
STEP: delete the pod
Sep  9 23:35:38.934: INFO: Waiting for pod pod-subpath-test-projected-dwzd to disappear
Sep  9 23:35:38.936: INFO: Pod pod-subpath-test-projected-dwzd no longer exists
STEP: Deleting pod pod-subpath-test-projected-dwzd
Sep  9 23:35:38.936: INFO: Deleting pod "pod-subpath-test-projected-dwzd" in namespace "subpath-532"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:35:38.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-532" for this suite.
Sep  9 23:35:44.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:35:45.000: INFO: namespace subpath-532 deletion completed in 6.060220916s

• [SLOW TEST:28.133 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:35:45.001: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  9 23:35:45.019: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  9 23:35:45.023: INFO: Waiting for terminating namespaces to be deleted...
Sep  9 23:35:45.024: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-224.us-east-2.compute.internal before test
Sep  9 23:35:45.028: INFO: kube-dns-f45c8b84b-z8pzt from kube-system started at 2019-09-09 23:21:52 +0000 UTC (3 container statuses recorded)
Sep  9 23:35:45.028: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  9 23:35:45.028: INFO: 	Container kubedns ready: true, restart count 0
Sep  9 23:35:45.028: INFO: 	Container sidecar ready: true, restart count 0
Sep  9 23:35:45.028: INFO: sonobuoy-e2e-job-f5f726dc9cee4f87 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:35:45.028: INFO: 	Container e2e ready: true, restart count 0
Sep  9 23:35:45.028: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:35:45.028: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-72pz6 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:35:45.028: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:35:45.028: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  9 23:35:45.028: INFO: kube-proxy-ip-172-20-60-224.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:58 +0000 UTC (1 container statuses recorded)
Sep  9 23:35:45.028: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  9 23:35:45.028: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 23:23:56 +0000 UTC (1 container statuses recorded)
Sep  9 23:35:45.028: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  9 23:35:45.028: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-62-19.us-east-2.compute.internal before test
Sep  9 23:35:45.032: INFO: kube-proxy-ip-172-20-62-19.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:41 +0000 UTC (1 container statuses recorded)
Sep  9 23:35:45.032: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  9 23:35:45.032: INFO: kube-dns-autoscaler-577b4774b5-cxb86 from kube-system started at 2019-09-09 23:21:48 +0000 UTC (1 container statuses recorded)
Sep  9 23:35:45.032: INFO: 	Container autoscaler ready: true, restart count 0
Sep  9 23:35:45.032: INFO: kube-dns-f45c8b84b-w9lqg from kube-system started at 2019-09-09 23:21:51 +0000 UTC (3 container statuses recorded)
Sep  9 23:35:45.032: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  9 23:35:45.032: INFO: 	Container kubedns ready: true, restart count 0
Sep  9 23:35:45.032: INFO: 	Container sidecar ready: true, restart count 0
Sep  9 23:35:45.032: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-7w5vm from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:35:45.032: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:35:45.032: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7ba1b4af-37cd-4d5c-b4a2-85398cdd4784 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7ba1b4af-37cd-4d5c-b4a2-85398cdd4784 off the node ip-172-20-60-224.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7ba1b4af-37cd-4d5c-b4a2-85398cdd4784
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:35:49.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7820" for this suite.
Sep  9 23:36:01.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:36:01.154: INFO: namespace sched-pred-7820 deletion completed in 12.064334379s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:16.154 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:36:01.155: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-15d91383-4043-48fa-a06e-3ca054f18057
STEP: Creating a pod to test consume configMaps
Sep  9 23:36:01.181: INFO: Waiting up to 5m0s for pod "pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30" in namespace "configmap-3310" to be "success or failure"
Sep  9 23:36:01.183: INFO: Pod "pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029957ms
Sep  9 23:36:03.185: INFO: Pod "pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004439839s
STEP: Saw pod success
Sep  9 23:36:03.185: INFO: Pod "pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30" satisfied condition "success or failure"
Sep  9 23:36:03.187: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  9 23:36:03.202: INFO: Waiting for pod pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30 to disappear
Sep  9 23:36:03.203: INFO: Pod pod-configmaps-38de45f7-bfac-4d51-a49e-e24a2e0c7f30 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:36:03.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3310" for this suite.
Sep  9 23:36:09.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:36:09.278: INFO: namespace configmap-3310 deletion completed in 6.072524361s

• [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:36:09.278: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-6307/configmap-test-e9c4373d-ef31-4e27-8efd-5013be0d24ae
STEP: Creating a pod to test consume configMaps
Sep  9 23:36:09.306: INFO: Waiting up to 5m0s for pod "pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2" in namespace "configmap-6307" to be "success or failure"
Sep  9 23:36:09.308: INFO: Pod "pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.947946ms
Sep  9 23:36:11.310: INFO: Pod "pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004072574s
STEP: Saw pod success
Sep  9 23:36:11.310: INFO: Pod "pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2" satisfied condition "success or failure"
Sep  9 23:36:11.312: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2 container env-test: <nil>
STEP: delete the pod
Sep  9 23:36:11.323: INFO: Waiting for pod pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2 to disappear
Sep  9 23:36:11.325: INFO: Pod pod-configmaps-c3136fdd-ad2b-4224-820e-02bc02a06aa2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:36:11.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6307" for this suite.
Sep  9 23:36:17.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:36:17.397: INFO: namespace configmap-6307 deletion completed in 6.070602684s

• [SLOW TEST:8.119 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:36:17.398: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 23:36:17.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2260'
Sep  9 23:36:17.488: INFO: stderr: ""
Sep  9 23:36:17.488: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep  9 23:36:17.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete pods e2e-test-nginx-pod --namespace=kubectl-2260'
Sep  9 23:36:21.515: INFO: stderr: ""
Sep  9 23:36:21.515: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:36:21.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2260" for this suite.
Sep  9 23:36:27.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:36:27.580: INFO: namespace kubectl-2260 deletion completed in 6.061951602s

• [SLOW TEST:10.182 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:36:27.580: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  9 23:36:31.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:31.622: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:31.714: INFO: Exec stderr: ""
Sep  9 23:36:31.714: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:31.714: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:31.807: INFO: Exec stderr: ""
Sep  9 23:36:31.807: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:31.807: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:31.897: INFO: Exec stderr: ""
Sep  9 23:36:31.897: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:31.897: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:31.994: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  9 23:36:31.994: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:31.994: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.087: INFO: Exec stderr: ""
Sep  9 23:36:32.087: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:32.087: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.174: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  9 23:36:32.174: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:32.174: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.263: INFO: Exec stderr: ""
Sep  9 23:36:32.263: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:32.263: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.355: INFO: Exec stderr: ""
Sep  9 23:36:32.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:32.355: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.445: INFO: Exec stderr: ""
Sep  9 23:36:32.445: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8087 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:36:32.445: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:36:32.536: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:36:32.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8087" for this suite.
Sep  9 23:37:12.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:37:12.597: INFO: namespace e2e-kubelet-etc-hosts-8087 deletion completed in 40.058892558s

• [SLOW TEST:45.017 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:37:12.597: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  9 23:37:12.627: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3622,SelfLink:/api/v1/namespaces/watch-3622/configmaps/e2e-watch-test-resource-version,UID:eabc7832-717b-4f95-be3e-a66a8a0cc4be,ResourceVersion:4097,Generation:0,CreationTimestamp:2019-09-09 23:37:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 23:37:12.627: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3622,SelfLink:/api/v1/namespaces/watch-3622/configmaps/e2e-watch-test-resource-version,UID:eabc7832-717b-4f95-be3e-a66a8a0cc4be,ResourceVersion:4098,Generation:0,CreationTimestamp:2019-09-09 23:37:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:37:12.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3622" for this suite.
Sep  9 23:37:18.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:37:18.690: INFO: namespace watch-3622 deletion completed in 6.060856699s

• [SLOW TEST:6.093 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:37:18.690: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:37:18.716: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  9 23:37:18.721: INFO: Number of nodes with available pods: 0
Sep  9 23:37:18.721: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  9 23:37:18.732: INFO: Number of nodes with available pods: 0
Sep  9 23:37:18.732: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:19.734: INFO: Number of nodes with available pods: 0
Sep  9 23:37:19.734: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:20.735: INFO: Number of nodes with available pods: 1
Sep  9 23:37:20.735: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  9 23:37:20.745: INFO: Number of nodes with available pods: 1
Sep  9 23:37:20.745: INFO: Number of running nodes: 0, number of available pods: 1
Sep  9 23:37:21.747: INFO: Number of nodes with available pods: 0
Sep  9 23:37:21.747: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  9 23:37:21.756: INFO: Number of nodes with available pods: 0
Sep  9 23:37:21.756: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:22.758: INFO: Number of nodes with available pods: 0
Sep  9 23:37:22.758: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:23.758: INFO: Number of nodes with available pods: 0
Sep  9 23:37:23.758: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:24.758: INFO: Number of nodes with available pods: 0
Sep  9 23:37:24.758: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:25.758: INFO: Number of nodes with available pods: 0
Sep  9 23:37:25.758: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:26.759: INFO: Number of nodes with available pods: 0
Sep  9 23:37:26.759: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:27.759: INFO: Number of nodes with available pods: 0
Sep  9 23:37:27.759: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:28.758: INFO: Number of nodes with available pods: 0
Sep  9 23:37:28.758: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:29.759: INFO: Number of nodes with available pods: 0
Sep  9 23:37:29.759: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:37:30.759: INFO: Number of nodes with available pods: 1
Sep  9 23:37:30.759: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7652, will wait for the garbage collector to delete the pods
Sep  9 23:37:30.819: INFO: Deleting DaemonSet.extensions daemon-set took: 5.569275ms
Sep  9 23:37:31.120: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.286986ms
Sep  9 23:37:38.622: INFO: Number of nodes with available pods: 0
Sep  9 23:37:38.622: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 23:37:38.625: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7652/daemonsets","resourceVersion":"4180"},"items":null}

Sep  9 23:37:38.626: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7652/pods","resourceVersion":"4180"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:37:38.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7652" for this suite.
Sep  9 23:37:44.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:37:44.704: INFO: namespace daemonsets-7652 deletion completed in 6.066057511s

• [SLOW TEST:26.014 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:37:44.704: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-dae37080-9544-42b1-80cf-d285e294b65b in namespace container-probe-2036
Sep  9 23:37:48.734: INFO: Started pod liveness-dae37080-9544-42b1-80cf-d285e294b65b in namespace container-probe-2036
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 23:37:48.735: INFO: Initial restart count of pod liveness-dae37080-9544-42b1-80cf-d285e294b65b is 0
Sep  9 23:38:02.753: INFO: Restart count of pod container-probe-2036/liveness-dae37080-9544-42b1-80cf-d285e294b65b is now 1 (14.017674045s elapsed)
Sep  9 23:38:22.776: INFO: Restart count of pod container-probe-2036/liveness-dae37080-9544-42b1-80cf-d285e294b65b is now 2 (34.041013614s elapsed)
Sep  9 23:38:42.799: INFO: Restart count of pod container-probe-2036/liveness-dae37080-9544-42b1-80cf-d285e294b65b is now 3 (54.06358225s elapsed)
Sep  9 23:39:02.821: INFO: Restart count of pod container-probe-2036/liveness-dae37080-9544-42b1-80cf-d285e294b65b is now 4 (1m14.085843197s elapsed)
Sep  9 23:40:16.907: INFO: Restart count of pod container-probe-2036/liveness-dae37080-9544-42b1-80cf-d285e294b65b is now 5 (2m28.172050828s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:40:16.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2036" for this suite.
Sep  9 23:40:22.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:40:22.987: INFO: namespace container-probe-2036 deletion completed in 6.069103761s

• [SLOW TEST:158.283 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:40:22.988: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep  9 23:40:23.013: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a" in namespace "projected-6934" to be "success or failure"
Sep  9 23:40:23.016: INFO: Pod "downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916271ms
Sep  9 23:40:25.018: INFO: Pod "downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005233513s
STEP: Saw pod success
Sep  9 23:40:25.018: INFO: Pod "downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a" satisfied condition "success or failure"
Sep  9 23:40:25.020: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a container client-container: <nil>
STEP: delete the pod
Sep  9 23:40:25.032: INFO: Waiting for pod downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a to disappear
Sep  9 23:40:25.034: INFO: Pod downwardapi-volume-17fa3c50-c58c-4c97-b955-22b2fa6e755a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:40:25.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6934" for this suite.
Sep  9 23:40:31.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:40:31.100: INFO: namespace projected-6934 deletion completed in 6.064441346s

• [SLOW TEST:8.113 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:40:31.101: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-8089/secret-test-aaadc672-0af3-4b93-9c64-79bdfc815d0f
STEP: Creating a pod to test consume secrets
Sep  9 23:40:31.124: INFO: Waiting up to 5m0s for pod "pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9" in namespace "secrets-8089" to be "success or failure"
Sep  9 23:40:31.126: INFO: Pod "pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.85782ms
Sep  9 23:40:33.128: INFO: Pod "pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004447915s
STEP: Saw pod success
Sep  9 23:40:33.129: INFO: Pod "pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9" satisfied condition "success or failure"
Sep  9 23:40:33.131: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9 container env-test: <nil>
STEP: delete the pod
Sep  9 23:40:33.145: INFO: Waiting for pod pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9 to disappear
Sep  9 23:40:33.147: INFO: Pod pod-configmaps-ddfbe349-6f6a-4477-b6e7-4cbf332e15e9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:40:33.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8089" for this suite.
Sep  9 23:40:39.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:40:39.214: INFO: namespace secrets-8089 deletion completed in 6.063789001s

• [SLOW TEST:8.114 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:40:39.215: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:40:39.242: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  9 23:40:39.246: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:39.250: INFO: Number of nodes with available pods: 0
Sep  9 23:40:39.250: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:40:40.253: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:40.255: INFO: Number of nodes with available pods: 0
Sep  9 23:40:40.255: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:40:41.254: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:41.256: INFO: Number of nodes with available pods: 2
Sep  9 23:40:41.256: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  9 23:40:41.282: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:41.282: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:41.284: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:42.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:42.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:42.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:43.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:43.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:43.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:44.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:44.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:44.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:44.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:45.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:45.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:45.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:45.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:46.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:46.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:46.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:46.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:47.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:47.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:47.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:47.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:48.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:48.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:48.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:48.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:49.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:49.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:49.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:49.290: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:50.288: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:50.288: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:50.288: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:50.290: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:51.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:51.287: INFO: Wrong image for pod: daemon-set-6bmpn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:51.287: INFO: Pod daemon-set-6bmpn is not available
Sep  9 23:40:51.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:52.287: INFO: Pod daemon-set-22hnr is not available
Sep  9 23:40:52.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:52.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:53.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:53.290: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:54.287: INFO: Wrong image for pod: daemon-set-4hb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  9 23:40:54.287: INFO: Pod daemon-set-4hb88 is not available
Sep  9 23:40:54.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:55.287: INFO: Pod daemon-set-bsv75 is not available
Sep  9 23:40:55.289: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  9 23:40:55.291: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:55.293: INFO: Number of nodes with available pods: 1
Sep  9 23:40:55.293: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:40:56.296: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:56.298: INFO: Number of nodes with available pods: 1
Sep  9 23:40:56.298: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:40:57.296: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:57.297: INFO: Number of nodes with available pods: 1
Sep  9 23:40:57.297: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:40:58.296: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:40:58.298: INFO: Number of nodes with available pods: 2
Sep  9 23:40:58.298: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9368, will wait for the garbage collector to delete the pods
Sep  9 23:40:58.366: INFO: Deleting DaemonSet.extensions daemon-set took: 7.306232ms
Sep  9 23:40:58.666: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.269641ms
Sep  9 23:41:11.569: INFO: Number of nodes with available pods: 0
Sep  9 23:41:11.569: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 23:41:11.570: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9368/daemonsets","resourceVersion":"4605"},"items":null}

Sep  9 23:41:11.572: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9368/pods","resourceVersion":"4605"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:41:11.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9368" for this suite.
Sep  9 23:41:17.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:41:17.641: INFO: namespace daemonsets-9368 deletion completed in 6.061715907s

• [SLOW TEST:38.426 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:41:17.641: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-8b1056a9-feed-445b-b285-ed8ea663a2e4 in namespace container-probe-8711
Sep  9 23:41:19.668: INFO: Started pod busybox-8b1056a9-feed-445b-b285-ed8ea663a2e4 in namespace container-probe-8711
STEP: checking the pod's current state and verifying that restartCount is present
Sep  9 23:41:19.669: INFO: Initial restart count of pod busybox-8b1056a9-feed-445b-b285-ed8ea663a2e4 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:45:19.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8711" for this suite.
Sep  9 23:45:26.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:45:26.064: INFO: namespace container-probe-8711 deletion completed in 6.063456639s

• [SLOW TEST:248.423 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:45:26.064: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep  9 23:45:26.083: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep  9 23:45:26.704: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep  9 23:45:28.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:45:30.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:45:32.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:45:34.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:45:36.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703669526, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  9 23:45:39.463: INFO: Waited 719.415658ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:45:39.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2932" for this suite.
Sep  9 23:45:46.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:45:46.067: INFO: namespace aggregator-2932 deletion completed in 6.153838235s

• [SLOW TEST:20.003 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:45:46.068: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep  9 23:45:46.599: INFO: created pod pod-service-account-defaultsa
Sep  9 23:45:46.599: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  9 23:45:46.602: INFO: created pod pod-service-account-mountsa
Sep  9 23:45:46.602: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  9 23:45:46.612: INFO: created pod pod-service-account-nomountsa
Sep  9 23:45:46.612: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  9 23:45:46.619: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  9 23:45:46.619: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  9 23:45:46.623: INFO: created pod pod-service-account-mountsa-mountspec
Sep  9 23:45:46.623: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  9 23:45:46.632: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  9 23:45:46.632: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  9 23:45:46.636: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  9 23:45:46.636: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  9 23:45:46.640: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  9 23:45:46.640: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  9 23:45:46.652: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  9 23:45:46.652: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:45:46.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7351" for this suite.
Sep  9 23:45:52.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:45:52.745: INFO: namespace svcaccounts-7351 deletion completed in 6.087827013s

• [SLOW TEST:6.677 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:45:52.745: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-4991
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4991
STEP: Deleting pre-stop pod
Sep  9 23:46:03.793: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:46:03.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4991" for this suite.
Sep  9 23:46:41.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:46:41.878: INFO: namespace prestop-4991 deletion completed in 38.069155442s

• [SLOW TEST:49.133 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:46:41.878: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9807
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9807
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9807
Sep  9 23:46:41.907: INFO: Found 0 stateful pods, waiting for 1
Sep  9 23:46:51.910: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  9 23:46:51.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 23:46:52.248: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 23:46:52.248: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 23:46:52.248: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 23:46:52.250: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  9 23:47:02.253: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 23:47:02.253: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 23:47:02.264: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998547s
Sep  9 23:47:03.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995093103s
Sep  9 23:47:04.270: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991715753s
Sep  9 23:47:05.273: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989019827s
Sep  9 23:47:06.275: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986333183s
Sep  9 23:47:07.278: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.984034749s
Sep  9 23:47:08.285: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.981395712s
Sep  9 23:47:09.287: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97397851s
Sep  9 23:47:10.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.971526626s
Sep  9 23:47:11.292: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.181214ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9807
Sep  9 23:47:12.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 23:47:12.453: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 23:47:12.453: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 23:47:12.453: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 23:47:12.455: INFO: Found 1 stateful pods, waiting for 3
Sep  9 23:47:22.464: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:47:22.464: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  9 23:47:22.464: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  9 23:47:22.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 23:47:22.631: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 23:47:22.631: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 23:47:22.631: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 23:47:22.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 23:47:22.801: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 23:47:22.801: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 23:47:22.801: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 23:47:22.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  9 23:47:22.966: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  9 23:47:22.966: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  9 23:47:22.966: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  9 23:47:22.966: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 23:47:22.968: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  9 23:47:32.972: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 23:47:32.972: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 23:47:32.972: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  9 23:47:32.979: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999996036s
Sep  9 23:47:33.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996884744s
Sep  9 23:47:34.986: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993540914s
Sep  9 23:47:35.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990058112s
Sep  9 23:47:36.992: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986892346s
Sep  9 23:47:37.995: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984063915s
Sep  9 23:47:38.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.981382975s
Sep  9 23:47:40.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9785179s
Sep  9 23:47:41.004: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975033505s
Sep  9 23:47:42.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.58116ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9807
Sep  9 23:47:43.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 23:47:43.179: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 23:47:43.179: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 23:47:43.179: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 23:47:43.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 23:47:43.346: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 23:47:43.346: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 23:47:43.346: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 23:47:43.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-9807 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  9 23:47:43.532: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  9 23:47:43.532: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  9 23:47:43.532: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  9 23:47:43.532: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep  9 23:48:03.542: INFO: Deleting all statefulset in ns statefulset-9807
Sep  9 23:48:03.543: INFO: Scaling statefulset ss to 0
Sep  9 23:48:03.548: INFO: Waiting for statefulset status.replicas updated to 0
Sep  9 23:48:03.550: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:48:03.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9807" for this suite.
Sep  9 23:48:09.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:48:09.626: INFO: namespace statefulset-9807 deletion completed in 6.065459794s

• [SLOW TEST:87.747 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:48:09.626: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-85124cf4-0c99-4864-ac9f-bcc8d476f977
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-85124cf4-0c99-4864-ac9f-bcc8d476f977
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:48:13.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3128" for this suite.
Sep  9 23:48:35.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:48:35.742: INFO: namespace configmap-3128 deletion completed in 22.062109189s

• [SLOW TEST:26.117 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:48:35.743: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-78f22cd6-20b1-46aa-9f8d-8ced31399fcc
STEP: Creating a pod to test consume secrets
Sep  9 23:48:35.765: INFO: Waiting up to 5m0s for pod "pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b" in namespace "secrets-8932" to be "success or failure"
Sep  9 23:48:35.768: INFO: Pod "pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.03345ms
Sep  9 23:48:37.771: INFO: Pod "pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005357683s
STEP: Saw pod success
Sep  9 23:48:37.771: INFO: Pod "pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b" satisfied condition "success or failure"
Sep  9 23:48:37.772: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:48:37.782: INFO: Waiting for pod pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b to disappear
Sep  9 23:48:37.785: INFO: Pod pod-secrets-722057c3-4aa5-4dc6-ba17-9c7b6815f99b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:48:37.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8932" for this suite.
Sep  9 23:48:43.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:48:43.863: INFO: namespace secrets-8932 deletion completed in 6.07632259s

• [SLOW TEST:8.120 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:48:43.863: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep  9 23:48:46.407: INFO: Successfully updated pod "annotationupdate1c588359-33be-4c77-8258-24191fe68d20"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:48:50.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8228" for this suite.
Sep  9 23:49:12.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:49:12.502: INFO: namespace downward-api-8228 deletion completed in 22.072152013s

• [SLOW TEST:28.638 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:49:12.502: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0909 23:49:22.560706      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  9 23:49:22.560: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:49:22.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8001" for this suite.
Sep  9 23:49:28.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:49:28.630: INFO: namespace gc-8001 deletion completed in 6.067773522s

• [SLOW TEST:16.129 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:49:28.631: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-06b44651-30d2-41ec-8a6f-140c578be4ac
STEP: Creating a pod to test consume secrets
Sep  9 23:49:28.654: INFO: Waiting up to 5m0s for pod "pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6" in namespace "secrets-1805" to be "success or failure"
Sep  9 23:49:28.658: INFO: Pod "pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064993ms
Sep  9 23:49:30.660: INFO: Pod "pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006587461s
STEP: Saw pod success
Sep  9 23:49:30.660: INFO: Pod "pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6" satisfied condition "success or failure"
Sep  9 23:49:30.662: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:49:30.672: INFO: Waiting for pod pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6 to disappear
Sep  9 23:49:30.674: INFO: Pod pod-secrets-fab09550-df62-44b8-b29a-e6650535ecf6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:49:30.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1805" for this suite.
Sep  9 23:49:36.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:49:36.738: INFO: namespace secrets-1805 deletion completed in 6.061998934s

• [SLOW TEST:8.107 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:49:36.738: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  9 23:49:36.760: INFO: Waiting up to 5m0s for pod "pod-0466800c-f682-4d14-b1bc-2a2649e0d290" in namespace "emptydir-6480" to be "success or failure"
Sep  9 23:49:36.762: INFO: Pod "pod-0466800c-f682-4d14-b1bc-2a2649e0d290": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220323ms
Sep  9 23:49:38.764: INFO: Pod "pod-0466800c-f682-4d14-b1bc-2a2649e0d290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004684325s
STEP: Saw pod success
Sep  9 23:49:38.764: INFO: Pod "pod-0466800c-f682-4d14-b1bc-2a2649e0d290" satisfied condition "success or failure"
Sep  9 23:49:38.766: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-0466800c-f682-4d14-b1bc-2a2649e0d290 container test-container: <nil>
STEP: delete the pod
Sep  9 23:49:38.778: INFO: Waiting for pod pod-0466800c-f682-4d14-b1bc-2a2649e0d290 to disappear
Sep  9 23:49:38.780: INFO: Pod pod-0466800c-f682-4d14-b1bc-2a2649e0d290 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:49:38.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6480" for this suite.
Sep  9 23:49:44.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:49:44.846: INFO: namespace emptydir-6480 deletion completed in 6.063425734s

• [SLOW TEST:8.107 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:49:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8024
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  9 23:49:44.863: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  9 23:50:06.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.66:8080/dial?request=hostName&protocol=http&host=100.96.1.65&port=8080&tries=1'] Namespace:pod-network-test-8024 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:50:06.912: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:50:07.010: INFO: Waiting for endpoints: map[]
Sep  9 23:50:07.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.66:8080/dial?request=hostName&protocol=http&host=100.96.2.43&port=8080&tries=1'] Namespace:pod-network-test-8024 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  9 23:50:07.012: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep  9 23:50:07.104: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:50:07.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8024" for this suite.
Sep  9 23:50:29.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:50:29.263: INFO: namespace pod-network-test-8024 deletion completed in 22.156621515s

• [SLOW TEST:44.417 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:50:29.263: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:50:29.282: INFO: Creating ReplicaSet my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983
Sep  9 23:50:29.288: INFO: Pod name my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983: Found 0 pods out of 1
Sep  9 23:50:34.290: INFO: Pod name my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983: Found 1 pods out of 1
Sep  9 23:50:34.291: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983" is running
Sep  9 23:50:34.292: INFO: Pod "my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983-nlj8w" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 23:50:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 23:50:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 23:50:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-09 23:50:29 +0000 UTC Reason: Message:}])
Sep  9 23:50:34.292: INFO: Trying to dial the pod
Sep  9 23:50:39.299: INFO: Controller my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983: Got expected result from replica 1 [my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983-nlj8w]: "my-hostname-basic-9e497b5f-26d3-4dd0-b216-1df50f016983-nlj8w", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:50:39.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4532" for this suite.
Sep  9 23:50:45.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:50:45.367: INFO: namespace replicaset-4532 deletion completed in 6.064953879s

• [SLOW TEST:16.104 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:50:45.367: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep  9 23:50:45.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-4436'
Sep  9 23:50:45.584: INFO: stderr: ""
Sep  9 23:50:45.584: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep  9 23:50:46.586: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 23:50:46.586: INFO: Found 0 / 1
Sep  9 23:50:47.587: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 23:50:47.587: INFO: Found 1 / 1
Sep  9 23:50:47.587: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  9 23:50:47.589: INFO: Selector matched 1 pods for map[app:redis]
Sep  9 23:50:47.589: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  9 23:50:47.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 logs redis-master-4qfx7 redis-master --namespace=kubectl-4436'
Sep  9 23:50:47.666: INFO: stderr: ""
Sep  9 23:50:47.666: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Sep 23:50:46.392 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Sep 23:50:46.392 # Server started, Redis version 3.2.12\n1:M 09 Sep 23:50:46.392 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Sep 23:50:46.392 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  9 23:50:47.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 log redis-master-4qfx7 redis-master --namespace=kubectl-4436 --tail=1'
Sep  9 23:50:47.742: INFO: stderr: ""
Sep  9 23:50:47.742: INFO: stdout: "1:M 09 Sep 23:50:46.392 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  9 23:50:47.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 log redis-master-4qfx7 redis-master --namespace=kubectl-4436 --limit-bytes=1'
Sep  9 23:50:47.817: INFO: stderr: ""
Sep  9 23:50:47.817: INFO: stdout: " "
STEP: exposing timestamps
Sep  9 23:50:47.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 log redis-master-4qfx7 redis-master --namespace=kubectl-4436 --tail=1 --timestamps'
Sep  9 23:50:47.892: INFO: stderr: ""
Sep  9 23:50:47.892: INFO: stdout: "2019-09-09T23:50:46.392907051Z 1:M 09 Sep 23:50:46.392 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  9 23:50:50.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 log redis-master-4qfx7 redis-master --namespace=kubectl-4436 --since=1s'
Sep  9 23:50:50.469: INFO: stderr: ""
Sep  9 23:50:50.469: INFO: stdout: ""
Sep  9 23:50:50.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 log redis-master-4qfx7 redis-master --namespace=kubectl-4436 --since=24h'
Sep  9 23:50:50.543: INFO: stderr: ""
Sep  9 23:50:50.543: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Sep 23:50:46.392 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Sep 23:50:46.392 # Server started, Redis version 3.2.12\n1:M 09 Sep 23:50:46.392 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Sep 23:50:46.392 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep  9 23:50:50.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-4436'
Sep  9 23:50:50.625: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  9 23:50:50.625: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  9 23:50:50.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4436'
Sep  9 23:50:50.694: INFO: stderr: "No resources found.\n"
Sep  9 23:50:50.694: INFO: stdout: ""
Sep  9 23:50:50.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -l name=nginx --namespace=kubectl-4436 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  9 23:50:50.773: INFO: stderr: ""
Sep  9 23:50:50.773: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:50:50.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4436" for this suite.
Sep  9 23:51:12.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:51:12.848: INFO: namespace kubectl-4436 deletion completed in 22.073015007s

• [SLOW TEST:27.481 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:51:12.849: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:51:14.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3638" for this suite.
Sep  9 23:52:04.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:04.949: INFO: namespace kubelet-test-3638 deletion completed in 50.064170374s

• [SLOW TEST:52.101 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:04.950: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep  9 23:52:04.967: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  9 23:52:04.971: INFO: Waiting for terminating namespaces to be deleted...
Sep  9 23:52:04.973: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-224.us-east-2.compute.internal before test
Sep  9 23:52:04.977: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 23:23:56 +0000 UTC (1 container statuses recorded)
Sep  9 23:52:04.977: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  9 23:52:04.977: INFO: kube-proxy-ip-172-20-60-224.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:58 +0000 UTC (1 container statuses recorded)
Sep  9 23:52:04.977: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  9 23:52:04.977: INFO: sonobuoy-e2e-job-f5f726dc9cee4f87 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:52:04.977: INFO: 	Container e2e ready: true, restart count 0
Sep  9 23:52:04.977: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:52:04.977: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-72pz6 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:52:04.977: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:52:04.977: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  9 23:52:04.977: INFO: kube-dns-f45c8b84b-z8pzt from kube-system started at 2019-09-09 23:21:52 +0000 UTC (3 container statuses recorded)
Sep  9 23:52:04.977: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  9 23:52:04.977: INFO: 	Container kubedns ready: true, restart count 0
Sep  9 23:52:04.977: INFO: 	Container sidecar ready: true, restart count 0
Sep  9 23:52:04.977: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-62-19.us-east-2.compute.internal before test
Sep  9 23:52:04.981: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-7w5vm from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep  9 23:52:04.981: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  9 23:52:04.981: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  9 23:52:04.981: INFO: kube-proxy-ip-172-20-62-19.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:41 +0000 UTC (1 container statuses recorded)
Sep  9 23:52:04.981: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  9 23:52:04.981: INFO: kube-dns-autoscaler-577b4774b5-cxb86 from kube-system started at 2019-09-09 23:21:48 +0000 UTC (1 container statuses recorded)
Sep  9 23:52:04.981: INFO: 	Container autoscaler ready: true, restart count 0
Sep  9 23:52:04.981: INFO: kube-dns-f45c8b84b-w9lqg from kube-system started at 2019-09-09 23:21:51 +0000 UTC (3 container statuses recorded)
Sep  9 23:52:04.981: INFO: 	Container dnsmasq ready: true, restart count 0
Sep  9 23:52:04.981: INFO: 	Container kubedns ready: true, restart count 0
Sep  9 23:52:04.981: INFO: 	Container sidecar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node ip-172-20-60-224.us-east-2.compute.internal
STEP: verifying the node has the label node ip-172-20-62-19.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-20-60-224.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod sonobuoy-e2e-job-f5f726dc9cee4f87 requesting resource cpu=0m on Node ip-172-20-60-224.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-72pz6 requesting resource cpu=0m on Node ip-172-20-60-224.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-7w5vm requesting resource cpu=0m on Node ip-172-20-62-19.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod kube-dns-autoscaler-577b4774b5-cxb86 requesting resource cpu=20m on Node ip-172-20-62-19.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod kube-dns-f45c8b84b-w9lqg requesting resource cpu=260m on Node ip-172-20-62-19.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod kube-dns-f45c8b84b-z8pzt requesting resource cpu=260m on Node ip-172-20-60-224.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod kube-proxy-ip-172-20-60-224.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-60-224.us-east-2.compute.internal
Sep  9 23:52:04.999: INFO: Pod kube-proxy-ip-172-20-62-19.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-20-62-19.us-east-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff.15c2ea32fe55b6cb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6818/filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff to ip-172-20-62-19.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff.15c2ea3325f3539c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff.15c2ea33286ea4e6], Reason = [Created], Message = [Created container filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff.15c2ea333329aa03], Reason = [Started], Message = [Started container filler-pod-40a60186-5c15-44ea-9fa0-9304357309ff]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460.15c2ea32fe0adadf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6818/filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460 to ip-172-20-60-224.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460.15c2ea3324575d52], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460.15c2ea33271ae0d5], Reason = [Created], Message = [Created container filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460.15c2ea333278016d], Reason = [Started], Message = [Started container filler-pod-d84fcfcf-c297-4c62-a27b-c2bcda7d2460]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c2ea3375e7e731], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-172-20-60-224.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-20-62-19.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:08.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6818" for this suite.
Sep  9 23:52:14.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:14.113: INFO: namespace sched-pred-6818 deletion completed in 6.073008505s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.163 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:14.113: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  9 23:52:14.136: INFO: Waiting up to 5m0s for pod "pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5" in namespace "emptydir-6183" to be "success or failure"
Sep  9 23:52:14.138: INFO: Pod "pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.30898ms
Sep  9 23:52:16.141: INFO: Pod "pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00520075s
STEP: Saw pod success
Sep  9 23:52:16.141: INFO: Pod "pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5" satisfied condition "success or failure"
Sep  9 23:52:16.143: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5 container test-container: <nil>
STEP: delete the pod
Sep  9 23:52:16.155: INFO: Waiting for pod pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5 to disappear
Sep  9 23:52:16.157: INFO: Pod pod-0e6ae4ae-90b8-4f9e-84e9-3fe66ec139d5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:16.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6183" for this suite.
Sep  9 23:52:22.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:22.226: INFO: namespace emptydir-6183 deletion completed in 6.066600485s

• [SLOW TEST:8.113 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:22.226: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  9 23:52:22.255: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6162,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  9 23:52:22.255: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6163,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  9 23:52:22.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6164,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  9 23:52:32.276: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6180,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  9 23:52:32.276: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6181,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  9 23:52:32.276: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6960,SelfLink:/api/v1/namespaces/watch-6960/configmaps/e2e-watch-test-label-changed,UID:e9f420c7-fa71-4fc2-9c74-6a9b79c32788,ResourceVersion:6182,Generation:0,CreationTimestamp:2019-09-09 23:52:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:32.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6960" for this suite.
Sep  9 23:52:38.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:38.354: INFO: namespace watch-6960 deletion completed in 6.074917501s

• [SLOW TEST:16.128 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:38.354: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep  9 23:52:38.374: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-004522922 proxy --unix-socket=/tmp/kubectl-proxy-unix520494021/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:38.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-682" for this suite.
Sep  9 23:52:44.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:44.492: INFO: namespace kubectl-682 deletion completed in 6.064094476s

• [SLOW TEST:6.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:44.492: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-93432538-0af5-4727-9314-b8a8b92b086b
STEP: Creating a pod to test consume secrets
Sep  9 23:52:44.515: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde" in namespace "projected-7608" to be "success or failure"
Sep  9 23:52:44.517: INFO: Pod "pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.122777ms
Sep  9 23:52:46.520: INFO: Pod "pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00481734s
STEP: Saw pod success
Sep  9 23:52:46.520: INFO: Pod "pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde" satisfied condition "success or failure"
Sep  9 23:52:46.522: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:52:46.535: INFO: Waiting for pod pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde to disappear
Sep  9 23:52:46.538: INFO: Pod pod-projected-secrets-29bc1ca6-49dc-4ea5-95b9-ef45fc417bde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:46.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7608" for this suite.
Sep  9 23:52:52.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:52:52.614: INFO: namespace projected-7608 deletion completed in 6.074337129s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:52:52.616: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:52:58.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4386" for this suite.
Sep  9 23:53:04.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:53:04.762: INFO: namespace namespaces-4386 deletion completed in 6.061981957s
STEP: Destroying namespace "nsdeletetest-8576" for this suite.
Sep  9 23:53:04.764: INFO: Namespace nsdeletetest-8576 was already deleted
STEP: Destroying namespace "nsdeletetest-5913" for this suite.
Sep  9 23:53:10.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:53:10.825: INFO: namespace nsdeletetest-5913 deletion completed in 6.061477994s

• [SLOW TEST:18.210 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:53:10.826: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep  9 23:53:20.857: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0909 23:53:20.857885      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:53:20.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5670" for this suite.
Sep  9 23:53:26.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:53:26.921: INFO: namespace gc-5670 deletion completed in 6.061445952s

• [SLOW TEST:16.095 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:53:26.921: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-4794
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4794 to expose endpoints map[]
Sep  9 23:53:26.965: INFO: Get endpoints failed (16.478046ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  9 23:53:27.967: INFO: successfully validated that service multi-endpoint-test in namespace services-4794 exposes endpoints map[] (1.018895318s elapsed)
STEP: Creating pod pod1 in namespace services-4794
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4794 to expose endpoints map[pod1:[100]]
Sep  9 23:53:29.985: INFO: successfully validated that service multi-endpoint-test in namespace services-4794 exposes endpoints map[pod1:[100]] (2.013770116s elapsed)
STEP: Creating pod pod2 in namespace services-4794
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4794 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  9 23:53:32.009: INFO: successfully validated that service multi-endpoint-test in namespace services-4794 exposes endpoints map[pod1:[100] pod2:[101]] (2.020870641s elapsed)
STEP: Deleting pod pod1 in namespace services-4794
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4794 to expose endpoints map[pod2:[101]]
Sep  9 23:53:33.024: INFO: successfully validated that service multi-endpoint-test in namespace services-4794 exposes endpoints map[pod2:[101]] (1.011308536s elapsed)
STEP: Deleting pod pod2 in namespace services-4794
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4794 to expose endpoints map[]
Sep  9 23:53:34.033: INFO: successfully validated that service multi-endpoint-test in namespace services-4794 exposes endpoints map[] (1.005367331s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:53:34.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4794" for this suite.
Sep  9 23:53:56.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:53:56.112: INFO: namespace services-4794 deletion completed in 22.064387604s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.191 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:53:56.113: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:54:20.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2428" for this suite.
Sep  9 23:54:26.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:54:26.239: INFO: namespace namespaces-2428 deletion completed in 6.060494419s
STEP: Destroying namespace "nsdeletetest-4382" for this suite.
Sep  9 23:54:26.242: INFO: Namespace nsdeletetest-4382 was already deleted
STEP: Destroying namespace "nsdeletetest-9693" for this suite.
Sep  9 23:54:32.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:54:32.303: INFO: namespace nsdeletetest-9693 deletion completed in 6.061703324s

• [SLOW TEST:36.190 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:54:32.303: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:54:32.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8532" for this suite.
Sep  9 23:54:54.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:54:54.394: INFO: namespace pods-8532 deletion completed in 22.062224392s

• [SLOW TEST:22.090 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:54:54.394: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-83616e1c-ba45-4f8b-a7d6-32a0a9c810b3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-83616e1c-ba45-4f8b-a7d6-32a0a9c810b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:54:58.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1220" for this suite.
Sep  9 23:55:20.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:55:20.512: INFO: namespace projected-1220 deletion completed in 22.064890444s

• [SLOW TEST:26.119 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:55:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep  9 23:55:20.536: INFO: Waiting up to 5m0s for pod "client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe" in namespace "containers-3011" to be "success or failure"
Sep  9 23:55:20.539: INFO: Pod "client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.97492ms
Sep  9 23:55:22.541: INFO: Pod "client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005535641s
Sep  9 23:55:24.544: INFO: Pod "client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007919257s
STEP: Saw pod success
Sep  9 23:55:24.544: INFO: Pod "client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe" satisfied condition "success or failure"
Sep  9 23:55:24.545: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe container test-container: <nil>
STEP: delete the pod
Sep  9 23:55:24.557: INFO: Waiting for pod client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe to disappear
Sep  9 23:55:24.559: INFO: Pod client-containers-ebe70327-bc25-4f34-824f-85dd63affbbe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:55:24.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3011" for this suite.
Sep  9 23:55:30.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:55:30.628: INFO: namespace containers-3011 deletion completed in 6.067042556s

• [SLOW TEST:10.116 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:55:30.629: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:55:30.652: INFO: (0) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.524905ms)
Sep  9 23:55:30.654: INFO: (1) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.156193ms)
Sep  9 23:55:30.656: INFO: (2) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.170154ms)
Sep  9 23:55:30.659: INFO: (3) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.269715ms)
Sep  9 23:55:30.661: INFO: (4) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.282398ms)
Sep  9 23:55:30.663: INFO: (5) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.180502ms)
Sep  9 23:55:30.666: INFO: (6) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.396076ms)
Sep  9 23:55:30.668: INFO: (7) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.234074ms)
Sep  9 23:55:30.670: INFO: (8) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.187187ms)
Sep  9 23:55:30.672: INFO: (9) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.359516ms)
Sep  9 23:55:30.675: INFO: (10) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.269831ms)
Sep  9 23:55:30.677: INFO: (11) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.054919ms)
Sep  9 23:55:30.679: INFO: (12) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.127717ms)
Sep  9 23:55:30.681: INFO: (13) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.219302ms)
Sep  9 23:55:30.683: INFO: (14) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.054134ms)
Sep  9 23:55:30.686: INFO: (15) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.191369ms)
Sep  9 23:55:30.688: INFO: (16) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.208419ms)
Sep  9 23:55:30.690: INFO: (17) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.074994ms)
Sep  9 23:55:30.692: INFO: (18) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.153552ms)
Sep  9 23:55:30.694: INFO: (19) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.277356ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:55:30.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7809" for this suite.
Sep  9 23:55:36.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:55:36.757: INFO: namespace proxy-7809 deletion completed in 6.060543701s

• [SLOW TEST:6.128 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:55:36.757: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:55:36.785: INFO: Create a RollingUpdate DaemonSet
Sep  9 23:55:36.787: INFO: Check that daemon pods launch on every node of the cluster
Sep  9 23:55:36.790: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:55:36.792: INFO: Number of nodes with available pods: 0
Sep  9 23:55:36.792: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:55:37.797: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:55:37.800: INFO: Number of nodes with available pods: 0
Sep  9 23:55:37.800: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep  9 23:55:38.795: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:55:38.797: INFO: Number of nodes with available pods: 2
Sep  9 23:55:38.797: INFO: Number of running nodes: 2, number of available pods: 2
Sep  9 23:55:38.797: INFO: Update the DaemonSet to trigger a rollout
Sep  9 23:55:38.802: INFO: Updating DaemonSet daemon-set
Sep  9 23:55:42.811: INFO: Roll back the DaemonSet before rollout is complete
Sep  9 23:55:42.815: INFO: Updating DaemonSet daemon-set
Sep  9 23:55:42.815: INFO: Make sure DaemonSet rollback is complete
Sep  9 23:55:42.818: INFO: Wrong image for pod: daemon-set-krhmb. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  9 23:55:42.818: INFO: Pod daemon-set-krhmb is not available
Sep  9 23:55:42.820: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:55:43.823: INFO: Wrong image for pod: daemon-set-krhmb. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  9 23:55:43.823: INFO: Pod daemon-set-krhmb is not available
Sep  9 23:55:43.825: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep  9 23:55:44.823: INFO: Pod daemon-set-jxmc2 is not available
Sep  9 23:55:44.825: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2953, will wait for the garbage collector to delete the pods
Sep  9 23:55:44.890: INFO: Deleting DaemonSet.extensions daemon-set took: 3.877949ms
Sep  9 23:55:45.190: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.2436ms
Sep  9 23:55:51.592: INFO: Number of nodes with available pods: 0
Sep  9 23:55:51.592: INFO: Number of running nodes: 0, number of available pods: 0
Sep  9 23:55:51.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2953/daemonsets","resourceVersion":"6746"},"items":null}

Sep  9 23:55:51.596: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2953/pods","resourceVersion":"6746"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:55:51.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2953" for this suite.
Sep  9 23:55:57.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:55:57.664: INFO: namespace daemonsets-2953 deletion completed in 6.060776741s

• [SLOW TEST:20.907 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:55:57.665: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-s8th
STEP: Creating a pod to test atomic-volume-subpath
Sep  9 23:55:57.690: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-s8th" in namespace "subpath-7240" to be "success or failure"
Sep  9 23:55:57.692: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Pending", Reason="", readiness=false. Elapsed: 2.479171ms
Sep  9 23:55:59.694: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 2.004837901s
Sep  9 23:56:01.697: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 4.006938956s
Sep  9 23:56:03.699: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 6.009396268s
Sep  9 23:56:05.703: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 8.013075329s
Sep  9 23:56:07.705: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 10.01535775s
Sep  9 23:56:09.707: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 12.017641157s
Sep  9 23:56:11.709: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 14.019882504s
Sep  9 23:56:13.712: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 16.022884533s
Sep  9 23:56:15.715: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 18.025367371s
Sep  9 23:56:17.718: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Running", Reason="", readiness=true. Elapsed: 20.02824022s
Sep  9 23:56:19.720: INFO: Pod "pod-subpath-test-downwardapi-s8th": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.030370671s
STEP: Saw pod success
Sep  9 23:56:19.720: INFO: Pod "pod-subpath-test-downwardapi-s8th" satisfied condition "success or failure"
Sep  9 23:56:19.722: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-subpath-test-downwardapi-s8th container test-container-subpath-downwardapi-s8th: <nil>
STEP: delete the pod
Sep  9 23:56:19.732: INFO: Waiting for pod pod-subpath-test-downwardapi-s8th to disappear
Sep  9 23:56:19.734: INFO: Pod pod-subpath-test-downwardapi-s8th no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-s8th
Sep  9 23:56:19.734: INFO: Deleting pod "pod-subpath-test-downwardapi-s8th" in namespace "subpath-7240"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:56:19.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7240" for this suite.
Sep  9 23:56:25.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:56:25.816: INFO: namespace subpath-7240 deletion completed in 6.078302393s

• [SLOW TEST:28.151 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:56:25.816: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  9 23:56:25.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7778'
Sep  9 23:56:25.907: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  9 23:56:25.907: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep  9 23:56:27.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7778'
Sep  9 23:56:27.987: INFO: stderr: ""
Sep  9 23:56:27.987: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:56:27.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7778" for this suite.
Sep  9 23:56:33.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:56:34.051: INFO: namespace kubectl-7778 deletion completed in 6.0605891s

• [SLOW TEST:8.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:56:34.051: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9761.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9761.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 68.186.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.186.68_udp@PTR;check="$$(dig +tcp +noall +answer +search 68.186.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.186.68_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9761.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9761.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9761.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9761.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9761.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 68.186.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.186.68_udp@PTR;check="$$(dig +tcp +noall +answer +search 68.186.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.186.68_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  9 23:56:44.097: INFO: Unable to read wheezy_udp@dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.100: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.102: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.104: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.118: INFO: Unable to read jessie_udp@dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.120: INFO: Unable to read jessie_tcp@dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.123: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.125: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local from pod dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae: the server could not find the requested resource (get pods dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae)
Sep  9 23:56:44.137: INFO: Lookups using dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae failed for: [wheezy_udp@dns-test-service.dns-9761.svc.cluster.local wheezy_tcp@dns-test-service.dns-9761.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local jessie_udp@dns-test-service.dns-9761.svc.cluster.local jessie_tcp@dns-test-service.dns-9761.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9761.svc.cluster.local]

Sep  9 23:56:49.180: INFO: DNS probes using dns-9761/dns-test-3f333266-08e7-4d61-87ef-85bcb07efcae succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:56:49.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9761" for this suite.
Sep  9 23:56:55.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:56:55.300: INFO: namespace dns-9761 deletion completed in 6.072177284s

• [SLOW TEST:21.249 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:56:55.300: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  9 23:56:57.898: INFO: Successfully updated pod "pod-update-9943a82b-11d2-41fd-b958-7f25c1706b3c"
STEP: verifying the updated pod is in kubernetes
Sep  9 23:56:57.908: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:56:57.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7166" for this suite.
Sep  9 23:57:19.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:57:20.005: INFO: namespace pods-7166 deletion completed in 22.084242594s

• [SLOW TEST:24.704 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:57:20.005: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  9 23:57:24.034: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0aa776e9-03ea-4307-90f9-18d01453c947,GenerateName:,Namespace:events-6460,SelfLink:/api/v1/namespaces/events-6460/pods/send-events-0aa776e9-03ea-4307-90f9-18d01453c947,UID:a1850187-cb06-478c-a82c-d0fc77dbde07,ResourceVersion:6981,Generation:0,CreationTimestamp:2019-09-09 23:57:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 22977884,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-r9jrl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r9jrl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-r9jrl true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003ce4e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003ce4e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:57:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:57:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:57:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:57:20 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.81,StartTime:2019-09-09 23:57:20 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-09 23:57:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://0d409d1b3fef6722ac79e890ba2da986c5d9ea2a1cee0d2a3286170283b2fa1e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  9 23:57:26.038: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  9 23:57:28.041: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:57:28.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6460" for this suite.
Sep  9 23:58:06.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:58:06.115: INFO: namespace events-6460 deletion completed in 38.067103696s

• [SLOW TEST:46.110 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:58:06.115: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep  9 23:58:07.159: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0909 23:58:07.159583      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:58:07.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7544" for this suite.
Sep  9 23:58:13.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:58:13.234: INFO: namespace gc-7544 deletion completed in 6.072700107s

• [SLOW TEST:7.119 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:58:13.234: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:58:38.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7901" for this suite.
Sep  9 23:58:44.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:58:44.452: INFO: namespace container-runtime-7901 deletion completed in 6.063641956s

• [SLOW TEST:31.217 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:58:44.452: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:58:44.476: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  9 23:58:44.481: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  9 23:58:49.484: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  9 23:58:49.484: INFO: Creating deployment "test-rolling-update-deployment"
Sep  9 23:58:49.488: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  9 23:58:49.495: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  9 23:58:51.500: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  9 23:58:51.501: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep  9 23:58:51.507: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3518,SelfLink:/apis/apps/v1/namespaces/deployment-3518/deployments/test-rolling-update-deployment,UID:13eff053-342a-43dc-83bf-ac154aee0a01,ResourceVersion:7209,Generation:1,CreationTimestamp:2019-09-09 23:58:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-09 23:58:49 +0000 UTC 2019-09-09 23:58:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-09 23:58:50 +0000 UTC 2019-09-09 23:58:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  9 23:58:51.509: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-3518,SelfLink:/apis/apps/v1/namespaces/deployment-3518/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:b5cfd328-8886-4740-b322-08e04707280b,ResourceVersion:7202,Generation:1,CreationTimestamp:2019-09-09 23:58:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 13eff053-342a-43dc-83bf-ac154aee0a01 0xc002b5b4a7 0xc002b5b4a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  9 23:58:51.509: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  9 23:58:51.509: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3518,SelfLink:/apis/apps/v1/namespaces/deployment-3518/replicasets/test-rolling-update-controller,UID:7bfad82d-f37d-475f-b457-8e5344115856,ResourceVersion:7208,Generation:2,CreationTimestamp:2019-09-09 23:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 13eff053-342a-43dc-83bf-ac154aee0a01 0xc002b5b3bf 0xc002b5b3d0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  9 23:58:51.511: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-5v5m6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-5v5m6,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-3518,SelfLink:/api/v1/namespaces/deployment-3518/pods/test-rolling-update-deployment-79f6b9d75c-5v5m6,UID:6f786368-d9bc-4e51-b140-6540f19792f3,ResourceVersion:7201,Generation:0,CreationTimestamp:2019-09-09 23:58:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c b5cfd328-8886-4740-b322-08e04707280b 0xc002a7e9c7 0xc002a7e9c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-swpjm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-swpjm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-swpjm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a7ea30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a7ea50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:58:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:58:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:58:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-09 23:58:49 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.84,StartTime:2019-09-09 23:58:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-09 23:58:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://975abad06b44ed21d5e687f6ef360f4253f997c39fe18492019ffe29668ac690}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:58:51.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3518" for this suite.
Sep  9 23:58:57.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:58:57.574: INFO: namespace deployment-3518 deletion completed in 6.061205998s

• [SLOW TEST:13.122 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:58:57.574: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep  9 23:58:57.592: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:58:59.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7867" for this suite.
Sep  9 23:59:43.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:59:43.768: INFO: namespace pods-7867 deletion completed in 44.06611081s

• [SLOW TEST:46.194 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:59:43.768: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-e8162531-f06e-43fa-9578-a7cb2aa718d7
STEP: Creating a pod to test consume secrets
Sep  9 23:59:43.801: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287" in namespace "projected-1379" to be "success or failure"
Sep  9 23:59:43.804: INFO: Pod "pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287": Phase="Pending", Reason="", readiness=false. Elapsed: 2.485586ms
Sep  9 23:59:45.807: INFO: Pod "pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005092457s
STEP: Saw pod success
Sep  9 23:59:45.807: INFO: Pod "pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287" satisfied condition "success or failure"
Sep  9 23:59:45.808: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  9 23:59:45.821: INFO: Waiting for pod pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287 to disappear
Sep  9 23:59:45.822: INFO: Pod pod-projected-secrets-33dddaf8-a9fe-413f-8235-0957ad1b2287 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep  9 23:59:45.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1379" for this suite.
Sep  9 23:59:51.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  9 23:59:51.887: INFO: namespace projected-1379 deletion completed in 6.062358505s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep  9 23:59:51.887: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep  9 23:59:53.922: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-004522922 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 10 00:00:05.452: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:00:05.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6453" for this suite.
Sep 10 00:00:11.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:00:11.519: INFO: namespace pods-6453 deletion completed in 6.062679906s

• [SLOW TEST:19.632 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:00:11.520: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:00:11.542: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5" in namespace "downward-api-8429" to be "success or failure"
Sep 10 00:00:11.548: INFO: Pod "downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.633025ms
Sep 10 00:00:13.551: INFO: Pod "downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009060987s
STEP: Saw pod success
Sep 10 00:00:13.551: INFO: Pod "downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5" satisfied condition "success or failure"
Sep 10 00:00:13.552: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5 container client-container: <nil>
STEP: delete the pod
Sep 10 00:00:13.565: INFO: Waiting for pod downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5 to disappear
Sep 10 00:00:13.567: INFO: Pod downwardapi-volume-e5fb8f48-c671-44e9-92fe-9e1a8b1c66f5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:00:13.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8429" for this suite.
Sep 10 00:00:19.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:00:19.648: INFO: namespace downward-api-8429 deletion completed in 6.078093802s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:00:19.649: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 10 00:00:21.681: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:00:21.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3794" for this suite.
Sep 10 00:00:27.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:00:27.757: INFO: namespace container-runtime-3794 deletion completed in 6.066244631s

• [SLOW TEST:8.108 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:00:27.757: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 10 00:00:27.780: INFO: Waiting up to 5m0s for pod "pod-66800028-b696-41b0-9b2c-8a160e14a785" in namespace "emptydir-7904" to be "success or failure"
Sep 10 00:00:27.784: INFO: Pod "pod-66800028-b696-41b0-9b2c-8a160e14a785": Phase="Pending", Reason="", readiness=false. Elapsed: 3.234953ms
Sep 10 00:00:29.786: INFO: Pod "pod-66800028-b696-41b0-9b2c-8a160e14a785": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005453895s
STEP: Saw pod success
Sep 10 00:00:29.786: INFO: Pod "pod-66800028-b696-41b0-9b2c-8a160e14a785" satisfied condition "success or failure"
Sep 10 00:00:29.788: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-66800028-b696-41b0-9b2c-8a160e14a785 container test-container: <nil>
STEP: delete the pod
Sep 10 00:00:29.804: INFO: Waiting for pod pod-66800028-b696-41b0-9b2c-8a160e14a785 to disappear
Sep 10 00:00:29.809: INFO: Pod pod-66800028-b696-41b0-9b2c-8a160e14a785 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:00:29.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7904" for this suite.
Sep 10 00:00:35.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:00:35.886: INFO: namespace emptydir-7904 deletion completed in 6.072745847s

• [SLOW TEST:8.129 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:00:35.886: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 10 00:00:35.910: INFO: Waiting up to 5m0s for pod "pod-d9c15be8-7972-48ca-a553-bb96e939fbd9" in namespace "emptydir-1215" to be "success or failure"
Sep 10 00:00:35.912: INFO: Pod "pod-d9c15be8-7972-48ca-a553-bb96e939fbd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114412ms
Sep 10 00:00:37.915: INFO: Pod "pod-d9c15be8-7972-48ca-a553-bb96e939fbd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004750289s
STEP: Saw pod success
Sep 10 00:00:37.915: INFO: Pod "pod-d9c15be8-7972-48ca-a553-bb96e939fbd9" satisfied condition "success or failure"
Sep 10 00:00:37.917: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-d9c15be8-7972-48ca-a553-bb96e939fbd9 container test-container: <nil>
STEP: delete the pod
Sep 10 00:00:37.927: INFO: Waiting for pod pod-d9c15be8-7972-48ca-a553-bb96e939fbd9 to disappear
Sep 10 00:00:37.929: INFO: Pod pod-d9c15be8-7972-48ca-a553-bb96e939fbd9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:00:37.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1215" for this suite.
Sep 10 00:00:43.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:00:43.993: INFO: namespace emptydir-1215 deletion completed in 6.061112358s

• [SLOW TEST:8.106 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:00:43.993: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 10 00:00:44.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8771'
Sep 10 00:00:44.221: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 10 00:00:44.221: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 10 00:00:44.228: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 10 00:00:44.251: INFO: scanned /root for discovery docs: <nil>
Sep 10 00:00:44.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8771'
Sep 10 00:00:59.983: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 10 00:00:59.983: INFO: stdout: "Created e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca\nScaling up e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 10 00:00:59.983: INFO: stdout: "Created e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca\nScaling up e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 10 00:00:59.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8771'
Sep 10 00:01:00.052: INFO: stderr: ""
Sep 10 00:01:00.052: INFO: stdout: "e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca-j6rc7 "
Sep 10 00:01:00.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca-j6rc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8771'
Sep 10 00:01:00.118: INFO: stderr: ""
Sep 10 00:01:00.118: INFO: stdout: "true"
Sep 10 00:01:00.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca-j6rc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8771'
Sep 10 00:01:00.184: INFO: stderr: ""
Sep 10 00:01:00.184: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 10 00:01:00.184: INFO: e2e-test-nginx-rc-14bbcef2f0a7bd0bd11ace63bea91cca-j6rc7 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep 10 00:01:00.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete rc e2e-test-nginx-rc --namespace=kubectl-8771'
Sep 10 00:01:00.255: INFO: stderr: ""
Sep 10 00:01:00.255: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:01:00.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8771" for this suite.
Sep 10 00:01:06.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:01:06.327: INFO: namespace kubectl-8771 deletion completed in 6.069280663s

• [SLOW TEST:22.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:01:06.327: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 10 00:01:06.346: INFO: PodSpec: initContainers in spec.initContainers
Sep 10 00:01:52.569: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-87189ab4-4ecf-4fe3-9f9a-498217873af9", GenerateName:"", Namespace:"init-container-3498", SelfLink:"/api/v1/namespaces/init-container-3498/pods/pod-init-87189ab4-4ecf-4fe3-9f9a-498217873af9", UID:"a304f04f-0680-49fe-8ef2-31a290eb4a74", ResourceVersion:"7665", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703670466, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"346093257"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s5ppn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002b5e100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s5ppn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s5ppn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s5ppn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b8c088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-20-62-19.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002d4a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b8c100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b8c120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001b8c128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001b8c12c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703670466, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703670466, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703670466, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703670466, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.62.19", PodIP:"100.96.1.90", StartTime:(*v1.Time)(0xc001cc6060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008900e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000890150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4f0da73a399c216d7b17e190521133064ee997cac7fe3c0d94116c4ea6558619"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001cc60a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001cc6080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:01:52.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3498" for this suite.
Sep 10 00:02:14.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:02:14.638: INFO: namespace init-container-3498 deletion completed in 22.066608066s

• [SLOW TEST:68.312 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:02:14.639: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 10 00:02:14.669: INFO: Waiting up to 5m0s for pod "pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc" in namespace "emptydir-4413" to be "success or failure"
Sep 10 00:02:14.671: INFO: Pod "pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.730014ms
Sep 10 00:02:16.673: INFO: Pod "pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003979392s
STEP: Saw pod success
Sep 10 00:02:16.673: INFO: Pod "pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc" satisfied condition "success or failure"
Sep 10 00:02:16.675: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc container test-container: <nil>
STEP: delete the pod
Sep 10 00:02:16.687: INFO: Waiting for pod pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc to disappear
Sep 10 00:02:16.689: INFO: Pod pod-dec7e7d4-8b48-4432-a198-f1bcac5bfbfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:02:16.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4413" for this suite.
Sep 10 00:02:22.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:02:22.755: INFO: namespace emptydir-4413 deletion completed in 6.063109151s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:02:22.756: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:02:22.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383" in namespace "projected-3678" to be "success or failure"
Sep 10 00:02:22.783: INFO: Pod "downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383": Phase="Pending", Reason="", readiness=false. Elapsed: 3.70624ms
Sep 10 00:02:24.785: INFO: Pod "downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005873086s
STEP: Saw pod success
Sep 10 00:02:24.785: INFO: Pod "downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383" satisfied condition "success or failure"
Sep 10 00:02:24.787: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383 container client-container: <nil>
STEP: delete the pod
Sep 10 00:02:24.804: INFO: Waiting for pod downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383 to disappear
Sep 10 00:02:24.807: INFO: Pod downwardapi-volume-3a3cd6db-5c41-4ced-a6ed-5cc70c470383 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:02:24.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3678" for this suite.
Sep 10 00:02:30.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:02:30.875: INFO: namespace projected-3678 deletion completed in 6.066110039s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:02:30.875: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 10 00:02:30.892: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 10 00:02:30.896: INFO: Waiting for terminating namespaces to be deleted...
Sep 10 00:02:30.897: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-60-224.us-east-2.compute.internal before test
Sep 10 00:02:30.901: INFO: kube-dns-f45c8b84b-z8pzt from kube-system started at 2019-09-09 23:21:52 +0000 UTC (3 container statuses recorded)
Sep 10 00:02:30.901: INFO: 	Container dnsmasq ready: true, restart count 0
Sep 10 00:02:30.901: INFO: 	Container kubedns ready: true, restart count 0
Sep 10 00:02:30.901: INFO: 	Container sidecar ready: true, restart count 0
Sep 10 00:02:30.901: INFO: sonobuoy-e2e-job-f5f726dc9cee4f87 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep 10 00:02:30.901: INFO: 	Container e2e ready: true, restart count 0
Sep 10 00:02:30.901: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 10 00:02:30.901: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-72pz6 from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep 10 00:02:30.901: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 10 00:02:30.901: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 10 00:02:30.901: INFO: kube-proxy-ip-172-20-60-224.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:58 +0000 UTC (1 container statuses recorded)
Sep 10 00:02:30.901: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 10 00:02:30.901: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-09 23:23:56 +0000 UTC (1 container statuses recorded)
Sep 10 00:02:30.901: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 10 00:02:30.901: INFO: 
Logging pods the kubelet thinks is on node ip-172-20-62-19.us-east-2.compute.internal before test
Sep 10 00:02:30.905: INFO: sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-7w5vm from heptio-sonobuoy started at 2019-09-09 23:24:01 +0000 UTC (2 container statuses recorded)
Sep 10 00:02:30.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 10 00:02:30.905: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 10 00:02:30.905: INFO: kube-proxy-ip-172-20-62-19.us-east-2.compute.internal from kube-system started at 2019-09-09 23:17:41 +0000 UTC (1 container statuses recorded)
Sep 10 00:02:30.905: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 10 00:02:30.905: INFO: kube-dns-autoscaler-577b4774b5-cxb86 from kube-system started at 2019-09-09 23:21:48 +0000 UTC (1 container statuses recorded)
Sep 10 00:02:30.905: INFO: 	Container autoscaler ready: true, restart count 0
Sep 10 00:02:30.905: INFO: kube-dns-f45c8b84b-w9lqg from kube-system started at 2019-09-09 23:21:51 +0000 UTC (3 container statuses recorded)
Sep 10 00:02:30.905: INFO: 	Container dnsmasq ready: true, restart count 0
Sep 10 00:02:30.905: INFO: 	Container kubedns ready: true, restart count 0
Sep 10 00:02:30.905: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c2eac4b91965a0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:02:31.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2971" for this suite.
Sep 10 00:02:37.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:02:37.989: INFO: namespace sched-pred-2971 deletion completed in 6.069370526s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.114 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:02:37.990: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-d69fc7c0-2463-4722-922b-c87bfc4f33f6 in namespace container-probe-2113
Sep 10 00:02:40.016: INFO: Started pod busybox-d69fc7c0-2463-4722-922b-c87bfc4f33f6 in namespace container-probe-2113
STEP: checking the pod's current state and verifying that restartCount is present
Sep 10 00:02:40.018: INFO: Initial restart count of pod busybox-d69fc7c0-2463-4722-922b-c87bfc4f33f6 is 0
Sep 10 00:03:30.084: INFO: Restart count of pod container-probe-2113/busybox-d69fc7c0-2463-4722-922b-c87bfc4f33f6 is now 1 (50.065873699s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:03:30.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2113" for this suite.
Sep 10 00:03:36.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:03:36.155: INFO: namespace container-probe-2113 deletion completed in 6.062893463s

• [SLOW TEST:58.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:03:36.155: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-31460783-ceae-4020-b1ea-9c4e6ebe22cc
STEP: Creating a pod to test consume configMaps
Sep 10 00:03:36.178: INFO: Waiting up to 5m0s for pod "pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7" in namespace "configmap-6461" to be "success or failure"
Sep 10 00:03:36.182: INFO: Pod "pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.383487ms
Sep 10 00:03:38.184: INFO: Pod "pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005439547s
STEP: Saw pod success
Sep 10 00:03:38.184: INFO: Pod "pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7" satisfied condition "success or failure"
Sep 10 00:03:38.185: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:03:38.197: INFO: Waiting for pod pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7 to disappear
Sep 10 00:03:38.198: INFO: Pod pod-configmaps-aaa010e2-d3fc-4d31-9be7-57417117b6c7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:03:38.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6461" for this suite.
Sep 10 00:03:44.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:03:44.262: INFO: namespace configmap-6461 deletion completed in 6.062036266s

• [SLOW TEST:8.107 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:03:44.263: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 10 00:03:44.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-2047'
Sep 10 00:03:44.439: INFO: stderr: ""
Sep 10 00:03:44.439: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 10 00:03:45.442: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:03:45.442: INFO: Found 1 / 1
Sep 10 00:03:45.442: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 10 00:03:45.444: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:03:45.444: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 10 00:03:45.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 patch pod redis-master-l8jnr --namespace=kubectl-2047 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 10 00:03:45.512: INFO: stderr: ""
Sep 10 00:03:45.512: INFO: stdout: "pod/redis-master-l8jnr patched\n"
STEP: checking annotations
Sep 10 00:03:45.514: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:03:45.514: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:03:45.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2047" for this suite.
Sep 10 00:04:07.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:04:07.579: INFO: namespace kubectl-2047 deletion completed in 22.062811581s

• [SLOW TEST:23.316 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:04:07.579: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-25kxj in namespace proxy-6908
I0910 00:04:07.608885      15 runners.go:180] Created replication controller with name: proxy-service-25kxj, namespace: proxy-6908, replica count: 1
I0910 00:04:08.659338      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0910 00:04:09.659947      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0910 00:04:10.660131      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:11.660370      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:12.660602      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:13.660869      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:14.661099      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:15.661333      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:16.661594      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:17.661842      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:18.662121      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0910 00:04:19.662395      15 runners.go:180] proxy-service-25kxj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 10 00:04:19.665: INFO: setup took 12.068067975s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 10 00:04:19.681: INFO: (0) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 16.316575ms)
Sep 10 00:04:19.684: INFO: (0) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 18.41926ms)
Sep 10 00:04:19.684: INFO: (0) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 18.706648ms)
Sep 10 00:04:19.688: INFO: (0) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 23.396231ms)
Sep 10 00:04:19.689: INFO: (0) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 23.787821ms)
Sep 10 00:04:19.689: INFO: (0) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 23.958568ms)
Sep 10 00:04:19.689: INFO: (0) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 24.14757ms)
Sep 10 00:04:19.689: INFO: (0) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 23.969678ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 26.011675ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 25.791791ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 25.479655ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 25.675693ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 26.021015ms)
Sep 10 00:04:19.691: INFO: (0) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 26.428623ms)
Sep 10 00:04:19.692: INFO: (0) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 26.667981ms)
Sep 10 00:04:19.692: INFO: (0) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 27.06098ms)
Sep 10 00:04:19.700: INFO: (1) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 7.002076ms)
Sep 10 00:04:19.705: INFO: (1) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 12.151862ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 12.332785ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 13.007458ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 13.399113ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 12.866819ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 13.645431ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 12.966523ms)
Sep 10 00:04:19.706: INFO: (1) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.924972ms)
Sep 10 00:04:19.708: INFO: (1) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 15.636937ms)
Sep 10 00:04:19.708: INFO: (1) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 14.699984ms)
Sep 10 00:04:19.708: INFO: (1) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 15.520732ms)
Sep 10 00:04:19.709: INFO: (1) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 15.948779ms)
Sep 10 00:04:19.709: INFO: (1) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 16.61807ms)
Sep 10 00:04:19.709: INFO: (1) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 16.358703ms)
Sep 10 00:04:19.709: INFO: (1) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 16.584331ms)
Sep 10 00:04:19.715: INFO: (2) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 5.659281ms)
Sep 10 00:04:19.716: INFO: (2) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 6.503775ms)
Sep 10 00:04:19.716: INFO: (2) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 6.284824ms)
Sep 10 00:04:19.720: INFO: (2) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 9.315666ms)
Sep 10 00:04:19.721: INFO: (2) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 10.268303ms)
Sep 10 00:04:19.721: INFO: (2) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 10.190443ms)
Sep 10 00:04:19.721: INFO: (2) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 10.457265ms)
Sep 10 00:04:19.721: INFO: (2) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 10.073997ms)
Sep 10 00:04:19.722: INFO: (2) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 12.051885ms)
Sep 10 00:04:19.722: INFO: (2) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 11.4263ms)
Sep 10 00:04:19.722: INFO: (2) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.739119ms)
Sep 10 00:04:19.724: INFO: (2) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 14.23018ms)
Sep 10 00:04:19.724: INFO: (2) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 14.340094ms)
Sep 10 00:04:19.724: INFO: (2) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 14.456549ms)
Sep 10 00:04:19.724: INFO: (2) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 14.127925ms)
Sep 10 00:04:19.725: INFO: (2) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 13.78842ms)
Sep 10 00:04:19.729: INFO: (3) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 4.514836ms)
Sep 10 00:04:19.737: INFO: (3) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.151853ms)
Sep 10 00:04:19.737: INFO: (3) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 12.25289ms)
Sep 10 00:04:19.737: INFO: (3) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.688038ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 13.115427ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 13.152059ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 12.876536ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 13.026135ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 13.347201ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 13.026725ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 12.980672ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 13.267009ms)
Sep 10 00:04:19.738: INFO: (3) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 13.0829ms)
Sep 10 00:04:19.739: INFO: (3) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 14.087479ms)
Sep 10 00:04:19.739: INFO: (3) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 14.0147ms)
Sep 10 00:04:19.739: INFO: (3) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 14.173878ms)
Sep 10 00:04:19.746: INFO: (4) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 6.995477ms)
Sep 10 00:04:19.747: INFO: (4) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 7.186379ms)
Sep 10 00:04:19.747: INFO: (4) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 7.899361ms)
Sep 10 00:04:19.747: INFO: (4) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 7.522791ms)
Sep 10 00:04:19.748: INFO: (4) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 8.457271ms)
Sep 10 00:04:19.748: INFO: (4) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.919354ms)
Sep 10 00:04:19.749: INFO: (4) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.993951ms)
Sep 10 00:04:19.750: INFO: (4) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 9.40069ms)
Sep 10 00:04:19.752: INFO: (4) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 11.657322ms)
Sep 10 00:04:19.752: INFO: (4) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 11.38966ms)
Sep 10 00:04:19.753: INFO: (4) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 12.408417ms)
Sep 10 00:04:19.753: INFO: (4) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 13.381237ms)
Sep 10 00:04:19.753: INFO: (4) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 13.0772ms)
Sep 10 00:04:19.753: INFO: (4) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 13.388715ms)
Sep 10 00:04:19.753: INFO: (4) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 13.60455ms)
Sep 10 00:04:19.754: INFO: (4) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 13.884609ms)
Sep 10 00:04:19.761: INFO: (5) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 7.495878ms)
Sep 10 00:04:19.762: INFO: (5) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 8.140766ms)
Sep 10 00:04:19.762: INFO: (5) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 7.932374ms)
Sep 10 00:04:19.762: INFO: (5) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.127408ms)
Sep 10 00:04:19.762: INFO: (5) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 8.298303ms)
Sep 10 00:04:19.766: INFO: (5) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.046175ms)
Sep 10 00:04:19.766: INFO: (5) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 12.376918ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 17.166327ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 17.080953ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 17.505156ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 17.191004ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 17.578536ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 17.289809ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 17.450705ms)
Sep 10 00:04:19.771: INFO: (5) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 17.582668ms)
Sep 10 00:04:19.772: INFO: (5) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 17.901883ms)
Sep 10 00:04:19.780: INFO: (6) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 7.764641ms)
Sep 10 00:04:19.780: INFO: (6) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 7.829218ms)
Sep 10 00:04:19.780: INFO: (6) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.232473ms)
Sep 10 00:04:19.780: INFO: (6) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.336431ms)
Sep 10 00:04:19.781: INFO: (6) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.66077ms)
Sep 10 00:04:19.781: INFO: (6) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 8.544822ms)
Sep 10 00:04:19.784: INFO: (6) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 11.659688ms)
Sep 10 00:04:19.784: INFO: (6) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 11.763905ms)
Sep 10 00:04:19.785: INFO: (6) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 12.188138ms)
Sep 10 00:04:19.785: INFO: (6) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 12.340292ms)
Sep 10 00:04:19.786: INFO: (6) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 14.193973ms)
Sep 10 00:04:19.787: INFO: (6) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 14.386348ms)
Sep 10 00:04:19.787: INFO: (6) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 14.817127ms)
Sep 10 00:04:19.787: INFO: (6) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 14.75575ms)
Sep 10 00:04:19.787: INFO: (6) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 14.526043ms)
Sep 10 00:04:19.787: INFO: (6) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 14.901121ms)
Sep 10 00:04:19.804: INFO: (7) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 16.298797ms)
Sep 10 00:04:19.804: INFO: (7) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 15.797699ms)
Sep 10 00:04:19.804: INFO: (7) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 16.465351ms)
Sep 10 00:04:19.805: INFO: (7) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 17.545183ms)
Sep 10 00:04:19.807: INFO: (7) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 19.149619ms)
Sep 10 00:04:19.807: INFO: (7) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 19.498789ms)
Sep 10 00:04:19.807: INFO: (7) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 19.357307ms)
Sep 10 00:04:19.807: INFO: (7) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 20.182402ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 19.526006ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 19.532026ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 19.361405ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 20.053007ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 20.380271ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 20.25103ms)
Sep 10 00:04:19.808: INFO: (7) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 20.745359ms)
Sep 10 00:04:19.809: INFO: (7) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 21.023601ms)
Sep 10 00:04:19.817: INFO: (8) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.057516ms)
Sep 10 00:04:19.817: INFO: (8) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 8.173671ms)
Sep 10 00:04:19.817: INFO: (8) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.433725ms)
Sep 10 00:04:19.818: INFO: (8) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 8.788332ms)
Sep 10 00:04:19.818: INFO: (8) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 9.446528ms)
Sep 10 00:04:19.818: INFO: (8) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 9.352209ms)
Sep 10 00:04:19.819: INFO: (8) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 9.351068ms)
Sep 10 00:04:19.819: INFO: (8) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 9.767654ms)
Sep 10 00:04:19.819: INFO: (8) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 9.694191ms)
Sep 10 00:04:19.819: INFO: (8) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 10.080018ms)
Sep 10 00:04:19.821: INFO: (8) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 11.479694ms)
Sep 10 00:04:19.821: INFO: (8) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.055796ms)
Sep 10 00:04:19.821: INFO: (8) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 12.042806ms)
Sep 10 00:04:19.821: INFO: (8) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.207974ms)
Sep 10 00:04:19.822: INFO: (8) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.628283ms)
Sep 10 00:04:19.822: INFO: (8) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 12.71981ms)
Sep 10 00:04:19.829: INFO: (9) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 7.407105ms)
Sep 10 00:04:19.829: INFO: (9) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 7.280558ms)
Sep 10 00:04:19.830: INFO: (9) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 7.863592ms)
Sep 10 00:04:19.831: INFO: (9) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.50938ms)
Sep 10 00:04:19.831: INFO: (9) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.449681ms)
Sep 10 00:04:19.831: INFO: (9) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 9.196276ms)
Sep 10 00:04:19.832: INFO: (9) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 9.843147ms)
Sep 10 00:04:19.833: INFO: (9) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 10.777264ms)
Sep 10 00:04:19.833: INFO: (9) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 10.895527ms)
Sep 10 00:04:19.833: INFO: (9) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.032306ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 11.363167ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 11.756069ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 11.63939ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 11.609646ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 11.503753ms)
Sep 10 00:04:19.834: INFO: (9) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 11.808341ms)
Sep 10 00:04:19.841: INFO: (10) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 7.121245ms)
Sep 10 00:04:19.842: INFO: (10) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 6.902671ms)
Sep 10 00:04:19.843: INFO: (10) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 8.64249ms)
Sep 10 00:04:19.843: INFO: (10) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.385609ms)
Sep 10 00:04:19.843: INFO: (10) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 8.433286ms)
Sep 10 00:04:19.843: INFO: (10) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 8.5888ms)
Sep 10 00:04:19.844: INFO: (10) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 9.250102ms)
Sep 10 00:04:19.844: INFO: (10) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 9.650883ms)
Sep 10 00:04:19.844: INFO: (10) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 9.290789ms)
Sep 10 00:04:19.844: INFO: (10) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 10.363666ms)
Sep 10 00:04:19.845: INFO: (10) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 10.984864ms)
Sep 10 00:04:19.845: INFO: (10) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 10.80054ms)
Sep 10 00:04:19.846: INFO: (10) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 11.269398ms)
Sep 10 00:04:19.846: INFO: (10) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 11.194513ms)
Sep 10 00:04:19.847: INFO: (10) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.306195ms)
Sep 10 00:04:19.847: INFO: (10) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 12.129339ms)
Sep 10 00:04:19.853: INFO: (11) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 5.48857ms)
Sep 10 00:04:19.853: INFO: (11) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 5.129968ms)
Sep 10 00:04:19.858: INFO: (11) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 9.32955ms)
Sep 10 00:04:19.858: INFO: (11) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 10.426879ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 14.689099ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 14.988266ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 15.07545ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 14.619316ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 14.492ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 14.720907ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 14.592196ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 15.262903ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 16.149244ms)
Sep 10 00:04:19.863: INFO: (11) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 15.748894ms)
Sep 10 00:04:19.864: INFO: (11) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 16.475906ms)
Sep 10 00:04:19.864: INFO: (11) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 16.578788ms)
Sep 10 00:04:19.869: INFO: (12) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 4.906159ms)
Sep 10 00:04:19.869: INFO: (12) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 4.943047ms)
Sep 10 00:04:19.869: INFO: (12) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 5.319643ms)
Sep 10 00:04:19.871: INFO: (12) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 6.675784ms)
Sep 10 00:04:19.871: INFO: (12) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 6.974207ms)
Sep 10 00:04:19.872: INFO: (12) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 7.369302ms)
Sep 10 00:04:19.872: INFO: (12) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 7.813546ms)
Sep 10 00:04:19.875: INFO: (12) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 10.801272ms)
Sep 10 00:04:19.876: INFO: (12) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 11.626767ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.750229ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 12.408403ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.458814ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 12.737238ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 12.564674ms)
Sep 10 00:04:19.877: INFO: (12) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 12.755053ms)
Sep 10 00:04:19.878: INFO: (12) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 13.659343ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 7.525446ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 7.474976ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 7.603865ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 7.572922ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 7.78659ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 7.779524ms)
Sep 10 00:04:19.886: INFO: (13) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 7.898072ms)
Sep 10 00:04:19.890: INFO: (13) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 11.976176ms)
Sep 10 00:04:19.891: INFO: (13) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 12.61678ms)
Sep 10 00:04:19.891: INFO: (13) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 12.369939ms)
Sep 10 00:04:19.892: INFO: (13) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 13.899793ms)
Sep 10 00:04:19.892: INFO: (13) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 13.939113ms)
Sep 10 00:04:19.892: INFO: (13) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 13.999334ms)
Sep 10 00:04:19.893: INFO: (13) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 13.907129ms)
Sep 10 00:04:19.893: INFO: (13) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 14.181554ms)
Sep 10 00:04:19.893: INFO: (13) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 14.194006ms)
Sep 10 00:04:19.901: INFO: (14) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.233828ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 8.457104ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 8.695829ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.861345ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 8.605193ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.95686ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 8.8439ms)
Sep 10 00:04:19.902: INFO: (14) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 9.191471ms)
Sep 10 00:04:19.903: INFO: (14) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 9.237064ms)
Sep 10 00:04:19.903: INFO: (14) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 9.344051ms)
Sep 10 00:04:19.905: INFO: (14) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 11.560517ms)
Sep 10 00:04:19.905: INFO: (14) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 12.147183ms)
Sep 10 00:04:19.905: INFO: (14) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.868353ms)
Sep 10 00:04:19.905: INFO: (14) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.007037ms)
Sep 10 00:04:19.906: INFO: (14) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 12.192668ms)
Sep 10 00:04:19.906: INFO: (14) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.352183ms)
Sep 10 00:04:19.915: INFO: (15) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.407927ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 11.440077ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 11.753711ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.242125ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 12.509769ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.067622ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 12.237129ms)
Sep 10 00:04:19.918: INFO: (15) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 12.46009ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 12.208074ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 12.125163ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 12.098231ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 12.150243ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 12.240128ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 12.691245ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 12.403009ms)
Sep 10 00:04:19.919: INFO: (15) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.577698ms)
Sep 10 00:04:19.925: INFO: (16) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 6.514745ms)
Sep 10 00:04:19.926: INFO: (16) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 6.583345ms)
Sep 10 00:04:19.926: INFO: (16) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 6.819053ms)
Sep 10 00:04:19.926: INFO: (16) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 6.504529ms)
Sep 10 00:04:19.926: INFO: (16) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 6.952853ms)
Sep 10 00:04:19.930: INFO: (16) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 10.282967ms)
Sep 10 00:04:19.930: INFO: (16) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 10.788551ms)
Sep 10 00:04:19.930: INFO: (16) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 10.661821ms)
Sep 10 00:04:19.930: INFO: (16) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 10.547865ms)
Sep 10 00:04:19.930: INFO: (16) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 11.26953ms)
Sep 10 00:04:19.931: INFO: (16) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 11.284831ms)
Sep 10 00:04:19.931: INFO: (16) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 11.06656ms)
Sep 10 00:04:19.931: INFO: (16) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 11.218911ms)
Sep 10 00:04:19.932: INFO: (16) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.159309ms)
Sep 10 00:04:19.932: INFO: (16) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.828023ms)
Sep 10 00:04:19.933: INFO: (16) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 12.880626ms)
Sep 10 00:04:19.938: INFO: (17) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 4.756784ms)
Sep 10 00:04:19.938: INFO: (17) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 4.927878ms)
Sep 10 00:04:19.940: INFO: (17) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 6.540313ms)
Sep 10 00:04:19.940: INFO: (17) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 6.819864ms)
Sep 10 00:04:19.940: INFO: (17) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 7.244589ms)
Sep 10 00:04:19.941: INFO: (17) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 7.523784ms)
Sep 10 00:04:19.941: INFO: (17) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 7.073912ms)
Sep 10 00:04:19.941: INFO: (17) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 7.656141ms)
Sep 10 00:04:19.944: INFO: (17) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 11.497368ms)
Sep 10 00:04:19.944: INFO: (17) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 11.506608ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 11.177727ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 10.726969ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 11.401225ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 11.26508ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.919867ms)
Sep 10 00:04:19.945: INFO: (17) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 11.310499ms)
Sep 10 00:04:19.950: INFO: (18) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 4.833103ms)
Sep 10 00:04:19.950: INFO: (18) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 5.235317ms)
Sep 10 00:04:19.953: INFO: (18) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 7.970989ms)
Sep 10 00:04:19.954: INFO: (18) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 8.596343ms)
Sep 10 00:04:19.954: INFO: (18) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 8.912989ms)
Sep 10 00:04:19.955: INFO: (18) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 9.334707ms)
Sep 10 00:04:19.955: INFO: (18) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 9.458712ms)
Sep 10 00:04:19.955: INFO: (18) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 9.359806ms)
Sep 10 00:04:19.955: INFO: (18) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 9.553577ms)
Sep 10 00:04:19.956: INFO: (18) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 10.061885ms)
Sep 10 00:04:19.957: INFO: (18) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 11.248415ms)
Sep 10 00:04:19.957: INFO: (18) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 11.612904ms)
Sep 10 00:04:19.958: INFO: (18) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 12.384227ms)
Sep 10 00:04:19.958: INFO: (18) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 12.093831ms)
Sep 10 00:04:19.958: INFO: (18) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 12.342556ms)
Sep 10 00:04:19.958: INFO: (18) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 12.316962ms)
Sep 10 00:04:19.968: INFO: (19) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:462/proxy/: tls qux (200; 8.825327ms)
Sep 10 00:04:19.968: INFO: (19) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:443/proxy/tlsrewritem... (200; 9.285317ms)
Sep 10 00:04:19.969: INFO: (19) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname2/proxy/: tls qux (200; 10.288229ms)
Sep 10 00:04:19.969: INFO: (19) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname2/proxy/: bar (200; 9.911417ms)
Sep 10 00:04:19.969: INFO: (19) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname1/proxy/: foo (200; 11.244941ms)
Sep 10 00:04:19.969: INFO: (19) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 10.764738ms)
Sep 10 00:04:19.969: INFO: (19) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">test<... (200; 11.087604ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/https:proxy-service-25kxj-b8mp2:460/proxy/: tls baz (200; 10.354452ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 11.048508ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2/proxy/rewriteme">test</a> (200; 11.225217ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/services/proxy-service-25kxj:portname2/proxy/: bar (200; 10.618998ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/: <a href="/api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:1080/proxy/rewriteme">... (200; 10.768024ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/services/https:proxy-service-25kxj:tlsportname1/proxy/: tls baz (200; 10.576576ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/http:proxy-service-25kxj-b8mp2:160/proxy/: foo (200; 10.799139ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/services/http:proxy-service-25kxj:portname1/proxy/: foo (200; 11.449141ms)
Sep 10 00:04:19.970: INFO: (19) /api/v1/namespaces/proxy-6908/pods/proxy-service-25kxj-b8mp2:162/proxy/: bar (200; 11.101094ms)
STEP: deleting ReplicationController proxy-service-25kxj in namespace proxy-6908, will wait for the garbage collector to delete the pods
Sep 10 00:04:20.026: INFO: Deleting ReplicationController proxy-service-25kxj took: 4.602989ms
Sep 10 00:04:20.329: INFO: Terminating ReplicationController proxy-service-25kxj pods took: 302.628826ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:04:28.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6908" for this suite.
Sep 10 00:04:34.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:04:34.692: INFO: namespace proxy-6908 deletion completed in 6.061222119s

• [SLOW TEST:27.114 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:04:34.692: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:04:40.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1190" for this suite.
Sep 10 00:04:46.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:04:46.354: INFO: namespace watch-1190 deletion completed in 6.157818123s

• [SLOW TEST:11.662 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:04:46.355: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:04:46.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 version'
Sep 10 00:04:46.434: INFO: stderr: ""
Sep 10 00:04:46.434: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:04:46.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7920" for this suite.
Sep 10 00:04:52.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:04:52.499: INFO: namespace kubectl-7920 deletion completed in 6.061381567s

• [SLOW TEST:6.144 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:04:52.499: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:04:54.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2917" for this suite.
Sep 10 00:05:44.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:05:44.602: INFO: namespace kubelet-test-2917 deletion completed in 50.068182394s

• [SLOW TEST:52.103 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:05:44.602: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7480
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 10 00:05:44.630: INFO: Found 0 stateful pods, waiting for 3
Sep 10 00:05:54.633: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 10 00:05:54.633: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 10 00:05:54.633: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 10 00:05:54.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-7480 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:05:54.803: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:05:54.803: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:05:54.803: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 10 00:06:04.830: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 10 00:06:14.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-7480 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:06:15.007: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 10 00:06:15.007: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 10 00:06:15.007: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 10 00:06:35.019: INFO: Waiting for StatefulSet statefulset-7480/ss2 to complete update
Sep 10 00:06:35.019: INFO: Waiting for Pod statefulset-7480/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep 10 00:06:45.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-7480 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:06:45.193: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:06:45.193: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:06:45.193: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 10 00:06:55.222: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 10 00:06:55.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-7480 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:06:55.400: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 10 00:06:55.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 10 00:06:55.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 10 00:07:05.424: INFO: Waiting for StatefulSet statefulset-7480/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 10 00:07:15.430: INFO: Deleting all statefulset in ns statefulset-7480
Sep 10 00:07:15.432: INFO: Scaling statefulset ss2 to 0
Sep 10 00:07:45.443: INFO: Waiting for statefulset status.replicas updated to 0
Sep 10 00:07:45.445: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:07:45.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7480" for this suite.
Sep 10 00:07:51.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:07:51.525: INFO: namespace statefulset-7480 deletion completed in 6.068629961s

• [SLOW TEST:126.922 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:07:51.525: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-fd499ede-b5ee-4012-a30a-86f5beee817d
STEP: Creating a pod to test consume secrets
Sep 10 00:07:51.548: INFO: Waiting up to 5m0s for pod "pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25" in namespace "secrets-7143" to be "success or failure"
Sep 10 00:07:51.552: INFO: Pod "pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.322518ms
Sep 10 00:07:53.554: INFO: Pod "pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005540049s
STEP: Saw pod success
Sep 10 00:07:53.554: INFO: Pod "pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25" satisfied condition "success or failure"
Sep 10 00:07:53.555: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25 container secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:07:53.566: INFO: Waiting for pod pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25 to disappear
Sep 10 00:07:53.568: INFO: Pod pod-secrets-53f18fe0-2589-4dd6-85c8-d9dccce8ea25 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:07:53.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7143" for this suite.
Sep 10 00:07:59.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:07:59.634: INFO: namespace secrets-7143 deletion completed in 6.064085508s

• [SLOW TEST:8.109 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:07:59.634: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:07:59.655: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113" in namespace "downward-api-1353" to be "success or failure"
Sep 10 00:07:59.659: INFO: Pod "downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113": Phase="Pending", Reason="", readiness=false. Elapsed: 4.140292ms
Sep 10 00:08:01.662: INFO: Pod "downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006567107s
STEP: Saw pod success
Sep 10 00:08:01.662: INFO: Pod "downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113" satisfied condition "success or failure"
Sep 10 00:08:01.664: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113 container client-container: <nil>
STEP: delete the pod
Sep 10 00:08:01.677: INFO: Waiting for pod downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113 to disappear
Sep 10 00:08:01.678: INFO: Pod downwardapi-volume-94c13cbe-dd14-44ff-86bc-89bae7409113 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:08:01.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1353" for this suite.
Sep 10 00:08:07.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:08:07.757: INFO: namespace downward-api-1353 deletion completed in 6.076964057s

• [SLOW TEST:8.123 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:08:07.758: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 10 00:08:07.780: INFO: Waiting up to 5m0s for pod "downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3" in namespace "downward-api-5201" to be "success or failure"
Sep 10 00:08:07.784: INFO: Pod "downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.396827ms
Sep 10 00:08:09.786: INFO: Pod "downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006020876s
STEP: Saw pod success
Sep 10 00:08:09.786: INFO: Pod "downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3" satisfied condition "success or failure"
Sep 10 00:08:09.792: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3 container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:08:09.808: INFO: Waiting for pod downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3 to disappear
Sep 10 00:08:09.813: INFO: Pod downward-api-b67dc043-d467-465b-be70-34c6e2bd8db3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:08:09.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5201" for this suite.
Sep 10 00:08:15.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:08:15.885: INFO: namespace downward-api-5201 deletion completed in 6.069672051s

• [SLOW TEST:8.127 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:08:15.885: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3192
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 10 00:08:15.902: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 10 00:08:33.955: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.105:8080/dial?request=hostName&protocol=udp&host=100.96.2.68&port=8081&tries=1'] Namespace:pod-network-test-3192 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 10 00:08:33.955: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep 10 00:08:34.047: INFO: Waiting for endpoints: map[]
Sep 10 00:08:34.049: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.105:8080/dial?request=hostName&protocol=udp&host=100.96.1.104&port=8081&tries=1'] Namespace:pod-network-test-3192 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 10 00:08:34.049: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep 10 00:08:34.145: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:08:34.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3192" for this suite.
Sep 10 00:08:56.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:08:56.221: INFO: namespace pod-network-test-3192 deletion completed in 22.072627389s

• [SLOW TEST:40.336 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:08:56.221: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3514, will wait for the garbage collector to delete the pods
Sep 10 00:08:58.307: INFO: Deleting Job.batch foo took: 3.913611ms
Sep 10 00:08:58.607: INFO: Terminating Job.batch foo pods took: 300.192531ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:09:41.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3514" for this suite.
Sep 10 00:09:47.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:09:47.686: INFO: namespace job-3514 deletion completed in 6.074017249s

• [SLOW TEST:51.464 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:09:47.686: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1a0ca95f-0094-4e97-8eed-afd12db95986
STEP: Creating a pod to test consume configMaps
Sep 10 00:09:47.709: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608" in namespace "projected-5426" to be "success or failure"
Sep 10 00:09:47.713: INFO: Pod "pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763904ms
Sep 10 00:09:49.716: INFO: Pod "pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006625375s
STEP: Saw pod success
Sep 10 00:09:49.716: INFO: Pod "pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608" satisfied condition "success or failure"
Sep 10 00:09:49.717: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:09:49.729: INFO: Waiting for pod pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608 to disappear
Sep 10 00:09:49.732: INFO: Pod pod-projected-configmaps-483fe75b-c0b1-4a78-a494-4f5e823f0608 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:09:49.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5426" for this suite.
Sep 10 00:09:55.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:09:55.804: INFO: namespace projected-5426 deletion completed in 6.070538764s

• [SLOW TEST:8.118 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:09:55.805: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 10 00:09:57.837: INFO: File wheezy_udp@dns-test-service-3.dns-9445.svc.cluster.local from pod  dns-9445/dns-test-7b0864a7-030e-4e2c-81da-628e9c5a7fb7 contains '' instead of 'foo.example.com.'
Sep 10 00:09:57.840: INFO: Lookups using dns-9445/dns-test-7b0864a7-030e-4e2c-81da-628e9c5a7fb7 failed for: [wheezy_udp@dns-test-service-3.dns-9445.svc.cluster.local]

Sep 10 00:10:02.845: INFO: DNS probes using dns-test-7b0864a7-030e-4e2c-81da-628e9c5a7fb7 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 10 00:10:04.875: INFO: DNS probes using dns-test-f7fe6f2b-7d56-4467-80d1-046554254df8 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9445.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9445.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 10 00:10:06.910: INFO: DNS probes using dns-test-85d034b1-d8c0-45b0-b9cf-b2fd01fe9d1f succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:10:06.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9445" for this suite.
Sep 10 00:10:12.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:10:13.005: INFO: namespace dns-9445 deletion completed in 6.075718798s

• [SLOW TEST:17.200 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:10:13.006: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-eb66a529-10f9-4a0f-a5f4-93a9a483267f
STEP: Creating a pod to test consume secrets
Sep 10 00:10:13.031: INFO: Waiting up to 5m0s for pod "pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706" in namespace "secrets-5325" to be "success or failure"
Sep 10 00:10:13.035: INFO: Pod "pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706": Phase="Pending", Reason="", readiness=false. Elapsed: 3.601081ms
Sep 10 00:10:15.037: INFO: Pod "pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006007788s
STEP: Saw pod success
Sep 10 00:10:15.037: INFO: Pod "pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706" satisfied condition "success or failure"
Sep 10 00:10:15.039: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706 container secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:10:15.051: INFO: Waiting for pod pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706 to disappear
Sep 10 00:10:15.053: INFO: Pod pod-secrets-fbd76331-f75a-419b-9ddf-7388dad66706 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:10:15.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5325" for this suite.
Sep 10 00:10:21.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:10:21.121: INFO: namespace secrets-5325 deletion completed in 6.06596222s

• [SLOW TEST:8.115 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:10:21.122: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep 10 00:10:21.146: INFO: Waiting up to 5m0s for pod "var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d" in namespace "var-expansion-7296" to be "success or failure"
Sep 10 00:10:21.148: INFO: Pod "var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111183ms
Sep 10 00:10:23.150: INFO: Pod "var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004384935s
STEP: Saw pod success
Sep 10 00:10:23.150: INFO: Pod "var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d" satisfied condition "success or failure"
Sep 10 00:10:23.152: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:10:23.163: INFO: Waiting for pod var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d to disappear
Sep 10 00:10:23.165: INFO: Pod var-expansion-72b13813-aced-49ad-b9e7-e35e42222c1d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:10:23.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7296" for this suite.
Sep 10 00:10:29.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:10:29.230: INFO: namespace var-expansion-7296 deletion completed in 6.062876992s

• [SLOW TEST:8.108 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:10:29.230: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 10 00:10:29.255: INFO: Waiting up to 5m0s for pod "downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea" in namespace "downward-api-1137" to be "success or failure"
Sep 10 00:10:29.259: INFO: Pod "downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20352ms
Sep 10 00:10:31.262: INFO: Pod "downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007499816s
STEP: Saw pod success
Sep 10 00:10:31.262: INFO: Pod "downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea" satisfied condition "success or failure"
Sep 10 00:10:31.265: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:10:31.278: INFO: Waiting for pod downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea to disappear
Sep 10 00:10:31.281: INFO: Pod downward-api-375ddcdf-5bdc-45db-877a-d4c5377ff2ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:10:31.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1137" for this suite.
Sep 10 00:10:37.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:10:37.356: INFO: namespace downward-api-1137 deletion completed in 6.072294079s

• [SLOW TEST:8.126 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:10:37.356: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-2f2d741a-cc6d-4a80-af85-a386b7fb7136 in namespace container-probe-3067
Sep 10 00:10:39.387: INFO: Started pod test-webserver-2f2d741a-cc6d-4a80-af85-a386b7fb7136 in namespace container-probe-3067
STEP: checking the pod's current state and verifying that restartCount is present
Sep 10 00:10:39.389: INFO: Initial restart count of pod test-webserver-2f2d741a-cc6d-4a80-af85-a386b7fb7136 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:14:39.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3067" for this suite.
Sep 10 00:14:45.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:14:45.806: INFO: namespace container-probe-3067 deletion completed in 6.073657412s

• [SLOW TEST:248.450 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:14:45.806: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-4638e4da-d90e-47e7-912f-b8df6f09ba33
STEP: Creating secret with name s-test-opt-upd-a0f7ed1f-0087-4bbe-9785-033ce084ac69
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4638e4da-d90e-47e7-912f-b8df6f09ba33
STEP: Updating secret s-test-opt-upd-a0f7ed1f-0087-4bbe-9785-033ce084ac69
STEP: Creating secret with name s-test-opt-create-7a9295d5-780c-482e-a6f9-afd4cbadac01
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:14:49.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1603" for this suite.
Sep 10 00:15:11.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:15:11.962: INFO: namespace projected-1603 deletion completed in 22.065909001s

• [SLOW TEST:26.156 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:15:11.962: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 10 00:15:11.983: INFO: Waiting up to 5m0s for pod "pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c" in namespace "emptydir-3841" to be "success or failure"
Sep 10 00:15:11.985: INFO: Pod "pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.787322ms
Sep 10 00:15:13.988: INFO: Pod "pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004202233s
STEP: Saw pod success
Sep 10 00:15:13.988: INFO: Pod "pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c" satisfied condition "success or failure"
Sep 10 00:15:13.989: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c container test-container: <nil>
STEP: delete the pod
Sep 10 00:15:14.000: INFO: Waiting for pod pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c to disappear
Sep 10 00:15:14.002: INFO: Pod pod-4e3e78e7-05aa-4a95-a888-659c9a14a07c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:15:14.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3841" for this suite.
Sep 10 00:15:20.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:15:20.092: INFO: namespace emptydir-3841 deletion completed in 6.086924691s

• [SLOW TEST:8.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:15:20.092: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:15:20.115: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad" in namespace "projected-251" to be "success or failure"
Sep 10 00:15:20.120: INFO: Pod "downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.698173ms
Sep 10 00:15:22.122: INFO: Pod "downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006674024s
STEP: Saw pod success
Sep 10 00:15:22.122: INFO: Pod "downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad" satisfied condition "success or failure"
Sep 10 00:15:22.123: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad container client-container: <nil>
STEP: delete the pod
Sep 10 00:15:22.136: INFO: Waiting for pod downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad to disappear
Sep 10 00:15:22.137: INFO: Pod downwardapi-volume-72c8ddaf-941d-44ca-8603-b9bd791cdfad no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:15:22.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-251" for this suite.
Sep 10 00:15:28.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:15:28.211: INFO: namespace projected-251 deletion completed in 6.071071319s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:15:28.211: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep 10 00:15:28.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 api-versions'
Sep 10 00:15:28.302: INFO: stderr: ""
Sep 10 00:15:28.302: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:15:28.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-148" for this suite.
Sep 10 00:15:34.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:15:34.375: INFO: namespace kubectl-148 deletion completed in 6.069689428s

• [SLOW TEST:6.164 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:15:34.375: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:15:36.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9075" for this suite.
Sep 10 00:16:18.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:16:18.475: INFO: namespace kubelet-test-9075 deletion completed in 42.062793184s

• [SLOW TEST:44.100 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:16:18.475: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 10 00:16:18.496: INFO: Waiting up to 5m0s for pod "downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c" in namespace "downward-api-9193" to be "success or failure"
Sep 10 00:16:18.502: INFO: Pod "downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.366489ms
Sep 10 00:16:20.505: INFO: Pod "downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009218021s
STEP: Saw pod success
Sep 10 00:16:20.505: INFO: Pod "downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c" satisfied condition "success or failure"
Sep 10 00:16:20.507: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:16:20.520: INFO: Waiting for pod downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c to disappear
Sep 10 00:16:20.522: INFO: Pod downward-api-ddc9c43c-9653-4e69-a24c-b095a7f1b05c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:16:20.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9193" for this suite.
Sep 10 00:16:26.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:16:26.588: INFO: namespace downward-api-9193 deletion completed in 6.063623388s

• [SLOW TEST:8.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:16:26.588: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1e5bf5f9-94d4-403b-88d7-2a6a55240797
STEP: Creating a pod to test consume configMaps
Sep 10 00:16:26.610: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431" in namespace "projected-3045" to be "success or failure"
Sep 10 00:16:26.613: INFO: Pod "pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431": Phase="Pending", Reason="", readiness=false. Elapsed: 2.828175ms
Sep 10 00:16:28.615: INFO: Pod "pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005120329s
STEP: Saw pod success
Sep 10 00:16:28.615: INFO: Pod "pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431" satisfied condition "success or failure"
Sep 10 00:16:28.617: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:16:28.629: INFO: Waiting for pod pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431 to disappear
Sep 10 00:16:28.631: INFO: Pod pod-projected-configmaps-7035d319-7dd0-442e-bb8d-028fbe8d8431 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:16:28.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3045" for this suite.
Sep 10 00:16:34.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:16:34.696: INFO: namespace projected-3045 deletion completed in 6.062300904s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:16:34.696: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-e3111197-4aa5-4315-9e21-1f6b7c8c5d5b
STEP: Creating a pod to test consume configMaps
Sep 10 00:16:34.718: INFO: Waiting up to 5m0s for pod "pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83" in namespace "configmap-6271" to be "success or failure"
Sep 10 00:16:34.721: INFO: Pod "pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394194ms
Sep 10 00:16:36.723: INFO: Pod "pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004936235s
STEP: Saw pod success
Sep 10 00:16:36.723: INFO: Pod "pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83" satisfied condition "success or failure"
Sep 10 00:16:36.725: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:16:36.738: INFO: Waiting for pod pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83 to disappear
Sep 10 00:16:36.739: INFO: Pod pod-configmaps-80af89eb-5d4e-4db8-9b8f-f0e32ec59c83 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:16:36.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6271" for this suite.
Sep 10 00:16:42.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:16:42.805: INFO: namespace configmap-6271 deletion completed in 6.063993464s

• [SLOW TEST:8.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:16:42.806: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-2qm7
STEP: Creating a pod to test atomic-volume-subpath
Sep 10 00:16:42.831: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2qm7" in namespace "subpath-2310" to be "success or failure"
Sep 10 00:16:42.842: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.822021ms
Sep 10 00:16:44.844: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 2.012993241s
Sep 10 00:16:46.847: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 4.016272012s
Sep 10 00:16:48.849: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 6.018548039s
Sep 10 00:16:50.852: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 8.021134596s
Sep 10 00:16:52.854: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 10.023553941s
Sep 10 00:16:54.856: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 12.025759354s
Sep 10 00:16:56.859: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 14.028483435s
Sep 10 00:16:58.862: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 16.03113264s
Sep 10 00:17:00.865: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 18.033842447s
Sep 10 00:17:02.867: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Running", Reason="", readiness=true. Elapsed: 20.036333649s
Sep 10 00:17:04.870: INFO: Pod "pod-subpath-test-configmap-2qm7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.0388491s
STEP: Saw pod success
Sep 10 00:17:04.870: INFO: Pod "pod-subpath-test-configmap-2qm7" satisfied condition "success or failure"
Sep 10 00:17:04.871: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-subpath-test-configmap-2qm7 container test-container-subpath-configmap-2qm7: <nil>
STEP: delete the pod
Sep 10 00:17:04.885: INFO: Waiting for pod pod-subpath-test-configmap-2qm7 to disappear
Sep 10 00:17:04.887: INFO: Pod pod-subpath-test-configmap-2qm7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2qm7
Sep 10 00:17:04.887: INFO: Deleting pod "pod-subpath-test-configmap-2qm7" in namespace "subpath-2310"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:17:04.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2310" for this suite.
Sep 10 00:17:10.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:17:10.954: INFO: namespace subpath-2310 deletion completed in 6.061505658s

• [SLOW TEST:28.148 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:17:10.954: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-19158b2f-3753-4d6e-bb79-e028e722e51a
STEP: Creating a pod to test consume configMaps
Sep 10 00:17:10.978: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38" in namespace "projected-8632" to be "success or failure"
Sep 10 00:17:10.981: INFO: Pod "pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.679957ms
Sep 10 00:17:12.984: INFO: Pod "pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005306732s
STEP: Saw pod success
Sep 10 00:17:12.984: INFO: Pod "pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38" satisfied condition "success or failure"
Sep 10 00:17:12.985: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:17:12.997: INFO: Waiting for pod pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38 to disappear
Sep 10 00:17:13.000: INFO: Pod pod-projected-configmaps-71688206-9aeb-44d1-95ec-66a288cd9d38 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:17:13.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8632" for this suite.
Sep 10 00:17:19.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:17:19.074: INFO: namespace projected-8632 deletion completed in 6.072024543s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:17:19.075: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-e0a5ace9-128a-40a0-ba9d-401b0ed6b175
STEP: Creating a pod to test consume secrets
Sep 10 00:17:19.101: INFO: Waiting up to 5m0s for pod "pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08" in namespace "secrets-132" to be "success or failure"
Sep 10 00:17:19.106: INFO: Pod "pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08": Phase="Pending", Reason="", readiness=false. Elapsed: 5.234601ms
Sep 10 00:17:21.109: INFO: Pod "pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007888139s
STEP: Saw pod success
Sep 10 00:17:21.109: INFO: Pod "pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08" satisfied condition "success or failure"
Sep 10 00:17:21.111: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08 container secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:17:21.129: INFO: Waiting for pod pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08 to disappear
Sep 10 00:17:21.131: INFO: Pod pod-secrets-a35bccd8-bf27-4d08-8d48-63a6b62e6f08 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:17:21.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-132" for this suite.
Sep 10 00:17:27.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:17:27.216: INFO: namespace secrets-132 deletion completed in 6.081808027s

• [SLOW TEST:8.140 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:17:27.216: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0910 00:17:57.757578      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 10 00:17:57.757: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:17:57.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5671" for this suite.
Sep 10 00:18:03.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:03.832: INFO: namespace gc-5671 deletion completed in 6.072036697s

• [SLOW TEST:36.616 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:18:03.832: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b5b07f0d-ba36-4029-b9fb-72c6a6b6cded
STEP: Creating a pod to test consume secrets
Sep 10 00:18:03.874: INFO: Waiting up to 5m0s for pod "pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a" in namespace "secrets-6521" to be "success or failure"
Sep 10 00:18:03.876: INFO: Pod "pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.327639ms
Sep 10 00:18:05.879: INFO: Pod "pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004925634s
STEP: Saw pod success
Sep 10 00:18:05.879: INFO: Pod "pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a" satisfied condition "success or failure"
Sep 10 00:18:05.880: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a container secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:18:05.898: INFO: Waiting for pod pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a to disappear
Sep 10 00:18:05.901: INFO: Pod pod-secrets-aef4c488-867f-49a8-a386-67d2ec32763a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:18:05.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6521" for this suite.
Sep 10 00:18:11.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:11.966: INFO: namespace secrets-6521 deletion completed in 6.062559195s
STEP: Destroying namespace "secret-namespace-6080" for this suite.
Sep 10 00:18:17.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:18.027: INFO: namespace secret-namespace-6080 deletion completed in 6.061592334s

• [SLOW TEST:14.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:18:18.028: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 10 00:18:21.064: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:18:22.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7062" for this suite.
Sep 10 00:18:44.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:44.142: INFO: namespace replicaset-7062 deletion completed in 22.066046918s

• [SLOW TEST:26.114 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:18:44.142: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:18:44.222: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce" in namespace "downward-api-3531" to be "success or failure"
Sep 10 00:18:44.225: INFO: Pod "downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.86238ms
Sep 10 00:18:46.227: INFO: Pod "downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005293493s
STEP: Saw pod success
Sep 10 00:18:46.227: INFO: Pod "downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce" satisfied condition "success or failure"
Sep 10 00:18:46.229: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce container client-container: <nil>
STEP: delete the pod
Sep 10 00:18:46.240: INFO: Waiting for pod downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce to disappear
Sep 10 00:18:46.242: INFO: Pod downwardapi-volume-b42ea78e-66db-46c7-b1c8-8c549026d3ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:18:46.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3531" for this suite.
Sep 10 00:18:52.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:52.304: INFO: namespace downward-api-3531 deletion completed in 6.060182305s

• [SLOW TEST:8.162 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:18:52.305: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:18:52.322: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 10 00:18:53.338: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:18:53.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3255" for this suite.
Sep 10 00:18:59.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:18:59.403: INFO: namespace replication-controller-3255 deletion completed in 6.059238048s

• [SLOW TEST:7.099 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:18:59.403: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 10 00:18:59.425: INFO: Waiting up to 5m0s for pod "downward-api-71aed517-e942-4cf8-b945-724ef5f4405c" in namespace "downward-api-7463" to be "success or failure"
Sep 10 00:18:59.428: INFO: Pod "downward-api-71aed517-e942-4cf8-b945-724ef5f4405c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.04027ms
Sep 10 00:19:01.430: INFO: Pod "downward-api-71aed517-e942-4cf8-b945-724ef5f4405c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005471895s
STEP: Saw pod success
Sep 10 00:19:01.430: INFO: Pod "downward-api-71aed517-e942-4cf8-b945-724ef5f4405c" satisfied condition "success or failure"
Sep 10 00:19:01.432: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downward-api-71aed517-e942-4cf8-b945-724ef5f4405c container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:19:01.444: INFO: Waiting for pod downward-api-71aed517-e942-4cf8-b945-724ef5f4405c to disappear
Sep 10 00:19:01.446: INFO: Pod downward-api-71aed517-e942-4cf8-b945-724ef5f4405c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:19:01.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7463" for this suite.
Sep 10 00:19:07.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:19:07.511: INFO: namespace downward-api-7463 deletion completed in 6.063024629s

• [SLOW TEST:8.108 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:19:07.511: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 10 00:19:07.532: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:19:21.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7581" for this suite.
Sep 10 00:19:27.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:19:27.595: INFO: namespace pods-7581 deletion completed in 6.073159992s

• [SLOW TEST:20.084 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:19:27.595: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep 10 00:19:27.617: INFO: Waiting up to 5m0s for pod "client-containers-0961707d-3801-495f-8217-2b5e4711a9fb" in namespace "containers-8467" to be "success or failure"
Sep 10 00:19:27.619: INFO: Pod "client-containers-0961707d-3801-495f-8217-2b5e4711a9fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063592ms
Sep 10 00:19:29.621: INFO: Pod "client-containers-0961707d-3801-495f-8217-2b5e4711a9fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004190606s
STEP: Saw pod success
Sep 10 00:19:29.621: INFO: Pod "client-containers-0961707d-3801-495f-8217-2b5e4711a9fb" satisfied condition "success or failure"
Sep 10 00:19:29.623: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod client-containers-0961707d-3801-495f-8217-2b5e4711a9fb container test-container: <nil>
STEP: delete the pod
Sep 10 00:19:29.648: INFO: Waiting for pod client-containers-0961707d-3801-495f-8217-2b5e4711a9fb to disappear
Sep 10 00:19:29.650: INFO: Pod client-containers-0961707d-3801-495f-8217-2b5e4711a9fb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:19:29.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8467" for this suite.
Sep 10 00:19:35.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:19:35.716: INFO: namespace containers-8467 deletion completed in 6.063700943s

• [SLOW TEST:8.120 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:19:35.716: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:19:35.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3" in namespace "downward-api-2793" to be "success or failure"
Sep 10 00:19:35.743: INFO: Pod "downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782928ms
Sep 10 00:19:37.746: INFO: Pod "downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006291391s
STEP: Saw pod success
Sep 10 00:19:37.746: INFO: Pod "downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3" satisfied condition "success or failure"
Sep 10 00:19:37.747: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3 container client-container: <nil>
STEP: delete the pod
Sep 10 00:19:37.760: INFO: Waiting for pod downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3 to disappear
Sep 10 00:19:37.761: INFO: Pod downwardapi-volume-4720ad65-e670-43b3-b908-8ed3ad10cda3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:19:37.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2793" for this suite.
Sep 10 00:19:43.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:19:43.827: INFO: namespace downward-api-2793 deletion completed in 6.063475482s

• [SLOW TEST:8.111 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:19:43.827: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:19:43.898: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851" in namespace "downward-api-4901" to be "success or failure"
Sep 10 00:19:43.902: INFO: Pod "downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334437ms
Sep 10 00:19:45.904: INFO: Pod "downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006057257s
STEP: Saw pod success
Sep 10 00:19:45.904: INFO: Pod "downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851" satisfied condition "success or failure"
Sep 10 00:19:45.906: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851 container client-container: <nil>
STEP: delete the pod
Sep 10 00:19:45.917: INFO: Waiting for pod downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851 to disappear
Sep 10 00:19:45.919: INFO: Pod downwardapi-volume-8ba4de02-9f98-4a06-b5d4-f93ac042a851 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:19:45.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4901" for this suite.
Sep 10 00:19:51.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:19:51.990: INFO: namespace downward-api-4901 deletion completed in 6.068874163s

• [SLOW TEST:8.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:19:51.991: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-67qn
STEP: Creating a pod to test atomic-volume-subpath
Sep 10 00:19:52.016: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-67qn" in namespace "subpath-6201" to be "success or failure"
Sep 10 00:19:52.019: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.519737ms
Sep 10 00:19:54.022: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 2.005391223s
Sep 10 00:19:56.025: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 4.008751541s
Sep 10 00:19:58.028: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 6.011405277s
Sep 10 00:20:00.033: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 8.016588171s
Sep 10 00:20:02.036: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 10.019089049s
Sep 10 00:20:04.039: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 12.022044927s
Sep 10 00:20:06.041: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 14.024765868s
Sep 10 00:20:08.044: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 16.027509628s
Sep 10 00:20:10.047: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 18.03045292s
Sep 10 00:20:12.050: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Running", Reason="", readiness=true. Elapsed: 20.033090886s
Sep 10 00:20:14.053: INFO: Pod "pod-subpath-test-configmap-67qn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036090785s
STEP: Saw pod success
Sep 10 00:20:14.053: INFO: Pod "pod-subpath-test-configmap-67qn" satisfied condition "success or failure"
Sep 10 00:20:14.055: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-subpath-test-configmap-67qn container test-container-subpath-configmap-67qn: <nil>
STEP: delete the pod
Sep 10 00:20:14.069: INFO: Waiting for pod pod-subpath-test-configmap-67qn to disappear
Sep 10 00:20:14.070: INFO: Pod pod-subpath-test-configmap-67qn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-67qn
Sep 10 00:20:14.071: INFO: Deleting pod "pod-subpath-test-configmap-67qn" in namespace "subpath-6201"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:20:14.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6201" for this suite.
Sep 10 00:20:20.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:20:20.137: INFO: namespace subpath-6201 deletion completed in 6.061969054s

• [SLOW TEST:28.146 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:20:20.137: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:20:20.159: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b" in namespace "downward-api-5548" to be "success or failure"
Sep 10 00:20:20.164: INFO: Pod "downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.356604ms
Sep 10 00:20:22.166: INFO: Pod "downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00691272s
STEP: Saw pod success
Sep 10 00:20:22.166: INFO: Pod "downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b" satisfied condition "success or failure"
Sep 10 00:20:22.168: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b container client-container: <nil>
STEP: delete the pod
Sep 10 00:20:22.180: INFO: Waiting for pod downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b to disappear
Sep 10 00:20:22.183: INFO: Pod downwardapi-volume-7134053c-89b3-40f0-bc40-621ffc8a579b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:20:22.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5548" for this suite.
Sep 10 00:20:28.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:20:28.252: INFO: namespace downward-api-5548 deletion completed in 6.067085393s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:20:28.252: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 10 00:20:28.286: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:20:28.288: INFO: Number of nodes with available pods: 0
Sep 10 00:20:28.288: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:20:29.291: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:20:29.293: INFO: Number of nodes with available pods: 1
Sep 10 00:20:29.293: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:20:30.291: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:20:30.293: INFO: Number of nodes with available pods: 2
Sep 10 00:20:30.293: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 10 00:20:30.304: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:20:30.309: INFO: Number of nodes with available pods: 1
Sep 10 00:20:30.309: INFO: Node ip-172-20-62-19.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:20:31.311: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:20:31.314: INFO: Number of nodes with available pods: 2
Sep 10 00:20:31.314: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8180, will wait for the garbage collector to delete the pods
Sep 10 00:20:31.374: INFO: Deleting DaemonSet.extensions daemon-set took: 4.808804ms
Sep 10 00:20:31.674: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.258975ms
Sep 10 00:20:41.576: INFO: Number of nodes with available pods: 0
Sep 10 00:20:41.576: INFO: Number of running nodes: 0, number of available pods: 0
Sep 10 00:20:41.578: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8180/daemonsets","resourceVersion":"10440"},"items":null}

Sep 10 00:20:41.580: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8180/pods","resourceVersion":"10440"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:20:41.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8180" for this suite.
Sep 10 00:20:47.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:20:47.658: INFO: namespace daemonsets-8180 deletion completed in 6.061673322s

• [SLOW TEST:19.406 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:20:47.658: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 10 00:20:47.683: INFO: Waiting up to 5m0s for pod "pod-094f4f69-b52e-4fa8-b422-86f38d1922e9" in namespace "emptydir-1257" to be "success or failure"
Sep 10 00:20:47.686: INFO: Pod "pod-094f4f69-b52e-4fa8-b422-86f38d1922e9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217441ms
Sep 10 00:20:49.689: INFO: Pod "pod-094f4f69-b52e-4fa8-b422-86f38d1922e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005489505s
STEP: Saw pod success
Sep 10 00:20:49.689: INFO: Pod "pod-094f4f69-b52e-4fa8-b422-86f38d1922e9" satisfied condition "success or failure"
Sep 10 00:20:49.690: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-094f4f69-b52e-4fa8-b422-86f38d1922e9 container test-container: <nil>
STEP: delete the pod
Sep 10 00:20:49.702: INFO: Waiting for pod pod-094f4f69-b52e-4fa8-b422-86f38d1922e9 to disappear
Sep 10 00:20:49.704: INFO: Pod pod-094f4f69-b52e-4fa8-b422-86f38d1922e9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:20:49.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1257" for this suite.
Sep 10 00:20:55.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:20:55.774: INFO: namespace emptydir-1257 deletion completed in 6.067867928s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:20:55.775: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f6d19b7f-9a05-4501-9bc9-6360cde82812
STEP: Creating a pod to test consume configMaps
Sep 10 00:20:55.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1" in namespace "configmap-2479" to be "success or failure"
Sep 10 00:20:55.818: INFO: Pod "pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.850663ms
Sep 10 00:20:57.824: INFO: Pod "pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008779673s
STEP: Saw pod success
Sep 10 00:20:57.824: INFO: Pod "pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1" satisfied condition "success or failure"
Sep 10 00:20:57.826: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:20:57.837: INFO: Waiting for pod pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1 to disappear
Sep 10 00:20:57.840: INFO: Pod pod-configmaps-7c0ea749-51b9-45a0-8448-f19de89652c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:20:57.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2479" for this suite.
Sep 10 00:21:03.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:21:03.910: INFO: namespace configmap-2479 deletion completed in 6.068059681s

• [SLOW TEST:8.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:21:03.910: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 10 00:21:03.931: INFO: Waiting up to 5m0s for pod "pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1" in namespace "emptydir-7431" to be "success or failure"
Sep 10 00:21:03.933: INFO: Pod "pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252076ms
Sep 10 00:21:05.936: INFO: Pod "pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004710465s
STEP: Saw pod success
Sep 10 00:21:05.936: INFO: Pod "pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1" satisfied condition "success or failure"
Sep 10 00:21:05.941: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1 container test-container: <nil>
STEP: delete the pod
Sep 10 00:21:05.952: INFO: Waiting for pod pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1 to disappear
Sep 10 00:21:05.954: INFO: Pod pod-a4d2ad8d-ecd6-47a9-a8af-b5363476d3d1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:21:05.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7431" for this suite.
Sep 10 00:21:11.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:21:12.028: INFO: namespace emptydir-7431 deletion completed in 6.072301498s

• [SLOW TEST:8.118 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:21:12.028: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 10 00:21:14.062: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:21:14.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8203" for this suite.
Sep 10 00:21:20.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:21:20.139: INFO: namespace container-runtime-8203 deletion completed in 6.064232195s

• [SLOW TEST:8.111 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:21:20.139: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:21:22.179: INFO: Waiting up to 5m0s for pod "client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597" in namespace "pods-7460" to be "success or failure"
Sep 10 00:21:22.182: INFO: Pod "client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597": Phase="Pending", Reason="", readiness=false. Elapsed: 3.064037ms
Sep 10 00:21:24.185: INFO: Pod "client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005908939s
STEP: Saw pod success
Sep 10 00:21:24.185: INFO: Pod "client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597" satisfied condition "success or failure"
Sep 10 00:21:24.187: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597 container env3cont: <nil>
STEP: delete the pod
Sep 10 00:21:24.200: INFO: Waiting for pod client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597 to disappear
Sep 10 00:21:24.202: INFO: Pod client-envvars-6d42d750-e473-44f6-a06a-ad7b576de597 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:21:24.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7460" for this suite.
Sep 10 00:22:14.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:22:14.268: INFO: namespace pods-7460 deletion completed in 50.063864178s

• [SLOW TEST:54.129 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:22:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 10 00:22:16.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec pod-sharedvolume-0e279b22-f321-4958-b482-ac65950c1205 -c busybox-main-container --namespace=emptydir-2462 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 10 00:22:16.658: INFO: stderr: ""
Sep 10 00:22:16.658: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:22:16.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2462" for this suite.
Sep 10 00:22:22.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:22:22.720: INFO: namespace emptydir-2462 deletion completed in 6.060303354s

• [SLOW TEST:8.452 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:22:22.721: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:22:22.756: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e0d0e761-f2d3-479e-aa1a-d3859ea97cb9", Controller:(*bool)(0xc000ff65a6), BlockOwnerDeletion:(*bool)(0xc000ff65a7)}}
Sep 10 00:22:22.761: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6353ef46-47ea-4f2f-bc06-20ac2ca4fe6b", Controller:(*bool)(0xc000ff6746), BlockOwnerDeletion:(*bool)(0xc000ff6747)}}
Sep 10 00:22:22.768: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b44d0651-7bb9-45cb-a668-1382f75451c4", Controller:(*bool)(0xc003c3f306), BlockOwnerDeletion:(*bool)(0xc003c3f307)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:22:27.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8099" for this suite.
Sep 10 00:22:33.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:22:33.862: INFO: namespace gc-8099 deletion completed in 6.085048232s

• [SLOW TEST:11.141 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:22:33.863: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 10 00:22:36.401: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558"
Sep 10 00:22:36.401: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558" in namespace "pods-2057" to be "terminated due to deadline exceeded"
Sep 10 00:22:36.403: INFO: Pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558": Phase="Running", Reason="", readiness=true. Elapsed: 2.000962ms
Sep 10 00:22:38.406: INFO: Pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558": Phase="Running", Reason="", readiness=true. Elapsed: 2.005086397s
Sep 10 00:22:40.408: INFO: Pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.00759381s
Sep 10 00:22:40.408: INFO: Pod "pod-update-activedeadlineseconds-1294a095-6151-463a-9f81-9069e4739558" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:22:40.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2057" for this suite.
Sep 10 00:22:46.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:22:46.480: INFO: namespace pods-2057 deletion completed in 6.070128099s

• [SLOW TEST:12.618 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:22:46.480: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-c7f3cd32-3732-45b1-b919-b112af9a75a5
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:22:46.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7423" for this suite.
Sep 10 00:22:52.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:22:52.562: INFO: namespace configmap-7423 deletion completed in 6.060421493s

• [SLOW TEST:6.081 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:22:52.562: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 10 00:22:55.095: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2993 pod-service-account-0ed337d5-bb63-4d2b-941e-092036cd772e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 10 00:22:55.267: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2993 pod-service-account-0ed337d5-bb63-4d2b-941e-092036cd772e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 10 00:22:55.428: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2993 pod-service-account-0ed337d5-bb63-4d2b-941e-092036cd772e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:22:55.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2993" for this suite.
Sep 10 00:23:01.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:01.663: INFO: namespace svcaccounts-2993 deletion completed in 6.072610448s

• [SLOW TEST:9.101 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:01.663: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 10 00:23:01.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1428'
Sep 10 00:23:01.756: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 10 00:23:01.756: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep 10 00:23:01.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete jobs e2e-test-nginx-job --namespace=kubectl-1428'
Sep 10 00:23:01.833: INFO: stderr: ""
Sep 10 00:23:01.833: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:23:01.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1428" for this suite.
Sep 10 00:23:07.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:07.901: INFO: namespace kubectl-1428 deletion completed in 6.064565555s

• [SLOW TEST:6.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:07.901: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 10 00:23:07.923: INFO: Waiting up to 5m0s for pod "pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2" in namespace "emptydir-5938" to be "success or failure"
Sep 10 00:23:07.924: INFO: Pod "pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.729656ms
Sep 10 00:23:09.927: INFO: Pod "pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004229913s
STEP: Saw pod success
Sep 10 00:23:09.927: INFO: Pod "pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2" satisfied condition "success or failure"
Sep 10 00:23:09.928: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2 container test-container: <nil>
STEP: delete the pod
Sep 10 00:23:09.941: INFO: Waiting for pod pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2 to disappear
Sep 10 00:23:09.943: INFO: Pod pod-d67ccfe9-f06b-4f76-961c-f52cf33be0e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:23:09.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5938" for this suite.
Sep 10 00:23:15.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:16.013: INFO: namespace emptydir-5938 deletion completed in 6.068867418s

• [SLOW TEST:8.113 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:16.014: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-f80c939d-d5b9-460a-b3b6-c8ba804125b3
STEP: Creating secret with name s-test-opt-upd-d78535cf-f41c-453e-b560-2c3614ba6811
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f80c939d-d5b9-460a-b3b6-c8ba804125b3
STEP: Updating secret s-test-opt-upd-d78535cf-f41c-453e-b560-2c3614ba6811
STEP: Creating secret with name s-test-opt-create-a38c9213-802b-4346-9449-09888b0ccaf3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:23:20.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-568" for this suite.
Sep 10 00:23:42.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:42.158: INFO: namespace secrets-568 deletion completed in 22.05990664s

• [SLOW TEST:26.144 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:42.158: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3529/configmap-test-d84617d9-ef65-4173-9747-f76eeb5c3a5f
STEP: Creating a pod to test consume configMaps
Sep 10 00:23:42.180: INFO: Waiting up to 5m0s for pod "pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e" in namespace "configmap-3529" to be "success or failure"
Sep 10 00:23:42.184: INFO: Pod "pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.481689ms
Sep 10 00:23:44.187: INFO: Pod "pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006108399s
STEP: Saw pod success
Sep 10 00:23:44.187: INFO: Pod "pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e" satisfied condition "success or failure"
Sep 10 00:23:44.188: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e container env-test: <nil>
STEP: delete the pod
Sep 10 00:23:44.199: INFO: Waiting for pod pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e to disappear
Sep 10 00:23:44.201: INFO: Pod pod-configmaps-1943f029-4543-4786-9afb-7352ca4bc56e no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:23:44.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3529" for this suite.
Sep 10 00:23:50.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:50.262: INFO: namespace configmap-3529 deletion completed in 6.059423163s

• [SLOW TEST:8.104 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:50.263: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 10 00:23:50.285: INFO: Waiting up to 5m0s for pod "downward-api-f518cd69-48fe-4103-afc9-4e969030d528" in namespace "downward-api-686" to be "success or failure"
Sep 10 00:23:50.287: INFO: Pod "downward-api-f518cd69-48fe-4103-afc9-4e969030d528": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226718ms
Sep 10 00:23:52.290: INFO: Pod "downward-api-f518cd69-48fe-4103-afc9-4e969030d528": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004897499s
STEP: Saw pod success
Sep 10 00:23:52.290: INFO: Pod "downward-api-f518cd69-48fe-4103-afc9-4e969030d528" satisfied condition "success or failure"
Sep 10 00:23:52.292: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downward-api-f518cd69-48fe-4103-afc9-4e969030d528 container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:23:52.304: INFO: Waiting for pod downward-api-f518cd69-48fe-4103-afc9-4e969030d528 to disappear
Sep 10 00:23:52.307: INFO: Pod downward-api-f518cd69-48fe-4103-afc9-4e969030d528 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:23:52.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-686" for this suite.
Sep 10 00:23:58.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:23:58.376: INFO: namespace downward-api-686 deletion completed in 6.066975315s

• [SLOW TEST:8.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:23:58.377: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep 10 00:23:58.397: INFO: Waiting up to 5m0s for pod "var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c" in namespace "var-expansion-7527" to be "success or failure"
Sep 10 00:23:58.400: INFO: Pod "var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.659719ms
Sep 10 00:24:00.402: INFO: Pod "var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004758939s
STEP: Saw pod success
Sep 10 00:24:00.402: INFO: Pod "var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c" satisfied condition "success or failure"
Sep 10 00:24:00.404: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c container dapi-container: <nil>
STEP: delete the pod
Sep 10 00:24:00.416: INFO: Waiting for pod var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c to disappear
Sep 10 00:24:00.420: INFO: Pod var-expansion-a67a9d66-80f0-48e8-b271-391e20b2631c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:00.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7527" for this suite.
Sep 10 00:24:06.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:06.491: INFO: namespace var-expansion-7527 deletion completed in 6.066617748s

• [SLOW TEST:8.114 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:06.491: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-fcfef180-cd78-4f99-b8f6-e547c58ed80b
STEP: Creating a pod to test consume configMaps
Sep 10 00:24:06.515: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6" in namespace "projected-8178" to be "success or failure"
Sep 10 00:24:06.519: INFO: Pod "pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.523904ms
Sep 10 00:24:08.521: INFO: Pod "pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005970338s
STEP: Saw pod success
Sep 10 00:24:08.521: INFO: Pod "pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6" satisfied condition "success or failure"
Sep 10 00:24:08.523: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:24:08.537: INFO: Waiting for pod pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6 to disappear
Sep 10 00:24:08.542: INFO: Pod pod-projected-configmaps-dcedb1ac-4283-4f89-b97f-314afb5466d6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:08.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8178" for this suite.
Sep 10 00:24:14.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:14.605: INFO: namespace projected-8178 deletion completed in 6.060773836s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:14.605: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:24:14.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10" in namespace "downward-api-440" to be "success or failure"
Sep 10 00:24:14.638: INFO: Pod "downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10": Phase="Pending", Reason="", readiness=false. Elapsed: 1.993287ms
Sep 10 00:24:16.641: INFO: Pod "downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004534404s
STEP: Saw pod success
Sep 10 00:24:16.641: INFO: Pod "downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10" satisfied condition "success or failure"
Sep 10 00:24:16.642: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10 container client-container: <nil>
STEP: delete the pod
Sep 10 00:24:16.654: INFO: Waiting for pod downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10 to disappear
Sep 10 00:24:16.657: INFO: Pod downwardapi-volume-e240eb5c-2a92-464d-8036-2effdd50fd10 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:16.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-440" for this suite.
Sep 10 00:24:22.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:22.726: INFO: namespace downward-api-440 deletion completed in 6.067259953s

• [SLOW TEST:8.121 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:22.726: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep 10 00:24:22.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 cluster-info'
Sep 10 00:24:22.810: INFO: stderr: ""
Sep 10 00:24:22.810: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:22.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4646" for this suite.
Sep 10 00:24:28.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:28.896: INFO: namespace kubectl-4646 deletion completed in 6.083456099s

• [SLOW TEST:6.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:28.897: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 10 00:24:28.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-9473'
Sep 10 00:24:28.989: INFO: stderr: ""
Sep 10 00:24:28.989: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 10 00:24:34.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pod e2e-test-nginx-pod --namespace=kubectl-9473 -o json'
Sep 10 00:24:34.112: INFO: stderr: ""
Sep 10 00:24:34.112: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-09-10T00:24:28Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-9473\",\n        \"resourceVersion\": \"11130\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9473/pods/e2e-test-nginx-pod\",\n        \"uid\": \"bb83fa3c-0d40-46d8-88cf-3aea7d5be005\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-r625j\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-20-62-19.us-east-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-r625j\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-r625j\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-10T00:24:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-10T00:24:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-10T00:24:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-10T00:24:28Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://d0911ab3f62d9b99f4c3e40398081645a9e58a992df1978460b4c30ab2db82c4\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-10T00:24:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.62.19\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.143\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-10T00:24:28Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 10 00:24:34.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 replace -f - --namespace=kubectl-9473'
Sep 10 00:24:34.266: INFO: stderr: ""
Sep 10 00:24:34.266: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep 10 00:24:34.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete pods e2e-test-nginx-pod --namespace=kubectl-9473'
Sep 10 00:24:41.519: INFO: stderr: ""
Sep 10 00:24:41.519: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:41.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9473" for this suite.
Sep 10 00:24:47.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:47.590: INFO: namespace kubectl-9473 deletion completed in 6.068705943s

• [SLOW TEST:18.693 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:47.590: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 10 00:24:47.613: INFO: Waiting up to 5m0s for pod "pod-5592bab9-62e6-482c-945d-5da5047691ea" in namespace "emptydir-8066" to be "success or failure"
Sep 10 00:24:47.617: INFO: Pod "pod-5592bab9-62e6-482c-945d-5da5047691ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.894559ms
Sep 10 00:24:49.620: INFO: Pod "pod-5592bab9-62e6-482c-945d-5da5047691ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006694899s
STEP: Saw pod success
Sep 10 00:24:49.620: INFO: Pod "pod-5592bab9-62e6-482c-945d-5da5047691ea" satisfied condition "success or failure"
Sep 10 00:24:49.622: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-5592bab9-62e6-482c-945d-5da5047691ea container test-container: <nil>
STEP: delete the pod
Sep 10 00:24:49.641: INFO: Waiting for pod pod-5592bab9-62e6-482c-945d-5da5047691ea to disappear
Sep 10 00:24:49.643: INFO: Pod pod-5592bab9-62e6-482c-945d-5da5047691ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:49.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8066" for this suite.
Sep 10 00:24:55.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:24:55.725: INFO: namespace emptydir-8066 deletion completed in 6.079415667s

• [SLOW TEST:8.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:24:55.725: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:24:55.745: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:24:57.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3603" for this suite.
Sep 10 00:25:47.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:25:47.845: INFO: namespace pods-3603 deletion completed in 50.074556824s

• [SLOW TEST:52.120 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:25:47.845: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-194c64c1-cc21-434c-afc1-2eb4612d4f8c
STEP: Creating a pod to test consume secrets
Sep 10 00:25:47.870: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3" in namespace "projected-341" to be "success or failure"
Sep 10 00:25:47.872: INFO: Pod "pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.918297ms
Sep 10 00:25:49.875: INFO: Pod "pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004569796s
STEP: Saw pod success
Sep 10 00:25:49.875: INFO: Pod "pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3" satisfied condition "success or failure"
Sep 10 00:25:49.877: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:25:49.892: INFO: Waiting for pod pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3 to disappear
Sep 10 00:25:49.893: INFO: Pod pod-projected-secrets-7b82661d-89ab-4c93-8672-3a891b8a3fd3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:25:49.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-341" for this suite.
Sep 10 00:25:55.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:25:55.961: INFO: namespace projected-341 deletion completed in 6.06516682s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:25:55.962: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-d7036ccc-a292-46b0-b49b-1140376c588d
STEP: Creating a pod to test consume configMaps
Sep 10 00:25:55.986: INFO: Waiting up to 5m0s for pod "pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27" in namespace "configmap-2508" to be "success or failure"
Sep 10 00:25:55.991: INFO: Pod "pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.342416ms
Sep 10 00:25:57.993: INFO: Pod "pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006563726s
STEP: Saw pod success
Sep 10 00:25:57.993: INFO: Pod "pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27" satisfied condition "success or failure"
Sep 10 00:25:57.994: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:25:58.007: INFO: Waiting for pod pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27 to disappear
Sep 10 00:25:58.009: INFO: Pod pod-configmaps-f243c1a5-4fb2-4185-b229-61bf01ad3f27 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:25:58.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2508" for this suite.
Sep 10 00:26:04.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:26:04.093: INFO: namespace configmap-2508 deletion completed in 6.081823878s

• [SLOW TEST:8.131 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:26:04.093: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 10 00:26:08.201: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:08.203: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:10.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:10.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:12.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:12.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:14.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:14.206: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:16.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:16.206: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:18.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:18.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:20.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:20.206: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:22.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:22.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:24.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:24.206: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:26.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:26.206: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:28.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:28.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:30.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:30.205: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 10 00:26:32.203: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 10 00:26:32.205: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:26:32.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1102" for this suite.
Sep 10 00:26:54.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:26:54.275: INFO: namespace container-lifecycle-hook-1102 deletion completed in 22.062578628s

• [SLOW TEST:50.182 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:26:54.276: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 10 00:27:34.314: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0910 00:27:34.314326      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 10 00:27:34.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6727" for this suite.
Sep 10 00:27:40.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:27:40.385: INFO: namespace gc-6727 deletion completed in 6.068908581s

• [SLOW TEST:46.109 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:27:40.386: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:27:40.404: INFO: Creating deployment "nginx-deployment"
Sep 10 00:27:40.407: INFO: Waiting for observed generation 1
Sep 10 00:27:42.412: INFO: Waiting for all required pods to come up
Sep 10 00:27:42.414: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 10 00:27:44.421: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 10 00:27:44.425: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 10 00:27:44.430: INFO: Updating deployment nginx-deployment
Sep 10 00:27:44.430: INFO: Waiting for observed generation 2
Sep 10 00:27:46.435: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 10 00:27:46.436: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 10 00:27:46.438: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 10 00:27:46.443: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 10 00:27:46.443: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 10 00:27:46.445: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 10 00:27:46.448: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 10 00:27:46.448: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 10 00:27:46.453: INFO: Updating deployment nginx-deployment
Sep 10 00:27:46.453: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 10 00:27:46.463: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 10 00:27:48.470: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 10 00:27:48.475: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-667,SelfLink:/apis/apps/v1/namespaces/deployment-667/deployments/nginx-deployment,UID:0107a9d1-4358-4b77-9c38-f4f8cd79987b,ResourceVersion:11771,Generation:3,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-09-10 00:27:46 +0000 UTC 2019-09-10 00:27:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-10 00:27:46 +0000 UTC 2019-09-10 00:27:40 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep 10 00:27:48.477: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-667,SelfLink:/apis/apps/v1/namespaces/deployment-667/replicasets/nginx-deployment-55fb7cb77f,UID:2cc2d303-5c31-491a-945d-fd17f7b98d26,ResourceVersion:11770,Generation:3,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0107a9d1-4358-4b77-9c38-f4f8cd79987b 0xc002add837 0xc002add838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 10 00:27:48.477: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 10 00:27:48.477: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-667,SelfLink:/apis/apps/v1/namespaces/deployment-667/replicasets/nginx-deployment-7b8c6f4498,UID:30577dc4-77e5-48ce-9451-6ca8107513d4,ResourceVersion:11765,Generation:3,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0107a9d1-4358-4b77-9c38-f4f8cd79987b 0xc002add907 0xc002add908}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-5kzzz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5kzzz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-5kzzz,UID:0b891049-9505-47ae-8a7f-18f9d544e924,ResourceVersion:11713,Generation:0,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a782e7 0xc001a782e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.160,StartTime:2019-09-10 00:27:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-7lw7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7lw7f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-7lw7f,UID:5782fdbb-3455-4be7-bb8b-44ce974ac884,ResourceVersion:11772,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78480 0xc001a78481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a784f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-8glk7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8glk7,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-8glk7,UID:c7f7d052-c496-4450-ad7c-5efee1c97d94,ResourceVersion:11766,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a785e0 0xc001a785e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-bqlsm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bqlsm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-bqlsm,UID:db88f5d5-aec3-4af8-823a-326d06889550,ResourceVersion:11759,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78770 0xc001a78771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a787e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-c5jw6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-c5jw6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-c5jw6,UID:9e4e47d2-29e7-4556-8976-847a10042240,ResourceVersion:11758,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78890 0xc001a78891}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-cpjtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cpjtp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-cpjtp,UID:21ba3121-e18d-470e-8688-2b9a26ef574f,ResourceVersion:11716,Generation:0,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a789a0 0xc001a789a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:100.96.2.101,StartTime:2019-09-10 00:27:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-gz7pm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gz7pm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-gz7pm,UID:87050173-7156-4ded-9003-e68e6e8f1b3c,ResourceVersion:11761,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78b30 0xc001a78b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-pl8hv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pl8hv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-pl8hv,UID:9f673965-a948-49fe-9b04-0bd60863073d,ResourceVersion:11781,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78c40 0xc001a78c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-qxnwp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qxnwp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-qxnwp,UID:b8f2a53b-5d52-4865-b850-7817efd93879,ResourceVersion:11752,Generation:0,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78da0 0xc001a78da1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.161,StartTime:2019-09-10 00:27:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.482: INFO: Pod "nginx-deployment-55fb7cb77f-r867p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r867p,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-r867p,UID:309ec4d8-5aa8-49b8-9cd7-5b3eba2ec8d3,ResourceVersion:11715,Generation:0,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a78f20 0xc001a78f21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a78f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a78fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:100.96.2.100,StartTime:2019-09-10 00:27:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-55fb7cb77f-szphw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-szphw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-szphw,UID:dfb3f69d-f991-4e7b-94f8-94c81b40c72f,ResourceVersion:11714,Generation:0,CreationTimestamp:2019-09-10 00:27:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a790a0 0xc001a790a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:44 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.159,StartTime:2019-09-10 00:27:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-55fb7cb77f-xprjv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-xprjv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-xprjv,UID:3cb97e89-8f52-4b5d-8496-732258fa5381,ResourceVersion:11768,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a79220 0xc001a79221}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a792b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-55fb7cb77f-z8zvs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-z8zvs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-55fb7cb77f-z8zvs,UID:5f729443-a0e7-42dc-8a9d-d9e778f5a211,ResourceVersion:11773,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 2cc2d303-5c31-491a-945d-fd17f7b98d26 0xc001a79330 0xc001a79331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a793a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a793c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-7b8c6f4498-2llkz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2llkz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-2llkz,UID:b7d86cc0-f8f1-4398-96f5-cb4005ad82da,ResourceVersion:11675,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79490 0xc001a79491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a794f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.154,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c7c0184ec2173721da3d445de274c7575bccff7b47a7d933b9b2ae2df6c3bfdd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-7b8c6f4498-4dkff" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4dkff,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-4dkff,UID:d0a46438-59af-4b2b-a6e9-5aa93f54fbd0,ResourceVersion:11664,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a795e7 0xc001a795e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.158,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e17ab056ca3996bd21fccd13a18cdfeb71d7a0c3e327f0cbaa120ef9c6c12e8f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-7b8c6f4498-87k5j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-87k5j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-87k5j,UID:3de0ac5d-b343-462b-9ee2-506cddbb494f,ResourceVersion:11763,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79747 0xc001a79748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a797b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a797d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.483: INFO: Pod "nginx-deployment-7b8c6f4498-9hx7d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9hx7d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-9hx7d,UID:22d05640-272d-4b93-b6d9-c9ac79dc118c,ResourceVersion:11780,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79850 0xc001a79851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a798b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a798d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.484: INFO: Pod "nginx-deployment-7b8c6f4498-cmhw9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cmhw9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-cmhw9,UID:22a7811c-d13e-43b3-b43a-f7aa90d5fb10,ResourceVersion:11756,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79997 0xc001a79998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79a20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.484: INFO: Pod "nginx-deployment-7b8c6f4498-ddmcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ddmcp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-ddmcp,UID:c4728f1a-21b1-4539-8783-0ae20917278c,ResourceVersion:11753,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79aa0 0xc001a79aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.484: INFO: Pod "nginx-deployment-7b8c6f4498-mfv79" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mfv79,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-mfv79,UID:a09cd9a9-87b4-4754-9e8a-794b928ab0d5,ResourceVersion:11767,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79be7 0xc001a79be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.484: INFO: Pod "nginx-deployment-7b8c6f4498-n5t2g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n5t2g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-n5t2g,UID:befaf8fe-20ea-4411-a800-9ee561efc17f,ResourceVersion:11776,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79cf0 0xc001a79cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-nrk2p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nrk2p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-nrk2p,UID:fcff21b8-b8f5-4560-91b6-436b5bc9db9f,ResourceVersion:11654,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79e37 0xc001a79e38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a79ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:100.96.2.97,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://719b860896fbb747bbc4304ddbcca68b13109119c750ff665c1c67a7732d0a69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-pw2xh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pw2xh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-pw2xh,UID:5d4594e5-d318-40f9-892a-5ad346df2858,ResourceVersion:11762,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc001a79f90 0xc001a79f91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a79ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-pzdmt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pzdmt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-pzdmt,UID:ab9dd5ed-05bf-4f97-a797-070d5a5d5cd6,ResourceVersion:11735,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e090 0xc003c3e091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-r4q6w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r4q6w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-r4q6w,UID:874a610a-027f-469f-a856-a72ddb802bc8,ResourceVersion:11779,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e1d7 0xc003c3e1d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-rkdlp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rkdlp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-rkdlp,UID:0f57a78a-3e01-48b7-87f3-406438369d4e,ResourceVersion:11672,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e327 0xc003c3e328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.156,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://233619c852867cdc99ca2d475175bd5abceeb12d9094d2145b1e1eddf6f91cfb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-rpbt2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rpbt2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-rpbt2,UID:ec92496c-a87e-487a-a4f2-47f0d26f4557,ResourceVersion:11651,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e487 0xc003c3e488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:100.96.2.96,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5f273a28ae6117e3a37b774d8b710a48819c5940bea08158888a928ecd0dc810}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-tfw5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tfw5s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-tfw5s,UID:50a66950-9c34-4262-ab5c-526c32596d8a,ResourceVersion:11782,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e5e0 0xc003c3e5e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-tggxz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tggxz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-tggxz,UID:8b21c8ae-768a-47ad-b374-1b56fadd7648,ResourceVersion:11777,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e727 0xc003c3e728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e7b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.485: INFO: Pod "nginx-deployment-7b8c6f4498-w95lc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w95lc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-w95lc,UID:ae89c660-4940-4c61-ad00-988d25330311,ResourceVersion:11661,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e877 0xc003c3e878}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3e8e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3e900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.155,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ac156df68f8409bafe669e3b176e99d7783f00786239e1f126a1895ef375690e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.486: INFO: Pod "nginx-deployment-7b8c6f4498-wg4rn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wg4rn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-wg4rn,UID:0855eaa4-e525-4f3e-ad5c-35a0a0c9d51e,ResourceVersion:11784,Generation:0,CreationTimestamp:2019-09-10 00:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3e9d7 0xc003c3e9d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3ea40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3ea60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:46 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:,StartTime:2019-09-10 00:27:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.486: INFO: Pod "nginx-deployment-7b8c6f4498-wvk8j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wvk8j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-wvk8j,UID:43611133-7a6e-44e9-80df-999bddccbde5,ResourceVersion:11657,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3eb27 0xc003c3eb28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-60-224.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3eb90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3ebb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.60.224,PodIP:100.96.2.99,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://391db4d574811384e0034344dd664202b34d325270a2922b070f2e05148c7105}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 10 00:27:48.486: INFO: Pod "nginx-deployment-7b8c6f4498-z4trm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z4trm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-667,SelfLink:/api/v1/namespaces/deployment-667/pods/nginx-deployment-7b8c6f4498-z4trm,UID:23aa329c-5154-4ad3-ad4f-11bdb0e09f5b,ResourceVersion:11646,Generation:0,CreationTimestamp:2019-09-10 00:27:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 30577dc4-77e5-48ce-9451-6ca8107513d4 0xc003c3ec80 0xc003c3ec81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t8g8x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t8g8x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t8g8x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3ece0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3ed00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:27:40 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.153,StartTime:2019-09-10 00:27:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-10 00:27:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b84d769b2b761672107747bb6b254e4fd918417248e13e985e6ec35a700b22d5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:27:48.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-667" for this suite.
Sep 10 00:27:54.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:27:54.549: INFO: namespace deployment-667 deletion completed in 6.061112304s

• [SLOW TEST:14.164 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:27:54.550: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d
Sep 10 00:27:54.575: INFO: Pod name my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d: Found 0 pods out of 1
Sep 10 00:27:59.577: INFO: Pod name my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d: Found 1 pods out of 1
Sep 10 00:27:59.577: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d" are running
Sep 10 00:28:01.581: INFO: Pod "my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d-8ntjj" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-10 00:27:54 +0000 UTC Reason: Message:}])
Sep 10 00:28:01.581: INFO: Trying to dial the pod
Sep 10 00:28:06.589: INFO: Controller my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d: Got expected result from replica 1 [my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d-8ntjj]: "my-hostname-basic-68192009-9cd4-4614-8c13-f0831c9eac5d-8ntjj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:28:06.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2853" for this suite.
Sep 10 00:28:12.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:28:12.664: INFO: namespace replication-controller-2853 deletion completed in 6.071665901s

• [SLOW TEST:18.113 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:28:12.664: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:28:12.688: INFO: (0) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.361691ms)
Sep 10 00:28:12.690: INFO: (1) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.238488ms)
Sep 10 00:28:12.692: INFO: (2) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.184636ms)
Sep 10 00:28:12.694: INFO: (3) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.098269ms)
Sep 10 00:28:12.697: INFO: (4) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.719619ms)
Sep 10 00:28:12.699: INFO: (5) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.149578ms)
Sep 10 00:28:12.701: INFO: (6) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.252312ms)
Sep 10 00:28:12.704: INFO: (7) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.210962ms)
Sep 10 00:28:12.706: INFO: (8) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.496066ms)
Sep 10 00:28:12.708: INFO: (9) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.268038ms)
Sep 10 00:28:12.711: INFO: (10) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.239288ms)
Sep 10 00:28:12.713: INFO: (11) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.288172ms)
Sep 10 00:28:12.715: INFO: (12) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.241548ms)
Sep 10 00:28:12.718: INFO: (13) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.491979ms)
Sep 10 00:28:12.720: INFO: (14) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.070411ms)
Sep 10 00:28:12.722: INFO: (15) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.199369ms)
Sep 10 00:28:12.724: INFO: (16) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.22685ms)
Sep 10 00:28:12.727: INFO: (17) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.252801ms)
Sep 10 00:28:12.729: INFO: (18) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.184985ms)
Sep 10 00:28:12.731: INFO: (19) /api/v1/nodes/ip-172-20-60-224.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.165831ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:28:12.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5679" for this suite.
Sep 10 00:28:18.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:28:18.795: INFO: namespace proxy-5679 deletion completed in 6.062508963s

• [SLOW TEST:6.131 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:28:18.796: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:29:18.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-763" for this suite.
Sep 10 00:29:40.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:29:40.887: INFO: namespace container-probe-763 deletion completed in 22.065963948s

• [SLOW TEST:82.091 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:29:40.887: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 10 00:29:40.908: INFO: Waiting up to 5m0s for pod "pod-6f337627-1687-4992-9cc6-bc1558161164" in namespace "emptydir-9407" to be "success or failure"
Sep 10 00:29:40.910: INFO: Pod "pod-6f337627-1687-4992-9cc6-bc1558161164": Phase="Pending", Reason="", readiness=false. Elapsed: 1.882116ms
Sep 10 00:29:42.913: INFO: Pod "pod-6f337627-1687-4992-9cc6-bc1558161164": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004676606s
STEP: Saw pod success
Sep 10 00:29:42.913: INFO: Pod "pod-6f337627-1687-4992-9cc6-bc1558161164" satisfied condition "success or failure"
Sep 10 00:29:42.915: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-6f337627-1687-4992-9cc6-bc1558161164 container test-container: <nil>
STEP: delete the pod
Sep 10 00:29:42.930: INFO: Waiting for pod pod-6f337627-1687-4992-9cc6-bc1558161164 to disappear
Sep 10 00:29:42.932: INFO: Pod pod-6f337627-1687-4992-9cc6-bc1558161164 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:29:42.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9407" for this suite.
Sep 10 00:29:48.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:29:49.011: INFO: namespace emptydir-9407 deletion completed in 6.076058324s

• [SLOW TEST:8.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:29:49.012: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 10 00:29:49.070: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:49.072: INFO: Number of nodes with available pods: 0
Sep 10 00:29:49.072: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:50.075: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:50.076: INFO: Number of nodes with available pods: 1
Sep 10 00:29:50.076: INFO: Node ip-172-20-60-224.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:51.075: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:51.077: INFO: Number of nodes with available pods: 2
Sep 10 00:29:51.077: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 10 00:29:51.088: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:51.089: INFO: Number of nodes with available pods: 1
Sep 10 00:29:51.089: INFO: Node ip-172-20-62-19.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:52.092: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:52.094: INFO: Number of nodes with available pods: 1
Sep 10 00:29:52.094: INFO: Node ip-172-20-62-19.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:53.092: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:53.094: INFO: Number of nodes with available pods: 1
Sep 10 00:29:53.094: INFO: Node ip-172-20-62-19.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:54.092: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:54.094: INFO: Number of nodes with available pods: 1
Sep 10 00:29:54.094: INFO: Node ip-172-20-62-19.us-east-2.compute.internal is running more than one daemon pod
Sep 10 00:29:55.092: INFO: DaemonSet pods can't tolerate node ip-172-20-57-181.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 10 00:29:55.094: INFO: Number of nodes with available pods: 2
Sep 10 00:29:55.094: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2291, will wait for the garbage collector to delete the pods
Sep 10 00:29:55.151: INFO: Deleting DaemonSet.extensions daemon-set took: 3.748182ms
Sep 10 00:29:55.451: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.220286ms
Sep 10 00:30:08.653: INFO: Number of nodes with available pods: 0
Sep 10 00:30:08.653: INFO: Number of running nodes: 0, number of available pods: 0
Sep 10 00:30:08.655: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2291/daemonsets","resourceVersion":"12223"},"items":null}

Sep 10 00:30:08.656: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2291/pods","resourceVersion":"12223"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:30:08.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2291" for this suite.
Sep 10 00:30:14.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:30:14.728: INFO: namespace daemonsets-2291 deletion completed in 6.064773583s

• [SLOW TEST:25.716 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:30:14.729: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:30:14.749: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296" in namespace "projected-9856" to be "success or failure"
Sep 10 00:30:14.751: INFO: Pod "downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060302ms
Sep 10 00:30:16.754: INFO: Pod "downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00465502s
STEP: Saw pod success
Sep 10 00:30:16.754: INFO: Pod "downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296" satisfied condition "success or failure"
Sep 10 00:30:16.755: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296 container client-container: <nil>
STEP: delete the pod
Sep 10 00:30:16.768: INFO: Waiting for pod downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296 to disappear
Sep 10 00:30:16.770: INFO: Pod downwardapi-volume-31abff4b-c7e9-451d-b10c-837616401296 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:30:16.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9856" for this suite.
Sep 10 00:30:22.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:30:22.833: INFO: namespace projected-9856 deletion completed in 6.060767951s

• [SLOW TEST:8.104 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:30:22.833: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:30:22.854: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c" in namespace "projected-7839" to be "success or failure"
Sep 10 00:30:22.856: INFO: Pod "downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404516ms
Sep 10 00:30:24.858: INFO: Pod "downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004545176s
STEP: Saw pod success
Sep 10 00:30:24.858: INFO: Pod "downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c" satisfied condition "success or failure"
Sep 10 00:30:24.860: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c container client-container: <nil>
STEP: delete the pod
Sep 10 00:30:24.881: INFO: Waiting for pod downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c to disappear
Sep 10 00:30:24.882: INFO: Pod downwardapi-volume-b6bc5c32-444f-4021-af70-a19436e81b7c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:30:24.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7839" for this suite.
Sep 10 00:30:30.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:30:30.959: INFO: namespace projected-7839 deletion completed in 6.074165364s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:30:30.961: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-e9953c9d-4f66-4764-9948-fe18b8396714 in namespace container-probe-7887
Sep 10 00:30:32.996: INFO: Started pod liveness-e9953c9d-4f66-4764-9948-fe18b8396714 in namespace container-probe-7887
STEP: checking the pod's current state and verifying that restartCount is present
Sep 10 00:30:32.997: INFO: Initial restart count of pod liveness-e9953c9d-4f66-4764-9948-fe18b8396714 is 0
Sep 10 00:30:55.028: INFO: Restart count of pod container-probe-7887/liveness-e9953c9d-4f66-4764-9948-fe18b8396714 is now 1 (22.030133138s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:30:55.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7887" for this suite.
Sep 10 00:31:01.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:31:01.099: INFO: namespace container-probe-7887 deletion completed in 6.062607395s

• [SLOW TEST:30.138 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:31:01.099: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-79e97771-329d-4fae-bcfe-d9883656a5ac
STEP: Creating a pod to test consume configMaps
Sep 10 00:31:01.123: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7" in namespace "projected-8274" to be "success or failure"
Sep 10 00:31:01.128: INFO: Pod "pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.034786ms
Sep 10 00:31:03.130: INFO: Pod "pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007349482s
STEP: Saw pod success
Sep 10 00:31:03.130: INFO: Pod "pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7" satisfied condition "success or failure"
Sep 10 00:31:03.132: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:31:03.143: INFO: Waiting for pod pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7 to disappear
Sep 10 00:31:03.145: INFO: Pod pod-projected-configmaps-4e08c042-e2e8-47e1-ada9-266c83092ce7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:31:03.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8274" for this suite.
Sep 10 00:31:09.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:31:09.211: INFO: namespace projected-8274 deletion completed in 6.064618338s

• [SLOW TEST:8.112 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:31:09.212: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2793
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-2793
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2793
Sep 10 00:31:09.242: INFO: Found 0 stateful pods, waiting for 1
Sep 10 00:31:19.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 10 00:31:19.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:31:19.414: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:31:19.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:31:19.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 10 00:31:19.416: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 10 00:31:29.419: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 10 00:31:29.419: INFO: Waiting for statefulset status.replicas updated to 0
Sep 10 00:31:29.428: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep 10 00:31:29.428: INFO: ss-0  ip-172-20-60-224.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  }]
Sep 10 00:31:29.428: INFO: 
Sep 10 00:31:29.428: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 10 00:31:30.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997280831s
Sep 10 00:31:31.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994664155s
Sep 10 00:31:32.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991136086s
Sep 10 00:31:33.440: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98821152s
Sep 10 00:31:34.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985330677s
Sep 10 00:31:35.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982494581s
Sep 10 00:31:36.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979792644s
Sep 10 00:31:37.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976626695s
Sep 10 00:31:38.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 974.110855ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2793
Sep 10 00:31:39.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:31:39.614: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 10 00:31:39.614: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 10 00:31:39.614: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 10 00:31:39.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:31:39.781: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 10 00:31:39.782: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 10 00:31:39.782: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 10 00:31:39.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:31:39.943: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 10 00:31:39.943: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 10 00:31:39.943: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 10 00:31:39.945: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 10 00:31:49.948: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 10 00:31:49.948: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 10 00:31:49.948: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 10 00:31:49.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:31:50.106: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:31:50.106: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:31:50.106: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 10 00:31:50.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:31:50.275: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:31:50.275: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:31:50.275: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 10 00:31:50.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 10 00:31:50.436: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 10 00:31:50.436: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 10 00:31:50.436: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 10 00:31:50.436: INFO: Waiting for statefulset status.replicas updated to 0
Sep 10 00:31:50.439: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 10 00:32:00.443: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 10 00:32:00.443: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 10 00:32:00.443: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 10 00:32:00.450: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep 10 00:32:00.450: INFO: ss-0  ip-172-20-60-224.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  }]
Sep 10 00:32:00.450: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:00.450: INFO: ss-2  ip-172-20-62-19.us-east-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:00.450: INFO: 
Sep 10 00:32:00.450: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 10 00:32:01.452: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep 10 00:32:01.453: INFO: ss-0  ip-172-20-60-224.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  }]
Sep 10 00:32:01.453: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:01.453: INFO: ss-2  ip-172-20-62-19.us-east-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:01.453: INFO: 
Sep 10 00:32:01.453: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 10 00:32:02.455: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Sep 10 00:32:02.455: INFO: ss-0  ip-172-20-60-224.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:09 +0000 UTC  }]
Sep 10 00:32:02.455: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:02.455: INFO: 
Sep 10 00:32:02.455: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 10 00:32:03.458: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:03.458: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:03.458: INFO: 
Sep 10 00:32:03.458: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:04.463: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:04.463: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:04.463: INFO: 
Sep 10 00:32:04.463: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:05.466: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:05.466: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:05.466: INFO: 
Sep 10 00:32:05.466: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:06.469: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:06.470: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:06.470: INFO: 
Sep 10 00:32:06.470: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:07.477: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:07.477: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:07.477: INFO: 
Sep 10 00:32:07.477: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:08.479: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:08.479: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:08.479: INFO: 
Sep 10 00:32:08.479: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 10 00:32:09.482: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Sep 10 00:32:09.482: INFO: ss-1  ip-172-20-62-19.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:31:29 +0000 UTC  }]
Sep 10 00:32:09.482: INFO: 
Sep 10 00:32:09.482: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2793
Sep 10 00:32:10.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:32:10.576: INFO: rc: 1
Sep 10 00:32:10.576: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002a65080 exit status 1 <nil> <nil> true [0xc00197e418 0xc00197e430 0xc00197e448] [0xc00197e418 0xc00197e430 0xc00197e448] [0xc00197e428 0xc00197e440] [0x9d21f0 0x9d21f0] 0xc003fc08a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Sep 10 00:32:20.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:32:20.826: INFO: rc: 1
Sep 10 00:32:20.826: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a653e0 exit status 1 <nil> <nil> true [0xc00197e450 0xc00197e478 0xc00197e4b8] [0xc00197e450 0xc00197e478 0xc00197e4b8] [0xc00197e470 0xc00197e4a8] [0x9d21f0 0x9d21f0] 0xc003fc10e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:32:30.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:32:30.893: INFO: rc: 1
Sep 10 00:32:30.893: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003f90480 exit status 1 <nil> <nil> true [0xc002e421b8 0xc002e421d0 0xc002e421e8] [0xc002e421b8 0xc002e421d0 0xc002e421e8] [0xc002e421c8 0xc002e421e0] [0x9d21f0 0x9d21f0] 0xc00263b620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:32:40.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:32:40.960: INFO: rc: 1
Sep 10 00:32:40.960: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a65740 exit status 1 <nil> <nil> true [0xc00197e4d0 0xc00197e4f8 0xc00197e520] [0xc00197e4d0 0xc00197e4f8 0xc00197e520] [0xc00197e4e0 0xc00197e518] [0x9d21f0 0x9d21f0] 0xc003fc17a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:32:50.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:32:51.028: INFO: rc: 1
Sep 10 00:32:51.028: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003f907b0 exit status 1 <nil> <nil> true [0xc002e421f0 0xc002e42208 0xc002e42220] [0xc002e421f0 0xc002e42208 0xc002e42220] [0xc002e42200 0xc002e42218] [0x9d21f0 0x9d21f0] 0xc00263b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:01.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:01.094: INFO: rc: 1
Sep 10 00:33:01.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a65c80 exit status 1 <nil> <nil> true [0xc00197e530 0xc00197e570 0xc00197e5a0] [0xc00197e530 0xc00197e570 0xc00197e5a0] [0xc00197e558 0xc00197e588] [0x9d21f0 0x9d21f0] 0xc003fc1ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:11.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:11.162: INFO: rc: 1
Sep 10 00:33:11.162: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003cec000 exit status 1 <nil> <nil> true [0xc00197e5b0 0xc00197e5f8 0xc00197e648] [0xc00197e5b0 0xc00197e5f8 0xc00197e648] [0xc00197e5e0 0xc00197e630] [0x9d21f0 0x9d21f0] 0xc002346d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:21.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:21.232: INFO: rc: 1
Sep 10 00:33:21.232: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003f90b70 exit status 1 <nil> <nil> true [0xc002e42228 0xc002e42240 0xc002e42258] [0xc002e42228 0xc002e42240 0xc002e42258] [0xc002e42238 0xc002e42250] [0x9d21f0 0x9d21f0] 0xc00263be60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:31.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:31.298: INFO: rc: 1
Sep 10 00:33:31.298: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003cec390 exit status 1 <nil> <nil> true [0xc00197e650 0xc00197e678 0xc00197e6c8] [0xc00197e650 0xc00197e678 0xc00197e6c8] [0xc00197e670 0xc00197e6b0] [0x9d21f0 0x9d21f0] 0xc002347b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:41.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:41.367: INFO: rc: 1
Sep 10 00:33:41.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a64300 exit status 1 <nil> <nil> true [0xc00197e028 0xc00197e040 0xc00197e070] [0xc00197e028 0xc00197e040 0xc00197e070] [0xc00197e038 0xc00197e060] [0x9d21f0 0x9d21f0] 0xc003fc02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:33:51.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:33:51.437: INFO: rc: 1
Sep 10 00:33:51.437: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afe330 exit status 1 <nil> <nil> true [0xc002e42000 0xc002e42018 0xc002e42030] [0xc002e42000 0xc002e42018 0xc002e42030] [0xc002e42010 0xc002e42028] [0x9d21f0 0x9d21f0] 0xc001eae360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:01.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:01.525: INFO: rc: 1
Sep 10 00:34:01.525: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a64690 exit status 1 <nil> <nil> true [0xc00197e090 0xc00197e0d0 0xc00197e0e8] [0xc00197e090 0xc00197e0d0 0xc00197e0e8] [0xc00197e0b8 0xc00197e0e0] [0x9d21f0 0x9d21f0] 0xc003fc0720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:11.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:11.593: INFO: rc: 1
Sep 10 00:34:11.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afe6c0 exit status 1 <nil> <nil> true [0xc002e42038 0xc002e42050 0xc002e42068] [0xc002e42038 0xc002e42050 0xc002e42068] [0xc002e42048 0xc002e42060] [0x9d21f0 0x9d21f0] 0xc001eae720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:21.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:21.660: INFO: rc: 1
Sep 10 00:34:21.660: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afea50 exit status 1 <nil> <nil> true [0xc002e42070 0xc002e42088 0xc002e420a0] [0xc002e42070 0xc002e42088 0xc002e420a0] [0xc002e42080 0xc002e42098] [0x9d21f0 0x9d21f0] 0xc001eaeae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:31.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:31.729: INFO: rc: 1
Sep 10 00:34:31.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a649f0 exit status 1 <nil> <nil> true [0xc00197e0f0 0xc00197e110 0xc00197e128] [0xc00197e0f0 0xc00197e110 0xc00197e128] [0xc00197e108 0xc00197e120] [0x9d21f0 0x9d21f0] 0xc003fc0f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:41.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:41.794: INFO: rc: 1
Sep 10 00:34:41.794: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afef00 exit status 1 <nil> <nil> true [0xc002e420a8 0xc002e420c0 0xc002e420d8] [0xc002e420a8 0xc002e420c0 0xc002e420d8] [0xc002e420b8 0xc002e420d0] [0x9d21f0 0x9d21f0] 0xc001eaef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:34:51.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:34:51.862: INFO: rc: 1
Sep 10 00:34:51.862: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff2f0 exit status 1 <nil> <nil> true [0xc002e420e0 0xc002e420f8 0xc002e42110] [0xc002e420e0 0xc002e420f8 0xc002e42110] [0xc002e420f0 0xc002e42108] [0x9d21f0 0x9d21f0] 0xc001eaf2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:01.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:01.929: INFO: rc: 1
Sep 10 00:35:01.929: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff650 exit status 1 <nil> <nil> true [0xc002e42118 0xc002e42130 0xc002e42148] [0xc002e42118 0xc002e42130 0xc002e42148] [0xc002e42128 0xc002e42140] [0x9d21f0 0x9d21f0] 0xc001eaf740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:11.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:11.996: INFO: rc: 1
Sep 10 00:35:11.996: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a64f60 exit status 1 <nil> <nil> true [0xc00197e130 0xc00197e148 0xc00197e160] [0xc00197e130 0xc00197e148 0xc00197e160] [0xc00197e140 0xc00197e158] [0x9d21f0 0x9d21f0] 0xc003fc1620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:21.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:22.067: INFO: rc: 1
Sep 10 00:35:22.067: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff9b0 exit status 1 <nil> <nil> true [0xc002e42150 0xc002e42168 0xc002e42180] [0xc002e42150 0xc002e42168 0xc002e42180] [0xc002e42160 0xc002e42178] [0x9d21f0 0x9d21f0] 0xc001eafbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:32.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:32.136: INFO: rc: 1
Sep 10 00:35:32.136: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001affd10 exit status 1 <nil> <nil> true [0xc002e42188 0xc002e421a0 0xc002e421b8] [0xc002e42188 0xc002e421a0 0xc002e421b8] [0xc002e42198 0xc002e421b0] [0x9d21f0 0x9d21f0] 0xc0023461e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:42.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:42.211: INFO: rc: 1
Sep 10 00:35:42.211: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001affd40 exit status 1 <nil> <nil> true [0xc00197e168 0xc00197e180 0xc00197e198] [0xc00197e168 0xc00197e180 0xc00197e198] [0xc00197e178 0xc00197e190] [0x9d21f0 0x9d21f0] 0xc002346420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:35:52.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:35:52.277: INFO: rc: 1
Sep 10 00:35:52.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afe360 exit status 1 <nil> <nil> true [0xc002e42008 0xc002e42020 0xc002e42038] [0xc002e42008 0xc002e42020 0xc002e42038] [0xc002e42018 0xc002e42030] [0x9d21f0 0x9d21f0] 0xc001eae360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:02.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:02.342: INFO: rc: 1
Sep 10 00:36:02.342: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afe6f0 exit status 1 <nil> <nil> true [0xc002e42040 0xc002e42058 0xc002e42070] [0xc002e42040 0xc002e42058 0xc002e42070] [0xc002e42050 0xc002e42068] [0x9d21f0 0x9d21f0] 0xc001eae720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:12.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:12.410: INFO: rc: 1
Sep 10 00:36:12.410: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001afeab0 exit status 1 <nil> <nil> true [0xc002e42078 0xc002e42090 0xc002e420a8] [0xc002e42078 0xc002e42090 0xc002e420a8] [0xc002e42088 0xc002e420a0] [0x9d21f0 0x9d21f0] 0xc001eaeae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:22.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:22.476: INFO: rc: 1
Sep 10 00:36:22.477: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002a64390 exit status 1 <nil> <nil> true [0xc00197e020 0xc00197e038 0xc00197e060] [0xc00197e020 0xc00197e038 0xc00197e060] [0xc00197e030 0xc00197e048] [0x9d21f0 0x9d21f0] 0xc0023471a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:32.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:32.543: INFO: rc: 1
Sep 10 00:36:32.543: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff020 exit status 1 <nil> <nil> true [0xc002e420b0 0xc002e420c8 0xc002e420e0] [0xc002e420b0 0xc002e420c8 0xc002e420e0] [0xc002e420c0 0xc002e420d8] [0x9d21f0 0x9d21f0] 0xc001eaef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:42.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:42.611: INFO: rc: 1
Sep 10 00:36:42.611: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff3b0 exit status 1 <nil> <nil> true [0xc002e420e8 0xc002e42100 0xc002e42118] [0xc002e420e8 0xc002e42100 0xc002e42118] [0xc002e420f8 0xc002e42110] [0x9d21f0 0x9d21f0] 0xc001eaf2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:36:52.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:36:52.681: INFO: rc: 1
Sep 10 00:36:52.681: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001aff740 exit status 1 <nil> <nil> true [0xc002e42120 0xc002e42138 0xc002e42150] [0xc002e42120 0xc002e42138 0xc002e42150] [0xc002e42130 0xc002e42148] [0x9d21f0 0x9d21f0] 0xc001eaf740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:37:02.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:37:02.753: INFO: rc: 1
Sep 10 00:37:02.753: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001affad0 exit status 1 <nil> <nil> true [0xc002e42158 0xc002e42170 0xc002e42188] [0xc002e42158 0xc002e42170 0xc002e42188] [0xc002e42168 0xc002e42180] [0x9d21f0 0x9d21f0] 0xc001eafbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Sep 10 00:37:12.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 exec --namespace=statefulset-2793 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 10 00:37:12.818: INFO: rc: 1
Sep 10 00:37:12.818: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Sep 10 00:37:12.818: INFO: Scaling statefulset ss to 0
Sep 10 00:37:12.824: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 10 00:37:12.825: INFO: Deleting all statefulset in ns statefulset-2793
Sep 10 00:37:12.827: INFO: Scaling statefulset ss to 0
Sep 10 00:37:12.832: INFO: Waiting for statefulset status.replicas updated to 0
Sep 10 00:37:12.833: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:37:12.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2793" for this suite.
Sep 10 00:37:18.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:37:18.905: INFO: namespace statefulset-2793 deletion completed in 6.06197141s

• [SLOW TEST:369.693 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:37:18.905: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 10 00:37:18.930: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8567,SelfLink:/api/v1/namespaces/watch-8567/configmaps/e2e-watch-test-watch-closed,UID:246e07dd-0f9b-4f40-b42d-93fad0eaeeef,ResourceVersion:12999,Generation:0,CreationTimestamp:2019-09-10 00:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 10 00:37:18.930: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8567,SelfLink:/api/v1/namespaces/watch-8567/configmaps/e2e-watch-test-watch-closed,UID:246e07dd-0f9b-4f40-b42d-93fad0eaeeef,ResourceVersion:13000,Generation:0,CreationTimestamp:2019-09-10 00:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 10 00:37:18.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8567,SelfLink:/api/v1/namespaces/watch-8567/configmaps/e2e-watch-test-watch-closed,UID:246e07dd-0f9b-4f40-b42d-93fad0eaeeef,ResourceVersion:13001,Generation:0,CreationTimestamp:2019-09-10 00:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 10 00:37:18.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8567,SelfLink:/api/v1/namespaces/watch-8567/configmaps/e2e-watch-test-watch-closed,UID:246e07dd-0f9b-4f40-b42d-93fad0eaeeef,ResourceVersion:13002,Generation:0,CreationTimestamp:2019-09-10 00:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:37:18.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8567" for this suite.
Sep 10 00:37:24.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:37:25.008: INFO: namespace watch-8567 deletion completed in 6.067781733s

• [SLOW TEST:6.103 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:37:25.009: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep 10 00:37:25.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-1630'
Sep 10 00:37:25.189: INFO: stderr: ""
Sep 10 00:37:25.189: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:37:25.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1630'
Sep 10 00:37:25.260: INFO: stderr: ""
Sep 10 00:37:25.260: INFO: stdout: "update-demo-nautilus-ps8qx update-demo-nautilus-zhwps "
Sep 10 00:37:25.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-ps8qx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:25.336: INFO: stderr: ""
Sep 10 00:37:25.336: INFO: stdout: ""
Sep 10 00:37:25.336: INFO: update-demo-nautilus-ps8qx is created but not running
Sep 10 00:37:30.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1630'
Sep 10 00:37:30.406: INFO: stderr: ""
Sep 10 00:37:30.406: INFO: stdout: "update-demo-nautilus-ps8qx update-demo-nautilus-zhwps "
Sep 10 00:37:30.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-ps8qx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:30.470: INFO: stderr: ""
Sep 10 00:37:30.470: INFO: stdout: "true"
Sep 10 00:37:30.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-ps8qx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:30.535: INFO: stderr: ""
Sep 10 00:37:30.535: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:37:30.535: INFO: validating pod update-demo-nautilus-ps8qx
Sep 10 00:37:30.539: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:37:30.539: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:37:30.539: INFO: update-demo-nautilus-ps8qx is verified up and running
Sep 10 00:37:30.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-zhwps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:30.604: INFO: stderr: ""
Sep 10 00:37:30.604: INFO: stdout: "true"
Sep 10 00:37:30.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-zhwps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:30.672: INFO: stderr: ""
Sep 10 00:37:30.672: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:37:30.672: INFO: validating pod update-demo-nautilus-zhwps
Sep 10 00:37:30.675: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:37:30.675: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:37:30.675: INFO: update-demo-nautilus-zhwps is verified up and running
STEP: rolling-update to new replication controller
Sep 10 00:37:30.676: INFO: scanned /root for discovery docs: <nil>
Sep 10 00:37:30.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1630'
Sep 10 00:37:52.968: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 10 00:37:52.968: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:37:52.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1630'
Sep 10 00:37:53.034: INFO: stderr: ""
Sep 10 00:37:53.034: INFO: stdout: "update-demo-kitten-hsgj5 update-demo-kitten-vrdh9 "
Sep 10 00:37:53.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-kitten-hsgj5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:53.098: INFO: stderr: ""
Sep 10 00:37:53.098: INFO: stdout: "true"
Sep 10 00:37:53.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-kitten-hsgj5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:53.162: INFO: stderr: ""
Sep 10 00:37:53.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 10 00:37:53.162: INFO: validating pod update-demo-kitten-hsgj5
Sep 10 00:37:53.165: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 10 00:37:53.165: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 10 00:37:53.165: INFO: update-demo-kitten-hsgj5 is verified up and running
Sep 10 00:37:53.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-kitten-vrdh9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:53.229: INFO: stderr: ""
Sep 10 00:37:53.229: INFO: stdout: "true"
Sep 10 00:37:53.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-kitten-vrdh9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1630'
Sep 10 00:37:53.292: INFO: stderr: ""
Sep 10 00:37:53.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 10 00:37:53.292: INFO: validating pod update-demo-kitten-vrdh9
Sep 10 00:37:53.295: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 10 00:37:53.295: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 10 00:37:53.295: INFO: update-demo-kitten-vrdh9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:37:53.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1630" for this suite.
Sep 10 00:38:15.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:38:15.358: INFO: namespace kubectl-1630 deletion completed in 22.060440298s

• [SLOW TEST:50.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:38:15.359: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-90f1d33b-bf3f-4cd3-af04-7608a3081f33
STEP: Creating a pod to test consume secrets
Sep 10 00:38:15.383: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390" in namespace "projected-6369" to be "success or failure"
Sep 10 00:38:15.386: INFO: Pod "pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390": Phase="Pending", Reason="", readiness=false. Elapsed: 3.267972ms
Sep 10 00:38:17.393: INFO: Pod "pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00999858s
STEP: Saw pod success
Sep 10 00:38:17.393: INFO: Pod "pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390" satisfied condition "success or failure"
Sep 10 00:38:17.399: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:38:17.412: INFO: Waiting for pod pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390 to disappear
Sep 10 00:38:17.414: INFO: Pod pod-projected-secrets-c17b240e-f6d7-4980-9466-954823122390 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:38:17.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6369" for this suite.
Sep 10 00:38:23.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:38:23.475: INFO: namespace projected-6369 deletion completed in 6.059786682s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:38:23.476: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep 10 00:38:23.497: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1892" to be "success or failure"
Sep 10 00:38:23.501: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.80379ms
Sep 10 00:38:25.504: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006334147s
STEP: Saw pod success
Sep 10 00:38:25.504: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 10 00:38:25.506: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 10 00:38:25.522: INFO: Waiting for pod pod-host-path-test to disappear
Sep 10 00:38:25.524: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:38:25.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1892" for this suite.
Sep 10 00:38:31.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:38:31.588: INFO: namespace hostpath-1892 deletion completed in 6.062348928s

• [SLOW TEST:8.113 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:38:31.589: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep 10 00:38:31.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 --namespace=kubectl-38 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 10 00:38:32.672: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 10 00:38:32.672: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:38:34.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-38" for this suite.
Sep 10 00:38:42.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:38:42.737: INFO: namespace kubectl-38 deletion completed in 8.059441189s

• [SLOW TEST:11.148 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:38:42.737: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6691.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6691.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6691.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6691.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6691.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6691.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 10 00:38:44.783: INFO: DNS probes using dns-6691/dns-test-23758155-ff19-447e-ab88-dfa39fff8517 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:38:44.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6691" for this suite.
Sep 10 00:38:50.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:38:50.856: INFO: namespace dns-6691 deletion completed in 6.062773379s

• [SLOW TEST:8.118 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:38:50.856: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 10 00:38:50.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-6248'
Sep 10 00:38:51.041: INFO: stderr: ""
Sep 10 00:38:51.041: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:38:51.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6248'
Sep 10 00:38:51.115: INFO: stderr: ""
Sep 10 00:38:51.115: INFO: stdout: "update-demo-nautilus-76pml update-demo-nautilus-v7p95 "
Sep 10 00:38:51.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-76pml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6248'
Sep 10 00:38:51.181: INFO: stderr: ""
Sep 10 00:38:51.181: INFO: stdout: ""
Sep 10 00:38:51.181: INFO: update-demo-nautilus-76pml is created but not running
Sep 10 00:38:56.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6248'
Sep 10 00:38:56.250: INFO: stderr: ""
Sep 10 00:38:56.250: INFO: stdout: "update-demo-nautilus-76pml update-demo-nautilus-v7p95 "
Sep 10 00:38:56.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-76pml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6248'
Sep 10 00:38:56.315: INFO: stderr: ""
Sep 10 00:38:56.315: INFO: stdout: "true"
Sep 10 00:38:56.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-76pml -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6248'
Sep 10 00:38:56.399: INFO: stderr: ""
Sep 10 00:38:56.399: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:38:56.399: INFO: validating pod update-demo-nautilus-76pml
Sep 10 00:38:56.402: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:38:56.402: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:38:56.402: INFO: update-demo-nautilus-76pml is verified up and running
Sep 10 00:38:56.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-v7p95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6248'
Sep 10 00:38:56.467: INFO: stderr: ""
Sep 10 00:38:56.467: INFO: stdout: "true"
Sep 10 00:38:56.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-v7p95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6248'
Sep 10 00:38:56.532: INFO: stderr: ""
Sep 10 00:38:56.532: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:38:56.532: INFO: validating pod update-demo-nautilus-v7p95
Sep 10 00:38:56.536: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:38:56.536: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:38:56.536: INFO: update-demo-nautilus-v7p95 is verified up and running
STEP: using delete to clean up resources
Sep 10 00:38:56.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-6248'
Sep 10 00:38:56.608: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:38:56.608: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 10 00:38:56.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6248'
Sep 10 00:38:56.739: INFO: stderr: "No resources found.\n"
Sep 10 00:38:56.740: INFO: stdout: ""
Sep 10 00:38:56.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -l name=update-demo --namespace=kubectl-6248 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 10 00:38:56.852: INFO: stderr: ""
Sep 10 00:38:56.852: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:38:56.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6248" for this suite.
Sep 10 00:39:18.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:39:18.918: INFO: namespace kubectl-6248 deletion completed in 22.063801838s

• [SLOW TEST:28.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:39:18.919: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-9a80c24a-f728-4e65-a38e-ac87cb8679a2
STEP: Creating a pod to test consume secrets
Sep 10 00:39:18.946: INFO: Waiting up to 5m0s for pod "pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74" in namespace "secrets-7259" to be "success or failure"
Sep 10 00:39:18.950: INFO: Pod "pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74": Phase="Pending", Reason="", readiness=false. Elapsed: 3.813258ms
Sep 10 00:39:20.952: INFO: Pod "pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005936037s
STEP: Saw pod success
Sep 10 00:39:20.952: INFO: Pod "pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74" satisfied condition "success or failure"
Sep 10 00:39:20.954: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74 container secret-env-test: <nil>
STEP: delete the pod
Sep 10 00:39:20.972: INFO: Waiting for pod pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74 to disappear
Sep 10 00:39:20.973: INFO: Pod pod-secrets-ec4023a9-5071-4b1b-a321-e583ac8d5d74 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:39:20.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7259" for this suite.
Sep 10 00:39:26.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:39:27.052: INFO: namespace secrets-7259 deletion completed in 6.076456174s

• [SLOW TEST:8.133 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:39:27.052: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep 10 00:39:27.077: INFO: Waiting up to 5m0s for pod "client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b" in namespace "containers-2753" to be "success or failure"
Sep 10 00:39:27.081: INFO: Pod "client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.687299ms
Sep 10 00:39:29.084: INFO: Pod "client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00716671s
STEP: Saw pod success
Sep 10 00:39:29.084: INFO: Pod "client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b" satisfied condition "success or failure"
Sep 10 00:39:29.086: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b container test-container: <nil>
STEP: delete the pod
Sep 10 00:39:29.100: INFO: Waiting for pod client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b to disappear
Sep 10 00:39:29.102: INFO: Pod client-containers-8d0ec8e4-bfd2-4e9e-9441-6f3e9bb3570b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:39:29.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2753" for this suite.
Sep 10 00:39:35.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:39:35.172: INFO: namespace containers-2753 deletion completed in 6.067468175s

• [SLOW TEST:8.120 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:39:35.172: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-6e837d1d-4460-4998-a7b4-abaeb346bb6d
STEP: Creating configMap with name cm-test-opt-upd-e11eb3c6-dde6-42c8-9482-12151bd0f53c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6e837d1d-4460-4998-a7b4-abaeb346bb6d
STEP: Updating configmap cm-test-opt-upd-e11eb3c6-dde6-42c8-9482-12151bd0f53c
STEP: Creating configMap with name cm-test-opt-create-c715de31-bf20-4286-889a-8ef9987ab062
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:41:09.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8253" for this suite.
Sep 10 00:41:31.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:41:31.625: INFO: namespace projected-8253 deletion completed in 22.060964639s

• [SLOW TEST:116.453 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:41:31.625: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:41:31.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6054" for this suite.
Sep 10 00:41:37.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:41:37.714: INFO: namespace services-6054 deletion completed in 6.06749646s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.089 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:41:37.714: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep 10 00:41:37.736: INFO: Waiting up to 5m0s for pod "client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab" in namespace "containers-7632" to be "success or failure"
Sep 10 00:41:37.738: INFO: Pod "client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265252ms
Sep 10 00:41:39.741: INFO: Pod "client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004429023s
STEP: Saw pod success
Sep 10 00:41:39.741: INFO: Pod "client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab" satisfied condition "success or failure"
Sep 10 00:41:39.742: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab container test-container: <nil>
STEP: delete the pod
Sep 10 00:41:39.753: INFO: Waiting for pod client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab to disappear
Sep 10 00:41:39.755: INFO: Pod client-containers-d281243d-5882-4b56-a29d-1cc4dd8e77ab no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:41:39.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7632" for this suite.
Sep 10 00:41:45.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:41:45.831: INFO: namespace containers-7632 deletion completed in 6.073128389s

• [SLOW TEST:8.116 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:41:45.831: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-7080ed01-abde-43f6-931f-56c0bf46816d
STEP: Creating a pod to test consume secrets
Sep 10 00:41:45.854: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237" in namespace "projected-2145" to be "success or failure"
Sep 10 00:41:45.856: INFO: Pod "pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237": Phase="Pending", Reason="", readiness=false. Elapsed: 2.331163ms
Sep 10 00:41:47.858: INFO: Pod "pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004380837s
STEP: Saw pod success
Sep 10 00:41:47.858: INFO: Pod "pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237" satisfied condition "success or failure"
Sep 10 00:41:47.860: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237 container secret-volume-test: <nil>
STEP: delete the pod
Sep 10 00:41:47.872: INFO: Waiting for pod pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237 to disappear
Sep 10 00:41:47.874: INFO: Pod pod-projected-secrets-ba9cbaf4-d4bc-4f54-8160-d89424d0f237 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:41:47.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2145" for this suite.
Sep 10 00:41:53.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:41:53.942: INFO: namespace projected-2145 deletion completed in 6.065777887s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:41:53.942: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:41:53.966: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 10 00:41:58.968: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 10 00:41:58.968: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 10 00:42:00.985: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-9061,SelfLink:/apis/apps/v1/namespaces/deployment-9061/deployments/test-cleanup-deployment,UID:15dd7fdf-9d62-401a-9c76-5700b1240432,ResourceVersion:13720,Generation:1,CreationTimestamp:2019-09-10 00:41:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-10 00:41:58 +0000 UTC 2019-09-10 00:41:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-10 00:42:00 +0000 UTC 2019-09-10 00:41:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 10 00:42:00.987: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-9061,SelfLink:/apis/apps/v1/namespaces/deployment-9061/replicasets/test-cleanup-deployment-55bbcbc84c,UID:fc1c06bf-81e1-4c22-873e-d9a79cb5b1d4,ResourceVersion:13713,Generation:1,CreationTimestamp:2019-09-10 00:41:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 15dd7fdf-9d62-401a-9c76-5700b1240432 0xc00385b9f7 0xc00385b9f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 10 00:42:00.989: INFO: Pod "test-cleanup-deployment-55bbcbc84c-c2gvr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-c2gvr,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-9061,SelfLink:/api/v1/namespaces/deployment-9061/pods/test-cleanup-deployment-55bbcbc84c-c2gvr,UID:66bfd4cb-1d3e-42fa-bc93-56421455a133,ResourceVersion:13712,Generation:0,CreationTimestamp:2019-09-10 00:41:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c fc1c06bf-81e1-4c22-873e-d9a79cb5b1d4 0xc002de0007 0xc002de0008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cls25 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cls25,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-cls25 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002de0070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002de0090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:41:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:42:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:42:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:41:58 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.190,StartTime:2019-09-10 00:41:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-10 00:41:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e689c883d4cd75395c72e8efdc738081849cf026c9e2426c5a844a975a851d11}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:42:00.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9061" for this suite.
Sep 10 00:42:06.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:42:07.056: INFO: namespace deployment-9061 deletion completed in 6.064823313s

• [SLOW TEST:13.114 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:42:07.056: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 10 00:42:07.080: INFO: Waiting up to 5m0s for pod "pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac" in namespace "emptydir-7328" to be "success or failure"
Sep 10 00:42:07.082: INFO: Pod "pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.82906ms
Sep 10 00:42:09.085: INFO: Pod "pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004518323s
STEP: Saw pod success
Sep 10 00:42:09.085: INFO: Pod "pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac" satisfied condition "success or failure"
Sep 10 00:42:09.086: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac container test-container: <nil>
STEP: delete the pod
Sep 10 00:42:09.100: INFO: Waiting for pod pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac to disappear
Sep 10 00:42:09.102: INFO: Pod pod-76ff9e73-181c-443b-a6ef-c83fddb7e9ac no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:42:09.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7328" for this suite.
Sep 10 00:42:15.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:42:15.164: INFO: namespace emptydir-7328 deletion completed in 6.059713001s

• [SLOW TEST:8.108 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:42:15.164: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 10 00:42:19.237: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:19.239: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:21.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:21.241: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:23.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:23.242: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:25.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:25.242: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:27.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:27.242: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:29.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:29.241: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:31.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:31.241: INFO: Pod pod-with-prestop-http-hook still exists
Sep 10 00:42:33.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 10 00:42:33.242: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:42:33.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6958" for this suite.
Sep 10 00:42:55.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:42:55.312: INFO: namespace container-lifecycle-hook-6958 deletion completed in 22.061691642s

• [SLOW TEST:40.148 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:42:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:42:55.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3461'
Sep 10 00:42:55.621: INFO: stderr: ""
Sep 10 00:42:55.621: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 10 00:42:55.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3461'
Sep 10 00:42:55.778: INFO: stderr: ""
Sep 10 00:42:55.778: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 10 00:42:56.780: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:42:56.780: INFO: Found 1 / 1
Sep 10 00:42:56.780: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 10 00:42:56.782: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:42:56.782: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 10 00:42:56.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 describe pod redis-master-9zjb9 --namespace=kubectl-3461'
Sep 10 00:42:56.857: INFO: stderr: ""
Sep 10 00:42:56.857: INFO: stdout: "Name:           redis-master-9zjb9\nNamespace:      kubectl-3461\nPriority:       0\nNode:           ip-172-20-62-19.us-east-2.compute.internal/172.20.62.19\nStart Time:     Tue, 10 Sep 2019 00:42:55 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             100.96.1.193\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a1fafde006504707eca5f39b3dbfa040bb353cf14746c6bb166fcd5fff516f10\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 10 Sep 2019 00:42:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hkdt7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hkdt7:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hkdt7\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  1s    default-scheduler                                    Successfully assigned kubectl-3461/redis-master-9zjb9 to ip-172-20-62-19.us-east-2.compute.internal\n  Normal  Pulled     0s    kubelet, ip-172-20-62-19.us-east-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, ip-172-20-62-19.us-east-2.compute.internal  Created container redis-master\n  Normal  Started    0s    kubelet, ip-172-20-62-19.us-east-2.compute.internal  Started container redis-master\n"
Sep 10 00:42:56.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 describe rc redis-master --namespace=kubectl-3461'
Sep 10 00:42:56.937: INFO: stderr: ""
Sep 10 00:42:56.937: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3461\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-9zjb9\n"
Sep 10 00:42:56.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 describe service redis-master --namespace=kubectl-3461'
Sep 10 00:42:57.011: INFO: stderr: ""
Sep 10 00:42:57.011: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3461\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.70.248.181\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.193:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 10 00:42:57.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 describe node ip-172-20-57-181.us-east-2.compute.internal'
Sep 10 00:42:57.105: INFO: stderr: ""
Sep 10 00:42:57.105: INFO: stdout: "Name:               ip-172-20-57-181.us-east-2.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c4.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-2\n                    failure-domain.beta.kubernetes.io/zone=us-east-2a\n                    kops.k8s.io/instancegroup=master-us-east-2a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-20-57-181.us-east-2.compute.internal\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 09 Sep 2019 23:21:27 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 09 Sep 2019 23:21:34 +0000   Mon, 09 Sep 2019 23:21:34 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 10 Sep 2019 00:42:50 +0000   Mon, 09 Sep 2019 23:21:27 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 10 Sep 2019 00:42:50 +0000   Mon, 09 Sep 2019 23:21:27 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 10 Sep 2019 00:42:50 +0000   Mon, 09 Sep 2019 23:21:27 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 10 Sep 2019 00:42:50 +0000   Mon, 09 Sep 2019 23:21:28 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   172.20.57.181\n  ExternalIP:   18.218.206.29\n  Hostname:     ip-172-20-57-181.us-east-2.compute.internal\n  InternalDNS:  ip-172-20-57-181.us-east-2.compute.internal\n  ExternalDNS:  ec2-18-218-206-29.us-east-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           62843416Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3857008Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           57916492090\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3754608Ki\n pods:                        110\nSystem Info:\n Machine ID:                 95d0a3920c9947049a815f85112ffa2d\n System UUID:                EC2D6480-714C-C5C9-7967-F4EA1A0DB8AC\n Boot ID:                    647e602e-89f4-4181-b536-48e87b24a3c8\n Kernel Version:             4.9.0-9-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nPodCIDR:                     100.96.0.0/24\nProviderID:                  aws:///us-east-2a/i-047580293dbb38381\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                   ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0795c71ba3af4099-lqqsr                0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  kube-system                dns-controller-7c77f9477f-k6z6l                                        50m (2%)      0 (0%)      50Mi (1%)        0 (0%)         81m\n  kube-system                etcd-manager-events-ip-172-20-57-181.us-east-2.compute.internal        100m (5%)     0 (0%)      100Mi (2%)       0 (0%)         80m\n  kube-system                etcd-manager-main-ip-172-20-57-181.us-east-2.compute.internal          200m (10%)    0 (0%)      100Mi (2%)       0 (0%)         80m\n  kube-system                kube-apiserver-ip-172-20-57-181.us-east-2.compute.internal             150m (7%)     0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                kube-controller-manager-ip-172-20-57-181.us-east-2.compute.internal    100m (5%)     0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                kube-proxy-ip-172-20-57-181.us-east-2.compute.internal                 100m (5%)     0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                kube-scheduler-ip-172-20-57-181.us-east-2.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)         80m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         800m (40%)  0 (0%)\n  memory                      250Mi (6%)  0 (0%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Sep 10 00:42:57.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 describe namespace kubectl-3461'
Sep 10 00:42:57.178: INFO: stderr: ""
Sep 10 00:42:57.178: INFO: stdout: "Name:         kubectl-3461\nLabels:       e2e-framework=kubectl\n              e2e-run=b17a4653-0b9a-4070-8a69-59385bdc6848\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:42:57.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3461" for this suite.
Sep 10 00:43:19.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:43:19.240: INFO: namespace kubectl-3461 deletion completed in 22.059881825s

• [SLOW TEST:23.928 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:43:19.241: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 10 00:43:21.784: INFO: Successfully updated pod "labelsupdatea0632193-240d-4f53-b9d5-36481595e698"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:43:25.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8446" for this suite.
Sep 10 00:43:47.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:43:47.875: INFO: namespace projected-8446 deletion completed in 22.069734957s

• [SLOW TEST:28.634 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:43:47.875: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7834.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7834.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 10 00:43:51.972: INFO: DNS probes using dns-7834/dns-test-43a4e620-bf36-4a6e-aa70-09c2f9e0fac8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:43:51.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7834" for this suite.
Sep 10 00:43:57.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:43:58.039: INFO: namespace dns-7834 deletion completed in 6.0582283s

• [SLOW TEST:10.164 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:43:58.040: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep 10 00:44:00.068: INFO: Pod pod-hostip-6bd34916-b76f-4a51-bd8b-e9914359d22e has hostIP: 172.20.60.224
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:44:00.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1130" for this suite.
Sep 10 00:44:22.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:44:22.131: INFO: namespace pods-1130 deletion completed in 22.061087193s

• [SLOW TEST:24.092 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:44:22.131: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:44:22.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6371" for this suite.
Sep 10 00:44:28.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:44:28.237: INFO: namespace kubelet-test-6371 deletion completed in 6.069768827s

• [SLOW TEST:6.106 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:44:28.238: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5242
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5242
STEP: Creating statefulset with conflicting port in namespace statefulset-5242
STEP: Waiting until pod test-pod will start running in namespace statefulset-5242
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5242
Sep 10 00:44:32.289: INFO: Observed stateful pod in namespace: statefulset-5242, name: ss-0, uid: 4458a0df-9825-402e-8eba-00442dd1f9fb, status phase: Pending. Waiting for statefulset controller to delete.
Sep 10 00:44:32.478: INFO: Observed stateful pod in namespace: statefulset-5242, name: ss-0, uid: 4458a0df-9825-402e-8eba-00442dd1f9fb, status phase: Failed. Waiting for statefulset controller to delete.
Sep 10 00:44:32.483: INFO: Observed stateful pod in namespace: statefulset-5242, name: ss-0, uid: 4458a0df-9825-402e-8eba-00442dd1f9fb, status phase: Failed. Waiting for statefulset controller to delete.
Sep 10 00:44:32.485: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5242
STEP: Removing pod with conflicting port in namespace statefulset-5242
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5242 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 10 00:44:36.504: INFO: Deleting all statefulset in ns statefulset-5242
Sep 10 00:44:36.506: INFO: Scaling statefulset ss to 0
Sep 10 00:44:46.515: INFO: Waiting for statefulset status.replicas updated to 0
Sep 10 00:44:46.517: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:44:46.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5242" for this suite.
Sep 10 00:44:52.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:44:52.586: INFO: namespace statefulset-5242 deletion completed in 6.059366882s

• [SLOW TEST:24.348 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:44:52.586: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:44:52.621: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f" in namespace "projected-5323" to be "success or failure"
Sep 10 00:44:52.625: INFO: Pod "downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.453548ms
Sep 10 00:44:54.628: INFO: Pod "downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007006227s
STEP: Saw pod success
Sep 10 00:44:54.628: INFO: Pod "downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f" satisfied condition "success or failure"
Sep 10 00:44:54.630: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f container client-container: <nil>
STEP: delete the pod
Sep 10 00:44:54.645: INFO: Waiting for pod downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f to disappear
Sep 10 00:44:54.649: INFO: Pod downwardapi-volume-d9e278ee-a8ed-4769-9abf-3c18e719e33f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:44:54.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5323" for this suite.
Sep 10 00:45:00.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:45:00.714: INFO: namespace projected-5323 deletion completed in 6.062149855s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:45:00.714: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 10 00:45:00.736: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 10 00:45:05.739: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 10 00:45:05.739: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 10 00:45:07.742: INFO: Creating deployment "test-rollover-deployment"
Sep 10 00:45:07.746: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 10 00:45:09.752: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 10 00:45:09.755: INFO: Ensure that both replica sets have 1 created replica
Sep 10 00:45:09.758: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 10 00:45:09.762: INFO: Updating deployment test-rollover-deployment
Sep 10 00:45:09.763: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 10 00:45:11.767: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 10 00:45:11.770: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 10 00:45:11.774: INFO: all replica sets need to contain the pod-template-hash label
Sep 10 00:45:11.774: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673110, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 10 00:45:13.780: INFO: all replica sets need to contain the pod-template-hash label
Sep 10 00:45:13.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673110, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 10 00:45:15.778: INFO: all replica sets need to contain the pod-template-hash label
Sep 10 00:45:15.778: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673110, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 10 00:45:17.778: INFO: all replica sets need to contain the pod-template-hash label
Sep 10 00:45:17.778: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673110, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 10 00:45:19.779: INFO: all replica sets need to contain the pod-template-hash label
Sep 10 00:45:19.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673110, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703673107, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 10 00:45:21.778: INFO: 
Sep 10 00:45:21.778: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 10 00:45:21.784: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9243,SelfLink:/apis/apps/v1/namespaces/deployment-9243/deployments/test-rollover-deployment,UID:be20fcef-c06c-4238-a6ed-bb262ee41bfc,ResourceVersion:14290,Generation:2,CreationTimestamp:2019-09-10 00:45:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-10 00:45:07 +0000 UTC 2019-09-10 00:45:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-10 00:45:20 +0000 UTC 2019-09-10 00:45:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 10 00:45:21.786: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9243,SelfLink:/apis/apps/v1/namespaces/deployment-9243/replicasets/test-rollover-deployment-854595fc44,UID:34ba1b19-6e28-4251-88e9-6d567c60b3bb,ResourceVersion:14283,Generation:2,CreationTimestamp:2019-09-10 00:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment be20fcef-c06c-4238-a6ed-bb262ee41bfc 0xc0024e32d7 0xc0024e32d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 10 00:45:21.786: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 10 00:45:21.786: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9243,SelfLink:/apis/apps/v1/namespaces/deployment-9243/replicasets/test-rollover-controller,UID:6f6e3423-57d7-4b4e-a446-2dbd2f5e93ff,ResourceVersion:14289,Generation:2,CreationTimestamp:2019-09-10 00:45:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment be20fcef-c06c-4238-a6ed-bb262ee41bfc 0xc0024e3207 0xc0024e3208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 10 00:45:21.786: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9243,SelfLink:/apis/apps/v1/namespaces/deployment-9243/replicasets/test-rollover-deployment-9b8b997cf,UID:4661bdd2-7be8-4491-bf59-93c7afffe684,ResourceVersion:14256,Generation:2,CreationTimestamp:2019-09-10 00:45:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment be20fcef-c06c-4238-a6ed-bb262ee41bfc 0xc0024e33a0 0xc0024e33a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 10 00:45:21.788: INFO: Pod "test-rollover-deployment-854595fc44-vxcz4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-vxcz4,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9243,SelfLink:/api/v1/namespaces/deployment-9243/pods/test-rollover-deployment-854595fc44-vxcz4,UID:ced04f6c-f563-4bf1-a39e-d7b2c53772cc,ResourceVersion:14266,Generation:0,CreationTimestamp:2019-09-10 00:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 34ba1b19-6e28-4251-88e9-6d567c60b3bb 0xc003b28b07 0xc003b28b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8gn9b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8gn9b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8gn9b true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-20-62-19.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b28b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b28b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:45:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:45:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:45:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-10 00:45:09 +0000 UTC  }],Message:,Reason:,HostIP:172.20.62.19,PodIP:100.96.1.198,StartTime:2019-09-10 00:45:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-10 00:45:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6f242abbcca5f1169e42e5de677a1edca08bd6926d41668ea0291c53cca773c9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:45:21.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9243" for this suite.
Sep 10 00:45:27.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:45:27.863: INFO: namespace deployment-9243 deletion completed in 6.073134381s

• [SLOW TEST:27.149 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:45:27.864: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-2543003b-e268-4766-ac00-3a7f251fd3e5
STEP: Creating secret with name secret-projected-all-test-volume-95f3f039-20d7-4d3b-ae33-db37397ba175
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 10 00:45:27.891: INFO: Waiting up to 5m0s for pod "projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861" in namespace "projected-3824" to be "success or failure"
Sep 10 00:45:27.893: INFO: Pod "projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861": Phase="Pending", Reason="", readiness=false. Elapsed: 2.351923ms
Sep 10 00:45:29.899: INFO: Pod "projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007801156s
STEP: Saw pod success
Sep 10 00:45:29.899: INFO: Pod "projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861" satisfied condition "success or failure"
Sep 10 00:45:29.902: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 10 00:45:29.914: INFO: Waiting for pod projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861 to disappear
Sep 10 00:45:29.918: INFO: Pod projected-volume-4ee9ccd9-f262-4de8-9f2c-93b0bcde4861 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:45:29.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3824" for this suite.
Sep 10 00:45:35.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:45:35.995: INFO: namespace projected-3824 deletion completed in 6.07408031s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:45:35.995: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 10 00:45:38.541: INFO: Successfully updated pod "annotationupdate5366e5ff-b28e-494e-b428-1e709a4137e5"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:45:42.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3701" for this suite.
Sep 10 00:46:04.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:46:04.624: INFO: namespace projected-3701 deletion completed in 22.060855988s

• [SLOW TEST:28.629 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:46:04.624: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-2775
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2775 to expose endpoints map[]
Sep 10 00:46:04.702: INFO: Get endpoints failed (5.000434ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 10 00:46:05.704: INFO: successfully validated that service endpoint-test2 in namespace services-2775 exposes endpoints map[] (1.007228506s elapsed)
STEP: Creating pod pod1 in namespace services-2775
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2775 to expose endpoints map[pod1:[80]]
Sep 10 00:46:06.722: INFO: successfully validated that service endpoint-test2 in namespace services-2775 exposes endpoints map[pod1:[80]] (1.013643748s elapsed)
STEP: Creating pod pod2 in namespace services-2775
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2775 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 10 00:46:08.748: INFO: successfully validated that service endpoint-test2 in namespace services-2775 exposes endpoints map[pod1:[80] pod2:[80]] (2.022946074s elapsed)
STEP: Deleting pod pod1 in namespace services-2775
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2775 to expose endpoints map[pod2:[80]]
Sep 10 00:46:08.762: INFO: successfully validated that service endpoint-test2 in namespace services-2775 exposes endpoints map[pod2:[80]] (8.469523ms elapsed)
STEP: Deleting pod pod2 in namespace services-2775
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2775 to expose endpoints map[]
Sep 10 00:46:08.771: INFO: successfully validated that service endpoint-test2 in namespace services-2775 exposes endpoints map[] (4.373557ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:46:08.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2775" for this suite.
Sep 10 00:46:14.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:46:14.857: INFO: namespace services-2775 deletion completed in 6.065188784s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:10.233 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:46:14.858: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-6ade29f9-9943-47ed-b822-808fbac07544
STEP: Creating configMap with name cm-test-opt-upd-51177f01-25dc-44a9-aa74-f6a8ff1fa132
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6ade29f9-9943-47ed-b822-808fbac07544
STEP: Updating configmap cm-test-opt-upd-51177f01-25dc-44a9-aa74-f6a8ff1fa132
STEP: Creating configMap with name cm-test-opt-create-97b124ef-f7a1-4ddc-99b8-47e78e488f07
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:46:18.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3254" for this suite.
Sep 10 00:46:40.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:46:41.009: INFO: namespace configmap-3254 deletion completed in 22.065439225s

• [SLOW TEST:26.151 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:46:41.009: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 10 00:46:41.030: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f" in namespace "downward-api-1282" to be "success or failure"
Sep 10 00:46:41.034: INFO: Pod "downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.882956ms
Sep 10 00:46:43.036: INFO: Pod "downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006065566s
STEP: Saw pod success
Sep 10 00:46:43.036: INFO: Pod "downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f" satisfied condition "success or failure"
Sep 10 00:46:43.038: INFO: Trying to get logs from node ip-172-20-62-19.us-east-2.compute.internal pod downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f container client-container: <nil>
STEP: delete the pod
Sep 10 00:46:43.049: INFO: Waiting for pod downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f to disappear
Sep 10 00:46:43.052: INFO: Pod downwardapi-volume-00dd3cfc-e032-42a0-aa1e-c7fa635f0d5f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:46:43.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1282" for this suite.
Sep 10 00:46:49.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:46:49.116: INFO: namespace downward-api-1282 deletion completed in 6.061764014s

• [SLOW TEST:8.107 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:46:49.116: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 10 00:46:53.171: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:46:53.173: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:46:55.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:46:55.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:46:57.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:46:57.175: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:46:59.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:46:59.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:01.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:01.175: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:03.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:03.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:05.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:05.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:07.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:07.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:09.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:09.176: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:11.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:11.175: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 10 00:47:13.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 10 00:47:13.175: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:47:13.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-936" for this suite.
Sep 10 00:47:35.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:47:35.237: INFO: namespace container-lifecycle-hook-936 deletion completed in 22.059113797s

• [SLOW TEST:46.120 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:47:35.237: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 10 00:47:35.255: INFO: namespace kubectl-4920
Sep 10 00:47:35.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-4920'
Sep 10 00:47:35.409: INFO: stderr: ""
Sep 10 00:47:35.409: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 10 00:47:36.412: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:47:36.412: INFO: Found 1 / 1
Sep 10 00:47:36.412: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 10 00:47:36.414: INFO: Selector matched 1 pods for map[app:redis]
Sep 10 00:47:36.414: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 10 00:47:36.414: INFO: wait on redis-master startup in kubectl-4920 
Sep 10 00:47:36.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 logs redis-master-xsxsg redis-master --namespace=kubectl-4920'
Sep 10 00:47:36.487: INFO: stderr: ""
Sep 10 00:47:36.487: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Sep 00:47:36.210 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Sep 00:47:36.210 # Server started, Redis version 3.2.12\n1:M 10 Sep 00:47:36.211 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Sep 00:47:36.211 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 10 00:47:36.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4920'
Sep 10 00:47:36.570: INFO: stderr: ""
Sep 10 00:47:36.570: INFO: stdout: "service/rm2 exposed\n"
Sep 10 00:47:36.573: INFO: Service rm2 in namespace kubectl-4920 found.
STEP: exposing service
Sep 10 00:47:38.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4920'
Sep 10 00:47:38.664: INFO: stderr: ""
Sep 10 00:47:38.664: INFO: stdout: "service/rm3 exposed\n"
Sep 10 00:47:38.668: INFO: Service rm3 in namespace kubectl-4920 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:47:40.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4920" for this suite.
Sep 10 00:48:02.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:48:02.734: INFO: namespace kubectl-4920 deletion completed in 22.060779782s

• [SLOW TEST:27.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:48:02.736: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:48:06.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5039" for this suite.
Sep 10 00:48:12.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:48:12.828: INFO: namespace kubelet-test-5039 deletion completed in 6.062766549s

• [SLOW TEST:10.092 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:48:12.829: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 10 00:48:12.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3804'
Sep 10 00:48:12.998: INFO: stderr: ""
Sep 10 00:48:12.998: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:48:12.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:13.067: INFO: stderr: ""
Sep 10 00:48:13.067: INFO: stdout: "update-demo-nautilus-72kr5 update-demo-nautilus-8nvh9 "
Sep 10 00:48:13.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-72kr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:13.135: INFO: stderr: ""
Sep 10 00:48:13.135: INFO: stdout: ""
Sep 10 00:48:13.135: INFO: update-demo-nautilus-72kr5 is created but not running
Sep 10 00:48:18.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:18.200: INFO: stderr: ""
Sep 10 00:48:18.200: INFO: stdout: "update-demo-nautilus-72kr5 update-demo-nautilus-8nvh9 "
Sep 10 00:48:18.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-72kr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:18.264: INFO: stderr: ""
Sep 10 00:48:18.264: INFO: stdout: "true"
Sep 10 00:48:18.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-72kr5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:18.330: INFO: stderr: ""
Sep 10 00:48:18.330: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:18.330: INFO: validating pod update-demo-nautilus-72kr5
Sep 10 00:48:18.333: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:18.333: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:18.333: INFO: update-demo-nautilus-72kr5 is verified up and running
Sep 10 00:48:18.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:18.397: INFO: stderr: ""
Sep 10 00:48:18.397: INFO: stdout: "true"
Sep 10 00:48:18.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:18.461: INFO: stderr: ""
Sep 10 00:48:18.461: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:18.461: INFO: validating pod update-demo-nautilus-8nvh9
Sep 10 00:48:18.464: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:18.464: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:18.464: INFO: update-demo-nautilus-8nvh9 is verified up and running
STEP: scaling down the replication controller
Sep 10 00:48:18.465: INFO: scanned /root for discovery docs: <nil>
Sep 10 00:48:18.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3804'
Sep 10 00:48:19.553: INFO: stderr: ""
Sep 10 00:48:19.553: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:48:19.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:19.621: INFO: stderr: ""
Sep 10 00:48:19.621: INFO: stdout: "update-demo-nautilus-72kr5 update-demo-nautilus-8nvh9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 10 00:48:24.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:24.688: INFO: stderr: ""
Sep 10 00:48:24.688: INFO: stdout: "update-demo-nautilus-72kr5 update-demo-nautilus-8nvh9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 10 00:48:29.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:29.761: INFO: stderr: ""
Sep 10 00:48:29.761: INFO: stdout: "update-demo-nautilus-72kr5 update-demo-nautilus-8nvh9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 10 00:48:34.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:34.830: INFO: stderr: ""
Sep 10 00:48:34.830: INFO: stdout: "update-demo-nautilus-8nvh9 "
Sep 10 00:48:34.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:34.895: INFO: stderr: ""
Sep 10 00:48:34.895: INFO: stdout: "true"
Sep 10 00:48:34.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:34.963: INFO: stderr: ""
Sep 10 00:48:34.963: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:34.963: INFO: validating pod update-demo-nautilus-8nvh9
Sep 10 00:48:34.965: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:34.965: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:34.965: INFO: update-demo-nautilus-8nvh9 is verified up and running
STEP: scaling up the replication controller
Sep 10 00:48:34.966: INFO: scanned /root for discovery docs: <nil>
Sep 10 00:48:34.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3804'
Sep 10 00:48:36.050: INFO: stderr: ""
Sep 10 00:48:36.051: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 10 00:48:36.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:36.119: INFO: stderr: ""
Sep 10 00:48:36.119: INFO: stdout: "update-demo-nautilus-8nvh9 update-demo-nautilus-khckb "
Sep 10 00:48:36.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:36.184: INFO: stderr: ""
Sep 10 00:48:36.184: INFO: stdout: "true"
Sep 10 00:48:36.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:36.250: INFO: stderr: ""
Sep 10 00:48:36.250: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:36.250: INFO: validating pod update-demo-nautilus-8nvh9
Sep 10 00:48:36.253: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:36.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:36.253: INFO: update-demo-nautilus-8nvh9 is verified up and running
Sep 10 00:48:36.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-khckb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:36.318: INFO: stderr: ""
Sep 10 00:48:36.318: INFO: stdout: ""
Sep 10 00:48:36.318: INFO: update-demo-nautilus-khckb is created but not running
Sep 10 00:48:41.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3804'
Sep 10 00:48:41.386: INFO: stderr: ""
Sep 10 00:48:41.386: INFO: stdout: "update-demo-nautilus-8nvh9 update-demo-nautilus-khckb "
Sep 10 00:48:41.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:41.452: INFO: stderr: ""
Sep 10 00:48:41.452: INFO: stdout: "true"
Sep 10 00:48:41.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-8nvh9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:41.517: INFO: stderr: ""
Sep 10 00:48:41.517: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:41.517: INFO: validating pod update-demo-nautilus-8nvh9
Sep 10 00:48:41.520: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:41.520: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:41.520: INFO: update-demo-nautilus-8nvh9 is verified up and running
Sep 10 00:48:41.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-khckb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:41.587: INFO: stderr: ""
Sep 10 00:48:41.587: INFO: stdout: "true"
Sep 10 00:48:41.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods update-demo-nautilus-khckb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3804'
Sep 10 00:48:41.653: INFO: stderr: ""
Sep 10 00:48:41.653: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 10 00:48:41.653: INFO: validating pod update-demo-nautilus-khckb
Sep 10 00:48:41.656: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 10 00:48:41.656: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 10 00:48:41.656: INFO: update-demo-nautilus-khckb is verified up and running
STEP: using delete to clean up resources
Sep 10 00:48:41.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3804'
Sep 10 00:48:41.723: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:48:41.723: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 10 00:48:41.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3804'
Sep 10 00:48:41.798: INFO: stderr: "No resources found.\n"
Sep 10 00:48:41.798: INFO: stdout: ""
Sep 10 00:48:41.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -l name=update-demo --namespace=kubectl-3804 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 10 00:48:41.865: INFO: stderr: ""
Sep 10 00:48:41.865: INFO: stdout: "update-demo-nautilus-8nvh9\nupdate-demo-nautilus-khckb\n"
Sep 10 00:48:42.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3804'
Sep 10 00:48:42.434: INFO: stderr: "No resources found.\n"
Sep 10 00:48:42.434: INFO: stdout: ""
Sep 10 00:48:42.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 get pods -l name=update-demo --namespace=kubectl-3804 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 10 00:48:42.506: INFO: stderr: ""
Sep 10 00:48:42.506: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:48:42.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3804" for this suite.
Sep 10 00:49:04.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:49:04.588: INFO: namespace kubectl-3804 deletion completed in 22.079277448s

• [SLOW TEST:51.760 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:49:04.589: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 10 00:49:04.854: INFO: Pod name wrapped-volume-race-7ce2998b-aea3-489d-8d1f-dd3661949e04: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7ce2998b-aea3-489d-8d1f-dd3661949e04 in namespace emptydir-wrapper-4132, will wait for the garbage collector to delete the pods
Sep 10 00:49:18.960: INFO: Deleting ReplicationController wrapped-volume-race-7ce2998b-aea3-489d-8d1f-dd3661949e04 took: 4.935622ms
Sep 10 00:49:19.260: INFO: Terminating ReplicationController wrapped-volume-race-7ce2998b-aea3-489d-8d1f-dd3661949e04 pods took: 300.244625ms
STEP: Creating RC which spawns configmap-volume pods
Sep 10 00:49:59.671: INFO: Pod name wrapped-volume-race-e5554460-6ea7-4093-943a-63a74b4551a4: Found 0 pods out of 5
Sep 10 00:50:04.675: INFO: Pod name wrapped-volume-race-e5554460-6ea7-4093-943a-63a74b4551a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e5554460-6ea7-4093-943a-63a74b4551a4 in namespace emptydir-wrapper-4132, will wait for the garbage collector to delete the pods
Sep 10 00:50:14.744: INFO: Deleting ReplicationController wrapped-volume-race-e5554460-6ea7-4093-943a-63a74b4551a4 took: 4.430219ms
Sep 10 00:50:15.044: INFO: Terminating ReplicationController wrapped-volume-race-e5554460-6ea7-4093-943a-63a74b4551a4 pods took: 300.320671ms
STEP: Creating RC which spawns configmap-volume pods
Sep 10 00:50:51.254: INFO: Pod name wrapped-volume-race-20d72f8a-4378-4085-ac2c-5f7e4fcb0ebe: Found 0 pods out of 5
Sep 10 00:50:56.258: INFO: Pod name wrapped-volume-race-20d72f8a-4378-4085-ac2c-5f7e4fcb0ebe: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-20d72f8a-4378-4085-ac2c-5f7e4fcb0ebe in namespace emptydir-wrapper-4132, will wait for the garbage collector to delete the pods
Sep 10 00:51:08.329: INFO: Deleting ReplicationController wrapped-volume-race-20d72f8a-4378-4085-ac2c-5f7e4fcb0ebe took: 5.326135ms
Sep 10 00:51:08.630: INFO: Terminating ReplicationController wrapped-volume-race-20d72f8a-4378-4085-ac2c-5f7e4fcb0ebe pods took: 300.210611ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:51:49.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4132" for this suite.
Sep 10 00:51:55.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:51:55.246: INFO: namespace emptydir-wrapper-4132 deletion completed in 6.060690651s

• [SLOW TEST:170.657 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:51:55.246: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep 10 00:51:55.264: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 10 00:51:55.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:55.426: INFO: stderr: ""
Sep 10 00:51:55.426: INFO: stdout: "service/redis-slave created\n"
Sep 10 00:51:55.426: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 10 00:51:55.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:55.605: INFO: stderr: ""
Sep 10 00:51:55.605: INFO: stdout: "service/redis-master created\n"
Sep 10 00:51:55.605: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 10 00:51:55.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:55.778: INFO: stderr: ""
Sep 10 00:51:55.778: INFO: stdout: "service/frontend created\n"
Sep 10 00:51:55.778: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 10 00:51:55.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:55.943: INFO: stderr: ""
Sep 10 00:51:55.943: INFO: stdout: "deployment.apps/frontend created\n"
Sep 10 00:51:55.943: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 10 00:51:55.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:56.110: INFO: stderr: ""
Sep 10 00:51:56.110: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 10 00:51:56.110: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 10 00:51:56.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 create -f - --namespace=kubectl-3158'
Sep 10 00:51:56.316: INFO: stderr: ""
Sep 10 00:51:56.316: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 10 00:51:56.316: INFO: Waiting for all frontend pods to be Running.
Sep 10 00:52:11.367: INFO: Waiting for frontend to serve content.
Sep 10 00:52:12.383: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep 10 00:52:17.394: INFO: Trying to add a new entry to the guestbook.
Sep 10 00:52:17.404: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 10 00:52:17.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.490: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 10 00:52:17.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.578: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.579: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 10 00:52:17.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.673: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 10 00:52:17.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.744: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.744: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 10 00:52:17.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.815: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.815: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 10 00:52:17.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete --grace-period=0 --force -f - --namespace=kubectl-3158'
Sep 10 00:52:17.882: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 10 00:52:17.882: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:52:17.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3158" for this suite.
Sep 10 00:52:59.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:52:59.943: INFO: namespace kubectl-3158 deletion completed in 42.058743014s

• [SLOW TEST:64.697 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:52:59.944: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 10 00:52:59.961: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:53:03.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2176" for this suite.
Sep 10 00:53:25.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:53:25.915: INFO: namespace init-container-2176 deletion completed in 22.072138798s

• [SLOW TEST:25.971 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:53:25.915: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-a0224236-c99a-4c7e-b24a-c71fd0b44b21
STEP: Creating a pod to test consume configMaps
Sep 10 00:53:25.941: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056" in namespace "projected-4503" to be "success or failure"
Sep 10 00:53:25.944: INFO: Pod "pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056": Phase="Pending", Reason="", readiness=false. Elapsed: 3.220897ms
Sep 10 00:53:27.947: INFO: Pod "pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005837249s
STEP: Saw pod success
Sep 10 00:53:27.947: INFO: Pod "pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056" satisfied condition "success or failure"
Sep 10 00:53:27.949: INFO: Trying to get logs from node ip-172-20-60-224.us-east-2.compute.internal pod pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 10 00:53:27.960: INFO: Waiting for pod pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056 to disappear
Sep 10 00:53:27.963: INFO: Pod pod-projected-configmaps-7c8c5487-e0c8-4b9f-b1c9-f36fbf1f4056 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:53:27.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4503" for this suite.
Sep 10 00:53:33.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:53:34.023: INFO: namespace projected-4503 deletion completed in 6.058291473s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:53:34.024: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 10 00:53:34.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1540'
Sep 10 00:53:34.256: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 10 00:53:34.256: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 10 00:53:34.264: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-g5snb]
Sep 10 00:53:34.264: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-g5snb" in namespace "kubectl-1540" to be "running and ready"
Sep 10 00:53:34.268: INFO: Pod "e2e-test-nginx-rc-g5snb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.373686ms
Sep 10 00:53:36.270: INFO: Pod "e2e-test-nginx-rc-g5snb": Phase="Running", Reason="", readiness=true. Elapsed: 2.00542647s
Sep 10 00:53:36.270: INFO: Pod "e2e-test-nginx-rc-g5snb" satisfied condition "running and ready"
Sep 10 00:53:36.270: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-g5snb]
Sep 10 00:53:36.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 logs rc/e2e-test-nginx-rc --namespace=kubectl-1540'
Sep 10 00:53:36.355: INFO: stderr: ""
Sep 10 00:53:36.355: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep 10 00:53:36.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-004522922 delete rc e2e-test-nginx-rc --namespace=kubectl-1540'
Sep 10 00:53:36.427: INFO: stderr: ""
Sep 10 00:53:36.427: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:53:36.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1540" for this suite.
Sep 10 00:53:42.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:53:42.497: INFO: namespace kubectl-1540 deletion completed in 6.068456657s

• [SLOW TEST:8.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:53:42.498: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4056
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 10 00:53:42.516: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 10 00:54:04.558: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.213 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4056 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 10 00:54:04.558: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep 10 00:54:05.651: INFO: Found all expected endpoints: [netserver-0]
Sep 10 00:54:05.654: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.152 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4056 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 10 00:54:05.654: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
Sep 10 00:54:06.755: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:54:06.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4056" for this suite.
Sep 10 00:54:28.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:54:28.820: INFO: namespace pod-network-test-4056 deletion completed in 22.062713603s

• [SLOW TEST:46.322 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 10 00:54:28.820: INFO: >>> kubeConfig: /tmp/kubeconfig-004522922
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 10 00:54:30.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9523" for this suite.
Sep 10 00:54:36.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 10 00:54:36.958: INFO: namespace emptydir-wrapper-9523 deletion completed in 6.082015932s

• [SLOW TEST:8.137 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSep 10 00:54:36.958: INFO: Running AfterSuite actions on all nodes
Sep 10 00:54:36.958: INFO: Running AfterSuite actions on node 1
Sep 10 00:54:36.958: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5407.709 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h30m9.062193176s
Test Suite Passed
