I1211 04:23:31.971181      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-018278524
I1211 04:23:31.971596      15 e2e.go:243] Starting e2e run "1c888cf5-ac0a-43f0-ae72-9d7450ea012b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576038210 - Will randomize all specs
Will run 215 of 4413 specs

Dec 11 04:23:32.141: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:23:32.145: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 11 04:23:32.164: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 11 04:23:32.197: INFO: 45 / 45 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 11 04:23:32.197: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Dec 11 04:23:32.197: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 11 04:23:32.205: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'ksc-flexvolume-ds' (0 seconds elapsed)
Dec 11 04:23:32.205: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'ksc-node-exporter' (0 seconds elapsed)
Dec 11 04:23:32.205: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
Dec 11 04:23:32.206: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 11 04:23:32.206: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Dec 11 04:23:32.206: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-controller' (0 seconds elapsed)
Dec 11 04:23:32.206: INFO: e2e test version: v1.15.5
Dec 11 04:23:32.207: INFO: kube-apiserver version: v1.15.5
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:23:32.207: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replicaset
Dec 11 04:23:32.231: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 11 04:23:37.256: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:23:38.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2591" for this suite.
Dec 11 04:24:00.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:24:00.358: INFO: namespace replicaset-2591 deletion completed in 22.08148933s

• [SLOW TEST:28.155 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:24:00.363: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 11 04:24:00.627: INFO: Pod name wrapped-volume-race-b4bab7c2-b6e1-4bb3-aff9-1be31c6d5cc9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b4bab7c2-b6e1-4bb3-aff9-1be31c6d5cc9 in namespace emptydir-wrapper-9175, will wait for the garbage collector to delete the pods
Dec 11 04:24:16.747: INFO: Deleting ReplicationController wrapped-volume-race-b4bab7c2-b6e1-4bb3-aff9-1be31c6d5cc9 took: 6.369514ms
Dec 11 04:24:17.147: INFO: Terminating ReplicationController wrapped-volume-race-b4bab7c2-b6e1-4bb3-aff9-1be31c6d5cc9 pods took: 400.335421ms
STEP: Creating RC which spawns configmap-volume pods
Dec 11 04:24:53.462: INFO: Pod name wrapped-volume-race-dd6dade9-ff4a-49cb-99c2-25f27cadc3b7: Found 0 pods out of 5
Dec 11 04:24:58.470: INFO: Pod name wrapped-volume-race-dd6dade9-ff4a-49cb-99c2-25f27cadc3b7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dd6dade9-ff4a-49cb-99c2-25f27cadc3b7 in namespace emptydir-wrapper-9175, will wait for the garbage collector to delete the pods
Dec 11 04:25:10.552: INFO: Deleting ReplicationController wrapped-volume-race-dd6dade9-ff4a-49cb-99c2-25f27cadc3b7 took: 5.843595ms
Dec 11 04:25:10.952: INFO: Terminating ReplicationController wrapped-volume-race-dd6dade9-ff4a-49cb-99c2-25f27cadc3b7 pods took: 400.264804ms
STEP: Creating RC which spawns configmap-volume pods
Dec 11 04:25:52.068: INFO: Pod name wrapped-volume-race-270b8057-49d6-43c9-b57f-264b0d6da629: Found 0 pods out of 5
Dec 11 04:25:57.076: INFO: Pod name wrapped-volume-race-270b8057-49d6-43c9-b57f-264b0d6da629: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-270b8057-49d6-43c9-b57f-264b0d6da629 in namespace emptydir-wrapper-9175, will wait for the garbage collector to delete the pods
Dec 11 04:26:09.157: INFO: Deleting ReplicationController wrapped-volume-race-270b8057-49d6-43c9-b57f-264b0d6da629 took: 5.809101ms
Dec 11 04:26:09.558: INFO: Terminating ReplicationController wrapped-volume-race-270b8057-49d6-43c9-b57f-264b0d6da629 pods took: 400.332269ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:26:52.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9175" for this suite.
Dec 11 04:26:58.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:26:58.680: INFO: namespace emptydir-wrapper-9175 deletion completed in 6.080729292s

• [SLOW TEST:178.318 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:26:58.693: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:26:58.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9" in namespace "projected-1456" to be "success or failure"
Dec 11 04:26:58.734: INFO: Pod "downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.930103ms
Dec 11 04:27:00.742: INFO: Pod "downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014555243s
Dec 11 04:27:02.746: INFO: Pod "downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018629833s
STEP: Saw pod success
Dec 11 04:27:02.746: INFO: Pod "downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9" satisfied condition "success or failure"
Dec 11 04:27:02.748: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9 container client-container: <nil>
STEP: delete the pod
Dec 11 04:27:02.774: INFO: Waiting for pod downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9 to disappear
Dec 11 04:27:02.776: INFO: Pod downwardapi-volume-51b4804c-2de8-4565-abe9-bc7aa8bb4ba9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:27:02.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1456" for this suite.
Dec 11 04:27:08.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:27:08.853: INFO: namespace projected-1456 deletion completed in 6.073959129s

• [SLOW TEST:10.161 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:27:08.855: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-bbb0c5af-6ed4-41e0-85c2-18268017b0e4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-bbb0c5af-6ed4-41e0-85c2-18268017b0e4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:27:12.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2413" for this suite.
Dec 11 04:27:34.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:27:35.000: INFO: namespace projected-2413 deletion completed in 22.076266194s

• [SLOW TEST:26.145 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:27:35.002: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 11 04:27:38.058: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:27:38.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-714" for this suite.
Dec 11 04:27:44.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:27:44.150: INFO: namespace container-runtime-714 deletion completed in 6.077920632s

• [SLOW TEST:9.149 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:27:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 11 04:27:48.761: INFO: Successfully updated pod "pod-update-activedeadlineseconds-59839923-873a-4e68-99fb-327734ea18ed"
Dec 11 04:27:48.761: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-59839923-873a-4e68-99fb-327734ea18ed" in namespace "pods-6685" to be "terminated due to deadline exceeded"
Dec 11 04:27:48.765: INFO: Pod "pod-update-activedeadlineseconds-59839923-873a-4e68-99fb-327734ea18ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.185976ms
Dec 11 04:27:50.768: INFO: Pod "pod-update-activedeadlineseconds-59839923-873a-4e68-99fb-327734ea18ed": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.007058524s
Dec 11 04:27:50.768: INFO: Pod "pod-update-activedeadlineseconds-59839923-873a-4e68-99fb-327734ea18ed" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:27:50.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6685" for this suite.
Dec 11 04:27:56.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:27:56.845: INFO: namespace pods-6685 deletion completed in 6.072368186s

• [SLOW TEST:12.694 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:27:56.848: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 11 04:27:59.401: INFO: Successfully updated pod "annotationupdatea75313ef-7094-4ad5-a0fc-6398ab16c194"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:28:01.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4340" for this suite.
Dec 11 04:28:23.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:28:23.493: INFO: namespace projected-4340 deletion completed in 22.073047997s

• [SLOW TEST:26.645 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:28:23.500: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:28:23.527: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:28:25.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7078" for this suite.
Dec 11 04:29:15.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:29:15.802: INFO: namespace pods-7078 deletion completed in 50.073273892s

• [SLOW TEST:52.302 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:29:15.803: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:29:15.831: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:29:21.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6646" for this suite.
Dec 11 04:29:27.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:29:27.951: INFO: namespace custom-resource-definition-6646 deletion completed in 6.081689005s

• [SLOW TEST:12.148 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:29:27.952: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-e5edcaf8-de2d-4e9f-8e3c-c62ea720e8f9 in namespace container-probe-4876
Dec 11 04:29:31.985: INFO: Started pod busybox-e5edcaf8-de2d-4e9f-8e3c-c62ea720e8f9 in namespace container-probe-4876
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 04:29:31.991: INFO: Initial restart count of pod busybox-e5edcaf8-de2d-4e9f-8e3c-c62ea720e8f9 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:33:32.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4876" for this suite.
Dec 11 04:33:38.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:33:38.533: INFO: namespace container-probe-4876 deletion completed in 6.074821702s

• [SLOW TEST:250.583 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:33:38.541: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Dec 11 04:33:38.569: INFO: Waiting up to 5m0s for pod "client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf" in namespace "containers-4140" to be "success or failure"
Dec 11 04:33:38.571: INFO: Pod "client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903989ms
Dec 11 04:33:40.574: INFO: Pod "client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004831724s
STEP: Saw pod success
Dec 11 04:33:40.574: INFO: Pod "client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf" satisfied condition "success or failure"
Dec 11 04:33:40.577: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf container test-container: <nil>
STEP: delete the pod
Dec 11 04:33:40.591: INFO: Waiting for pod client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf to disappear
Dec 11 04:33:40.593: INFO: Pod client-containers-77c08f8d-d949-4f4a-b248-57483b0b66bf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:33:40.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4140" for this suite.
Dec 11 04:33:46.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:33:46.668: INFO: namespace containers-4140 deletion completed in 6.071879844s

• [SLOW TEST:8.127 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:33:46.674: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-3754a41a-370a-41f0-96fe-97ea4035f8f1
STEP: Creating a pod to test consume configMaps
Dec 11 04:33:46.707: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315" in namespace "projected-4210" to be "success or failure"
Dec 11 04:33:46.709: INFO: Pod "pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230753ms
Dec 11 04:33:48.712: INFO: Pod "pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005515105s
STEP: Saw pod success
Dec 11 04:33:48.712: INFO: Pod "pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315" satisfied condition "success or failure"
Dec 11 04:33:48.714: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 04:33:48.733: INFO: Waiting for pod pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315 to disappear
Dec 11 04:33:48.735: INFO: Pod pod-projected-configmaps-0d99da6a-4f00-40f4-9eda-6a89d2a18315 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:33:48.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4210" for this suite.
Dec 11 04:33:54.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:33:54.814: INFO: namespace projected-4210 deletion completed in 6.075024116s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:33:54.824: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:34:54.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1669" for this suite.
Dec 11 04:35:16.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:35:16.942: INFO: namespace container-probe-1669 deletion completed in 22.077709808s

• [SLOW TEST:82.120 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:35:16.945: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1211 04:35:57.007749      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 04:35:57.008: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:35:57.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3009" for this suite.
Dec 11 04:36:03.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:36:03.087: INFO: namespace gc-3009 deletion completed in 6.073724527s

• [SLOW TEST:46.142 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:36:03.089: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Dec 11 04:36:03.122: INFO: Waiting up to 5m0s for pod "client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2" in namespace "containers-7536" to be "success or failure"
Dec 11 04:36:03.124: INFO: Pod "client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.461175ms
Dec 11 04:36:05.127: INFO: Pod "client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005534036s
Dec 11 04:36:07.131: INFO: Pod "client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009676626s
STEP: Saw pod success
Dec 11 04:36:07.131: INFO: Pod "client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2" satisfied condition "success or failure"
Dec 11 04:36:07.134: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2 container test-container: <nil>
STEP: delete the pod
Dec 11 04:36:07.148: INFO: Waiting for pod client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2 to disappear
Dec 11 04:36:07.150: INFO: Pod client-containers-219515d0-7784-4bac-9bd5-c4864f865cf2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:36:07.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7536" for this suite.
Dec 11 04:36:13.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:36:13.229: INFO: namespace containers-7536 deletion completed in 6.075011486s

• [SLOW TEST:10.140 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:36:13.231: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-4d606086-9267-4016-ae98-d24c1d74da50
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:36:17.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1100" for this suite.
Dec 11 04:36:39.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:36:39.405: INFO: namespace configmap-1100 deletion completed in 22.089241384s

• [SLOW TEST:26.175 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:36:39.406: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:36:39.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5" in namespace "projected-5233" to be "success or failure"
Dec 11 04:36:39.441: INFO: Pod "downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328817ms
Dec 11 04:36:41.445: INFO: Pod "downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005879349s
Dec 11 04:36:43.449: INFO: Pod "downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010291574s
STEP: Saw pod success
Dec 11 04:36:43.449: INFO: Pod "downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5" satisfied condition "success or failure"
Dec 11 04:36:43.454: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5 container client-container: <nil>
STEP: delete the pod
Dec 11 04:36:43.471: INFO: Waiting for pod downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5 to disappear
Dec 11 04:36:43.473: INFO: Pod downwardapi-volume-c2fae8b5-df76-4d52-b3bb-e3b90acc53a5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:36:43.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5233" for this suite.
Dec 11 04:36:49.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:36:49.548: INFO: namespace projected-5233 deletion completed in 6.071217362s

• [SLOW TEST:10.141 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:36:49.549: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:36:49.586: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462" in namespace "projected-163" to be "success or failure"
Dec 11 04:36:49.588: INFO: Pod "downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603621ms
Dec 11 04:36:51.592: INFO: Pod "downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005634735s
Dec 11 04:36:53.596: INFO: Pod "downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009670653s
STEP: Saw pod success
Dec 11 04:36:53.596: INFO: Pod "downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462" satisfied condition "success or failure"
Dec 11 04:36:53.598: INFO: Trying to get logs from node 192.168.5.23 pod downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462 container client-container: <nil>
STEP: delete the pod
Dec 11 04:36:53.614: INFO: Waiting for pod downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462 to disappear
Dec 11 04:36:53.616: INFO: Pod downwardapi-volume-22ecb6d6-02d8-4172-8bdf-8f5fd9382462 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:36:53.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-163" for this suite.
Dec 11 04:36:59.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:36:59.691: INFO: namespace projected-163 deletion completed in 6.072262222s

• [SLOW TEST:10.143 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:36:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:36:59.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c" in namespace "projected-7644" to be "success or failure"
Dec 11 04:36:59.730: INFO: Pod "downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.199485ms
Dec 11 04:37:01.734: INFO: Pod "downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006118218s
Dec 11 04:37:03.740: INFO: Pod "downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011512788s
STEP: Saw pod success
Dec 11 04:37:03.740: INFO: Pod "downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c" satisfied condition "success or failure"
Dec 11 04:37:03.742: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c container client-container: <nil>
STEP: delete the pod
Dec 11 04:37:03.758: INFO: Waiting for pod downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c to disappear
Dec 11 04:37:03.760: INFO: Pod downwardapi-volume-2b31841f-4805-452d-b068-730887ef1e5c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:37:03.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7644" for this suite.
Dec 11 04:37:09.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:37:09.837: INFO: namespace projected-7644 deletion completed in 6.073321819s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:37:09.837: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 11 04:37:09.869: INFO: Waiting up to 5m0s for pod "pod-85867a39-19d4-4d43-9464-434fbfdb173e" in namespace "emptydir-4085" to be "success or failure"
Dec 11 04:37:09.872: INFO: Pod "pod-85867a39-19d4-4d43-9464-434fbfdb173e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.712117ms
Dec 11 04:37:11.875: INFO: Pod "pod-85867a39-19d4-4d43-9464-434fbfdb173e": Phase="Running", Reason="", readiness=true. Elapsed: 2.005930715s
Dec 11 04:37:13.879: INFO: Pod "pod-85867a39-19d4-4d43-9464-434fbfdb173e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009773588s
STEP: Saw pod success
Dec 11 04:37:13.879: INFO: Pod "pod-85867a39-19d4-4d43-9464-434fbfdb173e" satisfied condition "success or failure"
Dec 11 04:37:13.881: INFO: Trying to get logs from node 192.168.5.21 pod pod-85867a39-19d4-4d43-9464-434fbfdb173e container test-container: <nil>
STEP: delete the pod
Dec 11 04:37:13.898: INFO: Waiting for pod pod-85867a39-19d4-4d43-9464-434fbfdb173e to disappear
Dec 11 04:37:13.900: INFO: Pod pod-85867a39-19d4-4d43-9464-434fbfdb173e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:37:13.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4085" for this suite.
Dec 11 04:37:19.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:37:19.981: INFO: namespace emptydir-4085 deletion completed in 6.077578657s

• [SLOW TEST:10.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:37:19.982: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-9586
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9586 to expose endpoints map[]
Dec 11 04:37:20.016: INFO: Get endpoints failed (1.525273ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 11 04:37:21.018: INFO: successfully validated that service endpoint-test2 in namespace services-9586 exposes endpoints map[] (1.004009116s elapsed)
STEP: Creating pod pod1 in namespace services-9586
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9586 to expose endpoints map[pod1:[80]]
Dec 11 04:37:23.039: INFO: successfully validated that service endpoint-test2 in namespace services-9586 exposes endpoints map[pod1:[80]] (2.014660708s elapsed)
STEP: Creating pod pod2 in namespace services-9586
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9586 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 11 04:37:25.063: INFO: successfully validated that service endpoint-test2 in namespace services-9586 exposes endpoints map[pod1:[80] pod2:[80]] (2.020221909s elapsed)
STEP: Deleting pod pod1 in namespace services-9586
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9586 to expose endpoints map[pod2:[80]]
Dec 11 04:37:25.080: INFO: successfully validated that service endpoint-test2 in namespace services-9586 exposes endpoints map[pod2:[80]] (5.858032ms elapsed)
STEP: Deleting pod pod2 in namespace services-9586
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9586 to expose endpoints map[]
Dec 11 04:37:25.087: INFO: successfully validated that service endpoint-test2 in namespace services-9586 exposes endpoints map[] (1.523441ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:37:25.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9586" for this suite.
Dec 11 04:37:47.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:37:47.177: INFO: namespace services-9586 deletion completed in 22.074129679s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:27.197 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:37:47.182: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-8e4c858f-a8f5-4cad-abd1-a1bf0231059d
STEP: Creating a pod to test consume secrets
Dec 11 04:37:47.223: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519" in namespace "projected-7352" to be "success or failure"
Dec 11 04:37:47.225: INFO: Pod "pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519": Phase="Pending", Reason="", readiness=false. Elapsed: 1.97736ms
Dec 11 04:37:49.228: INFO: Pod "pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004810198s
Dec 11 04:37:51.231: INFO: Pod "pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007978606s
STEP: Saw pod success
Dec 11 04:37:51.231: INFO: Pod "pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519" satisfied condition "success or failure"
Dec 11 04:37:51.233: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 04:37:51.260: INFO: Waiting for pod pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519 to disappear
Dec 11 04:37:51.269: INFO: Pod pod-projected-secrets-b0de37db-833a-4c4d-9bcc-f0aa0dc25519 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:37:51.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7352" for this suite.
Dec 11 04:37:57.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:37:57.356: INFO: namespace projected-7352 deletion completed in 6.082868546s

• [SLOW TEST:10.175 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:37:57.357: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-1923/secret-test-240cd335-a77b-4717-b4a3-ea70fe0eb3ac
STEP: Creating a pod to test consume secrets
Dec 11 04:37:57.393: INFO: Waiting up to 5m0s for pod "pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5" in namespace "secrets-1923" to be "success or failure"
Dec 11 04:37:57.397: INFO: Pod "pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.716148ms
Dec 11 04:37:59.400: INFO: Pod "pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006734965s
STEP: Saw pod success
Dec 11 04:37:59.400: INFO: Pod "pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5" satisfied condition "success or failure"
Dec 11 04:37:59.402: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5 container env-test: <nil>
STEP: delete the pod
Dec 11 04:37:59.419: INFO: Waiting for pod pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5 to disappear
Dec 11 04:37:59.421: INFO: Pod pod-configmaps-db6bfbc7-a579-4827-b4b2-1c1488713ce5 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:37:59.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1923" for this suite.
Dec 11 04:38:05.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:38:05.504: INFO: namespace secrets-1923 deletion completed in 6.078853125s

• [SLOW TEST:8.147 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:38:05.511: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 11 04:38:09.579: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 04:38:09.584: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 04:38:11.584: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 04:38:11.590: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 04:38:13.584: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 04:38:13.588: INFO: Pod pod-with-prestop-http-hook still exists
Dec 11 04:38:15.584: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 11 04:38:15.587: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:38:15.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8654" for this suite.
Dec 11 04:38:37.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:38:37.679: INFO: namespace container-lifecycle-hook-8654 deletion completed in 22.080012103s

• [SLOW TEST:32.168 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:38:37.680: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Dec 11 04:38:38.740: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1211 04:38:38.740142      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 04:38:38.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4431" for this suite.
Dec 11 04:38:44.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:38:44.821: INFO: namespace gc-4431 deletion completed in 6.07858078s

• [SLOW TEST:7.141 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:38:44.822: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-8a7aa8c7-8fd2-4cc9-abe1-e4fef1492b3e
STEP: Creating a pod to test consume configMaps
Dec 11 04:38:44.858: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37" in namespace "projected-7489" to be "success or failure"
Dec 11 04:38:44.860: INFO: Pod "pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.905407ms
Dec 11 04:38:46.866: INFO: Pod "pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007442129s
Dec 11 04:38:48.869: INFO: Pod "pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01086938s
STEP: Saw pod success
Dec 11 04:38:48.870: INFO: Pod "pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37" satisfied condition "success or failure"
Dec 11 04:38:48.872: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 04:38:48.888: INFO: Waiting for pod pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37 to disappear
Dec 11 04:38:48.890: INFO: Pod pod-projected-configmaps-522a7d90-6f24-402d-a327-660991f2cc37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:38:48.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7489" for this suite.
Dec 11 04:38:54.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:38:54.967: INFO: namespace projected-7489 deletion completed in 6.072995431s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:38:54.968: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 04:38:54.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-595'
Dec 11 04:38:55.334: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 04:38:55.334: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Dec 11 04:38:57.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete deployment e2e-test-nginx-deployment --namespace=kubectl-595'
Dec 11 04:38:57.432: INFO: stderr: ""
Dec 11 04:38:57.432: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:38:57.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-595" for this suite.
Dec 11 04:39:19.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:39:19.515: INFO: namespace kubectl-595 deletion completed in 22.073751383s

• [SLOW TEST:24.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:39:19.524: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:39:19.559: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0" in namespace "downward-api-5901" to be "success or failure"
Dec 11 04:39:19.566: INFO: Pod "downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.968168ms
Dec 11 04:39:21.569: INFO: Pod "downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009654837s
Dec 11 04:39:23.572: INFO: Pod "downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013418224s
STEP: Saw pod success
Dec 11 04:39:23.572: INFO: Pod "downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0" satisfied condition "success or failure"
Dec 11 04:39:23.575: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0 container client-container: <nil>
STEP: delete the pod
Dec 11 04:39:23.589: INFO: Waiting for pod downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0 to disappear
Dec 11 04:39:23.592: INFO: Pod downwardapi-volume-9f71b065-28df-4dc0-ac45-52108af2b3b0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:39:23.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5901" for this suite.
Dec 11 04:39:29.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:39:29.669: INFO: namespace downward-api-5901 deletion completed in 6.074571452s

• [SLOW TEST:10.145 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:39:29.675: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:39:53.714: INFO: Container started at 2019-12-11 04:39:30 +0000 UTC, pod became ready at 2019-12-11 04:39:51 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:39:53.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5745" for this suite.
Dec 11 04:40:15.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:40:15.800: INFO: namespace container-probe-5745 deletion completed in 22.080991238s

• [SLOW TEST:46.125 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:40:15.802: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:40:17.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-336" for this suite.
Dec 11 04:40:55.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:40:55.941: INFO: namespace kubelet-test-336 deletion completed in 38.085967393s

• [SLOW TEST:40.140 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:40:55.943: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:40:57.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3733" for this suite.
Dec 11 04:41:48.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:41:48.077: INFO: namespace kubelet-test-3733 deletion completed in 50.078465208s

• [SLOW TEST:52.135 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:41:48.081: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:41:48.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b" in namespace "downward-api-8527" to be "success or failure"
Dec 11 04:41:48.117: INFO: Pod "downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.644733ms
Dec 11 04:41:50.120: INFO: Pod "downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005421316s
STEP: Saw pod success
Dec 11 04:41:50.120: INFO: Pod "downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b" satisfied condition "success or failure"
Dec 11 04:41:50.124: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b container client-container: <nil>
STEP: delete the pod
Dec 11 04:41:50.140: INFO: Waiting for pod downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b to disappear
Dec 11 04:41:50.152: INFO: Pod downwardapi-volume-24399bd1-f949-4013-8bc9-3bc286c7b20b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:41:50.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8527" for this suite.
Dec 11 04:41:56.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:41:56.227: INFO: namespace downward-api-8527 deletion completed in 6.071132498s

• [SLOW TEST:8.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:41:56.228: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 11 04:41:56.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 04:41:56.255: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 04:41:56.257: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
Dec 11 04:41:56.263: INFO: kube-proxy-lqv66 from kube-system started at 2019-12-10 03:22:44 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 11 04:41:56.263: INFO: coredns-c97c9d4fc-s6cjg from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container coredns ready: true, restart count 4
Dec 11 04:41:56.263: INFO: kube-flannel-hvnk7 from kube-system started at 2019-12-10 03:23:03 +0000 UTC (2 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container install-cni ready: true, restart count 1
Dec 11 04:41:56.263: INFO: 	Container kube-flannel ready: true, restart count 3
Dec 11 04:41:56.263: INFO: coredns-c97c9d4fc-pc9tk from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container coredns ready: true, restart count 3
Dec 11 04:41:56.263: INFO: sonobuoy-e2e-job-7d5be29debef4914 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container e2e ready: true, restart count 0
Dec 11 04:41:56.263: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:41:56.263: INFO: ksc-flexvolume-ds-lzhhj from kube-system started at 2019-12-10 03:24:10 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 1
Dec 11 04:41:56.263: INFO: ksc-node-exporter-lxzvl from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container ksc-node-exporter ready: true, restart count 1
Dec 11 04:41:56.263: INFO: traefik-ingress-controller-f5njb from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container traefik-ingress-lb ready: true, restart count 1
Dec 11 04:41:56.263: INFO: sonobuoy from sonobuoy started at 2019-12-11 04:23:25 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 04:41:56.263: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-xjhp6 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:41:56.263: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:41:56.263: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 04:41:56.263: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.23 before test
Dec 11 04:41:56.270: INFO: system-monitor-75cf6f67b5-ppr59 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container system-monitor ready: false, restart count 10
Dec 11 04:41:56.270: INFO: disk-provisioner-656d7dfdc-gvvx7 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container disk-provisioner ready: true, restart count 0
Dec 11 04:41:56.270: INFO: kube-proxy-ldpcp from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 11 04:41:56.270: INFO: kube-flannel-4znx7 from kube-system started at 2019-12-10 04:24:44 +0000 UTC (2 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 04:41:56.270: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 11 04:41:56.270: INFO: metrics-server-987bf46cc-v2vwr from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 04:41:56.270: INFO: ksc-flexvolume-ds-bspbb from kube-system started at 2019-12-10 04:24:44 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
Dec 11 04:41:56.270: INFO: busybox-86dc4695f-vn8mb from default started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container busybox ready: true, restart count 23
Dec 11 04:41:56.270: INFO: ksc-node-exporter-w4n68 from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container ksc-node-exporter ready: true, restart count 0
Dec 11 04:41:56.270: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-gzxhn from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:41:56.270: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:41:56.271: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 04:41:56.271: INFO: traefik-ingress-controller-l8xcf from kube-system started at 2019-12-10 04:26:52 +0000 UTC (1 container statuses recorded)
Dec 11 04:41:56.271: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 192.168.5.21
STEP: verifying the node has the label node 192.168.5.23
Dec 11 04:41:56.305: INFO: Pod busybox-86dc4695f-vn8mb requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.305: INFO: Pod coredns-c97c9d4fc-pc9tk requesting resource cpu=100m on Node 192.168.5.21
Dec 11 04:41:56.305: INFO: Pod coredns-c97c9d4fc-s6cjg requesting resource cpu=100m on Node 192.168.5.21
Dec 11 04:41:56.305: INFO: Pod disk-provisioner-656d7dfdc-gvvx7 requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.305: INFO: Pod ksc-flexvolume-ds-bspbb requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.305: INFO: Pod ksc-flexvolume-ds-lzhhj requesting resource cpu=0m on Node 192.168.5.21
Dec 11 04:41:56.306: INFO: Pod ksc-node-exporter-lxzvl requesting resource cpu=10m on Node 192.168.5.21
Dec 11 04:41:56.306: INFO: Pod ksc-node-exporter-w4n68 requesting resource cpu=10m on Node 192.168.5.23
Dec 11 04:41:56.306: INFO: Pod kube-flannel-4znx7 requesting resource cpu=150m on Node 192.168.5.23
Dec 11 04:41:56.306: INFO: Pod kube-flannel-hvnk7 requesting resource cpu=150m on Node 192.168.5.21
Dec 11 04:41:56.306: INFO: Pod kube-proxy-ldpcp requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.306: INFO: Pod kube-proxy-lqv66 requesting resource cpu=0m on Node 192.168.5.21
Dec 11 04:41:56.306: INFO: Pod metrics-server-987bf46cc-v2vwr requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.306: INFO: Pod system-monitor-75cf6f67b5-ppr59 requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.307: INFO: Pod traefik-ingress-controller-f5njb requesting resource cpu=0m on Node 192.168.5.21
Dec 11 04:41:56.307: INFO: Pod traefik-ingress-controller-l8xcf requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.307: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.5.21
Dec 11 04:41:56.307: INFO: Pod sonobuoy-e2e-job-7d5be29debef4914 requesting resource cpu=0m on Node 192.168.5.21
Dec 11 04:41:56.307: INFO: Pod sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-gzxhn requesting resource cpu=0m on Node 192.168.5.23
Dec 11 04:41:56.307: INFO: Pod sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-xjhp6 requesting resource cpu=0m on Node 192.168.5.21
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e.15df3768713725a4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4307/filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e to 192.168.5.21]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e.15df3768b01071c8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e.15df3768b3ad0505], Reason = [Created], Message = [Created container filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e.15df3768c2ba7c28], Reason = [Started], Message = [Started container filler-pod-7669974f-e574-4384-9f38-cc8b5bd98a0e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c.15df3768715a91ed], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4307/filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c to 192.168.5.23]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c.15df3768af858d4d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c.15df3768b338fca9], Reason = [Created], Message = [Created container filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c.15df3768c0904697], Reason = [Started], Message = [Started container filler-pod-d5286ea6-34ea-428a-a23a-f9a34836162c]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15df376960c151f5], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node 192.168.5.23
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.5.21
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:42:01.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4307" for this suite.
Dec 11 04:42:07.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:42:07.444: INFO: namespace sched-pred-4307 deletion completed in 6.072302196s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.217 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:42:07.445: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 11 04:42:09.504: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-018278524 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 11 04:42:24.596: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:42:24.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1179" for this suite.
Dec 11 04:42:30.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:42:30.682: INFO: namespace pods-1179 deletion completed in 6.077807468s

• [SLOW TEST:23.237 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:42:30.683: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-ac1af95e-5bf8-47cf-b2f2-5a233d82ca8a
STEP: Creating configMap with name cm-test-opt-upd-4724c089-17aa-465b-8ce2-e079a9d657db
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ac1af95e-5bf8-47cf-b2f2-5a233d82ca8a
STEP: Updating configmap cm-test-opt-upd-4724c089-17aa-465b-8ce2-e079a9d657db
STEP: Creating configMap with name cm-test-opt-create-e65a24df-3078-4c9c-bf3c-ec2dea95a82a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:42:34.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6862" for this suite.
Dec 11 04:42:56.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:42:56.870: INFO: namespace projected-6862 deletion completed in 22.075906321s

• [SLOW TEST:26.187 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:42:56.873: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:42:56.912: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 11 04:43:01.917: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 04:43:01.917: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 11 04:43:01.933: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5116,SelfLink:/apis/apps/v1/namespaces/deployment-5116/deployments/test-cleanup-deployment,UID:5f62cf61-c421-4faf-9d1e-6a6e40b75879,ResourceVersion:162127,Generation:1,CreationTimestamp:2019-12-11 04:43:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 11 04:43:01.936: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 11 04:43:01.936: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 11 04:43:01.936: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-5116,SelfLink:/apis/apps/v1/namespaces/deployment-5116/replicasets/test-cleanup-controller,UID:d7d97b79-5ab2-4c26-a72a-c4384a3ce3f7,ResourceVersion:162128,Generation:1,CreationTimestamp:2019-12-11 04:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5f62cf61-c421-4faf-9d1e-6a6e40b75879 0xc002f6e717 0xc002f6e718}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 11 04:43:01.940: INFO: Pod "test-cleanup-controller-kmnz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-kmnz9,GenerateName:test-cleanup-controller-,Namespace:deployment-5116,SelfLink:/api/v1/namespaces/deployment-5116/pods/test-cleanup-controller-kmnz9,UID:65d783bb-0154-451d-9e44-b0d744a4d83c,ResourceVersion:162119,Generation:0,CreationTimestamp:2019-12-11 04:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller d7d97b79-5ab2-4c26-a72a-c4384a3ce3f7 0xc002f6ec97 0xc002f6ec98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pkpdt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pkpdt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pkpdt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:42:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:42:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.20,StartTime:2019-12-11 04:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:42:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://992bdf7d8dc4e730aaaa21ad16d7d5d6fb5b8f0427c96e14cd7cedfa326ad016}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:43:01.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5116" for this suite.
Dec 11 04:43:07.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:43:08.021: INFO: namespace deployment-5116 deletion completed in 6.07711786s

• [SLOW TEST:11.148 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:43:08.022: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Dec 11 04:43:08.050: INFO: Waiting up to 5m0s for pod "client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61" in namespace "containers-440" to be "success or failure"
Dec 11 04:43:08.052: INFO: Pod "client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.164569ms
Dec 11 04:43:10.055: INFO: Pod "client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00522508s
Dec 11 04:43:12.058: INFO: Pod "client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008250047s
STEP: Saw pod success
Dec 11 04:43:12.058: INFO: Pod "client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61" satisfied condition "success or failure"
Dec 11 04:43:12.061: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61 container test-container: <nil>
STEP: delete the pod
Dec 11 04:43:12.077: INFO: Waiting for pod client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61 to disappear
Dec 11 04:43:12.079: INFO: Pod client-containers-a9e2aefd-fc3a-440d-8bdb-26b32b5e3b61 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:43:12.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-440" for this suite.
Dec 11 04:43:18.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:43:18.153: INFO: namespace containers-440 deletion completed in 6.071554117s

• [SLOW TEST:10.131 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:43:18.154: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 11 04:43:18.178: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 04:43:18.184: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 04:43:18.187: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
Dec 11 04:43:18.193: INFO: ksc-flexvolume-ds-lzhhj from kube-system started at 2019-12-10 03:24:10 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 1
Dec 11 04:43:18.193: INFO: ksc-node-exporter-lxzvl from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container ksc-node-exporter ready: true, restart count 1
Dec 11 04:43:18.193: INFO: traefik-ingress-controller-f5njb from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container traefik-ingress-lb ready: true, restart count 1
Dec 11 04:43:18.193: INFO: sonobuoy from sonobuoy started at 2019-12-11 04:23:25 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 04:43:18.193: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-xjhp6 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:43:18.193: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 04:43:18.193: INFO: kube-proxy-lqv66 from kube-system started at 2019-12-10 03:22:44 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.193: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 11 04:43:18.193: INFO: coredns-c97c9d4fc-s6cjg from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.194: INFO: 	Container coredns ready: true, restart count 4
Dec 11 04:43:18.194: INFO: kube-flannel-hvnk7 from kube-system started at 2019-12-10 03:23:03 +0000 UTC (2 container statuses recorded)
Dec 11 04:43:18.194: INFO: 	Container install-cni ready: true, restart count 1
Dec 11 04:43:18.194: INFO: 	Container kube-flannel ready: true, restart count 3
Dec 11 04:43:18.194: INFO: coredns-c97c9d4fc-pc9tk from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.194: INFO: 	Container coredns ready: true, restart count 3
Dec 11 04:43:18.194: INFO: sonobuoy-e2e-job-7d5be29debef4914 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:43:18.194: INFO: 	Container e2e ready: true, restart count 0
Dec 11 04:43:18.194: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:43:18.194: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.23 before test
Dec 11 04:43:18.200: INFO: ksc-flexvolume-ds-bspbb from kube-system started at 2019-12-10 04:24:44 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.200: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
Dec 11 04:43:18.200: INFO: metrics-server-987bf46cc-v2vwr from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.200: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 04:43:18.200: INFO: ksc-node-exporter-w4n68 from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.200: INFO: 	Container ksc-node-exporter ready: true, restart count 0
Dec 11 04:43:18.200: INFO: busybox-86dc4695f-vn8mb from default started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.200: INFO: 	Container busybox ready: true, restart count 23
Dec 11 04:43:18.201: INFO: traefik-ingress-controller-l8xcf from kube-system started at 2019-12-10 04:26:52 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Dec 11 04:43:18.201: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-gzxhn from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 04:43:18.201: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 04:43:18.201: INFO: system-monitor-75cf6f67b5-ppr59 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container system-monitor ready: true, restart count 11
Dec 11 04:43:18.201: INFO: kube-proxy-ldpcp from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 11 04:43:18.201: INFO: disk-provisioner-656d7dfdc-gvvx7 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container disk-provisioner ready: true, restart count 0
Dec 11 04:43:18.201: INFO: kube-flannel-4znx7 from kube-system started at 2019-12-10 04:24:44 +0000 UTC (2 container statuses recorded)
Dec 11 04:43:18.201: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 04:43:18.201: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-44ccedf7-4a04-4f6b-9132-3552782e564a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-44ccedf7-4a04-4f6b-9132-3552782e564a off the node 192.168.5.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-44ccedf7-4a04-4f6b-9132-3552782e564a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:43:22.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-58" for this suite.
Dec 11 04:43:34.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:43:34.341: INFO: namespace sched-pred-58 deletion completed in 12.081561839s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:16.188 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:43:34.342: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:43:34.368: INFO: Creating deployment "nginx-deployment"
Dec 11 04:43:34.370: INFO: Waiting for observed generation 1
Dec 11 04:43:36.377: INFO: Waiting for all required pods to come up
Dec 11 04:43:36.380: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 11 04:43:38.390: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 11 04:43:38.395: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 11 04:43:38.401: INFO: Updating deployment nginx-deployment
Dec 11 04:43:38.401: INFO: Waiting for observed generation 2
Dec 11 04:43:40.406: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 11 04:43:40.408: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 11 04:43:40.409: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 11 04:43:40.416: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 11 04:43:40.416: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 11 04:43:40.417: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 11 04:43:40.421: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 11 04:43:40.421: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 11 04:43:40.426: INFO: Updating deployment nginx-deployment
Dec 11 04:43:40.426: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 11 04:43:40.429: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 11 04:43:40.433: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 11 04:43:40.440: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-5041,SelfLink:/apis/apps/v1/namespaces/deployment-5041/deployments/nginx-deployment,UID:4306a0f8-5517-4bac-8f98-9449fc0982c4,ResourceVersion:162353,Generation:3,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-12-11 04:43:37 +0000 UTC 2019-12-11 04:43:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-11 04:43:38 +0000 UTC 2019-12-11 04:43:34 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 11 04:43:40.446: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-5041,SelfLink:/apis/apps/v1/namespaces/deployment-5041/replicasets/nginx-deployment-55fb7cb77f,UID:7599f529-258f-438a-8725-646817368f8b,ResourceVersion:162355,Generation:3,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4306a0f8-5517-4bac-8f98-9449fc0982c4 0xc002ed74d7 0xc002ed74d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 04:43:40.446: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 11 04:43:40.446: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-5041,SelfLink:/apis/apps/v1/namespaces/deployment-5041/replicasets/nginx-deployment-7b8c6f4498,UID:4d4354cb-a11a-4609-9692-42058130c397,ResourceVersion:162354,Generation:3,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4306a0f8-5517-4bac-8f98-9449fc0982c4 0xc002ed75a7 0xc002ed75a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 11 04:43:40.460: INFO: Pod "nginx-deployment-55fb7cb77f-55x5k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-55x5k,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-55x5k,UID:13e7c6cd-88de-4d98-8646-fbe21fcd56c3,ResourceVersion:162339,Generation:0,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002ed7f07 0xc002ed7f08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:,StartTime:2019-12-11 04:43:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.460: INFO: Pod "nginx-deployment-55fb7cb77f-d78j5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d78j5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-d78j5,UID:de897c98-2e8d-4344-a647-41a179c83364,ResourceVersion:162351,Generation:0,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12030 0xc002a12031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:,StartTime:2019-12-11 04:43:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.460: INFO: Pod "nginx-deployment-55fb7cb77f-grr5g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-grr5g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-grr5g,UID:2ed5190c-3691-4242-8963-205ff0069ec6,ResourceVersion:162363,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12160 0xc002a12161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-55fb7cb77f-hrh4l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hrh4l,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-hrh4l,UID:8392e0e3-505b-48c0-be0c-3b7f2fd168f9,ResourceVersion:162349,Generation:0,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12220 0xc002a12221}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-12-11 04:43:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-55fb7cb77f-jlfxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jlfxt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-jlfxt,UID:ee9898f3-df7c-480a-8fee-dda990017da6,ResourceVersion:162369,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12350 0xc002a12351}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-55fb7cb77f-q829f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q829f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-q829f,UID:63f28389-a85d-4350-8bca-352d72c96c43,ResourceVersion:162340,Generation:0,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12430 0xc002a12431}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-12-11 04:43:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-55fb7cb77f-tlvxv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tlvxv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-tlvxv,UID:e41166f3-b71e-4f53-ad8d-c77529edb192,ResourceVersion:162336,Generation:0,CreationTimestamp:2019-12-11 04:43:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12560 0xc002a12561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-12-11 04:43:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-55fb7cb77f-w7brf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w7brf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-55fb7cb77f-w7brf,UID:3ff4ed37-76cb-4d2b-bd63-e3ac6c11299c,ResourceVersion:162368,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 7599f529-258f-438a-8725-646817368f8b 0xc002a12690 0xc002a12691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.461: INFO: Pod "nginx-deployment-7b8c6f4498-4h7rl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4h7rl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-4h7rl,UID:e97ac546-8694-43e7-8754-b53699a94339,ResourceVersion:162358,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12750 0xc002a12751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-5svw9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5svw9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-5svw9,UID:43060445-915e-4e54-821c-860236f19f49,ResourceVersion:162291,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12820 0xc002a12821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.26,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9d2ad70ae9438487ff43b45876685889fa29a843c5767e73bef15a50eb648f4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-7nqm9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7nqm9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-7nqm9,UID:c35c01bb-6b69-4381-a0c0-81b04cb14e52,ResourceVersion:162304,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12940 0xc002a12941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.19,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e21cbe49496a66d6cd2646fef32574e456117cee39843f22bb73aa589b119155}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-7vxww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7vxww,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-7vxww,UID:67534bea-7fbe-408e-932d-a50563c57ef7,ResourceVersion:162365,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12a60 0xc002a12a61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-g4b5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g4b5g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-g4b5g,UID:cc889c95-3271-49be-bb49-7d0ccc9ef6ef,ResourceVersion:162316,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12b10 0xc002a12b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.29,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8c104f01005e56cf5febd0b19b4482e20d606a1fe121606c85ac908106182b84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-g7km4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g7km4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-g7km4,UID:b7f13e19-38f8-4cc4-8eab-908f087e0b80,ResourceVersion:162301,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12c30 0xc002a12c31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.20,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7303df825d6f45c5c676f2635edf9be9a0b67c224291a893456983891cac9e76}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-hdbw9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hdbw9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-hdbw9,UID:c009009f-607f-4aec-9bc1-a27344dfdffe,ResourceVersion:162310,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12d50 0xc002a12d51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.22,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://84f7c00162081452e778ab3fd98c6c3f5021a86621373a66035bfbe5370122fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.462: INFO: Pod "nginx-deployment-7b8c6f4498-jqzg6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jqzg6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-jqzg6,UID:b91ad448-df4d-4bdd-a4d1-393de7c090b9,ResourceVersion:162288,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12e80 0xc002a12e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.28,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7f00c21e41e6a4345b153e6cc59332c0bcd23a65f225c61aeb2805f6fe795068}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-kxtjq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kxtjq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-kxtjq,UID:c5f0f2f4-07b0-4b71-9e42-d0c9b7e21ddd,ResourceVersion:162294,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a12fb0 0xc002a12fb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.25,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ec47fe041598ace7416e083db10a99da4ea5d30b500938314e84c453eea8552e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-mg5mz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mg5mz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-mg5mz,UID:27e9d118-288f-43b8-84ac-c8a09c33d8bc,ResourceVersion:162359,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a130e0 0xc002a130e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-n7wrk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n7wrk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-n7wrk,UID:bc3051de-96eb-4a95-8197-e9f729e0fed4,ResourceVersion:162364,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a13190 0xc002a13191}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-s5qrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s5qrs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-s5qrs,UID:d69077d9-6a4d-4dd5-a79f-4c84bbed542d,ResourceVersion:162366,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a13240 0xc002a13241}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-s6mdc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-s6mdc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-s6mdc,UID:665af718-7577-48f0-90ab-ea583aeb6d4c,ResourceVersion:162361,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a132f0 0xc002a132f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-tz7lz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tz7lz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-tz7lz,UID:d7e19786-18f0-4c83-8e52-f9240e1374c2,ResourceVersion:162367,Generation:0,CreationTimestamp:2019-12-11 04:43:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a133d0 0xc002a133d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 11 04:43:40.463: INFO: Pod "nginx-deployment-7b8c6f4498-xbcnc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xbcnc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-5041,SelfLink:/api/v1/namespaces/deployment-5041/pods/nginx-deployment-7b8c6f4498-xbcnc,UID:9411cd0b-7fb6-4e02-a32f-2ec021d83036,ResourceVersion:162307,Generation:0,CreationTimestamp:2019-12-11 04:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 4d4354cb-a11a-4609-9692-42058130c397 0xc002a13480 0xc002a13481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-vk76z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk76z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vk76z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:43:34 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.23,StartTime:2019-12-11 04:43:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-11 04:43:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e77b2fb617e04dac94b240722e6de656ee2c2916e7564a96eabafb49565b48af}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:43:40.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5041" for this suite.
Dec 11 04:43:46.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:43:46.554: INFO: namespace deployment-5041 deletion completed in 6.086951958s

• [SLOW TEST:12.213 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:43:46.555: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-cdb840c3-7493-4ffe-8fcb-c1ece46cf586 in namespace container-probe-2988
Dec 11 04:43:52.591: INFO: Started pod busybox-cdb840c3-7493-4ffe-8fcb-c1ece46cf586 in namespace container-probe-2988
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 04:43:52.594: INFO: Initial restart count of pod busybox-cdb840c3-7493-4ffe-8fcb-c1ece46cf586 is 0
Dec 11 04:44:40.692: INFO: Restart count of pod container-probe-2988/busybox-cdb840c3-7493-4ffe-8fcb-c1ece46cf586 is now 1 (48.097863714s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:44:40.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2988" for this suite.
Dec 11 04:44:46.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:44:46.787: INFO: namespace container-probe-2988 deletion completed in 6.083440801s

• [SLOW TEST:60.233 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:44:46.791: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f9d92c0c-89e1-46fa-a5dc-ca7dfb806523
STEP: Creating a pod to test consume configMaps
Dec 11 04:44:46.831: INFO: Waiting up to 5m0s for pod "pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730" in namespace "configmap-8636" to be "success or failure"
Dec 11 04:44:46.833: INFO: Pod "pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730": Phase="Pending", Reason="", readiness=false. Elapsed: 1.974276ms
Dec 11 04:44:48.837: INFO: Pod "pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00581764s
Dec 11 04:44:50.841: INFO: Pod "pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009688723s
STEP: Saw pod success
Dec 11 04:44:50.841: INFO: Pod "pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730" satisfied condition "success or failure"
Dec 11 04:44:50.843: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 04:44:50.876: INFO: Waiting for pod pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730 to disappear
Dec 11 04:44:50.879: INFO: Pod pod-configmaps-39c15aa8-dd64-4208-89be-96f3a09c6730 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:44:50.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8636" for this suite.
Dec 11 04:44:56.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:44:56.960: INFO: namespace configmap-8636 deletion completed in 6.072085519s

• [SLOW TEST:10.169 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:44:56.964: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 11 04:45:00.009: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:45:00.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8811" for this suite.
Dec 11 04:45:06.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:45:06.098: INFO: namespace container-runtime-8811 deletion completed in 6.075465788s

• [SLOW TEST:9.135 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:45:06.102: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 11 04:45:06.133: INFO: Waiting up to 5m0s for pod "downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8" in namespace "downward-api-4553" to be "success or failure"
Dec 11 04:45:06.135: INFO: Pod "downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.648896ms
Dec 11 04:45:08.138: INFO: Pod "downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005642319s
STEP: Saw pod success
Dec 11 04:45:08.139: INFO: Pod "downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8" satisfied condition "success or failure"
Dec 11 04:45:08.143: INFO: Trying to get logs from node 192.168.5.23 pod downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8 container dapi-container: <nil>
STEP: delete the pod
Dec 11 04:45:08.159: INFO: Waiting for pod downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8 to disappear
Dec 11 04:45:08.161: INFO: Pod downward-api-61f430de-82ce-462f-82be-2b8776cb3fc8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:45:08.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4553" for this suite.
Dec 11 04:45:14.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:45:14.242: INFO: namespace downward-api-4553 deletion completed in 6.076810319s

• [SLOW TEST:8.140 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:45:14.242: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-36736f59-4885-4db7-a8fc-89b14ae0d50e
STEP: Creating a pod to test consume secrets
Dec 11 04:45:14.275: INFO: Waiting up to 5m0s for pod "pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac" in namespace "secrets-6390" to be "success or failure"
Dec 11 04:45:14.277: INFO: Pod "pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.226408ms
Dec 11 04:45:16.281: INFO: Pod "pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005616554s
Dec 11 04:45:18.284: INFO: Pod "pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009113643s
STEP: Saw pod success
Dec 11 04:45:18.284: INFO: Pod "pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac" satisfied condition "success or failure"
Dec 11 04:45:18.287: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 04:45:18.304: INFO: Waiting for pod pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac to disappear
Dec 11 04:45:18.306: INFO: Pod pod-secrets-ee0c3e2f-495c-46d6-90fb-a2c0ea048aac no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:45:18.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6390" for this suite.
Dec 11 04:45:24.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:45:24.392: INFO: namespace secrets-6390 deletion completed in 6.082283297s

• [SLOW TEST:10.150 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:45:24.392: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-d6cac63b-dec6-47bb-a28f-6c77db951305
STEP: Creating a pod to test consume configMaps
Dec 11 04:45:24.424: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06" in namespace "projected-4932" to be "success or failure"
Dec 11 04:45:24.427: INFO: Pod "pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.436889ms
Dec 11 04:45:26.430: INFO: Pod "pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005615726s
Dec 11 04:45:28.440: INFO: Pod "pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015884114s
STEP: Saw pod success
Dec 11 04:45:28.440: INFO: Pod "pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06" satisfied condition "success or failure"
Dec 11 04:45:28.442: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 04:45:28.462: INFO: Waiting for pod pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06 to disappear
Dec 11 04:45:28.464: INFO: Pod pod-projected-configmaps-8cf560c3-f3a5-4fce-b3c4-140975b1ce06 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:45:28.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4932" for this suite.
Dec 11 04:45:34.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:45:34.549: INFO: namespace projected-4932 deletion completed in 6.082257768s

• [SLOW TEST:10.157 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:45:34.551: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:45:34.590: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 04:45:34.597: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:34.597: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:34.597: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:34.599: INFO: Number of nodes with available pods: 0
Dec 11 04:45:34.599: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:45:35.604: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:35.604: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:35.604: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:35.607: INFO: Number of nodes with available pods: 0
Dec 11 04:45:35.607: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:45:36.604: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:36.604: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:36.604: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:36.609: INFO: Number of nodes with available pods: 0
Dec 11 04:45:36.609: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:45:37.603: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:37.604: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:37.604: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:37.607: INFO: Number of nodes with available pods: 2
Dec 11 04:45:37.607: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 11 04:45:37.634: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:37.634: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:37.639: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:37.639: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:37.639: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:38.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:38.642: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:38.645: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:38.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:38.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:39.643: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:39.643: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:39.646: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:39.647: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:39.647: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:40.643: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:40.643: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:40.643: INFO: Pod daemon-set-rqrxh is not available
Dec 11 04:45:40.647: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:40.647: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:40.648: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:41.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:41.642: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:41.642: INFO: Pod daemon-set-rqrxh is not available
Dec 11 04:45:41.647: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:41.647: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:41.647: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:42.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:42.642: INFO: Wrong image for pod: daemon-set-rqrxh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:42.642: INFO: Pod daemon-set-rqrxh is not available
Dec 11 04:45:42.648: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:42.648: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:42.648: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:43.650: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:43.650: INFO: Pod daemon-set-q2whw is not available
Dec 11 04:45:43.653: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:43.653: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:43.653: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:44.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:44.642: INFO: Pod daemon-set-q2whw is not available
Dec 11 04:45:44.646: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:44.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:44.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:45.643: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:45.647: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:45.647: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:45.647: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:46.643: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:46.647: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:46.647: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:46.647: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:47.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:47.642: INFO: Pod daemon-set-2xn6q is not available
Dec 11 04:45:47.647: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:47.648: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:47.648: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:48.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:48.642: INFO: Pod daemon-set-2xn6q is not available
Dec 11 04:45:48.645: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:48.645: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:48.645: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:49.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:49.642: INFO: Pod daemon-set-2xn6q is not available
Dec 11 04:45:49.646: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:49.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:49.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:50.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:50.642: INFO: Pod daemon-set-2xn6q is not available
Dec 11 04:45:50.645: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:50.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:50.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:51.642: INFO: Wrong image for pod: daemon-set-2xn6q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 11 04:45:51.642: INFO: Pod daemon-set-2xn6q is not available
Dec 11 04:45:51.646: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:51.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:51.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.642: INFO: Pod daemon-set-fn99s is not available
Dec 11 04:45:52.646: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.646: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.646: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 11 04:45:52.649: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.649: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.649: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:52.651: INFO: Number of nodes with available pods: 1
Dec 11 04:45:52.651: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:45:53.655: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:53.655: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:53.655: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:53.658: INFO: Number of nodes with available pods: 1
Dec 11 04:45:53.658: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:45:54.655: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:54.656: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:54.656: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:45:54.658: INFO: Number of nodes with available pods: 2
Dec 11 04:45:54.658: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4944, will wait for the garbage collector to delete the pods
Dec 11 04:45:54.730: INFO: Deleting DaemonSet.extensions daemon-set took: 5.558494ms
Dec 11 04:45:55.130: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.208104ms
Dec 11 04:45:58.033: INFO: Number of nodes with available pods: 0
Dec 11 04:45:58.033: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 04:45:58.036: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4944/daemonsets","resourceVersion":"162905"},"items":null}

Dec 11 04:45:58.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4944/pods","resourceVersion":"162905"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:45:58.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4944" for this suite.
Dec 11 04:46:04.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:04.121: INFO: namespace daemonsets-4944 deletion completed in 6.07300681s

• [SLOW TEST:29.571 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:04.123: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 04:46:04.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-196'
Dec 11 04:46:04.256: INFO: stderr: ""
Dec 11 04:46:04.256: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Dec 11 04:46:04.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete pods e2e-test-nginx-pod --namespace=kubectl-196'
Dec 11 04:46:11.932: INFO: stderr: ""
Dec 11 04:46:11.933: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:46:11.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-196" for this suite.
Dec 11 04:46:17.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:18.020: INFO: namespace kubectl-196 deletion completed in 6.081852498s

• [SLOW TEST:13.897 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:18.022: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 11 04:46:18.060: INFO: Waiting up to 5m0s for pod "pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b" in namespace "emptydir-4052" to be "success or failure"
Dec 11 04:46:18.062: INFO: Pod "pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.235506ms
Dec 11 04:46:20.066: INFO: Pod "pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b": Phase="Running", Reason="", readiness=true. Elapsed: 2.005719137s
Dec 11 04:46:22.070: INFO: Pod "pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010043314s
STEP: Saw pod success
Dec 11 04:46:22.070: INFO: Pod "pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b" satisfied condition "success or failure"
Dec 11 04:46:22.073: INFO: Trying to get logs from node 192.168.5.21 pod pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b container test-container: <nil>
STEP: delete the pod
Dec 11 04:46:22.092: INFO: Waiting for pod pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b to disappear
Dec 11 04:46:22.095: INFO: Pod pod-226eafd6-fbc6-4f20-a912-33ce44e37a7b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:46:22.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4052" for this suite.
Dec 11 04:46:28.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:28.192: INFO: namespace emptydir-4052 deletion completed in 6.093248802s

• [SLOW TEST:10.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:28.196: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-603.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-603.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-603.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-603.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 04:46:32.267: INFO: DNS probes using dns-603/dns-test-d58b69ac-b256-480a-8529-b6c40628b125 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:46:32.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-603" for this suite.
Dec 11 04:46:38.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:38.370: INFO: namespace dns-603 deletion completed in 6.080559281s

• [SLOW TEST:10.175 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:38.373: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 11 04:46:38.404: INFO: Waiting up to 5m0s for pod "pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011" in namespace "emptydir-1980" to be "success or failure"
Dec 11 04:46:38.406: INFO: Pod "pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011": Phase="Pending", Reason="", readiness=false. Elapsed: 2.43053ms
Dec 11 04:46:40.411: INFO: Pod "pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006818623s
STEP: Saw pod success
Dec 11 04:46:40.411: INFO: Pod "pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011" satisfied condition "success or failure"
Dec 11 04:46:40.413: INFO: Trying to get logs from node 192.168.5.21 pod pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011 container test-container: <nil>
STEP: delete the pod
Dec 11 04:46:40.432: INFO: Waiting for pod pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011 to disappear
Dec 11 04:46:40.435: INFO: Pod pod-dfe9a813-ebcf-4bd5-8a9a-390adf2f6011 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:46:40.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1980" for this suite.
Dec 11 04:46:46.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:46.513: INFO: namespace emptydir-1980 deletion completed in 6.074675989s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:46.518: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 11 04:46:48.561: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:46:48.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7638" for this suite.
Dec 11 04:46:54.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:46:54.667: INFO: namespace container-runtime-7638 deletion completed in 6.081683176s

• [SLOW TEST:8.150 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:46:54.673: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9477
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 04:46:54.702: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 04:47:12.758: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.4.37:8080/dial?request=hostName&protocol=udp&host=10.8.2.50&port=8081&tries=1'] Namespace:pod-network-test-9477 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:47:12.758: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:47:12.961: INFO: Waiting for endpoints: map[]
Dec 11 04:47:12.964: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.4.37:8080/dial?request=hostName&protocol=udp&host=10.8.4.36&port=8081&tries=1'] Namespace:pod-network-test-9477 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:47:12.964: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:47:13.143: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:47:13.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9477" for this suite.
Dec 11 04:47:35.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:47:35.239: INFO: namespace pod-network-test-9477 deletion completed in 22.092015742s

• [SLOW TEST:40.567 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:47:35.241: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:47:35.273: INFO: Creating ReplicaSet my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee
Dec 11 04:47:35.279: INFO: Pod name my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee: Found 0 pods out of 1
Dec 11 04:47:40.283: INFO: Pod name my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee: Found 1 pods out of 1
Dec 11 04:47:40.283: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee" is running
Dec 11 04:47:40.287: INFO: Pod "my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee-dmghg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:47:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:47:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:47:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:47:35 +0000 UTC Reason: Message:}])
Dec 11 04:47:40.287: INFO: Trying to dial the pod
Dec 11 04:47:45.301: INFO: Controller my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee: Got expected result from replica 1 [my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee-dmghg]: "my-hostname-basic-d9bd0210-c91a-4639-b581-915666d973ee-dmghg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:47:45.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8444" for this suite.
Dec 11 04:47:51.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:47:51.390: INFO: namespace replicaset-8444 deletion completed in 6.083322467s

• [SLOW TEST:16.149 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:47:51.390: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 11 04:47:51.417: INFO: PodSpec: initContainers in spec.initContainers
Dec 11 04:48:35.486: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7169cf85-ee9f-4a39-8d96-ffce592211a0", GenerateName:"", Namespace:"init-container-420", SelfLink:"/api/v1/namespaces/init-container-420/pods/pod-init-7169cf85-ee9f-4a39-8d96-ffce592211a0", UID:"19711f14-cc0d-4763-82f2-cf69ed8d3e28", ResourceVersion:"163309", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63711636471, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"417758498"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-89dn7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021aeb80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-89dn7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-89dn7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-89dn7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00176b048), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.5.21", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023a0240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00176b0c0), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711636471, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711636471, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711636471, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711636471, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.21", PodIP:"10.8.2.52", StartTime:(*v1.Time)(0xc00212e660), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00189f340)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00189f3b0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c2358e3f5179bd56c1edaac7d8b5e351a0194ca38795dd77172649baa2f4f3dc"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00212e6a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00212e680), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:48:35.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-420" for this suite.
Dec 11 04:48:57.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:48:57.564: INFO: namespace init-container-420 deletion completed in 22.07212383s

• [SLOW TEST:66.174 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:48:57.565: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-34690dd5-df4d-456c-8d76-a01e774acafb in namespace container-probe-4178
Dec 11 04:49:01.599: INFO: Started pod liveness-34690dd5-df4d-456c-8d76-a01e774acafb in namespace container-probe-4178
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 04:49:01.601: INFO: Initial restart count of pod liveness-34690dd5-df4d-456c-8d76-a01e774acafb is 0
Dec 11 04:49:11.620: INFO: Restart count of pod container-probe-4178/liveness-34690dd5-df4d-456c-8d76-a01e774acafb is now 1 (10.018949974s elapsed)
Dec 11 04:49:31.654: INFO: Restart count of pod container-probe-4178/liveness-34690dd5-df4d-456c-8d76-a01e774acafb is now 2 (30.053249694s elapsed)
Dec 11 04:49:53.700: INFO: Restart count of pod container-probe-4178/liveness-34690dd5-df4d-456c-8d76-a01e774acafb is now 3 (52.09916763s elapsed)
Dec 11 04:50:11.732: INFO: Restart count of pod container-probe-4178/liveness-34690dd5-df4d-456c-8d76-a01e774acafb is now 4 (1m10.130767368s elapsed)
Dec 11 04:51:23.866: INFO: Restart count of pod container-probe-4178/liveness-34690dd5-df4d-456c-8d76-a01e774acafb is now 5 (2m22.265167892s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:51:23.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4178" for this suite.
Dec 11 04:51:29.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:51:29.968: INFO: namespace container-probe-4178 deletion completed in 6.081281581s

• [SLOW TEST:152.403 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:51:29.971: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 11 04:51:34.528: INFO: Successfully updated pod "labelsupdate82c4654e-528e-4d07-a7f3-bc3f8df16b1e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:51:36.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2156" for this suite.
Dec 11 04:51:58.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:51:58.627: INFO: namespace downward-api-2156 deletion completed in 22.077496616s

• [SLOW TEST:28.656 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:51:58.628: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 04:52:02.686: INFO: DNS probes using dns-test-a4d2a4dc-fc1a-48c2-af9c-6c32b1f2e5ab succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 04:52:04.722: INFO: File wheezy_udp@dns-test-service-3.dns-3335.svc.cluster.local from pod  dns-3335/dns-test-13de4c1f-6640-4036-b75a-0b274d2ef186 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 11 04:52:04.725: INFO: File jessie_udp@dns-test-service-3.dns-3335.svc.cluster.local from pod  dns-3335/dns-test-13de4c1f-6640-4036-b75a-0b274d2ef186 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 11 04:52:04.725: INFO: Lookups using dns-3335/dns-test-13de4c1f-6640-4036-b75a-0b274d2ef186 failed for: [wheezy_udp@dns-test-service-3.dns-3335.svc.cluster.local jessie_udp@dns-test-service-3.dns-3335.svc.cluster.local]

Dec 11 04:52:09.733: INFO: DNS probes using dns-test-13de4c1f-6640-4036-b75a-0b274d2ef186 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3335.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3335.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 04:52:13.792: INFO: DNS probes using dns-test-8b849ed8-ee2d-4101-9da1-25288b0cff03 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:52:13.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3335" for this suite.
Dec 11 04:52:19.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:52:19.898: INFO: namespace dns-3335 deletion completed in 6.080240843s

• [SLOW TEST:21.271 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:52:19.900: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Dec 11 04:52:19.930: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 11 04:52:19.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:20.228: INFO: stderr: ""
Dec 11 04:52:20.228: INFO: stdout: "service/redis-slave created\n"
Dec 11 04:52:20.229: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 11 04:52:20.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:20.483: INFO: stderr: ""
Dec 11 04:52:20.483: INFO: stdout: "service/redis-master created\n"
Dec 11 04:52:20.483: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 11 04:52:20.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:20.723: INFO: stderr: ""
Dec 11 04:52:20.723: INFO: stdout: "service/frontend created\n"
Dec 11 04:52:20.724: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 11 04:52:20.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:20.963: INFO: stderr: ""
Dec 11 04:52:20.963: INFO: stdout: "deployment.apps/frontend created\n"
Dec 11 04:52:20.963: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 11 04:52:20.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:21.210: INFO: stderr: ""
Dec 11 04:52:21.210: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 11 04:52:21.211: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 11 04:52:21.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-9605'
Dec 11 04:52:21.528: INFO: stderr: ""
Dec 11 04:52:21.528: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 11 04:52:21.528: INFO: Waiting for all frontend pods to be Running.
Dec 11 04:52:26.579: INFO: Waiting for frontend to serve content.
Dec 11 04:52:26.600: INFO: Trying to add a new entry to the guestbook.
Dec 11 04:52:26.616: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 11 04:52:26.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:26.716: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:26.716: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 04:52:26.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:26.829: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:26.829: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 04:52:26.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:26.960: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:26.960: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 04:52:26.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:27.062: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:27.062: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 04:52:27.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:27.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:27.145: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 11 04:52:27.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-9605'
Dec 11 04:52:27.221: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 04:52:27.221: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:52:27.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9605" for this suite.
Dec 11 04:53:05.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:53:05.297: INFO: namespace kubectl-9605 deletion completed in 38.071613292s

• [SLOW TEST:45.398 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:53:05.300: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 11 04:53:05.335: INFO: Waiting up to 5m0s for pod "downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb" in namespace "downward-api-7290" to be "success or failure"
Dec 11 04:53:05.339: INFO: Pod "downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.514898ms
Dec 11 04:53:07.343: INFO: Pod "downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007996765s
Dec 11 04:53:09.346: INFO: Pod "downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011290239s
STEP: Saw pod success
Dec 11 04:53:09.346: INFO: Pod "downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb" satisfied condition "success or failure"
Dec 11 04:53:09.350: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb container dapi-container: <nil>
STEP: delete the pod
Dec 11 04:53:09.367: INFO: Waiting for pod downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb to disappear
Dec 11 04:53:09.369: INFO: Pod downward-api-881c9ad4-e012-4434-a89a-e6104195b9cb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:53:09.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7290" for this suite.
Dec 11 04:53:15.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:53:15.451: INFO: namespace downward-api-7290 deletion completed in 6.075680018s

• [SLOW TEST:10.151 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:53:15.451: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 11 04:53:21.501: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:53:21.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1211 04:53:21.501465      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8464" for this suite.
Dec 11 04:53:27.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:53:27.579: INFO: namespace gc-8464 deletion completed in 6.075227172s

• [SLOW TEST:12.128 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:53:27.580: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1
Dec 11 04:53:27.611: INFO: Pod name my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1: Found 0 pods out of 1
Dec 11 04:53:32.614: INFO: Pod name my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1: Found 1 pods out of 1
Dec 11 04:53:32.615: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1" are running
Dec 11 04:53:32.617: INFO: Pod "my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1-d5zxk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:53:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:53:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:53:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-11 04:53:27 +0000 UTC Reason: Message:}])
Dec 11 04:53:32.617: INFO: Trying to dial the pod
Dec 11 04:53:37.627: INFO: Controller my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1: Got expected result from replica 1 [my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1-d5zxk]: "my-hostname-basic-af9a3d53-2a86-4f0c-adec-eb8077c253a1-d5zxk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:53:37.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8483" for this suite.
Dec 11 04:53:43.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:53:43.705: INFO: namespace replication-controller-8483 deletion completed in 6.075489572s

• [SLOW TEST:16.126 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:53:43.707: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 11 04:53:51.765: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:51.765: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:51.955: INFO: Exec stderr: ""
Dec 11 04:53:51.955: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:51.955: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:52.136: INFO: Exec stderr: ""
Dec 11 04:53:52.136: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:52.136: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:52.318: INFO: Exec stderr: ""
Dec 11 04:53:52.319: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:52.319: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:52.487: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 11 04:53:52.487: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:52.487: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:52.652: INFO: Exec stderr: ""
Dec 11 04:53:52.652: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:52.652: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:52.858: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 11 04:53:52.859: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:52.859: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:53.051: INFO: Exec stderr: ""
Dec 11 04:53:53.051: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:53.051: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:53.231: INFO: Exec stderr: ""
Dec 11 04:53:53.232: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:53.232: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:53.414: INFO: Exec stderr: ""
Dec 11 04:53:53.414: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-930 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:53:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:53:53.581: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:53:53.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-930" for this suite.
Dec 11 04:54:35.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:54:35.661: INFO: namespace e2e-kubelet-etc-hosts-930 deletion completed in 42.075975461s

• [SLOW TEST:51.954 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:54:35.666: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-1b22e6d7-6306-4780-8dfa-5e126e93db80
STEP: Creating a pod to test consume secrets
Dec 11 04:54:35.704: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4" in namespace "projected-287" to be "success or failure"
Dec 11 04:54:35.708: INFO: Pod "pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933072ms
Dec 11 04:54:37.710: INFO: Pod "pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006641437s
STEP: Saw pod success
Dec 11 04:54:37.710: INFO: Pod "pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4" satisfied condition "success or failure"
Dec 11 04:54:37.712: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 04:54:37.726: INFO: Waiting for pod pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4 to disappear
Dec 11 04:54:37.729: INFO: Pod pod-projected-secrets-e21fe67d-6239-4317-ae67-779a6c8621a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:54:37.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-287" for this suite.
Dec 11 04:54:43.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:54:43.806: INFO: namespace projected-287 deletion completed in 6.073622504s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:54:43.811: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:54:43.836: INFO: Creating deployment "test-recreate-deployment"
Dec 11 04:54:43.840: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 11 04:54:43.844: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 11 04:54:45.851: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 11 04:54:45.853: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 11 04:54:45.857: INFO: Updating deployment test-recreate-deployment
Dec 11 04:54:45.857: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 11 04:54:45.911: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-811,SelfLink:/apis/apps/v1/namespaces/deployment-811/deployments/test-recreate-deployment,UID:ad393ddc-b328-47ea-abfa-5594fd3aef12,ResourceVersion:164307,Generation:2,CreationTimestamp:2019-12-11 04:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-12-11 04:54:45 +0000 UTC 2019-12-11 04:54:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-11 04:54:45 +0000 UTC 2019-12-11 04:54:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 11 04:54:45.914: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-811,SelfLink:/apis/apps/v1/namespaces/deployment-811/replicasets/test-recreate-deployment-5c8c9cc69d,UID:0295aee0-a05b-4c0a-9e4b-a62a3d7d8ad9,ResourceVersion:164306,Generation:1,CreationTimestamp:2019-12-11 04:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ad393ddc-b328-47ea-abfa-5594fd3aef12 0xc0031ac8c7 0xc0031ac8c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 04:54:45.914: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 11 04:54:45.915: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-811,SelfLink:/apis/apps/v1/namespaces/deployment-811/replicasets/test-recreate-deployment-6df85df6b9,UID:4bfc16d6-4f3d-4a97-8ac6-f7d4d718dd2b,ResourceVersion:164297,Generation:2,CreationTimestamp:2019-12-11 04:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment ad393ddc-b328-47ea-abfa-5594fd3aef12 0xc0031ac997 0xc0031ac998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 04:54:45.918: INFO: Pod "test-recreate-deployment-5c8c9cc69d-d9ms5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-d9ms5,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-811,SelfLink:/api/v1/namespaces/deployment-811/pods/test-recreate-deployment-5c8c9cc69d-d9ms5,UID:9f31fff4-757e-48c8-8c19-a597c605d8a1,ResourceVersion:164305,Generation:0,CreationTimestamp:2019-12-11 04:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 0295aee0-a05b-4c0a-9e4b-a62a3d7d8ad9 0xc0031ad277 0xc0031ad278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-t747h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t747h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t747h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 04:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-12-11 04:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:54:45.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-811" for this suite.
Dec 11 04:54:51.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:54:51.993: INFO: namespace deployment-811 deletion completed in 6.071693796s

• [SLOW TEST:8.183 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:54:51.994: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c5308631-cf04-4f37-9fe5-02f08e4811bb
STEP: Creating a pod to test consume secrets
Dec 11 04:54:52.023: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87" in namespace "projected-5306" to be "success or failure"
Dec 11 04:54:52.026: INFO: Pod "pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.425979ms
Dec 11 04:54:54.030: INFO: Pod "pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006129684s
STEP: Saw pod success
Dec 11 04:54:54.030: INFO: Pod "pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87" satisfied condition "success or failure"
Dec 11 04:54:54.033: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 04:54:54.048: INFO: Waiting for pod pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87 to disappear
Dec 11 04:54:54.050: INFO: Pod pod-projected-secrets-faf3e548-2ba2-42b0-b97d-c68e7f645d87 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:54:54.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5306" for this suite.
Dec 11 04:55:00.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:55:00.129: INFO: namespace projected-5306 deletion completed in 6.075553219s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:55:00.130: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 04:55:00.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7548'
Dec 11 04:55:00.271: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 04:55:00.271: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 11 04:55:00.280: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 11 04:55:00.280: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 11 04:55:00.297: INFO: scanned /root for discovery docs: <nil>
Dec 11 04:55:00.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7548'
Dec 11 04:55:16.076: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 11 04:55:16.076: INFO: stdout: "Created e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b\nScaling up e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 11 04:55:16.076: INFO: stdout: "Created e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b\nScaling up e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 11 04:55:16.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7548'
Dec 11 04:55:16.165: INFO: stderr: ""
Dec 11 04:55:16.165: INFO: stdout: "e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b-dtzkf "
Dec 11 04:55:16.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b-dtzkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7548'
Dec 11 04:55:16.236: INFO: stderr: ""
Dec 11 04:55:16.236: INFO: stdout: "true"
Dec 11 04:55:16.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b-dtzkf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7548'
Dec 11 04:55:16.305: INFO: stderr: ""
Dec 11 04:55:16.305: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 11 04:55:16.305: INFO: e2e-test-nginx-rc-e12214ccb84f43ec95b039bec776158b-dtzkf is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Dec 11 04:55:16.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete rc e2e-test-nginx-rc --namespace=kubectl-7548'
Dec 11 04:55:16.387: INFO: stderr: ""
Dec 11 04:55:16.387: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:55:16.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7548" for this suite.
Dec 11 04:55:36.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:55:36.472: INFO: namespace kubectl-7548 deletion completed in 20.07724095s

• [SLOW TEST:36.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:55:36.473: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-8028ac2b-f218-4ebb-b0f1-4036fec0aa30
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:55:36.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5082" for this suite.
Dec 11 04:55:42.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:55:42.587: INFO: namespace secrets-5082 deletion completed in 6.084822206s

• [SLOW TEST:6.114 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:55:42.589: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3646.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3646.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 04:55:46.649: INFO: DNS probes using dns-3646/dns-test-bac507fe-a2a9-41c2-9b6e-98869420f49d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:55:46.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3646" for this suite.
Dec 11 04:55:52.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:55:52.755: INFO: namespace dns-3646 deletion completed in 6.082655402s

• [SLOW TEST:10.166 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:55:52.760: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:55:52.800: INFO: Create a RollingUpdate DaemonSet
Dec 11 04:55:52.804: INFO: Check that daemon pods launch on every node of the cluster
Dec 11 04:55:52.807: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:52.807: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:52.808: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:52.810: INFO: Number of nodes with available pods: 0
Dec 11 04:55:52.810: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:55:53.814: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:53.814: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:53.814: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:53.817: INFO: Number of nodes with available pods: 0
Dec 11 04:55:53.817: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 04:55:54.814: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:54.814: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:54.815: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:54.818: INFO: Number of nodes with available pods: 1
Dec 11 04:55:54.818: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 04:55:55.815: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:55.815: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:55.815: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:55.818: INFO: Number of nodes with available pods: 2
Dec 11 04:55:55.818: INFO: Number of running nodes: 2, number of available pods: 2
Dec 11 04:55:55.818: INFO: Update the DaemonSet to trigger a rollout
Dec 11 04:55:55.825: INFO: Updating DaemonSet daemon-set
Dec 11 04:55:58.839: INFO: Roll back the DaemonSet before rollout is complete
Dec 11 04:55:58.845: INFO: Updating DaemonSet daemon-set
Dec 11 04:55:58.845: INFO: Make sure DaemonSet rollback is complete
Dec 11 04:55:58.848: INFO: Wrong image for pod: daemon-set-r4s6n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 11 04:55:58.848: INFO: Pod daemon-set-r4s6n is not available
Dec 11 04:55:58.852: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:58.852: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:58.852: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:59.856: INFO: Wrong image for pod: daemon-set-r4s6n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 11 04:55:59.856: INFO: Pod daemon-set-r4s6n is not available
Dec 11 04:55:59.860: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:59.860: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:55:59.860: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:00.857: INFO: Wrong image for pod: daemon-set-r4s6n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 11 04:56:00.857: INFO: Pod daemon-set-r4s6n is not available
Dec 11 04:56:00.861: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:00.861: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:00.862: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:01.856: INFO: Wrong image for pod: daemon-set-r4s6n. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 11 04:56:01.856: INFO: Pod daemon-set-r4s6n is not available
Dec 11 04:56:01.860: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:01.860: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:01.860: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:02.855: INFO: Pod daemon-set-lh9nc is not available
Dec 11 04:56:02.859: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:02.859: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 04:56:02.859: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2673, will wait for the garbage collector to delete the pods
Dec 11 04:56:02.923: INFO: Deleting DaemonSet.extensions daemon-set took: 5.504453ms
Dec 11 04:56:03.323: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.243063ms
Dec 11 04:56:13.327: INFO: Number of nodes with available pods: 0
Dec 11 04:56:13.327: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 04:56:13.329: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2673/daemonsets","resourceVersion":"164608"},"items":null}

Dec 11 04:56:13.331: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2673/pods","resourceVersion":"164608"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:56:13.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2673" for this suite.
Dec 11 04:56:19.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:56:19.422: INFO: namespace daemonsets-2673 deletion completed in 6.078451428s

• [SLOW TEST:26.662 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:56:19.422: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 04:56:21.478: INFO: Waiting up to 5m0s for pod "client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc" in namespace "pods-4936" to be "success or failure"
Dec 11 04:56:21.481: INFO: Pod "client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.091713ms
Dec 11 04:56:23.486: INFO: Pod "client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007434331s
STEP: Saw pod success
Dec 11 04:56:23.486: INFO: Pod "client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc" satisfied condition "success or failure"
Dec 11 04:56:23.490: INFO: Trying to get logs from node 192.168.5.23 pod client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc container env3cont: <nil>
STEP: delete the pod
Dec 11 04:56:23.514: INFO: Waiting for pod client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc to disappear
Dec 11 04:56:23.517: INFO: Pod client-envvars-dee42ad2-f029-4781-8912-50e9e03832dc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:56:23.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4936" for this suite.
Dec 11 04:57:13.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:57:13.600: INFO: namespace pods-4936 deletion completed in 50.076992936s

• [SLOW TEST:54.177 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:57:13.604: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-b713816c-fb3c-4dfb-84c7-badece2ea4df
STEP: Creating a pod to test consume secrets
Dec 11 04:57:13.639: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0" in namespace "projected-8962" to be "success or failure"
Dec 11 04:57:13.642: INFO: Pod "pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.704507ms
Dec 11 04:57:15.645: INFO: Pod "pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0": Phase="Running", Reason="", readiness=true. Elapsed: 2.005769376s
Dec 11 04:57:17.648: INFO: Pod "pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008843467s
STEP: Saw pod success
Dec 11 04:57:17.648: INFO: Pod "pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0" satisfied condition "success or failure"
Dec 11 04:57:17.650: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 04:57:17.668: INFO: Waiting for pod pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0 to disappear
Dec 11 04:57:17.670: INFO: Pod pod-projected-secrets-70b517c7-999b-4daf-8896-4ae2d5f4e5f0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:57:17.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8962" for this suite.
Dec 11 04:57:23.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:57:23.749: INFO: namespace projected-8962 deletion completed in 6.075966845s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:57:23.750: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1bdc2db1-7901-4183-9589-4e2accaef949
STEP: Creating a pod to test consume configMaps
Dec 11 04:57:23.782: INFO: Waiting up to 5m0s for pod "pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314" in namespace "configmap-2855" to be "success or failure"
Dec 11 04:57:23.783: INFO: Pod "pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314": Phase="Pending", Reason="", readiness=false. Elapsed: 1.714995ms
Dec 11 04:57:25.786: INFO: Pod "pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004724348s
STEP: Saw pod success
Dec 11 04:57:25.787: INFO: Pod "pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314" satisfied condition "success or failure"
Dec 11 04:57:25.790: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 04:57:25.804: INFO: Waiting for pod pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314 to disappear
Dec 11 04:57:25.806: INFO: Pod pod-configmaps-7181d2d2-cbee-4690-a8a6-febe01f15314 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:57:25.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2855" for this suite.
Dec 11 04:57:31.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:57:31.890: INFO: namespace configmap-2855 deletion completed in 6.080219464s

• [SLOW TEST:8.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:57:31.892: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 11 04:57:34.452: INFO: Successfully updated pod "labelsupdate3fc29cf4-ec1b-4327-9877-9394af903993"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:57:38.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9511" for this suite.
Dec 11 04:58:00.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:58:00.565: INFO: namespace projected-9511 deletion completed in 22.085634847s

• [SLOW TEST:28.673 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:58:00.566: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 11 04:58:05.120: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3806 pod-service-account-0f5ab275-b630-4a50-b6e7-17d817e73f0e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 11 04:58:05.390: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3806 pod-service-account-0f5ab275-b630-4a50-b6e7-17d817e73f0e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 11 04:58:05.651: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3806 pod-service-account-0f5ab275-b630-4a50-b6e7-17d817e73f0e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:58:05.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3806" for this suite.
Dec 11 04:58:11.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:58:12.011: INFO: namespace svcaccounts-3806 deletion completed in 6.076465581s

• [SLOW TEST:11.445 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:58:12.012: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8835
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 04:58:12.037: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 04:58:34.088: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.8.2.82 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8835 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:58:34.088: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:58:35.266: INFO: Found all expected endpoints: [netserver-0]
Dec 11 04:58:35.269: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.8.4.51 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8835 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 04:58:35.269: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 04:58:36.463: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:58:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8835" for this suite.
Dec 11 04:58:58.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:58:58.547: INFO: namespace pod-network-test-8835 deletion completed in 22.079049043s

• [SLOW TEST:46.536 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:58:58.550: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 04:58:58.589: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9" in namespace "projected-4918" to be "success or failure"
Dec 11 04:58:58.591: INFO: Pod "downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.642ms
Dec 11 04:59:00.597: INFO: Pod "downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008071114s
Dec 11 04:59:02.601: INFO: Pod "downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011925859s
STEP: Saw pod success
Dec 11 04:59:02.601: INFO: Pod "downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9" satisfied condition "success or failure"
Dec 11 04:59:02.603: INFO: Trying to get logs from node 192.168.5.23 pod downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9 container client-container: <nil>
STEP: delete the pod
Dec 11 04:59:02.618: INFO: Waiting for pod downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9 to disappear
Dec 11 04:59:02.621: INFO: Pod downwardapi-volume-f6351c30-45e7-4f9f-b477-e3db38512dd9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:59:02.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4918" for this suite.
Dec 11 04:59:08.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:59:08.705: INFO: namespace projected-4918 deletion completed in 6.080638107s

• [SLOW TEST:10.155 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:59:08.706: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7851
I1211 04:59:08.746000      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7851, replica count: 1
I1211 04:59:09.797595      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 04:59:10.797832      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 11 04:59:10.906: INFO: Created: latency-svc-4s6bn
Dec 11 04:59:10.911: INFO: Got endpoints: latency-svc-4s6bn [13.393094ms]
Dec 11 04:59:10.919: INFO: Created: latency-svc-wgxsn
Dec 11 04:59:10.922: INFO: Got endpoints: latency-svc-wgxsn [10.71648ms]
Dec 11 04:59:10.925: INFO: Created: latency-svc-2sbtc
Dec 11 04:59:10.929: INFO: Got endpoints: latency-svc-2sbtc [17.139796ms]
Dec 11 04:59:10.930: INFO: Created: latency-svc-dlk5v
Dec 11 04:59:10.934: INFO: Got endpoints: latency-svc-dlk5v [22.213225ms]
Dec 11 04:59:10.935: INFO: Created: latency-svc-gnfqz
Dec 11 04:59:10.938: INFO: Got endpoints: latency-svc-gnfqz [25.688706ms]
Dec 11 04:59:10.943: INFO: Created: latency-svc-jz4cb
Dec 11 04:59:10.948: INFO: Got endpoints: latency-svc-jz4cb [35.036071ms]
Dec 11 04:59:10.951: INFO: Created: latency-svc-8bm6v
Dec 11 04:59:10.952: INFO: Got endpoints: latency-svc-8bm6v [37.621046ms]
Dec 11 04:59:10.954: INFO: Created: latency-svc-9xzp9
Dec 11 04:59:10.958: INFO: Got endpoints: latency-svc-9xzp9 [42.587912ms]
Dec 11 04:59:10.971: INFO: Created: latency-svc-nvlsm
Dec 11 04:59:10.974: INFO: Got endpoints: latency-svc-nvlsm [59.202947ms]
Dec 11 04:59:10.977: INFO: Created: latency-svc-jg92m
Dec 11 04:59:10.981: INFO: Got endpoints: latency-svc-jg92m [66.34859ms]
Dec 11 04:59:10.985: INFO: Created: latency-svc-j4lst
Dec 11 04:59:10.987: INFO: Got endpoints: latency-svc-j4lst [71.760818ms]
Dec 11 04:59:10.991: INFO: Created: latency-svc-pjc7k
Dec 11 04:59:10.993: INFO: Got endpoints: latency-svc-pjc7k [77.876892ms]
Dec 11 04:59:10.996: INFO: Created: latency-svc-8mkwf
Dec 11 04:59:10.999: INFO: Got endpoints: latency-svc-8mkwf [84.329606ms]
Dec 11 04:59:11.003: INFO: Created: latency-svc-zb7zx
Dec 11 04:59:11.005: INFO: Got endpoints: latency-svc-zb7zx [90.209831ms]
Dec 11 04:59:11.008: INFO: Created: latency-svc-hhkgx
Dec 11 04:59:11.011: INFO: Got endpoints: latency-svc-hhkgx [95.766085ms]
Dec 11 04:59:11.013: INFO: Created: latency-svc-b6lr7
Dec 11 04:59:11.016: INFO: Got endpoints: latency-svc-b6lr7 [100.73698ms]
Dec 11 04:59:11.017: INFO: Created: latency-svc-gbzmx
Dec 11 04:59:11.021: INFO: Got endpoints: latency-svc-gbzmx [99.279477ms]
Dec 11 04:59:11.025: INFO: Created: latency-svc-j2sf5
Dec 11 04:59:11.028: INFO: Got endpoints: latency-svc-j2sf5 [98.872198ms]
Dec 11 04:59:11.030: INFO: Created: latency-svc-246sn
Dec 11 04:59:11.033: INFO: Created: latency-svc-bclp9
Dec 11 04:59:11.033: INFO: Got endpoints: latency-svc-246sn [99.028485ms]
Dec 11 04:59:11.037: INFO: Got endpoints: latency-svc-bclp9 [99.157489ms]
Dec 11 04:59:11.039: INFO: Created: latency-svc-qwl6x
Dec 11 04:59:11.042: INFO: Got endpoints: latency-svc-qwl6x [93.970162ms]
Dec 11 04:59:11.045: INFO: Created: latency-svc-57vx6
Dec 11 04:59:11.053: INFO: Got endpoints: latency-svc-57vx6 [100.763683ms]
Dec 11 04:59:11.056: INFO: Created: latency-svc-7stn2
Dec 11 04:59:11.059: INFO: Got endpoints: latency-svc-7stn2 [101.172461ms]
Dec 11 04:59:11.062: INFO: Created: latency-svc-blfsw
Dec 11 04:59:11.065: INFO: Got endpoints: latency-svc-blfsw [90.726386ms]
Dec 11 04:59:11.070: INFO: Created: latency-svc-q7bdq
Dec 11 04:59:11.074: INFO: Created: latency-svc-r99mm
Dec 11 04:59:11.074: INFO: Got endpoints: latency-svc-q7bdq [92.675543ms]
Dec 11 04:59:11.076: INFO: Got endpoints: latency-svc-r99mm [88.996651ms]
Dec 11 04:59:11.080: INFO: Created: latency-svc-jh6jv
Dec 11 04:59:11.086: INFO: Got endpoints: latency-svc-jh6jv [93.30955ms]
Dec 11 04:59:11.088: INFO: Created: latency-svc-znl5m
Dec 11 04:59:11.091: INFO: Got endpoints: latency-svc-znl5m [91.097748ms]
Dec 11 04:59:11.092: INFO: Created: latency-svc-smdzg
Dec 11 04:59:11.094: INFO: Got endpoints: latency-svc-smdzg [88.474776ms]
Dec 11 04:59:11.096: INFO: Created: latency-svc-zf4dc
Dec 11 04:59:11.101: INFO: Created: latency-svc-pmgnw
Dec 11 04:59:11.101: INFO: Got endpoints: latency-svc-zf4dc [90.151821ms]
Dec 11 04:59:11.103: INFO: Got endpoints: latency-svc-pmgnw [87.430169ms]
Dec 11 04:59:11.105: INFO: Created: latency-svc-d4r8n
Dec 11 04:59:11.110: INFO: Got endpoints: latency-svc-d4r8n [88.230991ms]
Dec 11 04:59:11.116: INFO: Created: latency-svc-lkd25
Dec 11 04:59:11.116: INFO: Got endpoints: latency-svc-lkd25 [88.497165ms]
Dec 11 04:59:11.117: INFO: Created: latency-svc-fbxq9
Dec 11 04:59:11.122: INFO: Got endpoints: latency-svc-fbxq9 [88.671795ms]
Dec 11 04:59:11.123: INFO: Created: latency-svc-fhc7r
Dec 11 04:59:11.127: INFO: Created: latency-svc-9c9zk
Dec 11 04:59:11.133: INFO: Created: latency-svc-hh7zm
Dec 11 04:59:11.135: INFO: Created: latency-svc-2v4ls
Dec 11 04:59:11.140: INFO: Created: latency-svc-tf2kq
Dec 11 04:59:11.147: INFO: Created: latency-svc-g77xn
Dec 11 04:59:11.152: INFO: Created: latency-svc-vcjkk
Dec 11 04:59:11.155: INFO: Created: latency-svc-hxsps
Dec 11 04:59:11.158: INFO: Got endpoints: latency-svc-fhc7r [121.231852ms]
Dec 11 04:59:11.161: INFO: Created: latency-svc-mnvf6
Dec 11 04:59:11.163: INFO: Created: latency-svc-nr822
Dec 11 04:59:11.178: INFO: Created: latency-svc-qrccr
Dec 11 04:59:11.183: INFO: Created: latency-svc-qc79n
Dec 11 04:59:11.190: INFO: Created: latency-svc-29pxx
Dec 11 04:59:11.196: INFO: Created: latency-svc-nqz5d
Dec 11 04:59:11.200: INFO: Created: latency-svc-58bxq
Dec 11 04:59:11.203: INFO: Created: latency-svc-fspmq
Dec 11 04:59:11.213: INFO: Got endpoints: latency-svc-9c9zk [170.266667ms]
Dec 11 04:59:11.225: INFO: Created: latency-svc-szqj8
Dec 11 04:59:11.260: INFO: Got endpoints: latency-svc-hh7zm [207.360457ms]
Dec 11 04:59:11.267: INFO: Created: latency-svc-t8jct
Dec 11 04:59:11.309: INFO: Got endpoints: latency-svc-2v4ls [249.681104ms]
Dec 11 04:59:11.316: INFO: Created: latency-svc-b65lt
Dec 11 04:59:11.359: INFO: Got endpoints: latency-svc-tf2kq [294.445613ms]
Dec 11 04:59:11.372: INFO: Created: latency-svc-j7ftx
Dec 11 04:59:11.409: INFO: Got endpoints: latency-svc-g77xn [335.095449ms]
Dec 11 04:59:11.421: INFO: Created: latency-svc-hwrm9
Dec 11 04:59:11.459: INFO: Got endpoints: latency-svc-vcjkk [382.946837ms]
Dec 11 04:59:11.467: INFO: Created: latency-svc-c4zt4
Dec 11 04:59:11.511: INFO: Got endpoints: latency-svc-hxsps [425.062432ms]
Dec 11 04:59:11.519: INFO: Created: latency-svc-f6wfz
Dec 11 04:59:11.561: INFO: Got endpoints: latency-svc-mnvf6 [469.994917ms]
Dec 11 04:59:11.567: INFO: Created: latency-svc-gp5l6
Dec 11 04:59:11.609: INFO: Got endpoints: latency-svc-nr822 [514.515866ms]
Dec 11 04:59:11.616: INFO: Created: latency-svc-9q62d
Dec 11 04:59:11.659: INFO: Got endpoints: latency-svc-qrccr [557.507268ms]
Dec 11 04:59:11.670: INFO: Created: latency-svc-bkvjk
Dec 11 04:59:11.710: INFO: Got endpoints: latency-svc-qc79n [606.790043ms]
Dec 11 04:59:11.722: INFO: Created: latency-svc-tt5nq
Dec 11 04:59:11.763: INFO: Got endpoints: latency-svc-29pxx [653.006325ms]
Dec 11 04:59:11.770: INFO: Created: latency-svc-sstvl
Dec 11 04:59:11.809: INFO: Got endpoints: latency-svc-nqz5d [693.099543ms]
Dec 11 04:59:11.820: INFO: Created: latency-svc-g2jnw
Dec 11 04:59:11.859: INFO: Got endpoints: latency-svc-58bxq [737.121982ms]
Dec 11 04:59:11.867: INFO: Created: latency-svc-blpff
Dec 11 04:59:11.909: INFO: Got endpoints: latency-svc-fspmq [750.459183ms]
Dec 11 04:59:11.919: INFO: Created: latency-svc-25v45
Dec 11 04:59:11.960: INFO: Got endpoints: latency-svc-szqj8 [747.450551ms]
Dec 11 04:59:11.969: INFO: Created: latency-svc-89697
Dec 11 04:59:12.009: INFO: Got endpoints: latency-svc-t8jct [748.947542ms]
Dec 11 04:59:12.019: INFO: Created: latency-svc-hgdtt
Dec 11 04:59:12.059: INFO: Got endpoints: latency-svc-b65lt [750.380378ms]
Dec 11 04:59:12.068: INFO: Created: latency-svc-qwhmp
Dec 11 04:59:12.109: INFO: Got endpoints: latency-svc-j7ftx [749.260157ms]
Dec 11 04:59:12.115: INFO: Created: latency-svc-vlwff
Dec 11 04:59:12.159: INFO: Got endpoints: latency-svc-hwrm9 [749.835667ms]
Dec 11 04:59:12.170: INFO: Created: latency-svc-7kb7s
Dec 11 04:59:12.209: INFO: Got endpoints: latency-svc-c4zt4 [750.303321ms]
Dec 11 04:59:12.221: INFO: Created: latency-svc-7k69t
Dec 11 04:59:12.259: INFO: Got endpoints: latency-svc-f6wfz [747.259822ms]
Dec 11 04:59:12.271: INFO: Created: latency-svc-5xfgc
Dec 11 04:59:12.309: INFO: Got endpoints: latency-svc-gp5l6 [747.748792ms]
Dec 11 04:59:12.320: INFO: Created: latency-svc-r2svb
Dec 11 04:59:12.359: INFO: Got endpoints: latency-svc-9q62d [750.411044ms]
Dec 11 04:59:12.367: INFO: Created: latency-svc-9b7zh
Dec 11 04:59:12.409: INFO: Got endpoints: latency-svc-bkvjk [746.587857ms]
Dec 11 04:59:12.415: INFO: Created: latency-svc-hh7cd
Dec 11 04:59:12.459: INFO: Got endpoints: latency-svc-tt5nq [748.694252ms]
Dec 11 04:59:12.466: INFO: Created: latency-svc-jf7lx
Dec 11 04:59:12.509: INFO: Got endpoints: latency-svc-sstvl [746.025427ms]
Dec 11 04:59:12.518: INFO: Created: latency-svc-77qdv
Dec 11 04:59:12.560: INFO: Got endpoints: latency-svc-g2jnw [750.572298ms]
Dec 11 04:59:12.570: INFO: Created: latency-svc-zb75j
Dec 11 04:59:12.609: INFO: Got endpoints: latency-svc-blpff [749.086422ms]
Dec 11 04:59:12.618: INFO: Created: latency-svc-grlkp
Dec 11 04:59:12.659: INFO: Got endpoints: latency-svc-25v45 [750.38157ms]
Dec 11 04:59:12.668: INFO: Created: latency-svc-9wjgc
Dec 11 04:59:12.709: INFO: Got endpoints: latency-svc-89697 [748.547918ms]
Dec 11 04:59:12.720: INFO: Created: latency-svc-bqxqb
Dec 11 04:59:12.759: INFO: Got endpoints: latency-svc-hgdtt [748.940474ms]
Dec 11 04:59:12.774: INFO: Created: latency-svc-rhczb
Dec 11 04:59:12.809: INFO: Got endpoints: latency-svc-qwhmp [749.87455ms]
Dec 11 04:59:12.817: INFO: Created: latency-svc-pdtzg
Dec 11 04:59:12.861: INFO: Got endpoints: latency-svc-vlwff [752.412684ms]
Dec 11 04:59:12.868: INFO: Created: latency-svc-fzkhd
Dec 11 04:59:12.909: INFO: Got endpoints: latency-svc-7kb7s [750.054209ms]
Dec 11 04:59:12.918: INFO: Created: latency-svc-m75xg
Dec 11 04:59:12.960: INFO: Got endpoints: latency-svc-7k69t [750.695356ms]
Dec 11 04:59:12.970: INFO: Created: latency-svc-z6znz
Dec 11 04:59:13.009: INFO: Got endpoints: latency-svc-5xfgc [750.439203ms]
Dec 11 04:59:13.020: INFO: Created: latency-svc-zrl4h
Dec 11 04:59:13.061: INFO: Got endpoints: latency-svc-r2svb [752.851695ms]
Dec 11 04:59:13.073: INFO: Created: latency-svc-zlzlf
Dec 11 04:59:13.109: INFO: Got endpoints: latency-svc-9b7zh [749.382111ms]
Dec 11 04:59:13.120: INFO: Created: latency-svc-mhzjq
Dec 11 04:59:13.159: INFO: Got endpoints: latency-svc-hh7cd [749.165783ms]
Dec 11 04:59:13.168: INFO: Created: latency-svc-7rnql
Dec 11 04:59:13.209: INFO: Got endpoints: latency-svc-jf7lx [750.043465ms]
Dec 11 04:59:13.216: INFO: Created: latency-svc-q6rxt
Dec 11 04:59:13.261: INFO: Got endpoints: latency-svc-77qdv [752.428532ms]
Dec 11 04:59:13.269: INFO: Created: latency-svc-r5k8j
Dec 11 04:59:13.311: INFO: Got endpoints: latency-svc-zb75j [750.657766ms]
Dec 11 04:59:13.319: INFO: Created: latency-svc-s8ns5
Dec 11 04:59:13.362: INFO: Got endpoints: latency-svc-grlkp [752.694584ms]
Dec 11 04:59:13.374: INFO: Created: latency-svc-srgkd
Dec 11 04:59:13.409: INFO: Got endpoints: latency-svc-9wjgc [749.091554ms]
Dec 11 04:59:13.417: INFO: Created: latency-svc-ms79d
Dec 11 04:59:13.459: INFO: Got endpoints: latency-svc-bqxqb [750.222556ms]
Dec 11 04:59:13.466: INFO: Created: latency-svc-7qw4q
Dec 11 04:59:13.512: INFO: Got endpoints: latency-svc-rhczb [753.061032ms]
Dec 11 04:59:13.520: INFO: Created: latency-svc-svmnv
Dec 11 04:59:13.559: INFO: Got endpoints: latency-svc-pdtzg [749.856753ms]
Dec 11 04:59:13.570: INFO: Created: latency-svc-4xwq8
Dec 11 04:59:13.610: INFO: Got endpoints: latency-svc-fzkhd [748.834327ms]
Dec 11 04:59:13.621: INFO: Created: latency-svc-m4q65
Dec 11 04:59:13.660: INFO: Got endpoints: latency-svc-m75xg [750.243865ms]
Dec 11 04:59:13.666: INFO: Created: latency-svc-4x7rq
Dec 11 04:59:13.710: INFO: Got endpoints: latency-svc-z6znz [749.11293ms]
Dec 11 04:59:13.720: INFO: Created: latency-svc-8fh5c
Dec 11 04:59:13.759: INFO: Got endpoints: latency-svc-zrl4h [750.010328ms]
Dec 11 04:59:13.773: INFO: Created: latency-svc-4pk85
Dec 11 04:59:13.809: INFO: Got endpoints: latency-svc-zlzlf [747.518235ms]
Dec 11 04:59:13.817: INFO: Created: latency-svc-pjjb5
Dec 11 04:59:13.859: INFO: Got endpoints: latency-svc-mhzjq [746.399542ms]
Dec 11 04:59:13.866: INFO: Created: latency-svc-dmqth
Dec 11 04:59:13.909: INFO: Got endpoints: latency-svc-7rnql [750.693499ms]
Dec 11 04:59:13.922: INFO: Created: latency-svc-5vvc6
Dec 11 04:59:13.959: INFO: Got endpoints: latency-svc-q6rxt [750.247958ms]
Dec 11 04:59:13.970: INFO: Created: latency-svc-89fp8
Dec 11 04:59:14.009: INFO: Got endpoints: latency-svc-r5k8j [747.727544ms]
Dec 11 04:59:14.019: INFO: Created: latency-svc-2vlbr
Dec 11 04:59:14.059: INFO: Got endpoints: latency-svc-s8ns5 [747.83306ms]
Dec 11 04:59:14.065: INFO: Created: latency-svc-q5q6w
Dec 11 04:59:14.109: INFO: Got endpoints: latency-svc-srgkd [744.546993ms]
Dec 11 04:59:14.116: INFO: Created: latency-svc-j85n5
Dec 11 04:59:14.160: INFO: Got endpoints: latency-svc-ms79d [751.28141ms]
Dec 11 04:59:14.167: INFO: Created: latency-svc-hfqnr
Dec 11 04:59:14.209: INFO: Got endpoints: latency-svc-7qw4q [749.314858ms]
Dec 11 04:59:14.218: INFO: Created: latency-svc-4jvlb
Dec 11 04:59:14.260: INFO: Got endpoints: latency-svc-svmnv [747.749086ms]
Dec 11 04:59:14.267: INFO: Created: latency-svc-pjbhn
Dec 11 04:59:14.309: INFO: Got endpoints: latency-svc-4xwq8 [750.016539ms]
Dec 11 04:59:14.320: INFO: Created: latency-svc-tj6jd
Dec 11 04:59:14.359: INFO: Got endpoints: latency-svc-m4q65 [748.675148ms]
Dec 11 04:59:14.370: INFO: Created: latency-svc-kwj44
Dec 11 04:59:14.409: INFO: Got endpoints: latency-svc-4x7rq [749.215691ms]
Dec 11 04:59:14.418: INFO: Created: latency-svc-5r7g6
Dec 11 04:59:14.460: INFO: Got endpoints: latency-svc-8fh5c [746.663969ms]
Dec 11 04:59:14.467: INFO: Created: latency-svc-qb54f
Dec 11 04:59:14.508: INFO: Got endpoints: latency-svc-4pk85 [747.549793ms]
Dec 11 04:59:14.517: INFO: Created: latency-svc-xqvkv
Dec 11 04:59:14.560: INFO: Got endpoints: latency-svc-pjjb5 [750.633228ms]
Dec 11 04:59:14.568: INFO: Created: latency-svc-7mc55
Dec 11 04:59:14.610: INFO: Got endpoints: latency-svc-dmqth [750.729549ms]
Dec 11 04:59:14.616: INFO: Created: latency-svc-9x2qq
Dec 11 04:59:14.661: INFO: Got endpoints: latency-svc-5vvc6 [751.194811ms]
Dec 11 04:59:14.668: INFO: Created: latency-svc-n4pzv
Dec 11 04:59:14.710: INFO: Got endpoints: latency-svc-89fp8 [749.847141ms]
Dec 11 04:59:14.717: INFO: Created: latency-svc-gxcjp
Dec 11 04:59:14.760: INFO: Got endpoints: latency-svc-2vlbr [750.390639ms]
Dec 11 04:59:14.769: INFO: Created: latency-svc-9bmq2
Dec 11 04:59:14.810: INFO: Got endpoints: latency-svc-q5q6w [750.527584ms]
Dec 11 04:59:14.819: INFO: Created: latency-svc-zzhps
Dec 11 04:59:14.859: INFO: Got endpoints: latency-svc-j85n5 [749.729995ms]
Dec 11 04:59:14.866: INFO: Created: latency-svc-2f56b
Dec 11 04:59:14.909: INFO: Got endpoints: latency-svc-hfqnr [748.813709ms]
Dec 11 04:59:14.920: INFO: Created: latency-svc-nzjf6
Dec 11 04:59:14.960: INFO: Got endpoints: latency-svc-4jvlb [751.001475ms]
Dec 11 04:59:14.969: INFO: Created: latency-svc-6l6xb
Dec 11 04:59:15.009: INFO: Got endpoints: latency-svc-pjbhn [749.172088ms]
Dec 11 04:59:15.025: INFO: Created: latency-svc-d7t8v
Dec 11 04:59:15.060: INFO: Got endpoints: latency-svc-tj6jd [748.359942ms]
Dec 11 04:59:15.070: INFO: Created: latency-svc-mm6zh
Dec 11 04:59:15.109: INFO: Got endpoints: latency-svc-kwj44 [749.573611ms]
Dec 11 04:59:15.123: INFO: Created: latency-svc-v7zrl
Dec 11 04:59:15.160: INFO: Got endpoints: latency-svc-5r7g6 [748.772149ms]
Dec 11 04:59:15.169: INFO: Created: latency-svc-96pzj
Dec 11 04:59:15.209: INFO: Got endpoints: latency-svc-qb54f [748.930341ms]
Dec 11 04:59:15.217: INFO: Created: latency-svc-znjlb
Dec 11 04:59:15.260: INFO: Got endpoints: latency-svc-xqvkv [751.169041ms]
Dec 11 04:59:15.269: INFO: Created: latency-svc-4rr4h
Dec 11 04:59:15.310: INFO: Got endpoints: latency-svc-7mc55 [749.292639ms]
Dec 11 04:59:15.318: INFO: Created: latency-svc-kb7p7
Dec 11 04:59:15.360: INFO: Got endpoints: latency-svc-9x2qq [749.74619ms]
Dec 11 04:59:15.370: INFO: Created: latency-svc-bh4pk
Dec 11 04:59:15.410: INFO: Got endpoints: latency-svc-n4pzv [748.977796ms]
Dec 11 04:59:15.418: INFO: Created: latency-svc-pclq8
Dec 11 04:59:15.459: INFO: Got endpoints: latency-svc-gxcjp [749.294808ms]
Dec 11 04:59:15.467: INFO: Created: latency-svc-sqjkx
Dec 11 04:59:15.509: INFO: Got endpoints: latency-svc-9bmq2 [748.691003ms]
Dec 11 04:59:15.520: INFO: Created: latency-svc-t7vss
Dec 11 04:59:15.559: INFO: Got endpoints: latency-svc-zzhps [749.832668ms]
Dec 11 04:59:15.569: INFO: Created: latency-svc-2dngm
Dec 11 04:59:15.610: INFO: Got endpoints: latency-svc-2f56b [751.159122ms]
Dec 11 04:59:15.621: INFO: Created: latency-svc-pxt8t
Dec 11 04:59:15.661: INFO: Got endpoints: latency-svc-nzjf6 [751.559523ms]
Dec 11 04:59:15.671: INFO: Created: latency-svc-rf4db
Dec 11 04:59:15.709: INFO: Got endpoints: latency-svc-6l6xb [749.107353ms]
Dec 11 04:59:15.719: INFO: Created: latency-svc-kds9f
Dec 11 04:59:15.761: INFO: Got endpoints: latency-svc-d7t8v [751.592652ms]
Dec 11 04:59:15.770: INFO: Created: latency-svc-2gpjq
Dec 11 04:59:15.815: INFO: Got endpoints: latency-svc-mm6zh [755.193521ms]
Dec 11 04:59:15.827: INFO: Created: latency-svc-8h66z
Dec 11 04:59:15.859: INFO: Got endpoints: latency-svc-v7zrl [750.546808ms]
Dec 11 04:59:15.867: INFO: Created: latency-svc-bj4c7
Dec 11 04:59:15.910: INFO: Got endpoints: latency-svc-96pzj [749.540749ms]
Dec 11 04:59:15.925: INFO: Created: latency-svc-wks8x
Dec 11 04:59:15.960: INFO: Got endpoints: latency-svc-znjlb [750.781019ms]
Dec 11 04:59:15.966: INFO: Created: latency-svc-t8k7w
Dec 11 04:59:16.009: INFO: Got endpoints: latency-svc-4rr4h [745.470209ms]
Dec 11 04:59:16.016: INFO: Created: latency-svc-qsvm4
Dec 11 04:59:16.059: INFO: Got endpoints: latency-svc-kb7p7 [748.616023ms]
Dec 11 04:59:16.067: INFO: Created: latency-svc-bfwhc
Dec 11 04:59:16.109: INFO: Got endpoints: latency-svc-bh4pk [746.141951ms]
Dec 11 04:59:16.121: INFO: Created: latency-svc-fbrvm
Dec 11 04:59:16.159: INFO: Got endpoints: latency-svc-pclq8 [747.66128ms]
Dec 11 04:59:16.167: INFO: Created: latency-svc-7k56x
Dec 11 04:59:16.209: INFO: Got endpoints: latency-svc-sqjkx [750.263092ms]
Dec 11 04:59:16.219: INFO: Created: latency-svc-xldc5
Dec 11 04:59:16.260: INFO: Got endpoints: latency-svc-t7vss [751.283097ms]
Dec 11 04:59:16.269: INFO: Created: latency-svc-7wsff
Dec 11 04:59:16.309: INFO: Got endpoints: latency-svc-2dngm [746.488334ms]
Dec 11 04:59:16.317: INFO: Created: latency-svc-2tvbc
Dec 11 04:59:16.359: INFO: Got endpoints: latency-svc-pxt8t [744.901842ms]
Dec 11 04:59:16.367: INFO: Created: latency-svc-l8jrh
Dec 11 04:59:16.410: INFO: Got endpoints: latency-svc-rf4db [747.475887ms]
Dec 11 04:59:16.418: INFO: Created: latency-svc-7qhv4
Dec 11 04:59:16.460: INFO: Got endpoints: latency-svc-kds9f [748.732834ms]
Dec 11 04:59:16.467: INFO: Created: latency-svc-xmznq
Dec 11 04:59:16.509: INFO: Got endpoints: latency-svc-2gpjq [748.567206ms]
Dec 11 04:59:16.517: INFO: Created: latency-svc-b6rsl
Dec 11 04:59:16.560: INFO: Got endpoints: latency-svc-8h66z [744.426673ms]
Dec 11 04:59:16.571: INFO: Created: latency-svc-wm7wx
Dec 11 04:59:16.609: INFO: Got endpoints: latency-svc-bj4c7 [749.766169ms]
Dec 11 04:59:16.618: INFO: Created: latency-svc-hjbcx
Dec 11 04:59:16.660: INFO: Got endpoints: latency-svc-wks8x [742.910706ms]
Dec 11 04:59:16.668: INFO: Created: latency-svc-wkk7m
Dec 11 04:59:16.709: INFO: Got endpoints: latency-svc-t8k7w [749.657467ms]
Dec 11 04:59:16.720: INFO: Created: latency-svc-96rrc
Dec 11 04:59:16.759: INFO: Got endpoints: latency-svc-qsvm4 [750.672748ms]
Dec 11 04:59:16.768: INFO: Created: latency-svc-mvjlg
Dec 11 04:59:16.810: INFO: Got endpoints: latency-svc-bfwhc [749.403231ms]
Dec 11 04:59:16.823: INFO: Created: latency-svc-nr4kd
Dec 11 04:59:16.859: INFO: Got endpoints: latency-svc-fbrvm [747.218095ms]
Dec 11 04:59:16.869: INFO: Created: latency-svc-vck4l
Dec 11 04:59:16.911: INFO: Got endpoints: latency-svc-7k56x [752.156596ms]
Dec 11 04:59:16.920: INFO: Created: latency-svc-62jbt
Dec 11 04:59:16.960: INFO: Got endpoints: latency-svc-xldc5 [749.477396ms]
Dec 11 04:59:16.971: INFO: Created: latency-svc-4tgfl
Dec 11 04:59:17.010: INFO: Got endpoints: latency-svc-7wsff [749.289311ms]
Dec 11 04:59:17.017: INFO: Created: latency-svc-5kmzh
Dec 11 04:59:17.059: INFO: Got endpoints: latency-svc-2tvbc [749.49218ms]
Dec 11 04:59:17.069: INFO: Created: latency-svc-jqsbt
Dec 11 04:59:17.110: INFO: Got endpoints: latency-svc-l8jrh [750.368676ms]
Dec 11 04:59:17.118: INFO: Created: latency-svc-tpz7x
Dec 11 04:59:17.159: INFO: Got endpoints: latency-svc-7qhv4 [749.439646ms]
Dec 11 04:59:17.168: INFO: Created: latency-svc-jb4jb
Dec 11 04:59:17.209: INFO: Got endpoints: latency-svc-xmznq [749.713195ms]
Dec 11 04:59:17.217: INFO: Created: latency-svc-4n7bw
Dec 11 04:59:17.259: INFO: Got endpoints: latency-svc-b6rsl [749.704008ms]
Dec 11 04:59:17.266: INFO: Created: latency-svc-frjv5
Dec 11 04:59:17.310: INFO: Got endpoints: latency-svc-wm7wx [749.556122ms]
Dec 11 04:59:17.322: INFO: Created: latency-svc-rnvm9
Dec 11 04:59:17.360: INFO: Got endpoints: latency-svc-hjbcx [749.246561ms]
Dec 11 04:59:17.370: INFO: Created: latency-svc-mswxx
Dec 11 04:59:17.411: INFO: Got endpoints: latency-svc-wkk7m [749.918396ms]
Dec 11 04:59:17.421: INFO: Created: latency-svc-tsr6l
Dec 11 04:59:17.459: INFO: Got endpoints: latency-svc-96rrc [749.544458ms]
Dec 11 04:59:17.467: INFO: Created: latency-svc-xzdlk
Dec 11 04:59:17.509: INFO: Got endpoints: latency-svc-mvjlg [749.083683ms]
Dec 11 04:59:17.519: INFO: Created: latency-svc-6x5kq
Dec 11 04:59:17.559: INFO: Got endpoints: latency-svc-nr4kd [749.355714ms]
Dec 11 04:59:17.567: INFO: Created: latency-svc-l2sxj
Dec 11 04:59:17.609: INFO: Got endpoints: latency-svc-vck4l [749.711291ms]
Dec 11 04:59:17.615: INFO: Created: latency-svc-pthl2
Dec 11 04:59:17.659: INFO: Got endpoints: latency-svc-62jbt [747.877642ms]
Dec 11 04:59:17.668: INFO: Created: latency-svc-xcbxb
Dec 11 04:59:17.713: INFO: Got endpoints: latency-svc-4tgfl [753.111485ms]
Dec 11 04:59:17.725: INFO: Created: latency-svc-rzgdx
Dec 11 04:59:17.759: INFO: Got endpoints: latency-svc-5kmzh [749.579322ms]
Dec 11 04:59:17.767: INFO: Created: latency-svc-hsm6m
Dec 11 04:59:17.811: INFO: Got endpoints: latency-svc-jqsbt [749.861552ms]
Dec 11 04:59:17.821: INFO: Created: latency-svc-98lfz
Dec 11 04:59:17.860: INFO: Got endpoints: latency-svc-tpz7x [748.685594ms]
Dec 11 04:59:17.870: INFO: Created: latency-svc-x8nfn
Dec 11 04:59:17.910: INFO: Got endpoints: latency-svc-jb4jb [750.227899ms]
Dec 11 04:59:17.928: INFO: Created: latency-svc-g562b
Dec 11 04:59:17.961: INFO: Got endpoints: latency-svc-4n7bw [750.754414ms]
Dec 11 04:59:17.969: INFO: Created: latency-svc-rhqq4
Dec 11 04:59:18.011: INFO: Got endpoints: latency-svc-frjv5 [751.54786ms]
Dec 11 04:59:18.023: INFO: Created: latency-svc-mh8fd
Dec 11 04:59:18.059: INFO: Got endpoints: latency-svc-rnvm9 [746.268824ms]
Dec 11 04:59:18.066: INFO: Created: latency-svc-r62mr
Dec 11 04:59:18.110: INFO: Got endpoints: latency-svc-mswxx [749.901266ms]
Dec 11 04:59:18.117: INFO: Created: latency-svc-hzc6p
Dec 11 04:59:18.160: INFO: Got endpoints: latency-svc-tsr6l [748.300946ms]
Dec 11 04:59:18.169: INFO: Created: latency-svc-xvhjx
Dec 11 04:59:18.210: INFO: Got endpoints: latency-svc-xzdlk [750.281011ms]
Dec 11 04:59:18.217: INFO: Created: latency-svc-h4stc
Dec 11 04:59:18.259: INFO: Got endpoints: latency-svc-6x5kq [749.838552ms]
Dec 11 04:59:18.271: INFO: Created: latency-svc-d9h9s
Dec 11 04:59:18.310: INFO: Got endpoints: latency-svc-l2sxj [750.917601ms]
Dec 11 04:59:18.321: INFO: Created: latency-svc-7lmc5
Dec 11 04:59:18.360: INFO: Got endpoints: latency-svc-pthl2 [750.77198ms]
Dec 11 04:59:18.368: INFO: Created: latency-svc-hzrtx
Dec 11 04:59:18.410: INFO: Got endpoints: latency-svc-xcbxb [749.990325ms]
Dec 11 04:59:18.418: INFO: Created: latency-svc-7rnzg
Dec 11 04:59:18.459: INFO: Got endpoints: latency-svc-rzgdx [746.244137ms]
Dec 11 04:59:18.468: INFO: Created: latency-svc-nvgr5
Dec 11 04:59:18.510: INFO: Got endpoints: latency-svc-hsm6m [749.932028ms]
Dec 11 04:59:18.517: INFO: Created: latency-svc-k68ft
Dec 11 04:59:18.561: INFO: Got endpoints: latency-svc-98lfz [749.022239ms]
Dec 11 04:59:18.568: INFO: Created: latency-svc-w7ztc
Dec 11 04:59:18.610: INFO: Got endpoints: latency-svc-x8nfn [750.351336ms]
Dec 11 04:59:18.616: INFO: Created: latency-svc-k99zg
Dec 11 04:59:18.659: INFO: Got endpoints: latency-svc-g562b [749.433271ms]
Dec 11 04:59:18.670: INFO: Created: latency-svc-bgpn5
Dec 11 04:59:18.709: INFO: Got endpoints: latency-svc-rhqq4 [748.854148ms]
Dec 11 04:59:18.721: INFO: Created: latency-svc-nm9n2
Dec 11 04:59:18.759: INFO: Got endpoints: latency-svc-mh8fd [748.068841ms]
Dec 11 04:59:18.810: INFO: Got endpoints: latency-svc-r62mr [750.176141ms]
Dec 11 04:59:18.860: INFO: Got endpoints: latency-svc-hzc6p [750.512536ms]
Dec 11 04:59:18.910: INFO: Got endpoints: latency-svc-xvhjx [749.594673ms]
Dec 11 04:59:18.959: INFO: Got endpoints: latency-svc-h4stc [749.647608ms]
Dec 11 04:59:19.015: INFO: Got endpoints: latency-svc-d9h9s [756.320422ms]
Dec 11 04:59:19.059: INFO: Got endpoints: latency-svc-7lmc5 [749.068588ms]
Dec 11 04:59:19.109: INFO: Got endpoints: latency-svc-hzrtx [749.442632ms]
Dec 11 04:59:19.160: INFO: Got endpoints: latency-svc-7rnzg [750.734696ms]
Dec 11 04:59:19.212: INFO: Got endpoints: latency-svc-nvgr5 [752.274831ms]
Dec 11 04:59:19.260: INFO: Got endpoints: latency-svc-k68ft [750.326432ms]
Dec 11 04:59:19.310: INFO: Got endpoints: latency-svc-w7ztc [748.834366ms]
Dec 11 04:59:19.360: INFO: Got endpoints: latency-svc-k99zg [749.604195ms]
Dec 11 04:59:19.410: INFO: Got endpoints: latency-svc-bgpn5 [747.086053ms]
Dec 11 04:59:19.460: INFO: Got endpoints: latency-svc-nm9n2 [749.544062ms]
Dec 11 04:59:19.460: INFO: Latencies: [10.71648ms 17.139796ms 22.213225ms 25.688706ms 35.036071ms 37.621046ms 42.587912ms 59.202947ms 66.34859ms 71.760818ms 77.876892ms 84.329606ms 87.430169ms 88.230991ms 88.474776ms 88.497165ms 88.671795ms 88.996651ms 90.151821ms 90.209831ms 90.726386ms 91.097748ms 92.675543ms 93.30955ms 93.970162ms 95.766085ms 98.872198ms 99.028485ms 99.157489ms 99.279477ms 100.73698ms 100.763683ms 101.172461ms 121.231852ms 170.266667ms 207.360457ms 249.681104ms 294.445613ms 335.095449ms 382.946837ms 425.062432ms 469.994917ms 514.515866ms 557.507268ms 606.790043ms 653.006325ms 693.099543ms 737.121982ms 742.910706ms 744.426673ms 744.546993ms 744.901842ms 745.470209ms 746.025427ms 746.141951ms 746.244137ms 746.268824ms 746.399542ms 746.488334ms 746.587857ms 746.663969ms 747.086053ms 747.218095ms 747.259822ms 747.450551ms 747.475887ms 747.518235ms 747.549793ms 747.66128ms 747.727544ms 747.748792ms 747.749086ms 747.83306ms 747.877642ms 748.068841ms 748.300946ms 748.359942ms 748.547918ms 748.567206ms 748.616023ms 748.675148ms 748.685594ms 748.691003ms 748.694252ms 748.732834ms 748.772149ms 748.813709ms 748.834327ms 748.834366ms 748.854148ms 748.930341ms 748.940474ms 748.947542ms 748.977796ms 749.022239ms 749.068588ms 749.083683ms 749.086422ms 749.091554ms 749.107353ms 749.11293ms 749.165783ms 749.172088ms 749.215691ms 749.246561ms 749.260157ms 749.289311ms 749.292639ms 749.294808ms 749.314858ms 749.355714ms 749.382111ms 749.403231ms 749.433271ms 749.439646ms 749.442632ms 749.477396ms 749.49218ms 749.540749ms 749.544062ms 749.544458ms 749.556122ms 749.573611ms 749.579322ms 749.594673ms 749.604195ms 749.647608ms 749.657467ms 749.704008ms 749.711291ms 749.713195ms 749.729995ms 749.74619ms 749.766169ms 749.832668ms 749.835667ms 749.838552ms 749.847141ms 749.856753ms 749.861552ms 749.87455ms 749.901266ms 749.918396ms 749.932028ms 749.990325ms 750.010328ms 750.016539ms 750.043465ms 750.054209ms 750.176141ms 750.222556ms 750.227899ms 750.243865ms 750.247958ms 750.263092ms 750.281011ms 750.303321ms 750.326432ms 750.351336ms 750.368676ms 750.380378ms 750.38157ms 750.390639ms 750.411044ms 750.439203ms 750.459183ms 750.512536ms 750.527584ms 750.546808ms 750.572298ms 750.633228ms 750.657766ms 750.672748ms 750.693499ms 750.695356ms 750.729549ms 750.734696ms 750.754414ms 750.77198ms 750.781019ms 750.917601ms 751.001475ms 751.159122ms 751.169041ms 751.194811ms 751.28141ms 751.283097ms 751.54786ms 751.559523ms 751.592652ms 752.156596ms 752.274831ms 752.412684ms 752.428532ms 752.694584ms 752.851695ms 753.061032ms 753.111485ms 755.193521ms 756.320422ms]
Dec 11 04:59:19.460: INFO: 50 %ile: 749.11293ms
Dec 11 04:59:19.460: INFO: 90 %ile: 750.917601ms
Dec 11 04:59:19.460: INFO: 99 %ile: 755.193521ms
Dec 11 04:59:19.460: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:59:19.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7851" for this suite.
Dec 11 04:59:35.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 04:59:35.543: INFO: namespace svc-latency-7851 deletion completed in 16.076140897s

• [SLOW TEST:26.839 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 04:59:35.551: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 11 04:59:41.618: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 04:59:41.620: INFO: Pod pod-with-poststart-http-hook still exists
Dec 11 04:59:43.621: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 04:59:43.625: INFO: Pod pod-with-poststart-http-hook still exists
Dec 11 04:59:45.621: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 11 04:59:45.626: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 04:59:45.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8752" for this suite.
Dec 11 05:00:07.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:00:07.700: INFO: namespace container-lifecycle-hook-8752 deletion completed in 22.070504234s

• [SLOW TEST:32.149 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:00:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 11 05:00:07.742: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 11 05:00:12.747: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:00:13.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-168" for this suite.
Dec 11 05:00:19.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:00:19.836: INFO: namespace replication-controller-168 deletion completed in 6.07285684s

• [SLOW TEST:12.131 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:00:19.837: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:00:19.868: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea" in namespace "projected-8522" to be "success or failure"
Dec 11 05:00:19.871: INFO: Pod "downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.514826ms
Dec 11 05:00:21.874: INFO: Pod "downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea": Phase="Running", Reason="", readiness=true. Elapsed: 2.005284299s
Dec 11 05:00:23.878: INFO: Pod "downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009813847s
STEP: Saw pod success
Dec 11 05:00:23.878: INFO: Pod "downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea" satisfied condition "success or failure"
Dec 11 05:00:23.880: INFO: Trying to get logs from node 192.168.5.23 pod downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea container client-container: <nil>
STEP: delete the pod
Dec 11 05:00:23.896: INFO: Waiting for pod downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea to disappear
Dec 11 05:00:23.898: INFO: Pod downwardapi-volume-71428f28-eb5d-4e18-839e-e08451ca0cea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:00:23.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8522" for this suite.
Dec 11 05:00:29.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:00:29.982: INFO: namespace projected-8522 deletion completed in 6.08100397s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:00:29.983: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 05:00:30.024: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:30.024: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:30.025: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:30.027: INFO: Number of nodes with available pods: 0
Dec 11 05:00:30.027: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:00:31.031: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:31.031: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:31.031: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:31.034: INFO: Number of nodes with available pods: 0
Dec 11 05:00:31.034: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:00:32.030: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:32.031: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:32.031: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:32.033: INFO: Number of nodes with available pods: 0
Dec 11 05:00:32.033: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:00:33.030: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.030: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.030: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.033: INFO: Number of nodes with available pods: 2
Dec 11 05:00:33.033: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 11 05:00:33.046: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.046: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.047: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:33.049: INFO: Number of nodes with available pods: 1
Dec 11 05:00:33.049: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:34.054: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:34.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:34.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:34.056: INFO: Number of nodes with available pods: 1
Dec 11 05:00:34.056: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:35.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:35.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:35.058: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:35.061: INFO: Number of nodes with available pods: 1
Dec 11 05:00:35.061: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:36.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:36.053: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:36.053: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:36.056: INFO: Number of nodes with available pods: 1
Dec 11 05:00:36.057: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:37.054: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:37.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:37.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:37.057: INFO: Number of nodes with available pods: 1
Dec 11 05:00:37.057: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:38.054: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:38.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:38.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:38.058: INFO: Number of nodes with available pods: 1
Dec 11 05:00:38.058: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:39.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:39.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:39.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:39.056: INFO: Number of nodes with available pods: 1
Dec 11 05:00:39.057: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:40.055: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:40.055: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:40.055: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:40.058: INFO: Number of nodes with available pods: 1
Dec 11 05:00:40.058: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:41.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:41.053: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:41.053: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:41.060: INFO: Number of nodes with available pods: 1
Dec 11 05:00:41.060: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:42.060: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:42.060: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:42.060: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:42.063: INFO: Number of nodes with available pods: 1
Dec 11 05:00:42.063: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:43.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:43.053: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:43.053: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:43.055: INFO: Number of nodes with available pods: 1
Dec 11 05:00:43.056: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:44.054: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:44.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:44.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:44.056: INFO: Number of nodes with available pods: 1
Dec 11 05:00:44.056: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:45.054: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:45.054: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:45.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:45.057: INFO: Number of nodes with available pods: 1
Dec 11 05:00:45.057: INFO: Node 192.168.5.23 is running more than one daemon pod
Dec 11 05:00:46.053: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:46.053: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:46.054: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:00:46.056: INFO: Number of nodes with available pods: 2
Dec 11 05:00:46.056: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6765, will wait for the garbage collector to delete the pods
Dec 11 05:00:46.117: INFO: Deleting DaemonSet.extensions daemon-set took: 5.313415ms
Dec 11 05:00:46.518: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.274978ms
Dec 11 05:00:49.821: INFO: Number of nodes with available pods: 0
Dec 11 05:00:49.821: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 05:00:49.824: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6765/daemonsets","resourceVersion":"166548"},"items":null}

Dec 11 05:00:49.827: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6765/pods","resourceVersion":"166548"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:00:49.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6765" for this suite.
Dec 11 05:00:55.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:00:55.919: INFO: namespace daemonsets-6765 deletion completed in 6.07823279s

• [SLOW TEST:25.936 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:00:55.921: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2525/configmap-test-0caf3781-e84c-4b56-92ca-af4cb7f292b2
STEP: Creating a pod to test consume configMaps
Dec 11 05:00:55.957: INFO: Waiting up to 5m0s for pod "pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381" in namespace "configmap-2525" to be "success or failure"
Dec 11 05:00:55.960: INFO: Pod "pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646271ms
Dec 11 05:00:57.963: INFO: Pod "pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005786271s
Dec 11 05:00:59.966: INFO: Pod "pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008949575s
STEP: Saw pod success
Dec 11 05:00:59.966: INFO: Pod "pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381" satisfied condition "success or failure"
Dec 11 05:00:59.968: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381 container env-test: <nil>
STEP: delete the pod
Dec 11 05:00:59.985: INFO: Waiting for pod pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381 to disappear
Dec 11 05:00:59.987: INFO: Pod pod-configmaps-9be8d5a7-d045-4824-b9e5-f8f1b05a1381 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:00:59.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2525" for this suite.
Dec 11 05:01:05.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:01:06.062: INFO: namespace configmap-2525 deletion completed in 6.071309198s

• [SLOW TEST:10.141 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:01:06.068: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 05:01:06.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-336'
Dec 11 05:01:06.184: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 05:01:06.184: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Dec 11 05:01:06.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete jobs e2e-test-nginx-job --namespace=kubectl-336'
Dec 11 05:01:06.276: INFO: stderr: ""
Dec 11 05:01:06.276: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:01:06.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-336" for this suite.
Dec 11 05:01:12.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:01:12.355: INFO: namespace kubectl-336 deletion completed in 6.076039254s

• [SLOW TEST:6.288 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:01:12.357: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 11 05:01:12.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-8125'
Dec 11 05:01:12.581: INFO: stderr: ""
Dec 11 05:01:12.581: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 11 05:01:13.586: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:01:13.586: INFO: Found 0 / 1
Dec 11 05:01:14.584: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:01:14.584: INFO: Found 1 / 1
Dec 11 05:01:14.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 11 05:01:14.586: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:01:14.586: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 11 05:01:14.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 patch pod redis-master-75sgd --namespace=kubectl-8125 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 11 05:01:14.676: INFO: stderr: ""
Dec 11 05:01:14.677: INFO: stdout: "pod/redis-master-75sgd patched\n"
STEP: checking annotations
Dec 11 05:01:14.681: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:01:14.681: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:01:14.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8125" for this suite.
Dec 11 05:01:36.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:01:36.757: INFO: namespace kubectl-8125 deletion completed in 22.070940216s

• [SLOW TEST:24.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:01:36.758: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-04e358c0-da80-411e-8507-91d40f4de668
STEP: Creating a pod to test consume configMaps
Dec 11 05:01:36.794: INFO: Waiting up to 5m0s for pod "pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf" in namespace "configmap-1329" to be "success or failure"
Dec 11 05:01:36.797: INFO: Pod "pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.768394ms
Dec 11 05:01:38.800: INFO: Pod "pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005853559s
Dec 11 05:01:40.803: INFO: Pod "pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009096981s
STEP: Saw pod success
Dec 11 05:01:40.803: INFO: Pod "pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf" satisfied condition "success or failure"
Dec 11 05:01:40.806: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:01:40.823: INFO: Waiting for pod pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf to disappear
Dec 11 05:01:40.825: INFO: Pod pod-configmaps-3988c66c-83a8-4171-a51b-8b8087b03bdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:01:40.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1329" for this suite.
Dec 11 05:01:46.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:01:46.912: INFO: namespace configmap-1329 deletion completed in 6.084087289s

• [SLOW TEST:10.155 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:01:46.919: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-5ab1cec9-7916-4f42-917b-2dc894f1ee0d
STEP: Creating secret with name s-test-opt-upd-dff64b7a-8755-4104-9432-f4671a3d3feb
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5ab1cec9-7916-4f42-917b-2dc894f1ee0d
STEP: Updating secret s-test-opt-upd-dff64b7a-8755-4104-9432-f4671a3d3feb
STEP: Creating secret with name s-test-opt-create-1f0a1a0d-3297-489a-a6fa-425c5dd953ee
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:02:57.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7694" for this suite.
Dec 11 05:03:19.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:03:19.411: INFO: namespace projected-7694 deletion completed in 22.076147702s

• [SLOW TEST:92.493 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:03:19.413: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:03:19.440: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:03:21.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5687" for this suite.
Dec 11 05:04:03.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:04:03.542: INFO: namespace pods-5687 deletion completed in 42.070791469s

• [SLOW TEST:44.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:04:03.548: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 11 05:04:03.581: INFO: Waiting up to 5m0s for pod "pod-f626a06d-045b-4d85-88aa-ab611f96129e" in namespace "emptydir-1954" to be "success or failure"
Dec 11 05:04:03.587: INFO: Pod "pod-f626a06d-045b-4d85-88aa-ab611f96129e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.178686ms
Dec 11 05:04:05.590: INFO: Pod "pod-f626a06d-045b-4d85-88aa-ab611f96129e": Phase="Running", Reason="", readiness=true. Elapsed: 2.006641361s
Dec 11 05:04:07.593: INFO: Pod "pod-f626a06d-045b-4d85-88aa-ab611f96129e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009586853s
STEP: Saw pod success
Dec 11 05:04:07.594: INFO: Pod "pod-f626a06d-045b-4d85-88aa-ab611f96129e" satisfied condition "success or failure"
Dec 11 05:04:07.596: INFO: Trying to get logs from node 192.168.5.21 pod pod-f626a06d-045b-4d85-88aa-ab611f96129e container test-container: <nil>
STEP: delete the pod
Dec 11 05:04:07.613: INFO: Waiting for pod pod-f626a06d-045b-4d85-88aa-ab611f96129e to disappear
Dec 11 05:04:07.615: INFO: Pod pod-f626a06d-045b-4d85-88aa-ab611f96129e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:04:07.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1954" for this suite.
Dec 11 05:04:13.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:04:13.699: INFO: namespace emptydir-1954 deletion completed in 6.08057198s

• [SLOW TEST:10.152 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:04:13.702: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:04:19.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9819" for this suite.
Dec 11 05:04:25.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:04:25.870: INFO: namespace namespaces-9819 deletion completed in 6.075743999s
STEP: Destroying namespace "nsdeletetest-861" for this suite.
Dec 11 05:04:25.873: INFO: Namespace nsdeletetest-861 was already deleted
STEP: Destroying namespace "nsdeletetest-8022" for this suite.
Dec 11 05:04:31.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:04:31.955: INFO: namespace nsdeletetest-8022 deletion completed in 6.081798489s

• [SLOW TEST:18.253 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:04:31.956: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 11 05:04:32.036: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 11 05:04:41.075: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:04:41.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9446" for this suite.
Dec 11 05:04:47.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:04:47.172: INFO: namespace pods-9446 deletion completed in 6.085343166s

• [SLOW TEST:15.216 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:04:47.173: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 05:04:47.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6603'
Dec 11 05:04:47.365: INFO: stderr: ""
Dec 11 05:04:47.365: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 11 05:04:52.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pod e2e-test-nginx-pod --namespace=kubectl-6603 -o json'
Dec 11 05:04:52.489: INFO: stderr: ""
Dec 11 05:04:52.489: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-11T05:04:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6603\",\n        \"resourceVersion\": \"167133\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6603/pods/e2e-test-nginx-pod\",\n        \"uid\": \"88e46350-70f2-418b-9228-9ba35cd0d5d6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-rjp25\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.5.21\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-rjp25\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-rjp25\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-11T05:04:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-11T05:04:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-11T05:04:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-11T05:04:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f284aa7e798c9078bb861f7ea2cd40951c6486a7cf1fc1e97476728d118012d7\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-11T05:04:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.5.21\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.8.2.94\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-11T05:04:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 11 05:04:52.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 replace -f - --namespace=kubectl-6603'
Dec 11 05:04:52.721: INFO: stderr: ""
Dec 11 05:04:52.721: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Dec 11 05:04:52.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete pods e2e-test-nginx-pod --namespace=kubectl-6603'
Dec 11 05:04:54.803: INFO: stderr: ""
Dec 11 05:04:54.803: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:04:54.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6603" for this suite.
Dec 11 05:05:00.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:05:00.881: INFO: namespace kubectl-6603 deletion completed in 6.075236721s

• [SLOW TEST:13.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:05:00.882: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:05:00.913: INFO: (0) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.22675ms)
Dec 11 05:05:00.915: INFO: (1) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.274403ms)
Dec 11 05:05:00.918: INFO: (2) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.541596ms)
Dec 11 05:05:00.920: INFO: (3) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.731643ms)
Dec 11 05:05:00.923: INFO: (4) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.394414ms)
Dec 11 05:05:00.925: INFO: (5) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.572917ms)
Dec 11 05:05:00.928: INFO: (6) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.459947ms)
Dec 11 05:05:00.933: INFO: (7) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 5.511442ms)
Dec 11 05:05:00.936: INFO: (8) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.74929ms)
Dec 11 05:05:00.939: INFO: (9) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.59507ms)
Dec 11 05:05:00.942: INFO: (10) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.756357ms)
Dec 11 05:05:00.944: INFO: (11) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.671259ms)
Dec 11 05:05:00.947: INFO: (12) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.38078ms)
Dec 11 05:05:00.949: INFO: (13) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.583838ms)
Dec 11 05:05:00.952: INFO: (14) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.366615ms)
Dec 11 05:05:00.954: INFO: (15) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.749954ms)
Dec 11 05:05:00.957: INFO: (16) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.336155ms)
Dec 11 05:05:00.960: INFO: (17) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.693557ms)
Dec 11 05:05:00.962: INFO: (18) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.729456ms)
Dec 11 05:05:00.966: INFO: (19) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.460535ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:05:00.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1904" for this suite.
Dec 11 05:05:06.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:05:07.041: INFO: namespace proxy-1904 deletion completed in 6.072319189s

• [SLOW TEST:6.159 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:05:07.041: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 11 05:05:07.070: INFO: Waiting up to 5m0s for pod "downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72" in namespace "downward-api-3082" to be "success or failure"
Dec 11 05:05:07.072: INFO: Pod "downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.857141ms
Dec 11 05:05:09.077: INFO: Pod "downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00687488s
Dec 11 05:05:11.080: INFO: Pod "downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010232154s
STEP: Saw pod success
Dec 11 05:05:11.081: INFO: Pod "downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72" satisfied condition "success or failure"
Dec 11 05:05:11.083: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72 container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:05:11.099: INFO: Waiting for pod downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72 to disappear
Dec 11 05:05:11.101: INFO: Pod downward-api-6adaa366-ca3d-4924-94f6-d5c5bd5f8b72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:05:11.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3082" for this suite.
Dec 11 05:05:17.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:05:17.182: INFO: namespace downward-api-3082 deletion completed in 6.077104677s

• [SLOW TEST:10.141 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:05:17.193: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-2fce4aac-1527-47d5-a3d3-f8b3997181ec
STEP: Creating a pod to test consume secrets
Dec 11 05:05:17.231: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc" in namespace "projected-6521" to be "success or failure"
Dec 11 05:05:17.233: INFO: Pod "pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.483812ms
Dec 11 05:05:19.238: INFO: Pod "pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006831718s
Dec 11 05:05:21.241: INFO: Pod "pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010124806s
STEP: Saw pod success
Dec 11 05:05:21.241: INFO: Pod "pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc" satisfied condition "success or failure"
Dec 11 05:05:21.243: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:05:21.261: INFO: Waiting for pod pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc to disappear
Dec 11 05:05:21.263: INFO: Pod pod-projected-secrets-027b2e70-bdcd-4cdf-a657-d4ea41cd3dfc no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:05:21.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6521" for this suite.
Dec 11 05:05:27.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:05:27.342: INFO: namespace projected-6521 deletion completed in 6.075072056s

• [SLOW TEST:10.149 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:05:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:05:27.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb" in namespace "downward-api-4592" to be "success or failure"
Dec 11 05:05:27.380: INFO: Pod "downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.363586ms
Dec 11 05:05:29.384: INFO: Pod "downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012173472s
Dec 11 05:05:31.388: INFO: Pod "downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015872103s
STEP: Saw pod success
Dec 11 05:05:31.388: INFO: Pod "downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb" satisfied condition "success or failure"
Dec 11 05:05:31.391: INFO: Trying to get logs from node 192.168.5.23 pod downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb container client-container: <nil>
STEP: delete the pod
Dec 11 05:05:31.408: INFO: Waiting for pod downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb to disappear
Dec 11 05:05:31.410: INFO: Pod downwardapi-volume-61d3dfae-eba9-4033-b534-f9a00e8003bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:05:31.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4592" for this suite.
Dec 11 05:05:37.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:05:37.488: INFO: namespace downward-api-4592 deletion completed in 6.074270976s

• [SLOW TEST:10.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:05:37.489: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-rm52
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 05:05:37.527: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rm52" in namespace "subpath-4017" to be "success or failure"
Dec 11 05:05:37.529: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117607ms
Dec 11 05:05:39.534: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006994275s
Dec 11 05:05:41.541: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 4.014174661s
Dec 11 05:05:43.544: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 6.017285302s
Dec 11 05:05:45.549: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 8.021882789s
Dec 11 05:05:47.553: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 10.02567231s
Dec 11 05:05:49.558: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 12.030807646s
Dec 11 05:05:51.561: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 14.033689266s
Dec 11 05:05:53.564: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 16.036704516s
Dec 11 05:05:55.567: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 18.040019715s
Dec 11 05:05:57.570: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 20.043434799s
Dec 11 05:05:59.575: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Running", Reason="", readiness=true. Elapsed: 22.048014329s
Dec 11 05:06:01.579: INFO: Pod "pod-subpath-test-projected-rm52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05172488s
STEP: Saw pod success
Dec 11 05:06:01.579: INFO: Pod "pod-subpath-test-projected-rm52" satisfied condition "success or failure"
Dec 11 05:06:01.581: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-projected-rm52 container test-container-subpath-projected-rm52: <nil>
STEP: delete the pod
Dec 11 05:06:01.598: INFO: Waiting for pod pod-subpath-test-projected-rm52 to disappear
Dec 11 05:06:01.600: INFO: Pod pod-subpath-test-projected-rm52 no longer exists
STEP: Deleting pod pod-subpath-test-projected-rm52
Dec 11 05:06:01.600: INFO: Deleting pod "pod-subpath-test-projected-rm52" in namespace "subpath-4017"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:01.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4017" for this suite.
Dec 11 05:06:07.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:07.679: INFO: namespace subpath-4017 deletion completed in 6.073863204s

• [SLOW TEST:30.191 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:07.682: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 11 05:06:07.707: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 11 05:06:07.719: INFO: Waiting for terminating namespaces to be deleted...
Dec 11 05:06:07.721: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
Dec 11 05:06:07.729: INFO: coredns-c97c9d4fc-pc9tk from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.729: INFO: 	Container coredns ready: true, restart count 3
Dec 11 05:06:07.732: INFO: sonobuoy-e2e-job-7d5be29debef4914 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 05:06:07.732: INFO: 	Container e2e ready: true, restart count 0
Dec 11 05:06:07.733: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 05:06:07.733: INFO: ksc-flexvolume-ds-lzhhj from kube-system started at 2019-12-10 03:24:10 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 1
Dec 11 05:06:07.733: INFO: ksc-node-exporter-lxzvl from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container ksc-node-exporter ready: true, restart count 1
Dec 11 05:06:07.733: INFO: traefik-ingress-controller-f5njb from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container traefik-ingress-lb ready: true, restart count 1
Dec 11 05:06:07.733: INFO: sonobuoy from sonobuoy started at 2019-12-11 04:23:25 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 11 05:06:07.733: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-xjhp6 from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 05:06:07.733: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 05:06:07.733: INFO: kube-proxy-lqv66 from kube-system started at 2019-12-10 03:22:44 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 11 05:06:07.733: INFO: coredns-c97c9d4fc-s6cjg from kube-system started at 2019-12-10 03:24:12 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container coredns ready: true, restart count 4
Dec 11 05:06:07.733: INFO: kube-flannel-hvnk7 from kube-system started at 2019-12-10 03:23:03 +0000 UTC (2 container statuses recorded)
Dec 11 05:06:07.733: INFO: 	Container install-cni ready: true, restart count 1
Dec 11 05:06:07.733: INFO: 	Container kube-flannel ready: true, restart count 3
Dec 11 05:06:07.733: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.23 before test
Dec 11 05:06:07.739: INFO: kube-flannel-4znx7 from kube-system started at 2019-12-10 04:24:44 +0000 UTC (2 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container install-cni ready: true, restart count 0
Dec 11 05:06:07.739: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 11 05:06:07.739: INFO: ksc-flexvolume-ds-bspbb from kube-system started at 2019-12-10 04:24:44 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
Dec 11 05:06:07.739: INFO: metrics-server-987bf46cc-v2vwr from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container metrics-server ready: true, restart count 0
Dec 11 05:06:07.739: INFO: ksc-node-exporter-w4n68 from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container ksc-node-exporter ready: true, restart count 0
Dec 11 05:06:07.739: INFO: busybox-86dc4695f-vn8mb from default started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container busybox ready: true, restart count 23
Dec 11 05:06:07.739: INFO: traefik-ingress-controller-l8xcf from kube-system started at 2019-12-10 04:26:52 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Dec 11 05:06:07.739: INFO: sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-gzxhn from sonobuoy started at 2019-12-11 04:23:27 +0000 UTC (2 container statuses recorded)
Dec 11 05:06:07.739: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 11 05:06:07.739: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 11 05:06:07.739: INFO: system-monitor-75cf6f67b5-ppr59 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.740: INFO: 	Container system-monitor ready: false, restart count 13
Dec 11 05:06:07.740: INFO: kube-proxy-ldpcp from kube-system started at 2019-12-10 04:24:43 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.740: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 11 05:06:07.740: INFO: disk-provisioner-656d7dfdc-gvvx7 from kube-system started at 2019-12-10 05:14:20 +0000 UTC (1 container statuses recorded)
Dec 11 05:06:07.740: INFO: 	Container disk-provisioner ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15df38ba61e92c2b], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:08.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1903" for this suite.
Dec 11 05:06:14.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:14.834: INFO: namespace sched-pred-1903 deletion completed in 6.07070163s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.153 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:14.835: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b7a28226-7e5f-4e03-be39-df8aaa53056f
STEP: Creating a pod to test consume secrets
Dec 11 05:06:14.866: INFO: Waiting up to 5m0s for pod "pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6" in namespace "secrets-9897" to be "success or failure"
Dec 11 05:06:14.868: INFO: Pod "pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.971116ms
Dec 11 05:06:16.871: INFO: Pod "pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005157295s
Dec 11 05:06:18.875: INFO: Pod "pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00879454s
STEP: Saw pod success
Dec 11 05:06:18.875: INFO: Pod "pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6" satisfied condition "success or failure"
Dec 11 05:06:18.878: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6 container secret-env-test: <nil>
STEP: delete the pod
Dec 11 05:06:18.891: INFO: Waiting for pod pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6 to disappear
Dec 11 05:06:18.893: INFO: Pod pod-secrets-5719ed69-deaa-4db3-b070-1c042675d7f6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:18.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9897" for this suite.
Dec 11 05:06:24.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:24.967: INFO: namespace secrets-9897 deletion completed in 6.070663819s

• [SLOW TEST:10.132 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:24.968: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-9d4d3173-78d6-4ed3-a490-5f83373b8a36
STEP: Creating a pod to test consume secrets
Dec 11 05:06:25.000: INFO: Waiting up to 5m0s for pod "pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0" in namespace "secrets-8260" to be "success or failure"
Dec 11 05:06:25.002: INFO: Pod "pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.201138ms
Dec 11 05:06:27.005: INFO: Pod "pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005247716s
Dec 11 05:06:29.008: INFO: Pod "pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007924312s
STEP: Saw pod success
Dec 11 05:06:29.008: INFO: Pod "pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0" satisfied condition "success or failure"
Dec 11 05:06:29.010: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:06:29.025: INFO: Waiting for pod pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0 to disappear
Dec 11 05:06:29.027: INFO: Pod pod-secrets-969f030b-fcd5-41a0-89c6-861175eee0e0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:29.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8260" for this suite.
Dec 11 05:06:35.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:35.102: INFO: namespace secrets-8260 deletion completed in 6.071682072s

• [SLOW TEST:10.135 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:35.105: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-2d18fc71-cfc3-4bcd-8fb1-23eeabff3521
STEP: Creating secret with name secret-projected-all-test-volume-e312fd8f-4dba-4b3a-b4fd-056b6fd484e2
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 11 05:06:35.151: INFO: Waiting up to 5m0s for pod "projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287" in namespace "projected-1324" to be "success or failure"
Dec 11 05:06:35.153: INFO: Pod "projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204755ms
Dec 11 05:06:37.156: INFO: Pod "projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005212316s
Dec 11 05:06:39.159: INFO: Pod "projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008353793s
STEP: Saw pod success
Dec 11 05:06:39.159: INFO: Pod "projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287" satisfied condition "success or failure"
Dec 11 05:06:39.163: INFO: Trying to get logs from node 192.168.5.21 pod projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 11 05:06:39.180: INFO: Waiting for pod projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287 to disappear
Dec 11 05:06:39.182: INFO: Pod projected-volume-d327f8f5-3d4d-4324-85f5-5960b4524287 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:39.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1324" for this suite.
Dec 11 05:06:45.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:45.259: INFO: namespace projected-1324 deletion completed in 6.073881805s

• [SLOW TEST:10.154 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:45.262: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 11 05:06:45.301: INFO: Waiting up to 5m0s for pod "pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991" in namespace "emptydir-1468" to be "success or failure"
Dec 11 05:06:45.306: INFO: Pod "pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306572ms
Dec 11 05:06:47.313: INFO: Pod "pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991": Phase="Running", Reason="", readiness=true. Elapsed: 2.011014711s
Dec 11 05:06:49.316: INFO: Pod "pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014542018s
STEP: Saw pod success
Dec 11 05:06:49.316: INFO: Pod "pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991" satisfied condition "success or failure"
Dec 11 05:06:49.323: INFO: Trying to get logs from node 192.168.5.21 pod pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991 container test-container: <nil>
STEP: delete the pod
Dec 11 05:06:49.342: INFO: Waiting for pod pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991 to disappear
Dec 11 05:06:49.344: INFO: Pod pod-cba96bd8-bd1e-4bc3-a3e2-a78c33528991 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:49.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1468" for this suite.
Dec 11 05:06:55.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:06:55.433: INFO: namespace emptydir-1468 deletion completed in 6.085583711s

• [SLOW TEST:10.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:06:55.439: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:06:55.471: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e" in namespace "projected-8621" to be "success or failure"
Dec 11 05:06:55.473: INFO: Pod "downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081427ms
Dec 11 05:06:57.476: INFO: Pod "downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005401419s
Dec 11 05:06:59.480: INFO: Pod "downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009101836s
STEP: Saw pod success
Dec 11 05:06:59.480: INFO: Pod "downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e" satisfied condition "success or failure"
Dec 11 05:06:59.482: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e container client-container: <nil>
STEP: delete the pod
Dec 11 05:06:59.499: INFO: Waiting for pod downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e to disappear
Dec 11 05:06:59.502: INFO: Pod downwardapi-volume-f877827e-465a-48f9-8f70-c04f8a91d10e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:06:59.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8621" for this suite.
Dec 11 05:07:05.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:07:05.584: INFO: namespace projected-8621 deletion completed in 6.078191576s

• [SLOW TEST:10.147 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:07:05.589: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:07:05.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6" in namespace "downward-api-8507" to be "success or failure"
Dec 11 05:07:05.625: INFO: Pod "downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415729ms
Dec 11 05:07:07.628: INFO: Pod "downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.005430276s
Dec 11 05:07:09.634: INFO: Pod "downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011717645s
STEP: Saw pod success
Dec 11 05:07:09.634: INFO: Pod "downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6" satisfied condition "success or failure"
Dec 11 05:07:09.637: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6 container client-container: <nil>
STEP: delete the pod
Dec 11 05:07:09.655: INFO: Waiting for pod downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6 to disappear
Dec 11 05:07:09.657: INFO: Pod downwardapi-volume-d7092f07-a9a6-4bb0-9871-893489e403a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:07:09.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8507" for this suite.
Dec 11 05:07:15.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:07:15.736: INFO: namespace downward-api-8507 deletion completed in 6.074665079s

• [SLOW TEST:10.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:07:15.739: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 11 05:07:17.784: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e2ada820-a3a6-47e7-af95-66d4992c2db6,GenerateName:,Namespace:events-1572,SelfLink:/api/v1/namespaces/events-1572/pods/send-events-e2ada820-a3a6-47e7-af95-66d4992c2db6,UID:5610f3a9-81f7-43a7-bdf0-354e44d4a455,ResourceVersion:167575,Generation:0,CreationTimestamp:2019-12-11 05:07:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 766900947,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dgqlh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dgqlh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dgqlh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:07:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:07:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:07:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:07:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.2.104,StartTime:2019-12-11 05:07:15 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-12-11 05:07:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://0b28b522b4b2c524af5e6aaa042cfd47d30cccfda917fdb81e07f1f2883e7e57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 11 05:07:19.787: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 11 05:07:21.791: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:07:21.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1572" for this suite.
Dec 11 05:08:03.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:08:03.877: INFO: namespace events-1572 deletion completed in 42.077807366s

• [SLOW TEST:48.138 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:08:03.877: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Dec 11 05:08:07.931: INFO: Pod pod-hostip-c3e51919-122f-4e75-be40-4293eed38ee7 has hostIP: 192.168.5.21
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:08:07.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8957" for this suite.
Dec 11 05:08:29.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:08:30.014: INFO: namespace pods-8957 deletion completed in 22.078501336s

• [SLOW TEST:26.136 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:08:30.014: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Dec 11 05:08:30.039: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-018278524 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:08:30.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-800" for this suite.
Dec 11 05:08:36.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:08:36.194: INFO: namespace kubectl-800 deletion completed in 6.072843534s

• [SLOW TEST:6.180 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:08:36.197: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 11 05:08:36.228: INFO: Waiting up to 5m0s for pod "pod-648f88f1-fe15-4238-91b5-1b56194d995d" in namespace "emptydir-1026" to be "success or failure"
Dec 11 05:08:36.230: INFO: Pod "pod-648f88f1-fe15-4238-91b5-1b56194d995d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213563ms
Dec 11 05:08:38.234: INFO: Pod "pod-648f88f1-fe15-4238-91b5-1b56194d995d": Phase="Running", Reason="", readiness=true. Elapsed: 2.005865433s
Dec 11 05:08:40.237: INFO: Pod "pod-648f88f1-fe15-4238-91b5-1b56194d995d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009197688s
STEP: Saw pod success
Dec 11 05:08:40.237: INFO: Pod "pod-648f88f1-fe15-4238-91b5-1b56194d995d" satisfied condition "success or failure"
Dec 11 05:08:40.239: INFO: Trying to get logs from node 192.168.5.21 pod pod-648f88f1-fe15-4238-91b5-1b56194d995d container test-container: <nil>
STEP: delete the pod
Dec 11 05:08:40.254: INFO: Waiting for pod pod-648f88f1-fe15-4238-91b5-1b56194d995d to disappear
Dec 11 05:08:40.256: INFO: Pod pod-648f88f1-fe15-4238-91b5-1b56194d995d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:08:40.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1026" for this suite.
Dec 11 05:08:46.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:08:46.338: INFO: namespace emptydir-1026 deletion completed in 6.078719179s

• [SLOW TEST:10.141 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:08:46.339: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 05:08:46.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-510'
Dec 11 05:08:46.471: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 05:08:46.471: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Dec 11 05:08:48.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete deployment e2e-test-nginx-deployment --namespace=kubectl-510'
Dec 11 05:08:48.567: INFO: stderr: ""
Dec 11 05:08:48.567: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:08:48.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-510" for this suite.
Dec 11 05:09:10.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:09:10.653: INFO: namespace kubectl-510 deletion completed in 22.079643294s

• [SLOW TEST:24.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:09:10.653: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Dec 11 05:09:11.195: INFO: created pod pod-service-account-defaultsa
Dec 11 05:09:11.195: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 11 05:09:11.199: INFO: created pod pod-service-account-mountsa
Dec 11 05:09:11.199: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 11 05:09:11.203: INFO: created pod pod-service-account-nomountsa
Dec 11 05:09:11.203: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 11 05:09:11.206: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 11 05:09:11.206: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 11 05:09:11.210: INFO: created pod pod-service-account-mountsa-mountspec
Dec 11 05:09:11.210: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 11 05:09:11.213: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 11 05:09:11.214: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 11 05:09:11.218: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 11 05:09:11.218: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 11 05:09:11.221: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 11 05:09:11.221: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 11 05:09:11.226: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 11 05:09:11.226: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:09:11.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4197" for this suite.
Dec 11 05:09:17.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:09:17.301: INFO: namespace svcaccounts-4197 deletion completed in 6.07216707s

• [SLOW TEST:6.648 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:09:17.302: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8178/configmap-test-4c5c6558-6141-4d91-a718-d29e83defca4
STEP: Creating a pod to test consume configMaps
Dec 11 05:09:17.335: INFO: Waiting up to 5m0s for pod "pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea" in namespace "configmap-8178" to be "success or failure"
Dec 11 05:09:17.339: INFO: Pod "pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.656277ms
Dec 11 05:09:19.342: INFO: Pod "pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006749489s
STEP: Saw pod success
Dec 11 05:09:19.342: INFO: Pod "pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea" satisfied condition "success or failure"
Dec 11 05:09:19.344: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea container env-test: <nil>
STEP: delete the pod
Dec 11 05:09:19.359: INFO: Waiting for pod pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea to disappear
Dec 11 05:09:19.361: INFO: Pod pod-configmaps-924f3e28-5454-43ae-9054-9b1ca57494ea no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:09:19.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8178" for this suite.
Dec 11 05:09:25.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:09:25.448: INFO: namespace configmap-8178 deletion completed in 6.083812414s

• [SLOW TEST:8.146 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:09:25.449: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Dec 11 05:09:25.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-2046'
Dec 11 05:09:25.705: INFO: stderr: ""
Dec 11 05:09:25.705: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:09:25.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2046'
Dec 11 05:09:25.797: INFO: stderr: ""
Dec 11 05:09:25.797: INFO: stdout: "update-demo-nautilus-b82dj update-demo-nautilus-qtsgc "
Dec 11 05:09:25.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-b82dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:25.873: INFO: stderr: ""
Dec 11 05:09:25.873: INFO: stdout: ""
Dec 11 05:09:25.873: INFO: update-demo-nautilus-b82dj is created but not running
Dec 11 05:09:30.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2046'
Dec 11 05:09:30.962: INFO: stderr: ""
Dec 11 05:09:30.962: INFO: stdout: "update-demo-nautilus-b82dj update-demo-nautilus-qtsgc "
Dec 11 05:09:30.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-b82dj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:31.039: INFO: stderr: ""
Dec 11 05:09:31.039: INFO: stdout: "true"
Dec 11 05:09:31.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-b82dj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:31.113: INFO: stderr: ""
Dec 11 05:09:31.113: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:09:31.113: INFO: validating pod update-demo-nautilus-b82dj
Dec 11 05:09:31.119: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:09:31.119: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:09:31.119: INFO: update-demo-nautilus-b82dj is verified up and running
Dec 11 05:09:31.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-qtsgc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:31.200: INFO: stderr: ""
Dec 11 05:09:31.200: INFO: stdout: "true"
Dec 11 05:09:31.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-qtsgc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:31.278: INFO: stderr: ""
Dec 11 05:09:31.278: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:09:31.278: INFO: validating pod update-demo-nautilus-qtsgc
Dec 11 05:09:31.282: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:09:31.283: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:09:31.283: INFO: update-demo-nautilus-qtsgc is verified up and running
STEP: rolling-update to new replication controller
Dec 11 05:09:31.285: INFO: scanned /root for discovery docs: <nil>
Dec 11 05:09:31.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2046'
Dec 11 05:09:53.666: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 11 05:09:53.666: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:09:53.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2046'
Dec 11 05:09:53.764: INFO: stderr: ""
Dec 11 05:09:53.764: INFO: stdout: "update-demo-kitten-5btn8 update-demo-kitten-jds75 "
Dec 11 05:09:53.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-kitten-5btn8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:53.836: INFO: stderr: ""
Dec 11 05:09:53.836: INFO: stdout: "true"
Dec 11 05:09:53.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-kitten-5btn8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:53.914: INFO: stderr: ""
Dec 11 05:09:53.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 11 05:09:53.914: INFO: validating pod update-demo-kitten-5btn8
Dec 11 05:09:53.921: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 11 05:09:53.921: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 11 05:09:53.921: INFO: update-demo-kitten-5btn8 is verified up and running
Dec 11 05:09:53.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-kitten-jds75 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:54.010: INFO: stderr: ""
Dec 11 05:09:54.010: INFO: stdout: "true"
Dec 11 05:09:54.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-kitten-jds75 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2046'
Dec 11 05:09:54.097: INFO: stderr: ""
Dec 11 05:09:54.097: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 11 05:09:54.097: INFO: validating pod update-demo-kitten-jds75
Dec 11 05:09:54.103: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 11 05:09:54.103: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 11 05:09:54.103: INFO: update-demo-kitten-jds75 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:09:54.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2046" for this suite.
Dec 11 05:10:16.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:10:16.193: INFO: namespace kubectl-2046 deletion completed in 22.081872886s

• [SLOW TEST:50.747 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:10:16.198: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:10:16.230: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf" in namespace "projected-7504" to be "success or failure"
Dec 11 05:10:16.232: INFO: Pod "downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.988111ms
Dec 11 05:10:18.235: INFO: Pod "downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004974886s
Dec 11 05:10:20.239: INFO: Pod "downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008375796s
STEP: Saw pod success
Dec 11 05:10:20.239: INFO: Pod "downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf" satisfied condition "success or failure"
Dec 11 05:10:20.241: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf container client-container: <nil>
STEP: delete the pod
Dec 11 05:10:20.257: INFO: Waiting for pod downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf to disappear
Dec 11 05:10:20.259: INFO: Pod downwardapi-volume-eda5ee09-5ca5-42cc-aab6-dd61bf7770cf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:10:20.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7504" for this suite.
Dec 11 05:10:26.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:10:26.337: INFO: namespace projected-7504 deletion completed in 6.074687313s

• [SLOW TEST:10.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:10:26.345: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1211 05:10:36.430796      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 11 05:10:36.431: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:10:36.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7224" for this suite.
Dec 11 05:10:42.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:10:42.510: INFO: namespace gc-7224 deletion completed in 6.074687752s

• [SLOW TEST:16.165 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:10:42.514: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:10:42.561: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"26975e33-c92f-45bd-a4be-ab89750646fa", Controller:(*bool)(0xc0026c740a), BlockOwnerDeletion:(*bool)(0xc0026c740b)}}
Dec 11 05:10:42.565: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a3e624bf-4525-4eb0-a6a8-3974e42d3aac", Controller:(*bool)(0xc002754a5a), BlockOwnerDeletion:(*bool)(0xc002754a5b)}}
Dec 11 05:10:42.568: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"7faff785-e6ec-4c7a-be66-39fb8c0b52e5", Controller:(*bool)(0xc002754bca), BlockOwnerDeletion:(*bool)(0xc002754bcb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:10:47.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4078" for this suite.
Dec 11 05:10:53.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:10:53.671: INFO: namespace gc-4078 deletion completed in 6.074459304s

• [SLOW TEST:11.157 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:10:53.678: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 11 05:10:53.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4790'
Dec 11 05:10:53.811: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 11 05:10:53.811: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 11 05:10:53.822: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-p7vln]
Dec 11 05:10:53.822: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-p7vln" in namespace "kubectl-4790" to be "running and ready"
Dec 11 05:10:53.825: INFO: Pod "e2e-test-nginx-rc-p7vln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.955824ms
Dec 11 05:10:55.828: INFO: Pod "e2e-test-nginx-rc-p7vln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005753814s
Dec 11 05:10:57.832: INFO: Pod "e2e-test-nginx-rc-p7vln": Phase="Running", Reason="", readiness=true. Elapsed: 4.009702907s
Dec 11 05:10:57.832: INFO: Pod "e2e-test-nginx-rc-p7vln" satisfied condition "running and ready"
Dec 11 05:10:57.832: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-p7vln]
Dec 11 05:10:57.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs rc/e2e-test-nginx-rc --namespace=kubectl-4790'
Dec 11 05:10:57.934: INFO: stderr: ""
Dec 11 05:10:57.934: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Dec 11 05:10:57.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete rc e2e-test-nginx-rc --namespace=kubectl-4790'
Dec 11 05:10:58.029: INFO: stderr: ""
Dec 11 05:10:58.029: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:10:58.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4790" for this suite.
Dec 11 05:11:04.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:11:04.115: INFO: namespace kubectl-4790 deletion completed in 6.07790051s

• [SLOW TEST:10.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:11:04.123: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-4933f9d6-0c91-483c-8f53-eea8505d43d9 in namespace container-probe-3410
Dec 11 05:11:08.158: INFO: Started pod liveness-4933f9d6-0c91-483c-8f53-eea8505d43d9 in namespace container-probe-3410
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 05:11:08.161: INFO: Initial restart count of pod liveness-4933f9d6-0c91-483c-8f53-eea8505d43d9 is 0
Dec 11 05:11:28.209: INFO: Restart count of pod container-probe-3410/liveness-4933f9d6-0c91-483c-8f53-eea8505d43d9 is now 1 (20.04730888s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:11:28.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3410" for this suite.
Dec 11 05:11:34.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:11:34.303: INFO: namespace container-probe-3410 deletion completed in 6.079869188s

• [SLOW TEST:30.180 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:11:34.311: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7564
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 05:11:34.338: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 05:11:58.388: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.4.75:8080/dial?request=hostName&protocol=http&host=10.8.4.74&port=8080&tries=1'] Namespace:pod-network-test-7564 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 05:11:58.388: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 05:11:58.577: INFO: Waiting for endpoints: map[]
Dec 11 05:11:58.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.4.75:8080/dial?request=hostName&protocol=http&host=10.8.2.126&port=8080&tries=1'] Namespace:pod-network-test-7564 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 05:11:58.579: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 05:11:58.771: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:11:58.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7564" for this suite.
Dec 11 05:12:20.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:12:20.851: INFO: namespace pod-network-test-7564 deletion completed in 22.075896289s

• [SLOW TEST:46.541 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:12:20.852: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6422
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 11 05:12:20.880: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 11 05:12:38.936: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.2.127:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6422 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 05:12:38.936: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 05:12:39.120: INFO: Found all expected endpoints: [netserver-0]
Dec 11 05:12:39.123: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.4.76:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6422 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 11 05:12:39.123: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
Dec 11 05:12:39.345: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:12:39.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6422" for this suite.
Dec 11 05:13:01.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:13:01.434: INFO: namespace pod-network-test-6422 deletion completed in 22.084469792s

• [SLOW TEST:40.583 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:13:01.439: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:13:01.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8994" for this suite.
Dec 11 05:13:23.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:13:23.561: INFO: namespace pods-8994 deletion completed in 22.073347978s

• [SLOW TEST:22.122 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:13:23.563: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Dec 11 05:13:23.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 cluster-info'
Dec 11 05:13:23.680: INFO: stderr: ""
Dec 11 05:13:23.680: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mNodeExporter\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/ksc-node-exporter:metrics/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:13:23.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6271" for this suite.
Dec 11 05:13:29.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:13:29.759: INFO: namespace kubectl-6271 deletion completed in 6.073816727s

• [SLOW TEST:6.196 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:13:29.761: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-23c6531e-2942-4072-a64a-90a7f8466d6d
STEP: Creating a pod to test consume secrets
Dec 11 05:13:29.798: INFO: Waiting up to 5m0s for pod "pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9" in namespace "secrets-5080" to be "success or failure"
Dec 11 05:13:29.800: INFO: Pod "pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031522ms
Dec 11 05:13:31.804: INFO: Pod "pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006063335s
Dec 11 05:13:33.807: INFO: Pod "pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009079834s
STEP: Saw pod success
Dec 11 05:13:33.807: INFO: Pod "pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9" satisfied condition "success or failure"
Dec 11 05:13:33.810: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:13:33.824: INFO: Waiting for pod pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9 to disappear
Dec 11 05:13:33.826: INFO: Pod pod-secrets-6654ae31-1694-4ac3-94f1-cc66aef6fbf9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:13:33.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5080" for this suite.
Dec 11 05:13:39.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:13:39.907: INFO: namespace secrets-5080 deletion completed in 6.077656723s

• [SLOW TEST:10.146 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:13:39.908: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:13:39.940: INFO: Waiting up to 5m0s for pod "downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc" in namespace "downward-api-3030" to be "success or failure"
Dec 11 05:13:39.942: INFO: Pod "downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.469691ms
Dec 11 05:13:41.946: INFO: Pod "downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc": Phase="Running", Reason="", readiness=true. Elapsed: 2.005846415s
Dec 11 05:13:43.951: INFO: Pod "downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011325724s
STEP: Saw pod success
Dec 11 05:13:43.951: INFO: Pod "downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc" satisfied condition "success or failure"
Dec 11 05:13:43.954: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc container client-container: <nil>
STEP: delete the pod
Dec 11 05:13:43.975: INFO: Waiting for pod downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc to disappear
Dec 11 05:13:43.978: INFO: Pod downwardapi-volume-854e97fd-b767-4036-956c-80214fd963bc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:13:43.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3030" for this suite.
Dec 11 05:13:49.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:13:50.064: INFO: namespace downward-api-3030 deletion completed in 6.080808369s

• [SLOW TEST:10.156 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:13:50.065: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 11 05:13:50.113: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168770,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 05:13:50.113: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168770,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 11 05:14:00.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168787,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 11 05:14:00.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168787,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 11 05:14:10.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168803,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 05:14:10.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168803,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 11 05:14:20.142: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168821,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 05:14:20.142: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-a,UID:07771289-00a6-4062-a2dd-18ab53b27ed5,ResourceVersion:168821,Generation:0,CreationTimestamp:2019-12-11 05:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 11 05:14:30.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-b,UID:efca4c8b-f74d-490d-9f33-e5e435fde911,ResourceVersion:168837,Generation:0,CreationTimestamp:2019-12-11 05:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 05:14:30.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-b,UID:efca4c8b-f74d-490d-9f33-e5e435fde911,ResourceVersion:168837,Generation:0,CreationTimestamp:2019-12-11 05:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 11 05:14:40.161: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-b,UID:efca4c8b-f74d-490d-9f33-e5e435fde911,ResourceVersion:168856,Generation:0,CreationTimestamp:2019-12-11 05:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 05:14:40.161: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-830,SelfLink:/api/v1/namespaces/watch-830/configmaps/e2e-watch-test-configmap-b,UID:efca4c8b-f74d-490d-9f33-e5e435fde911,ResourceVersion:168856,Generation:0,CreationTimestamp:2019-12-11 05:14:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:14:50.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-830" for this suite.
Dec 11 05:14:56.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:14:56.260: INFO: namespace watch-830 deletion completed in 6.089813427s

• [SLOW TEST:66.194 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:14:56.267: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-503997bf-63d4-4d14-9345-2ca77252152e
STEP: Creating a pod to test consume secrets
Dec 11 05:14:56.322: INFO: Waiting up to 5m0s for pod "pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b" in namespace "secrets-1848" to be "success or failure"
Dec 11 05:14:56.324: INFO: Pod "pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220371ms
Dec 11 05:14:58.327: INFO: Pod "pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005262691s
STEP: Saw pod success
Dec 11 05:14:58.327: INFO: Pod "pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b" satisfied condition "success or failure"
Dec 11 05:14:58.330: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:14:58.346: INFO: Waiting for pod pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b to disappear
Dec 11 05:14:58.349: INFO: Pod pod-secrets-66e1db29-33b9-4665-8f26-e9257ec73e6b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:14:58.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1848" for this suite.
Dec 11 05:15:04.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:15:04.436: INFO: namespace secrets-1848 deletion completed in 6.0842937s
STEP: Destroying namespace "secret-namespace-2773" for this suite.
Dec 11 05:15:10.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:15:10.523: INFO: namespace secret-namespace-2773 deletion completed in 6.086724455s

• [SLOW TEST:14.256 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:15:10.525: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:15:14.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5871" for this suite.
Dec 11 05:15:20.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:15:20.641: INFO: namespace kubelet-test-5871 deletion completed in 6.074282593s

• [SLOW TEST:10.117 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:15:20.650: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-64642d28-5e55-4f94-9199-3785f9fb1f5a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-64642d28-5e55-4f94-9199-3785f9fb1f5a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:16:47.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6401" for this suite.
Dec 11 05:17:09.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:17:09.149: INFO: namespace configmap-6401 deletion completed in 22.080726495s

• [SLOW TEST:108.499 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:17:09.150: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Dec 11 05:17:09.184: INFO: Waiting up to 5m0s for pod "var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c" in namespace "var-expansion-109" to be "success or failure"
Dec 11 05:17:09.188: INFO: Pod "var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.464201ms
Dec 11 05:17:11.192: INFO: Pod "var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007580353s
Dec 11 05:17:13.196: INFO: Pod "var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011196926s
STEP: Saw pod success
Dec 11 05:17:13.196: INFO: Pod "var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c" satisfied condition "success or failure"
Dec 11 05:17:13.198: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:17:13.214: INFO: Waiting for pod var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c to disappear
Dec 11 05:17:13.216: INFO: Pod var-expansion-bc0202ae-7524-4eb4-968c-3e45586a4a7c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:17:13.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-109" for this suite.
Dec 11 05:17:19.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:17:19.295: INFO: namespace var-expansion-109 deletion completed in 6.074928745s

• [SLOW TEST:10.145 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:17:19.296: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Dec 11 05:17:19.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-7263'
Dec 11 05:17:19.619: INFO: stderr: ""
Dec 11 05:17:19.619: INFO: stdout: "pod/pause created\n"
Dec 11 05:17:19.619: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 11 05:17:19.619: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7263" to be "running and ready"
Dec 11 05:17:19.623: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.400253ms
Dec 11 05:17:21.626: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006049658s
Dec 11 05:17:23.630: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.010062552s
Dec 11 05:17:23.630: INFO: Pod "pause" satisfied condition "running and ready"
Dec 11 05:17:23.630: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 11 05:17:23.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 label pods pause testing-label=testing-label-value --namespace=kubectl-7263'
Dec 11 05:17:23.726: INFO: stderr: ""
Dec 11 05:17:23.726: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 11 05:17:23.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pod pause -L testing-label --namespace=kubectl-7263'
Dec 11 05:17:23.806: INFO: stderr: ""
Dec 11 05:17:23.806: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 11 05:17:23.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 label pods pause testing-label- --namespace=kubectl-7263'
Dec 11 05:17:23.879: INFO: stderr: ""
Dec 11 05:17:23.879: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 11 05:17:23.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pod pause -L testing-label --namespace=kubectl-7263'
Dec 11 05:17:23.964: INFO: stderr: ""
Dec 11 05:17:23.964: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Dec 11 05:17:23.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-7263'
Dec 11 05:17:24.057: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 05:17:24.057: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 11 05:17:24.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=pause --no-headers --namespace=kubectl-7263'
Dec 11 05:17:24.190: INFO: stderr: "No resources found.\n"
Dec 11 05:17:24.190: INFO: stdout: ""
Dec 11 05:17:24.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=pause --namespace=kubectl-7263 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:17:24.314: INFO: stderr: ""
Dec 11 05:17:24.314: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:17:24.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7263" for this suite.
Dec 11 05:17:30.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:17:30.409: INFO: namespace kubectl-7263 deletion completed in 6.091724904s

• [SLOW TEST:11.113 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:17:30.414: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Dec 11 05:17:30.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 --namespace=kubectl-3780 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 11 05:17:33.065: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 11 05:17:33.065: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:17:35.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3780" for this suite.
Dec 11 05:17:43.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:17:43.153: INFO: namespace kubectl-3780 deletion completed in 8.076923431s

• [SLOW TEST:12.740 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:17:43.156: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 11 05:17:43.186: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:17:47.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7356" for this suite.
Dec 11 05:17:53.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:17:53.340: INFO: namespace init-container-7356 deletion completed in 6.087195696s

• [SLOW TEST:10.184 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:17:53.341: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:17:57.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7023" for this suite.
Dec 11 05:18:47.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:18:47.501: INFO: namespace kubelet-test-7023 deletion completed in 50.080803798s

• [SLOW TEST:54.160 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:18:47.501: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 11 05:18:57.551: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1211 05:18:57.551155      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:18:57.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7793" for this suite.
Dec 11 05:19:03.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:19:03.637: INFO: namespace gc-7793 deletion completed in 6.08270642s

• [SLOW TEST:16.136 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:19:03.639: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7597.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7597.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7597.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7597.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 252.13.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.13.252_udp@PTR;check="$$(dig +tcp +noall +answer +search 252.13.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.13.252_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7597.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7597.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7597.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7597.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7597.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7597.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 252.13.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.13.252_udp@PTR;check="$$(dig +tcp +noall +answer +search 252.13.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.13.252_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 11 05:19:07.701: INFO: Unable to read wheezy_udp@dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.706: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.711: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.714: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.736: INFO: Unable to read jessie_udp@dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.739: INFO: Unable to read jessie_tcp@dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.743: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.746: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local from pod dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18: the server could not find the requested resource (get pods dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18)
Dec 11 05:19:07.760: INFO: Lookups using dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18 failed for: [wheezy_udp@dns-test-service.dns-7597.svc.cluster.local wheezy_tcp@dns-test-service.dns-7597.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local jessie_udp@dns-test-service.dns-7597.svc.cluster.local jessie_tcp@dns-test-service.dns-7597.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7597.svc.cluster.local]

Dec 11 05:19:12.809: INFO: DNS probes using dns-7597/dns-test-b7b8b6fb-2f6a-40ff-b3ee-3a8920daff18 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:19:12.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7597" for this suite.
Dec 11 05:19:18.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:19:18.931: INFO: namespace dns-7597 deletion completed in 6.079000764s

• [SLOW TEST:15.292 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:19:18.932: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Dec 11 05:19:18.957: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-018278524 proxy --unix-socket=/tmp/kubectl-proxy-unix525740459/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:19:19.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2036" for this suite.
Dec 11 05:19:25.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:19:25.191: INFO: namespace kubectl-2036 deletion completed in 6.1287661s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:19:25.192: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Dec 11 05:19:25.223: INFO: Waiting up to 5m0s for pod "var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001" in namespace "var-expansion-3867" to be "success or failure"
Dec 11 05:19:25.225: INFO: Pod "var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001": Phase="Pending", Reason="", readiness=false. Elapsed: 2.372984ms
Dec 11 05:19:27.228: INFO: Pod "var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005604882s
Dec 11 05:19:29.231: INFO: Pod "var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00836193s
STEP: Saw pod success
Dec 11 05:19:29.231: INFO: Pod "var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001" satisfied condition "success or failure"
Dec 11 05:19:29.236: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001 container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:19:29.251: INFO: Waiting for pod var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001 to disappear
Dec 11 05:19:29.254: INFO: Pod var-expansion-29a4e188-ceec-4d1e-86ba-973105f9a001 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:19:29.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3867" for this suite.
Dec 11 05:19:35.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:19:35.328: INFO: namespace var-expansion-3867 deletion completed in 6.071097751s

• [SLOW TEST:10.136 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:19:35.329: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:20:01.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4765" for this suite.
Dec 11 05:20:07.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:20:07.493: INFO: namespace namespaces-4765 deletion completed in 6.069120941s
STEP: Destroying namespace "nsdeletetest-300" for this suite.
Dec 11 05:20:07.495: INFO: Namespace nsdeletetest-300 was already deleted
STEP: Destroying namespace "nsdeletetest-7091" for this suite.
Dec 11 05:20:13.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:20:13.579: INFO: namespace nsdeletetest-7091 deletion completed in 6.083785889s

• [SLOW TEST:38.250 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:20:13.580: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:20:13.624: INFO: (0) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.056523ms)
Dec 11 05:20:13.627: INFO: (1) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.647309ms)
Dec 11 05:20:13.630: INFO: (2) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.792048ms)
Dec 11 05:20:13.632: INFO: (3) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.39193ms)
Dec 11 05:20:13.635: INFO: (4) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.979969ms)
Dec 11 05:20:13.638: INFO: (5) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.32124ms)
Dec 11 05:20:13.641: INFO: (6) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.707179ms)
Dec 11 05:20:13.644: INFO: (7) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.640344ms)
Dec 11 05:20:13.646: INFO: (8) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.441282ms)
Dec 11 05:20:13.650: INFO: (9) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.473017ms)
Dec 11 05:20:13.653: INFO: (10) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.292107ms)
Dec 11 05:20:13.656: INFO: (11) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.945261ms)
Dec 11 05:20:13.659: INFO: (12) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.295226ms)
Dec 11 05:20:13.663: INFO: (13) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.017673ms)
Dec 11 05:20:13.666: INFO: (14) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.957988ms)
Dec 11 05:20:13.668: INFO: (15) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.922081ms)
Dec 11 05:20:13.671: INFO: (16) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.935707ms)
Dec 11 05:20:13.675: INFO: (17) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.032037ms)
Dec 11 05:20:13.679: INFO: (18) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 4.159176ms)
Dec 11 05:20:13.682: INFO: (19) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.779592ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:20:13.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-942" for this suite.
Dec 11 05:20:19.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:20:19.757: INFO: namespace proxy-942 deletion completed in 6.072542037s

• [SLOW TEST:6.177 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:20:19.759: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:20:24.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5135" for this suite.
Dec 11 05:20:46.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:20:46.898: INFO: namespace replication-controller-5135 deletion completed in 22.089272529s

• [SLOW TEST:27.139 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:20:46.898: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 11 05:20:46.929: INFO: Waiting up to 5m0s for pod "pod-4753d4f4-acf6-406a-a2a2-d27093dec579" in namespace "emptydir-3540" to be "success or failure"
Dec 11 05:20:46.931: INFO: Pod "pod-4753d4f4-acf6-406a-a2a2-d27093dec579": Phase="Pending", Reason="", readiness=false. Elapsed: 2.257856ms
Dec 11 05:20:48.935: INFO: Pod "pod-4753d4f4-acf6-406a-a2a2-d27093dec579": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005798756s
Dec 11 05:20:50.941: INFO: Pod "pod-4753d4f4-acf6-406a-a2a2-d27093dec579": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011880441s
STEP: Saw pod success
Dec 11 05:20:50.941: INFO: Pod "pod-4753d4f4-acf6-406a-a2a2-d27093dec579" satisfied condition "success or failure"
Dec 11 05:20:50.943: INFO: Trying to get logs from node 192.168.5.21 pod pod-4753d4f4-acf6-406a-a2a2-d27093dec579 container test-container: <nil>
STEP: delete the pod
Dec 11 05:20:50.959: INFO: Waiting for pod pod-4753d4f4-acf6-406a-a2a2-d27093dec579 to disappear
Dec 11 05:20:50.961: INFO: Pod pod-4753d4f4-acf6-406a-a2a2-d27093dec579 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:20:50.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3540" for this suite.
Dec 11 05:20:56.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:20:57.040: INFO: namespace emptydir-3540 deletion completed in 6.07572228s

• [SLOW TEST:10.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:20:57.041: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-175
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-175
STEP: Deleting pre-stop pod
Dec 11 05:21:10.106: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:21:10.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-175" for this suite.
Dec 11 05:21:48.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:21:48.185: INFO: namespace prestop-175 deletion completed in 38.070274065s

• [SLOW TEST:51.148 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:21:48.190: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Dec 11 05:21:48.226: INFO: Waiting up to 5m0s for pod "client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0" in namespace "containers-7114" to be "success or failure"
Dec 11 05:21:48.228: INFO: Pod "client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025005ms
Dec 11 05:21:50.231: INFO: Pod "client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005493498s
Dec 11 05:21:52.234: INFO: Pod "client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008286538s
STEP: Saw pod success
Dec 11 05:21:52.234: INFO: Pod "client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0" satisfied condition "success or failure"
Dec 11 05:21:52.236: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0 container test-container: <nil>
STEP: delete the pod
Dec 11 05:21:52.251: INFO: Waiting for pod client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0 to disappear
Dec 11 05:21:52.253: INFO: Pod client-containers-b14da429-37bd-455c-8b5f-4d3189291ca0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:21:52.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7114" for this suite.
Dec 11 05:21:58.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:21:58.331: INFO: namespace containers-7114 deletion completed in 6.075840275s

• [SLOW TEST:10.142 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:21:58.338: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:21:58.372: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 11 05:22:03.378: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 05:22:03.378: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 11 05:22:05.382: INFO: Creating deployment "test-rollover-deployment"
Dec 11 05:22:05.390: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 11 05:22:07.397: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 11 05:22:07.403: INFO: Ensure that both replica sets have 1 created replica
Dec 11 05:22:07.407: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 11 05:22:07.412: INFO: Updating deployment test-rollover-deployment
Dec 11 05:22:07.412: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 11 05:22:09.417: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 11 05:22:09.422: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 11 05:22:09.426: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:09.427: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638527, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:11.433: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:11.433: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638529, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:13.433: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:13.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638529, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:15.433: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:15.433: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638529, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:17.433: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:17.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638529, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:19.433: INFO: all replica sets need to contain the pod-template-hash label
Dec 11 05:22:19.433: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638529, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638525, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:22:21.433: INFO: 
Dec 11 05:22:21.433: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 11 05:22:21.445: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2915,SelfLink:/apis/apps/v1/namespaces/deployment-2915/deployments/test-rollover-deployment,UID:ccebaae6-640a-4827-8010-a03c6be778f7,ResourceVersion:170007,Generation:2,CreationTimestamp:2019-12-11 05:22:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-11 05:22:05 +0000 UTC 2019-12-11 05:22:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-11 05:22:19 +0000 UTC 2019-12-11 05:22:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 11 05:22:21.448: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-2915,SelfLink:/apis/apps/v1/namespaces/deployment-2915/replicasets/test-rollover-deployment-854595fc44,UID:ceab9927-d127-4174-93c4-3a4117ce2078,ResourceVersion:170000,Generation:2,CreationTimestamp:2019-12-11 05:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ccebaae6-640a-4827-8010-a03c6be778f7 0xc001fda047 0xc001fda048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 11 05:22:21.448: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 11 05:22:21.448: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2915,SelfLink:/apis/apps/v1/namespaces/deployment-2915/replicasets/test-rollover-controller,UID:bdef588a-8179-4e11-a62d-bbce89eb8e0f,ResourceVersion:170006,Generation:2,CreationTimestamp:2019-12-11 05:21:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ccebaae6-640a-4827-8010-a03c6be778f7 0xc0026c7f77 0xc0026c7f78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 05:22:21.448: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-2915,SelfLink:/apis/apps/v1/namespaces/deployment-2915/replicasets/test-rollover-deployment-9b8b997cf,UID:144b767a-c695-4e44-a579-960d3f89ed4d,ResourceVersion:169972,Generation:2,CreationTimestamp:2019-12-11 05:22:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ccebaae6-640a-4827-8010-a03c6be778f7 0xc001fda110 0xc001fda111}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 05:22:21.453: INFO: Pod "test-rollover-deployment-854595fc44-j49mb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-j49mb,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-2915,SelfLink:/api/v1/namespaces/deployment-2915/pods/test-rollover-deployment-854595fc44-j49mb,UID:9d73470c-e81f-49e7-a9e3-8619e265ff5f,ResourceVersion:169980,Generation:0,CreationTimestamp:2019-12-11 05:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 ceab9927-d127-4174-93c4-3a4117ce2078 0xc001fdacf7 0xc001fdacf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mbh44 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mbh44,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mbh44 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:22:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:22:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:22:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:22:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.82,StartTime:2019-12-11 05:22:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-11 05:22:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4cb0b461696dd219120310ec4f6568071dec91fb342cecb32d5fa3855c1a552f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:22:21.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2915" for this suite.
Dec 11 05:22:27.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:22:27.530: INFO: namespace deployment-2915 deletion completed in 6.073652488s

• [SLOW TEST:29.193 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:22:27.531: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-3697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3697 to expose endpoints map[]
Dec 11 05:22:27.571: INFO: Get endpoints failed (5.574305ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 11 05:22:28.574: INFO: successfully validated that service multi-endpoint-test in namespace services-3697 exposes endpoints map[] (1.008142582s elapsed)
STEP: Creating pod pod1 in namespace services-3697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3697 to expose endpoints map[pod1:[100]]
Dec 11 05:22:31.598: INFO: successfully validated that service multi-endpoint-test in namespace services-3697 exposes endpoints map[pod1:[100]] (3.018348566s elapsed)
STEP: Creating pod pod2 in namespace services-3697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3697 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 11 05:22:34.630: INFO: successfully validated that service multi-endpoint-test in namespace services-3697 exposes endpoints map[pod1:[100] pod2:[101]] (3.028133023s elapsed)
STEP: Deleting pod pod1 in namespace services-3697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3697 to expose endpoints map[pod2:[101]]
Dec 11 05:22:35.644: INFO: successfully validated that service multi-endpoint-test in namespace services-3697 exposes endpoints map[pod2:[101]] (1.010085262s elapsed)
STEP: Deleting pod pod2 in namespace services-3697
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3697 to expose endpoints map[]
Dec 11 05:22:36.653: INFO: successfully validated that service multi-endpoint-test in namespace services-3697 exposes endpoints map[] (1.003992645s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:22:36.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3697" for this suite.
Dec 11 05:22:58.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:22:58.752: INFO: namespace services-3697 deletion completed in 22.078836047s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.220 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:22:58.752: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:22:58.780: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 11 05:22:58.786: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 11 05:23:03.790: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 11 05:23:03.790: INFO: Creating deployment "test-rolling-update-deployment"
Dec 11 05:23:03.794: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 11 05:23:03.798: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 11 05:23:05.803: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 11 05:23:05.809: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638583, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638583, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638583, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638583, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:23:07.813: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 11 05:23:07.820: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8982,SelfLink:/apis/apps/v1/namespaces/deployment-8982/deployments/test-rolling-update-deployment,UID:93e8e6ff-bf15-4af9-a617-86a21d2564bc,ResourceVersion:170162,Generation:1,CreationTimestamp:2019-12-11 05:23:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-11 05:23:03 +0000 UTC 2019-12-11 05:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-11 05:23:05 +0000 UTC 2019-12-11 05:23:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 11 05:23:07.823: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-8982,SelfLink:/apis/apps/v1/namespaces/deployment-8982/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:cfc0e0a9-699a-496f-9825-f231f019926d,ResourceVersion:170155,Generation:1,CreationTimestamp:2019-12-11 05:23:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 93e8e6ff-bf15-4af9-a617-86a21d2564bc 0xc002f6f447 0xc002f6f448}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 11 05:23:07.823: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 11 05:23:07.823: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8982,SelfLink:/apis/apps/v1/namespaces/deployment-8982/replicasets/test-rolling-update-controller,UID:505d67bb-8db0-43c8-87f1-75f3fe709530,ResourceVersion:170161,Generation:2,CreationTimestamp:2019-12-11 05:22:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 93e8e6ff-bf15-4af9-a617-86a21d2564bc 0xc002f6f377 0xc002f6f378}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 11 05:23:07.826: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-r97hd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-r97hd,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-8982,SelfLink:/api/v1/namespaces/deployment-8982/pods/test-rolling-update-deployment-79f6b9d75c-r97hd,UID:68ef8d7b-0044-4d7e-a7a9-dc596b3bbdd0,ResourceVersion:170154,Generation:0,CreationTimestamp:2019-12-11 05:23:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c cfc0e0a9-699a-496f-9825-f231f019926d 0xc0035bf047 0xc0035bf048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-g4kk4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4kk4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g4kk4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.23,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.23,PodIP:10.8.4.84,StartTime:2019-12-11 05:23:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-11 05:23:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://822317a2f70aca81e0940d0a2d4fe243d883ce60b7c4cdeee71aecb66f9d0823}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:23:07.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8982" for this suite.
Dec 11 05:23:13.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:23:13.901: INFO: namespace deployment-8982 deletion completed in 6.071129557s

• [SLOW TEST:15.149 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:23:13.902: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8dzx
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 05:23:13.937: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8dzx" in namespace "subpath-2285" to be "success or failure"
Dec 11 05:23:13.939: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119784ms
Dec 11 05:23:15.942: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005070627s
Dec 11 05:23:17.945: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 4.008340696s
Dec 11 05:23:19.949: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 6.012072656s
Dec 11 05:23:21.952: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 8.015325938s
Dec 11 05:23:23.956: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 10.01887377s
Dec 11 05:23:25.960: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 12.023299733s
Dec 11 05:23:27.964: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 14.027147556s
Dec 11 05:23:29.968: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 16.030454785s
Dec 11 05:23:31.983: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 18.045536329s
Dec 11 05:23:33.986: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Running", Reason="", readiness=true. Elapsed: 20.048590186s
Dec 11 05:23:35.989: INFO: Pod "pod-subpath-test-configmap-8dzx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.051396854s
STEP: Saw pod success
Dec 11 05:23:35.989: INFO: Pod "pod-subpath-test-configmap-8dzx" satisfied condition "success or failure"
Dec 11 05:23:35.992: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-configmap-8dzx container test-container-subpath-configmap-8dzx: <nil>
STEP: delete the pod
Dec 11 05:23:36.008: INFO: Waiting for pod pod-subpath-test-configmap-8dzx to disappear
Dec 11 05:23:36.010: INFO: Pod pod-subpath-test-configmap-8dzx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8dzx
Dec 11 05:23:36.010: INFO: Deleting pod "pod-subpath-test-configmap-8dzx" in namespace "subpath-2285"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:23:36.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2285" for this suite.
Dec 11 05:23:42.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:23:42.090: INFO: namespace subpath-2285 deletion completed in 6.074689608s

• [SLOW TEST:28.189 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:23:42.093: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec 11 05:23:42.135: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Dec 11 05:23:42.651: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 11 05:23:44.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638622, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711638622, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 11 05:23:47.429: INFO: Waited 715.460527ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:23:47.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8567" for this suite.
Dec 11 05:23:54.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:23:54.153: INFO: namespace aggregator-8567 deletion completed in 6.168279271s

• [SLOW TEST:12.064 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:23:54.159: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8214
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8214
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8214
Dec 11 05:23:54.196: INFO: Found 0 stateful pods, waiting for 1
Dec 11 05:24:04.202: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 11 05:24:04.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:24:04.565: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:24:04.565: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:24:04.565: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:24:04.568: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 11 05:24:14.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:24:14.573: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:24:14.583: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:14.583: INFO: ss-0  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  }]
Dec 11 05:24:14.584: INFO: 
Dec 11 05:24:14.584: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 11 05:24:15.588: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997349797s
Dec 11 05:24:16.592: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992972352s
Dec 11 05:24:17.595: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989117401s
Dec 11 05:24:18.599: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985391694s
Dec 11 05:24:19.603: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981311404s
Dec 11 05:24:20.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977573752s
Dec 11 05:24:21.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974282505s
Dec 11 05:24:22.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971123862s
Dec 11 05:24:23.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.269601ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8214
Dec 11 05:24:24.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:24:24.977: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:24:24.977: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:24:24.977: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:24:24.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:24:25.394: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 11 05:24:25.394: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:24:25.394: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:24:25.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:24:25.659: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 11 05:24:25.659: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:24:25.659: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:24:25.665: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 11 05:24:35.670: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:24:35.670: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:24:35.670: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 11 05:24:35.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:24:36.022: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:24:36.022: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:24:36.022: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:24:36.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:24:36.405: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:24:36.405: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:24:36.405: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:24:36.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-8214 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:24:36.685: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:24:36.685: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:24:36.685: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:24:36.685: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:24:36.693: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 11 05:24:46.701: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:24:46.701: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:24:46.701: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:24:46.710: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:46.710: INFO: ss-0  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  }]
Dec 11 05:24:46.710: INFO: ss-1  192.168.5.23  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:46.710: INFO: ss-2  192.168.5.23  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:46.710: INFO: 
Dec 11 05:24:46.710: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 11 05:24:47.714: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:47.714: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:23:54 +0000 UTC  }]
Dec 11 05:24:47.714: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:47.714: INFO: ss-2  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:47.714: INFO: 
Dec 11 05:24:47.714: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 11 05:24:48.717: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:48.717: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:48.717: INFO: ss-2  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:48.717: INFO: 
Dec 11 05:24:48.717: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 05:24:49.721: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:49.721: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:49.721: INFO: ss-2  192.168.5.23  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:49.721: INFO: 
Dec 11 05:24:49.721: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 05:24:50.725: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:50.725: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:50.725: INFO: ss-2  192.168.5.23  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:50.725: INFO: 
Dec 11 05:24:50.725: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 05:24:51.728: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:51.728: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:51.730: INFO: ss-2  192.168.5.23  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:51.730: INFO: 
Dec 11 05:24:51.730: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 05:24:52.733: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Dec 11 05:24:52.733: INFO: ss-1  192.168.5.23  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:52.733: INFO: ss-2  192.168.5.23  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-11 05:24:14 +0000 UTC  }]
Dec 11 05:24:52.733: INFO: 
Dec 11 05:24:52.733: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 11 05:24:53.738: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974323535s
Dec 11 05:24:54.741: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.969877562s
Dec 11 05:24:55.744: INFO: Verifying statefulset ss doesn't scale past 0 for another 966.828973ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8214
Dec 11 05:24:56.747: INFO: Scaling statefulset ss to 0
Dec 11 05:24:56.753: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 11 05:24:56.755: INFO: Deleting all statefulset in ns statefulset-8214
Dec 11 05:24:56.758: INFO: Scaling statefulset ss to 0
Dec 11 05:24:56.764: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:24:56.766: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:24:56.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8214" for this suite.
Dec 11 05:25:02.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:25:02.861: INFO: namespace statefulset-8214 deletion completed in 6.082079644s

• [SLOW TEST:68.702 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:25:02.864: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:25:02.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-758" for this suite.
Dec 11 05:25:08.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:25:08.975: INFO: namespace services-758 deletion completed in 6.071714157s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.112 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:25:08.976: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Dec 11 05:25:09.005: INFO: Waiting up to 5m0s for pod "var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd" in namespace "var-expansion-5044" to be "success or failure"
Dec 11 05:25:09.008: INFO: Pod "var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.095467ms
Dec 11 05:25:11.012: INFO: Pod "var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006684756s
Dec 11 05:25:13.015: INFO: Pod "var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009688583s
STEP: Saw pod success
Dec 11 05:25:13.015: INFO: Pod "var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd" satisfied condition "success or failure"
Dec 11 05:25:13.017: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:25:13.031: INFO: Waiting for pod var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd to disappear
Dec 11 05:25:13.033: INFO: Pod var-expansion-4213793f-4f5d-43a6-b39e-7b7574c8c0bd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:25:13.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5044" for this suite.
Dec 11 05:25:19.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:25:19.126: INFO: namespace var-expansion-5044 deletion completed in 6.089603482s

• [SLOW TEST:10.150 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:25:19.127: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:25:19.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3371" for this suite.
Dec 11 05:25:25.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:25:25.275: INFO: namespace kubelet-test-3371 deletion completed in 6.0734307s

• [SLOW TEST:6.148 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:25:25.282: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 11 05:25:28.338: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:25:28.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6279" for this suite.
Dec 11 05:25:34.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:25:34.432: INFO: namespace container-runtime-6279 deletion completed in 6.07982768s

• [SLOW TEST:9.157 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:25:34.441: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1391
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 11 05:25:34.479: INFO: Found 0 stateful pods, waiting for 3
Dec 11 05:25:44.485: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:25:44.486: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:25:44.486: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:25:44.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1391 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:25:44.812: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:25:44.812: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:25:44.812: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 11 05:25:54.846: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 11 05:26:04.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1391 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:26:05.180: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:26:05.180: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:26:05.180: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:26:15.197: INFO: Waiting for StatefulSet statefulset-1391/ss2 to complete update
Dec 11 05:26:15.197: INFO: Waiting for Pod statefulset-1391/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 11 05:26:15.197: INFO: Waiting for Pod statefulset-1391/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 11 05:26:25.204: INFO: Waiting for StatefulSet statefulset-1391/ss2 to complete update
Dec 11 05:26:25.204: INFO: Waiting for Pod statefulset-1391/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Dec 11 05:26:35.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1391 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:26:35.536: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:26:35.536: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:26:35.536: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:26:45.569: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 11 05:26:55.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1391 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:26:55.894: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:26:55.894: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:26:55.894: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 11 05:27:25.912: INFO: Deleting all statefulset in ns statefulset-1391
Dec 11 05:27:25.914: INFO: Scaling statefulset ss2 to 0
Dec 11 05:27:55.927: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:27:55.930: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:27:55.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1391" for this suite.
Dec 11 05:28:01.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:28:02.046: INFO: namespace statefulset-1391 deletion completed in 6.090683109s

• [SLOW TEST:147.605 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:28:02.047: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 11 05:28:04.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec pod-sharedvolume-5f8ad145-d643-49f4-a63e-fe5954b6615c -c busybox-main-container --namespace=emptydir-1173 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 11 05:28:04.477: INFO: stderr: ""
Dec 11 05:28:04.477: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:28:04.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1173" for this suite.
Dec 11 05:28:10.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:28:10.554: INFO: namespace emptydir-1173 deletion completed in 6.073013794s

• [SLOW TEST:8.507 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:28:10.556: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 11 05:28:10.586: INFO: Waiting up to 5m0s for pod "pod-39663886-818c-4e2e-aeeb-d144c808bad0" in namespace "emptydir-7206" to be "success or failure"
Dec 11 05:28:10.588: INFO: Pod "pod-39663886-818c-4e2e-aeeb-d144c808bad0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06961ms
Dec 11 05:28:12.592: INFO: Pod "pod-39663886-818c-4e2e-aeeb-d144c808bad0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005541602s
Dec 11 05:28:14.595: INFO: Pod "pod-39663886-818c-4e2e-aeeb-d144c808bad0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00868891s
STEP: Saw pod success
Dec 11 05:28:14.595: INFO: Pod "pod-39663886-818c-4e2e-aeeb-d144c808bad0" satisfied condition "success or failure"
Dec 11 05:28:14.597: INFO: Trying to get logs from node 192.168.5.21 pod pod-39663886-818c-4e2e-aeeb-d144c808bad0 container test-container: <nil>
STEP: delete the pod
Dec 11 05:28:14.613: INFO: Waiting for pod pod-39663886-818c-4e2e-aeeb-d144c808bad0 to disappear
Dec 11 05:28:14.615: INFO: Pod pod-39663886-818c-4e2e-aeeb-d144c808bad0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:28:14.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7206" for this suite.
Dec 11 05:28:20.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:28:20.693: INFO: namespace emptydir-7206 deletion completed in 6.075356576s

• [SLOW TEST:10.137 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:28:20.699: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:28:20.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 version'
Dec 11 05:28:20.824: INFO: stderr: ""
Dec 11 05:28:20.825: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:07:57Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:28:20.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4910" for this suite.
Dec 11 05:28:26.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:28:26.909: INFO: namespace kubectl-4910 deletion completed in 6.077164116s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:28:26.910: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1080
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1080
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1080
Dec 11 05:28:26.951: INFO: Found 0 stateful pods, waiting for 1
Dec 11 05:28:36.956: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 11 05:28:36.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:28:37.284: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:28:37.284: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:28:37.284: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:28:37.287: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 11 05:28:47.292: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:28:47.293: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:28:47.307: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999759s
Dec 11 05:28:48.311: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996132108s
Dec 11 05:28:49.314: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992508732s
Dec 11 05:28:50.319: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988735177s
Dec 11 05:28:51.323: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984441958s
Dec 11 05:28:52.326: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.980315094s
Dec 11 05:28:53.330: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977012505s
Dec 11 05:28:54.337: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972760332s
Dec 11 05:28:55.345: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.965573992s
Dec 11 05:28:56.349: INFO: Verifying statefulset ss doesn't scale past 1 for another 958.105726ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1080
Dec 11 05:28:57.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:28:57.717: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:28:57.717: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:28:57.717: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:28:57.721: INFO: Found 1 stateful pods, waiting for 3
Dec 11 05:29:07.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:29:07.726: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:29:07.726: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 11 05:29:07.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:29:08.105: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:29:08.105: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:29:08.105: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:29:08.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:29:08.493: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:29:08.493: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:29:08.493: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:29:08.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 11 05:29:08.790: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 11 05:29:08.790: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 11 05:29:08.790: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 11 05:29:08.790: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:29:08.793: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 11 05:29:18.805: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:29:18.805: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:29:18.805: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 11 05:29:18.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999785s
Dec 11 05:29:19.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99734376s
Dec 11 05:29:20.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994226731s
Dec 11 05:29:21.825: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990987957s
Dec 11 05:29:22.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987418484s
Dec 11 05:29:23.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983221236s
Dec 11 05:29:24.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978957714s
Dec 11 05:29:25.845: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97185538s
Dec 11 05:29:26.849: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968339264s
Dec 11 05:29:27.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.038833ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1080
Dec 11 05:29:28.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:29:29.263: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:29:29.263: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:29:29.263: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:29:29.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:29:29.610: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:29:29.610: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:29:29.610: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:29:29.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 exec --namespace=statefulset-1080 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 11 05:29:29.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 11 05:29:29.922: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 11 05:29:29.922: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 11 05:29:29.922: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 11 05:29:59.939: INFO: Deleting all statefulset in ns statefulset-1080
Dec 11 05:29:59.942: INFO: Scaling statefulset ss to 0
Dec 11 05:29:59.949: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:29:59.951: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:29:59.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1080" for this suite.
Dec 11 05:30:05.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:30:06.049: INFO: namespace statefulset-1080 deletion completed in 6.083224937s

• [SLOW TEST:99.140 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:30:06.056: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 11 05:30:06.089: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:30:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5021" for this suite.
Dec 11 05:30:32.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:30:32.613: INFO: namespace init-container-5021 deletion completed in 22.078516953s

• [SLOW TEST:26.556 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:30:32.614: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-316d203a-0a32-460e-97a4-ad3ebfd745dd
STEP: Creating a pod to test consume configMaps
Dec 11 05:30:32.657: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d" in namespace "projected-1094" to be "success or failure"
Dec 11 05:30:32.660: INFO: Pod "pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.383073ms
Dec 11 05:30:34.663: INFO: Pod "pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005682099s
Dec 11 05:30:36.667: INFO: Pod "pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009253339s
STEP: Saw pod success
Dec 11 05:30:36.667: INFO: Pod "pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d" satisfied condition "success or failure"
Dec 11 05:30:36.669: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:30:36.686: INFO: Waiting for pod pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d to disappear
Dec 11 05:30:36.688: INFO: Pod pod-projected-configmaps-39bb2185-a22f-4f81-bf8f-a78a8b151d4d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:30:36.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1094" for this suite.
Dec 11 05:30:42.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:30:42.769: INFO: namespace projected-1094 deletion completed in 6.076949123s

• [SLOW TEST:10.155 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:30:42.769: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 11 05:30:42.802: INFO: Waiting up to 5m0s for pod "pod-3f68d6fa-a655-4c32-8de3-688f50e254b6" in namespace "emptydir-2699" to be "success or failure"
Dec 11 05:30:42.806: INFO: Pod "pod-3f68d6fa-a655-4c32-8de3-688f50e254b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.649645ms
Dec 11 05:30:44.809: INFO: Pod "pod-3f68d6fa-a655-4c32-8de3-688f50e254b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006752305s
Dec 11 05:30:46.813: INFO: Pod "pod-3f68d6fa-a655-4c32-8de3-688f50e254b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010943015s
STEP: Saw pod success
Dec 11 05:30:46.813: INFO: Pod "pod-3f68d6fa-a655-4c32-8de3-688f50e254b6" satisfied condition "success or failure"
Dec 11 05:30:46.818: INFO: Trying to get logs from node 192.168.5.21 pod pod-3f68d6fa-a655-4c32-8de3-688f50e254b6 container test-container: <nil>
STEP: delete the pod
Dec 11 05:30:46.836: INFO: Waiting for pod pod-3f68d6fa-a655-4c32-8de3-688f50e254b6 to disappear
Dec 11 05:30:46.838: INFO: Pod pod-3f68d6fa-a655-4c32-8de3-688f50e254b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:30:46.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2699" for this suite.
Dec 11 05:30:52.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:30:52.915: INFO: namespace emptydir-2699 deletion completed in 6.073614665s

• [SLOW TEST:10.146 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:30:52.916: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-b95j8 in namespace proxy-5740
I1211 05:30:52.957149      15 runners.go:180] Created replication controller with name: proxy-service-b95j8, namespace: proxy-5740, replica count: 1
I1211 05:30:54.009994      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 05:30:55.010341      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1211 05:30:56.010784      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:30:57.011083      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:30:58.011365      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:30:59.011764      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:31:00.012177      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:31:01.012445      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:31:02.012625      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1211 05:31:03.012909      15 runners.go:180] proxy-service-b95j8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 11 05:31:03.018: INFO: setup took 10.07399889s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 11 05:31:03.036: INFO: (0) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 17.803246ms)
Dec 11 05:31:03.036: INFO: (0) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 17.712045ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 18.233968ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 17.336705ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 17.812352ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 18.076851ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 18.549828ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 19.038308ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 18.256569ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 18.069608ms)
Dec 11 05:31:03.037: INFO: (0) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 18.235842ms)
Dec 11 05:31:03.041: INFO: (0) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 22.353011ms)
Dec 11 05:31:03.046: INFO: (0) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 27.186276ms)
Dec 11 05:31:03.051: INFO: (0) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 31.205398ms)
Dec 11 05:31:03.051: INFO: (0) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 32.704349ms)
Dec 11 05:31:03.055: INFO: (0) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 36.028681ms)
Dec 11 05:31:03.060: INFO: (1) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.992983ms)
Dec 11 05:31:03.063: INFO: (1) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 7.488762ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 11.775184ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 12.296818ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 11.999817ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 11.449638ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 11.971962ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 12.573405ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 11.8364ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 12.197554ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 11.643372ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 11.737807ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 11.847268ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 12.458353ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 12.65473ms)
Dec 11 05:31:03.068: INFO: (1) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 12.852395ms)
Dec 11 05:31:03.074: INFO: (2) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 5.690193ms)
Dec 11 05:31:03.075: INFO: (2) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 7.257404ms)
Dec 11 05:31:03.075: INFO: (2) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.865996ms)
Dec 11 05:31:03.075: INFO: (2) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.827282ms)
Dec 11 05:31:03.075: INFO: (2) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 6.146151ms)
Dec 11 05:31:03.075: INFO: (2) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 6.293855ms)
Dec 11 05:31:03.076: INFO: (2) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.851013ms)
Dec 11 05:31:03.076: INFO: (2) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 7.296814ms)
Dec 11 05:31:03.076: INFO: (2) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 6.401072ms)
Dec 11 05:31:03.076: INFO: (2) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.821889ms)
Dec 11 05:31:03.076: INFO: (2) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.18261ms)
Dec 11 05:31:03.078: INFO: (2) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 8.468855ms)
Dec 11 05:31:03.078: INFO: (2) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.615962ms)
Dec 11 05:31:03.078: INFO: (2) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.757089ms)
Dec 11 05:31:03.078: INFO: (2) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.325383ms)
Dec 11 05:31:03.078: INFO: (2) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 9.562805ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.91209ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 7.770657ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 7.374483ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.341106ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 7.814441ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.521317ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.76542ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 6.896705ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 7.152909ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.410551ms)
Dec 11 05:31:03.086: INFO: (3) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 7.063741ms)
Dec 11 05:31:03.087: INFO: (3) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.010256ms)
Dec 11 05:31:03.087: INFO: (3) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 7.274866ms)
Dec 11 05:31:03.087: INFO: (3) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.357831ms)
Dec 11 05:31:03.087: INFO: (3) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 9.163278ms)
Dec 11 05:31:03.087: INFO: (3) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.472173ms)
Dec 11 05:31:03.092: INFO: (4) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 4.971048ms)
Dec 11 05:31:03.092: INFO: (4) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 4.673938ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.540443ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.586088ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 5.990644ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 5.949403ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 6.327225ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 6.015055ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 6.654155ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 5.852352ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.328805ms)
Dec 11 05:31:03.094: INFO: (4) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 6.183462ms)
Dec 11 05:31:03.096: INFO: (4) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.331102ms)
Dec 11 05:31:03.096: INFO: (4) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.134627ms)
Dec 11 05:31:03.096: INFO: (4) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.289838ms)
Dec 11 05:31:03.096: INFO: (4) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 8.413988ms)
Dec 11 05:31:03.099: INFO: (5) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 2.77863ms)
Dec 11 05:31:03.103: INFO: (5) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 6.493897ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.599765ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.239034ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.15307ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 8.0717ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 7.89866ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 7.622744ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.704145ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 7.571705ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 8.083837ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.460705ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.52087ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.532247ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.96099ms)
Dec 11 05:31:03.105: INFO: (5) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 8.90811ms)
Dec 11 05:31:03.108: INFO: (6) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 2.331925ms)
Dec 11 05:31:03.110: INFO: (6) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 4.270509ms)
Dec 11 05:31:03.111: INFO: (6) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 4.643269ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 6.248711ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 6.386848ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 6.105189ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 6.002612ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.904744ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 6.364799ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 6.832013ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 6.180884ms)
Dec 11 05:31:03.112: INFO: (6) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.62992ms)
Dec 11 05:31:03.113: INFO: (6) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.177533ms)
Dec 11 05:31:03.113: INFO: (6) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 6.587454ms)
Dec 11 05:31:03.113: INFO: (6) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 6.699046ms)
Dec 11 05:31:03.114: INFO: (6) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.886546ms)
Dec 11 05:31:03.118: INFO: (7) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.19381ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.779213ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 6.084399ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 6.479287ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 6.363019ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 6.754182ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.392949ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 5.9881ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.424787ms)
Dec 11 05:31:03.121: INFO: (7) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.553927ms)
Dec 11 05:31:03.122: INFO: (7) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.240543ms)
Dec 11 05:31:03.122: INFO: (7) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.144723ms)
Dec 11 05:31:03.122: INFO: (7) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.345641ms)
Dec 11 05:31:03.123: INFO: (7) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 8.061846ms)
Dec 11 05:31:03.123: INFO: (7) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.296439ms)
Dec 11 05:31:03.123: INFO: (7) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 7.532978ms)
Dec 11 05:31:03.126: INFO: (8) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 2.977761ms)
Dec 11 05:31:03.126: INFO: (8) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 3.409466ms)
Dec 11 05:31:03.128: INFO: (8) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 4.518789ms)
Dec 11 05:31:03.128: INFO: (8) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.161227ms)
Dec 11 05:31:03.128: INFO: (8) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.873511ms)
Dec 11 05:31:03.128: INFO: (8) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.10249ms)
Dec 11 05:31:03.128: INFO: (8) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 5.571939ms)
Dec 11 05:31:03.129: INFO: (8) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 5.915246ms)
Dec 11 05:31:03.129: INFO: (8) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 5.748774ms)
Dec 11 05:31:03.130: INFO: (8) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 5.991179ms)
Dec 11 05:31:03.130: INFO: (8) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 6.032615ms)
Dec 11 05:31:03.133: INFO: (8) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 9.263606ms)
Dec 11 05:31:03.133: INFO: (8) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 9.374808ms)
Dec 11 05:31:03.133: INFO: (8) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 9.535319ms)
Dec 11 05:31:03.133: INFO: (8) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 9.338862ms)
Dec 11 05:31:03.133: INFO: (8) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 9.53632ms)
Dec 11 05:31:03.138: INFO: (9) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 4.71981ms)
Dec 11 05:31:03.138: INFO: (9) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 4.548833ms)
Dec 11 05:31:03.138: INFO: (9) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 4.543573ms)
Dec 11 05:31:03.138: INFO: (9) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 4.967064ms)
Dec 11 05:31:03.139: INFO: (9) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 5.517685ms)
Dec 11 05:31:03.139: INFO: (9) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.628835ms)
Dec 11 05:31:03.139: INFO: (9) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.801608ms)
Dec 11 05:31:03.139: INFO: (9) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 5.745859ms)
Dec 11 05:31:03.139: INFO: (9) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 6.182865ms)
Dec 11 05:31:03.140: INFO: (9) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 6.191735ms)
Dec 11 05:31:03.140: INFO: (9) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.174742ms)
Dec 11 05:31:03.140: INFO: (9) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.186429ms)
Dec 11 05:31:03.140: INFO: (9) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 6.833759ms)
Dec 11 05:31:03.142: INFO: (9) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.122774ms)
Dec 11 05:31:03.142: INFO: (9) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.13182ms)
Dec 11 05:31:03.142: INFO: (9) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.243964ms)
Dec 11 05:31:03.146: INFO: (10) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 3.482323ms)
Dec 11 05:31:03.146: INFO: (10) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.184587ms)
Dec 11 05:31:03.146: INFO: (10) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 4.020221ms)
Dec 11 05:31:03.148: INFO: (10) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 5.568778ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.85467ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 6.877643ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.012282ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.680745ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 7.205471ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 7.485638ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 7.282203ms)
Dec 11 05:31:03.150: INFO: (10) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.176115ms)
Dec 11 05:31:03.153: INFO: (10) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 9.717731ms)
Dec 11 05:31:03.153: INFO: (10) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 9.521572ms)
Dec 11 05:31:03.153: INFO: (10) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 9.925827ms)
Dec 11 05:31:03.153: INFO: (10) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 10.171314ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 15.064156ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 15.941475ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 16.062074ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 15.357531ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 15.70676ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 16.292306ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 15.302747ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 15.416314ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 15.495891ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 15.904622ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 16.323687ms)
Dec 11 05:31:03.169: INFO: (11) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 15.432308ms)
Dec 11 05:31:03.170: INFO: (11) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 15.769681ms)
Dec 11 05:31:03.170: INFO: (11) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 15.785382ms)
Dec 11 05:31:03.170: INFO: (11) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 16.428053ms)
Dec 11 05:31:03.170: INFO: (11) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 16.036308ms)
Dec 11 05:31:03.176: INFO: (12) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 5.891872ms)
Dec 11 05:31:03.176: INFO: (12) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.666425ms)
Dec 11 05:31:03.176: INFO: (12) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.859314ms)
Dec 11 05:31:03.176: INFO: (12) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 6.018803ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 6.382261ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.969972ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 6.155346ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 6.181114ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 6.313105ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 6.621549ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 6.86552ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 6.336019ms)
Dec 11 05:31:03.177: INFO: (12) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.234316ms)
Dec 11 05:31:03.178: INFO: (12) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.225161ms)
Dec 11 05:31:03.178: INFO: (12) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.232558ms)
Dec 11 05:31:03.178: INFO: (12) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 7.388886ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 5.837998ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 5.364577ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.629317ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.408665ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.798714ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.859418ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 5.970518ms)
Dec 11 05:31:03.184: INFO: (13) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 5.952881ms)
Dec 11 05:31:03.185: INFO: (13) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 5.790215ms)
Dec 11 05:31:03.187: INFO: (13) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 8.455603ms)
Dec 11 05:31:03.187: INFO: (13) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.69776ms)
Dec 11 05:31:03.187: INFO: (13) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.813226ms)
Dec 11 05:31:03.187: INFO: (13) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 8.684553ms)
Dec 11 05:31:03.188: INFO: (13) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 9.191682ms)
Dec 11 05:31:03.188: INFO: (13) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 9.02567ms)
Dec 11 05:31:03.188: INFO: (13) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 9.04163ms)
Dec 11 05:31:03.191: INFO: (14) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 2.990931ms)
Dec 11 05:31:03.193: INFO: (14) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 4.617624ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 5.416284ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.702496ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 5.513899ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 5.46312ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 6.422846ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 5.820152ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 6.187274ms)
Dec 11 05:31:03.194: INFO: (14) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.563668ms)
Dec 11 05:31:03.196: INFO: (14) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 7.218305ms)
Dec 11 05:31:03.196: INFO: (14) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.657381ms)
Dec 11 05:31:03.196: INFO: (14) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.771565ms)
Dec 11 05:31:03.197: INFO: (14) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.103266ms)
Dec 11 05:31:03.197: INFO: (14) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.084597ms)
Dec 11 05:31:03.197: INFO: (14) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 7.971664ms)
Dec 11 05:31:03.201: INFO: (15) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 4.2432ms)
Dec 11 05:31:03.202: INFO: (15) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 4.897238ms)
Dec 11 05:31:03.202: INFO: (15) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 4.848422ms)
Dec 11 05:31:03.202: INFO: (15) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 4.109478ms)
Dec 11 05:31:03.202: INFO: (15) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 4.851012ms)
Dec 11 05:31:03.203: INFO: (15) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 4.439081ms)
Dec 11 05:31:03.203: INFO: (15) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 4.602061ms)
Dec 11 05:31:03.203: INFO: (15) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.341167ms)
Dec 11 05:31:03.203: INFO: (15) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.094394ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 6.833927ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 7.690163ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.954807ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 7.711887ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.255655ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 6.579191ms)
Dec 11 05:31:03.205: INFO: (15) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 7.254903ms)
Dec 11 05:31:03.208: INFO: (16) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 2.846888ms)
Dec 11 05:31:03.209: INFO: (16) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 3.191412ms)
Dec 11 05:31:03.209: INFO: (16) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 3.391528ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 4.530114ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 4.724904ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 4.944183ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 4.586333ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 5.90447ms)
Dec 11 05:31:03.211: INFO: (16) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.661906ms)
Dec 11 05:31:03.212: INFO: (16) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 4.959853ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 6.608744ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 7.400999ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 7.713454ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 6.133437ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.169464ms)
Dec 11 05:31:03.213: INFO: (16) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.017729ms)
Dec 11 05:31:03.217: INFO: (17) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 3.481375ms)
Dec 11 05:31:03.217: INFO: (17) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 3.633843ms)
Dec 11 05:31:03.218: INFO: (17) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 4.613531ms)
Dec 11 05:31:03.219: INFO: (17) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 5.997481ms)
Dec 11 05:31:03.219: INFO: (17) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 5.852732ms)
Dec 11 05:31:03.219: INFO: (17) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.680499ms)
Dec 11 05:31:03.219: INFO: (17) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 5.906606ms)
Dec 11 05:31:03.219: INFO: (17) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 5.70035ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 6.286396ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 5.879882ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.967236ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 5.711339ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 5.993329ms)
Dec 11 05:31:03.220: INFO: (17) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 5.903511ms)
Dec 11 05:31:03.223: INFO: (17) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 8.680287ms)
Dec 11 05:31:03.223: INFO: (17) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 8.672463ms)
Dec 11 05:31:03.228: INFO: (18) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 5.101385ms)
Dec 11 05:31:03.228: INFO: (18) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 4.933954ms)
Dec 11 05:31:03.228: INFO: (18) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 5.108808ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 7.322415ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 6.753091ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 7.035524ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 7.387572ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 7.731192ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.709743ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 7.46572ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.211743ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.216279ms)
Dec 11 05:31:03.231: INFO: (18) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 7.514182ms)
Dec 11 05:31:03.232: INFO: (18) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 8.159229ms)
Dec 11 05:31:03.232: INFO: (18) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 8.247339ms)
Dec 11 05:31:03.232: INFO: (18) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 9.128154ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname1/proxy/: tls baz (200; 7.388231ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.993813ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.416543ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:160/proxy/: foo (200; 7.888656ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9:1080/proxy/rewriteme">test<... (200; 8.044546ms)
Dec 11 05:31:03.240: INFO: (19) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname2/proxy/: bar (200; 7.863864ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/proxy-service-b95j8-46mv9/proxy/rewriteme">test</a> (200; 7.405713ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:443/proxy/tlsrewritem... (200; 7.496841ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:462/proxy/: tls qux (200; 7.658616ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/https:proxy-service-b95j8-46mv9:460/proxy/: tls baz (200; 7.673624ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/: <a href="/api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:1080/proxy/rewriteme">... (200; 7.62448ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/pods/http:proxy-service-b95j8-46mv9:162/proxy/: bar (200; 7.925516ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/services/proxy-service-b95j8:portname1/proxy/: foo (200; 7.92084ms)
Dec 11 05:31:03.241: INFO: (19) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname1/proxy/: foo (200; 8.240197ms)
Dec 11 05:31:03.245: INFO: (19) /api/v1/namespaces/proxy-5740/services/http:proxy-service-b95j8:portname2/proxy/: bar (200; 12.080269ms)
Dec 11 05:31:03.245: INFO: (19) /api/v1/namespaces/proxy-5740/services/https:proxy-service-b95j8:tlsportname2/proxy/: tls qux (200; 12.396453ms)
STEP: deleting ReplicationController proxy-service-b95j8 in namespace proxy-5740, will wait for the garbage collector to delete the pods
Dec 11 05:31:03.307: INFO: Deleting ReplicationController proxy-service-b95j8 took: 8.943414ms
Dec 11 05:31:03.707: INFO: Terminating ReplicationController proxy-service-b95j8 pods took: 400.178441ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:31:12.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5740" for this suite.
Dec 11 05:31:18.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:31:18.088: INFO: namespace proxy-5740 deletion completed in 6.07597979s

• [SLOW TEST:25.173 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:31:18.093: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 11 05:31:26.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:26.153: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:28.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:28.156: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:30.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:30.160: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:32.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:32.157: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:34.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:34.156: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:36.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:36.157: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:38.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:38.157: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:40.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:40.158: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:42.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:42.157: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 11 05:31:44.153: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 11 05:31:44.156: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:31:44.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-419" for this suite.
Dec 11 05:32:06.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:32:06.247: INFO: namespace container-lifecycle-hook-419 deletion completed in 22.079105002s

• [SLOW TEST:48.154 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:32:06.254: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5875, will wait for the garbage collector to delete the pods
Dec 11 05:32:10.349: INFO: Deleting Job.batch foo took: 4.710955ms
Dec 11 05:32:10.753: INFO: Terminating Job.batch foo pods took: 403.557753ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:32:53.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5875" for this suite.
Dec 11 05:32:59.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:32:59.446: INFO: namespace job-5875 deletion completed in 6.085848919s

• [SLOW TEST:53.196 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:32:59.455: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:32:59.486: INFO: Waiting up to 5m0s for pod "downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1" in namespace "projected-4268" to be "success or failure"
Dec 11 05:32:59.489: INFO: Pod "downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738693ms
Dec 11 05:33:01.493: INFO: Pod "downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006382681s
Dec 11 05:33:03.502: INFO: Pod "downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015873763s
STEP: Saw pod success
Dec 11 05:33:03.502: INFO: Pod "downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1" satisfied condition "success or failure"
Dec 11 05:33:03.510: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1 container client-container: <nil>
STEP: delete the pod
Dec 11 05:33:03.544: INFO: Waiting for pod downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1 to disappear
Dec 11 05:33:03.553: INFO: Pod downwardapi-volume-549c648b-d73f-4faf-9362-d9d07ff86ca1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:33:03.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4268" for this suite.
Dec 11 05:33:09.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:33:09.634: INFO: namespace projected-4268 deletion completed in 6.075802066s

• [SLOW TEST:10.185 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:33:09.645: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-kr9d
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 05:33:09.680: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kr9d" in namespace "subpath-3745" to be "success or failure"
Dec 11 05:33:09.686: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.57927ms
Dec 11 05:33:11.696: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015838086s
Dec 11 05:33:13.702: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 4.021147417s
Dec 11 05:33:15.705: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 6.024550878s
Dec 11 05:33:17.709: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 8.028245452s
Dec 11 05:33:19.714: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 10.033507797s
Dec 11 05:33:21.719: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 12.038089262s
Dec 11 05:33:23.722: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 14.041724029s
Dec 11 05:33:25.725: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 16.044844154s
Dec 11 05:33:27.728: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 18.048046013s
Dec 11 05:33:29.734: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 20.053315141s
Dec 11 05:33:31.737: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Running", Reason="", readiness=true. Elapsed: 22.056534609s
Dec 11 05:33:33.741: INFO: Pod "pod-subpath-test-configmap-kr9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060609717s
STEP: Saw pod success
Dec 11 05:33:33.741: INFO: Pod "pod-subpath-test-configmap-kr9d" satisfied condition "success or failure"
Dec 11 05:33:33.743: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-configmap-kr9d container test-container-subpath-configmap-kr9d: <nil>
STEP: delete the pod
Dec 11 05:33:33.765: INFO: Waiting for pod pod-subpath-test-configmap-kr9d to disappear
Dec 11 05:33:33.767: INFO: Pod pod-subpath-test-configmap-kr9d no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kr9d
Dec 11 05:33:33.767: INFO: Deleting pod "pod-subpath-test-configmap-kr9d" in namespace "subpath-3745"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:33:33.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3745" for this suite.
Dec 11 05:33:39.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:33:39.859: INFO: namespace subpath-3745 deletion completed in 6.085136655s

• [SLOW TEST:30.214 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:33:39.867: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 11 05:33:39.896: INFO: Waiting up to 5m0s for pod "pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f" in namespace "emptydir-8087" to be "success or failure"
Dec 11 05:33:39.898: INFO: Pod "pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342345ms
Dec 11 05:33:41.901: INFO: Pod "pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005316961s
Dec 11 05:33:43.905: INFO: Pod "pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009073269s
STEP: Saw pod success
Dec 11 05:33:43.905: INFO: Pod "pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f" satisfied condition "success or failure"
Dec 11 05:33:43.907: INFO: Trying to get logs from node 192.168.5.21 pod pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f container test-container: <nil>
STEP: delete the pod
Dec 11 05:33:43.935: INFO: Waiting for pod pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f to disappear
Dec 11 05:33:43.941: INFO: Pod pod-8cb98a5d-2c62-4c1a-8034-1a24eb2c0b0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:33:43.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8087" for this suite.
Dec 11 05:33:49.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:33:50.018: INFO: namespace emptydir-8087 deletion completed in 6.073944884s

• [SLOW TEST:10.151 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:33:50.020: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:33:50.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-5722'
Dec 11 05:33:50.325: INFO: stderr: ""
Dec 11 05:33:50.325: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 11 05:33:50.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-5722'
Dec 11 05:33:50.592: INFO: stderr: ""
Dec 11 05:33:50.592: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 11 05:33:51.596: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:33:51.596: INFO: Found 0 / 1
Dec 11 05:33:52.596: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:33:52.596: INFO: Found 0 / 1
Dec 11 05:33:53.596: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:33:53.596: INFO: Found 1 / 1
Dec 11 05:33:53.596: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 11 05:33:53.603: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:33:53.603: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 11 05:33:53.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 describe pod redis-master-7mlbm --namespace=kubectl-5722'
Dec 11 05:33:53.729: INFO: stderr: ""
Dec 11 05:33:53.729: INFO: stdout: "Name:           redis-master-7mlbm\nNamespace:      kubectl-5722\nNode:           192.168.5.21/192.168.5.21\nStart Time:     Wed, 11 Dec 2019 05:33:50 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.8.2.174\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://034a4df63e08e991b91f9790d96680e9d434d9cac98e2214ed23881cda7c3508\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 11 Dec 2019 05:33:51 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7jjgl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7jjgl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7jjgl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned kubectl-5722/redis-master-7mlbm to 192.168.5.21\n  Normal  Pulled     2s    kubelet, 192.168.5.21  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 192.168.5.21  Created container redis-master\n  Normal  Started    2s    kubelet, 192.168.5.21  Started container redis-master\n"
Dec 11 05:33:53.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 describe rc redis-master --namespace=kubectl-5722'
Dec 11 05:33:53.852: INFO: stderr: ""
Dec 11 05:33:53.852: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5722\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-7mlbm\n"
Dec 11 05:33:53.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 describe service redis-master --namespace=kubectl-5722'
Dec 11 05:33:53.986: INFO: stderr: ""
Dec 11 05:33:53.986: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5722\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.60.19\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.8.2.174:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 11 05:33:53.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 describe node 192.168.5.11'
Dec 11 05:33:54.114: INFO: stderr: ""
Dec 11 05:33:54.114: INFO: stdout: "Name:               192.168.5.11\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-east-1\n                    failure-domain.beta.kubernetes.io/zone=eu-east-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.5.11\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: null\n                    flannel.alpha.coreos.com/backend-type: \n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.5.11\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 10 Dec 2019 03:22:36 +0000\nTaints:             dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 11 Dec 2019 05:33:45 +0000   Tue, 10 Dec 2019 03:22:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 11 Dec 2019 05:33:45 +0000   Tue, 10 Dec 2019 03:22:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 11 Dec 2019 05:33:45 +0000   Tue, 10 Dec 2019 03:22:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 11 Dec 2019 05:33:45 +0000   Tue, 10 Dec 2019 03:23:16 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.5.11\n  Hostname:    192.168.5.11\nCapacity:\n cpu:                4\n ephemeral-storage:  20509308Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8168012Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  18901378222\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8065612Ki\n pods:               110\nSystem Info:\n Machine ID:                 ad51b672e83841f5afad0520a4857197\n System UUID:                2B683CB5-B5F8-41EE-BB01-23540628D767\n Boot ID:                    acf327b1-9f36-41b6-a89b-93724bc1a4da\n Kernel Version:             4.15.0-29-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.5\n Kubelet Version:            v1.15.5\n Kube-Proxy Version:         v1.15.5\nPodCIDR:                     10.8.3.0/24\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                cloud-controller-manager-54c4664c9d-jdvpg                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                etcd-192.168.5.11                                          300m (7%)     0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                eventetcd-192.168.5.11                                     300m (7%)     0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                ksc-flexvolume-ds-jrmhj                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                ksc-node-exporter-mvgwg                                    10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      26h\n  kube-system                kube-apiserver-192.168.5.11                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         20h\n  kube-system                kube-controller-manager-192.168.5.11                       200m (5%)     0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                kube-flannel-smllx                                         150m (3%)     300m (7%)   64M (0%)         500M (6%)      26h\n  kube-system                kube-proxy-8c2l6                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         26h\n  kube-system                kube-scheduler-192.168.5.11                                100m (2%)     0 (0%)      0 (0%)           0 (0%)         26h\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-f3a8f6003e544e1f-fpvgm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                1310m (32%)    310m (7%)\n  memory             113700Ki (1%)  552428800 (6%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Dec 11 05:33:54.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 describe namespace kubectl-5722'
Dec 11 05:33:54.228: INFO: stderr: ""
Dec 11 05:33:54.228: INFO: stdout: "Name:         kubectl-5722\nLabels:       e2e-framework=kubectl\n              e2e-run=1c888cf5-ac0a-43f0-ae72-9d7450ea012b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:33:54.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5722" for this suite.
Dec 11 05:34:16.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:34:16.316: INFO: namespace kubectl-5722 deletion completed in 22.081644202s

• [SLOW TEST:26.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:34:16.318: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 11 05:34:16.362: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-601,SelfLink:/api/v1/namespaces/watch-601/configmaps/e2e-watch-test-watch-closed,UID:c7e7fbd3-c9f0-4ed6-ab7d-1f0908e9ae88,ResourceVersion:171995,Generation:0,CreationTimestamp:2019-12-11 05:34:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 05:34:16.362: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-601,SelfLink:/api/v1/namespaces/watch-601/configmaps/e2e-watch-test-watch-closed,UID:c7e7fbd3-c9f0-4ed6-ab7d-1f0908e9ae88,ResourceVersion:171996,Generation:0,CreationTimestamp:2019-12-11 05:34:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 11 05:34:16.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-601,SelfLink:/api/v1/namespaces/watch-601/configmaps/e2e-watch-test-watch-closed,UID:c7e7fbd3-c9f0-4ed6-ab7d-1f0908e9ae88,ResourceVersion:171997,Generation:0,CreationTimestamp:2019-12-11 05:34:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 05:34:16.373: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-601,SelfLink:/api/v1/namespaces/watch-601/configmaps/e2e-watch-test-watch-closed,UID:c7e7fbd3-c9f0-4ed6-ab7d-1f0908e9ae88,ResourceVersion:171998,Generation:0,CreationTimestamp:2019-12-11 05:34:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:34:16.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-601" for this suite.
Dec 11 05:34:22.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:34:22.466: INFO: namespace watch-601 deletion completed in 6.08962058s

• [SLOW TEST:6.147 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:34:22.466: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:34:22.499: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382" in namespace "downward-api-8637" to be "success or failure"
Dec 11 05:34:22.502: INFO: Pod "downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382": Phase="Pending", Reason="", readiness=false. Elapsed: 2.884615ms
Dec 11 05:34:24.505: INFO: Pod "downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006421436s
Dec 11 05:34:26.509: INFO: Pod "downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010472642s
STEP: Saw pod success
Dec 11 05:34:26.509: INFO: Pod "downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382" satisfied condition "success or failure"
Dec 11 05:34:26.512: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382 container client-container: <nil>
STEP: delete the pod
Dec 11 05:34:26.528: INFO: Waiting for pod downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382 to disappear
Dec 11 05:34:26.530: INFO: Pod downwardapi-volume-1c097636-9f21-4971-b215-6c385f848382 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:34:26.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8637" for this suite.
Dec 11 05:34:32.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:34:32.612: INFO: namespace downward-api-8637 deletion completed in 6.079089615s

• [SLOW TEST:10.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:34:32.615: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7b2210eb-5ede-4460-ac79-72071f1cfc62
STEP: Creating a pod to test consume configMaps
Dec 11 05:34:32.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177" in namespace "configmap-8268" to be "success or failure"
Dec 11 05:34:32.650: INFO: Pod "pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109053ms
Dec 11 05:34:34.654: INFO: Pod "pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006362734s
Dec 11 05:34:36.657: INFO: Pod "pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009794125s
STEP: Saw pod success
Dec 11 05:34:36.657: INFO: Pod "pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177" satisfied condition "success or failure"
Dec 11 05:34:36.659: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:34:36.676: INFO: Waiting for pod pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177 to disappear
Dec 11 05:34:36.678: INFO: Pod pod-configmaps-113a90a6-784c-4ec9-a2cd-f2f05bdc9177 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:34:36.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8268" for this suite.
Dec 11 05:34:42.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:34:42.756: INFO: namespace configmap-8268 deletion completed in 6.074347085s

• [SLOW TEST:10.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:34:42.756: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Dec 11 05:34:42.785: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3561" to be "success or failure"
Dec 11 05:34:42.787: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.147721ms
Dec 11 05:34:44.790: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005388554s
Dec 11 05:34:46.795: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009682534s
STEP: Saw pod success
Dec 11 05:34:46.795: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 11 05:34:46.797: INFO: Trying to get logs from node 192.168.5.23 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 11 05:34:46.812: INFO: Waiting for pod pod-host-path-test to disappear
Dec 11 05:34:46.814: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:34:46.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3561" for this suite.
Dec 11 05:34:52.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:34:52.891: INFO: namespace hostpath-3561 deletion completed in 6.073704591s

• [SLOW TEST:10.135 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:34:52.893: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 11 05:34:52.924: INFO: Waiting up to 5m0s for pod "pod-69c07cea-e1e6-4074-9173-f16e386d910c" in namespace "emptydir-697" to be "success or failure"
Dec 11 05:34:52.927: INFO: Pod "pod-69c07cea-e1e6-4074-9173-f16e386d910c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.532476ms
Dec 11 05:34:54.930: INFO: Pod "pod-69c07cea-e1e6-4074-9173-f16e386d910c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006021751s
Dec 11 05:34:56.934: INFO: Pod "pod-69c07cea-e1e6-4074-9173-f16e386d910c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009496426s
STEP: Saw pod success
Dec 11 05:34:56.934: INFO: Pod "pod-69c07cea-e1e6-4074-9173-f16e386d910c" satisfied condition "success or failure"
Dec 11 05:34:56.936: INFO: Trying to get logs from node 192.168.5.21 pod pod-69c07cea-e1e6-4074-9173-f16e386d910c container test-container: <nil>
STEP: delete the pod
Dec 11 05:34:56.956: INFO: Waiting for pod pod-69c07cea-e1e6-4074-9173-f16e386d910c to disappear
Dec 11 05:34:56.958: INFO: Pod pod-69c07cea-e1e6-4074-9173-f16e386d910c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:34:56.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-697" for this suite.
Dec 11 05:35:02.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:35:03.042: INFO: namespace emptydir-697 deletion completed in 6.080351532s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:35:03.046: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-2648ac5c-6c23-428c-a925-43698bf49aea
STEP: Creating a pod to test consume secrets
Dec 11 05:35:03.081: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6" in namespace "projected-4361" to be "success or failure"
Dec 11 05:35:03.083: INFO: Pod "pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.952191ms
Dec 11 05:35:05.086: INFO: Pod "pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004674481s
Dec 11 05:35:07.092: INFO: Pod "pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011200165s
STEP: Saw pod success
Dec 11 05:35:07.092: INFO: Pod "pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6" satisfied condition "success or failure"
Dec 11 05:35:07.094: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:35:07.112: INFO: Waiting for pod pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6 to disappear
Dec 11 05:35:07.114: INFO: Pod pod-projected-secrets-490f0a8b-1c87-4e4d-9747-385e8ed7e9e6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:35:07.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4361" for this suite.
Dec 11 05:35:13.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:35:13.192: INFO: namespace projected-4361 deletion completed in 6.073993274s

• [SLOW TEST:10.146 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:35:13.193: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9653
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9653
STEP: Creating statefulset with conflicting port in namespace statefulset-9653
STEP: Waiting until pod test-pod will start running in namespace statefulset-9653
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9653
Dec 11 05:35:17.258: INFO: Observed stateful pod in namespace: statefulset-9653, name: ss-0, uid: 53332009-58a4-44bb-a16f-f2eb22745074, status phase: Pending. Waiting for statefulset controller to delete.
Dec 11 05:35:17.643: INFO: Observed stateful pod in namespace: statefulset-9653, name: ss-0, uid: 53332009-58a4-44bb-a16f-f2eb22745074, status phase: Failed. Waiting for statefulset controller to delete.
Dec 11 05:35:17.649: INFO: Observed stateful pod in namespace: statefulset-9653, name: ss-0, uid: 53332009-58a4-44bb-a16f-f2eb22745074, status phase: Failed. Waiting for statefulset controller to delete.
Dec 11 05:35:17.652: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9653
STEP: Removing pod with conflicting port in namespace statefulset-9653
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9653 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 11 05:35:21.671: INFO: Deleting all statefulset in ns statefulset-9653
Dec 11 05:35:21.673: INFO: Scaling statefulset ss to 0
Dec 11 05:35:41.687: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:35:41.694: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:35:41.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9653" for this suite.
Dec 11 05:35:47.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:35:47.783: INFO: namespace statefulset-9653 deletion completed in 6.075275042s

• [SLOW TEST:34.591 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:35:47.788: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 11 05:35:53.884: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:35:53.887: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:35:55.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:35:55.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:35:57.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:35:57.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:35:59.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:35:59.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:01.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:01.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:03.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:03.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:05.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:05.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:07.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:07.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:09.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:09.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:11.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:11.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:13.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:13.894: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:15.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:15.891: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:17.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:17.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:19.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:19.893: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:21.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:21.890: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 11 05:36:23.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 11 05:36:23.897: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:36:23.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6992" for this suite.
Dec 11 05:36:45.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:36:46.003: INFO: namespace container-lifecycle-hook-6992 deletion completed in 22.101824383s

• [SLOW TEST:58.216 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:36:46.005: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 11 05:36:46.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-3360'
Dec 11 05:36:46.284: INFO: stderr: ""
Dec 11 05:36:46.284: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:36:46.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:36:46.399: INFO: stderr: ""
Dec 11 05:36:46.399: INFO: stdout: "update-demo-nautilus-np9hl update-demo-nautilus-sr5cb "
Dec 11 05:36:46.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-np9hl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:46.508: INFO: stderr: ""
Dec 11 05:36:46.508: INFO: stdout: ""
Dec 11 05:36:46.508: INFO: update-demo-nautilus-np9hl is created but not running
Dec 11 05:36:51.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:36:51.616: INFO: stderr: ""
Dec 11 05:36:51.617: INFO: stdout: "update-demo-nautilus-np9hl update-demo-nautilus-sr5cb "
Dec 11 05:36:51.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-np9hl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:51.710: INFO: stderr: ""
Dec 11 05:36:51.710: INFO: stdout: "true"
Dec 11 05:36:51.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-np9hl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:51.801: INFO: stderr: ""
Dec 11 05:36:51.801: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:36:51.801: INFO: validating pod update-demo-nautilus-np9hl
Dec 11 05:36:51.806: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:36:51.806: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:36:51.806: INFO: update-demo-nautilus-np9hl is verified up and running
Dec 11 05:36:51.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:51.898: INFO: stderr: ""
Dec 11 05:36:51.898: INFO: stdout: "true"
Dec 11 05:36:51.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:52.005: INFO: stderr: ""
Dec 11 05:36:52.005: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:36:52.005: INFO: validating pod update-demo-nautilus-sr5cb
Dec 11 05:36:52.010: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:36:52.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:36:52.010: INFO: update-demo-nautilus-sr5cb is verified up and running
STEP: scaling down the replication controller
Dec 11 05:36:52.016: INFO: scanned /root for discovery docs: <nil>
Dec 11 05:36:52.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3360'
Dec 11 05:36:53.151: INFO: stderr: ""
Dec 11 05:36:53.151: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:36:53.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:36:53.263: INFO: stderr: ""
Dec 11 05:36:53.263: INFO: stdout: "update-demo-nautilus-np9hl update-demo-nautilus-sr5cb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 11 05:36:58.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:36:58.374: INFO: stderr: ""
Dec 11 05:36:58.374: INFO: stdout: "update-demo-nautilus-sr5cb "
Dec 11 05:36:58.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:58.476: INFO: stderr: ""
Dec 11 05:36:58.476: INFO: stdout: "true"
Dec 11 05:36:58.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:36:58.606: INFO: stderr: ""
Dec 11 05:36:58.606: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:36:58.607: INFO: validating pod update-demo-nautilus-sr5cb
Dec 11 05:36:58.621: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:36:58.621: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:36:58.621: INFO: update-demo-nautilus-sr5cb is verified up and running
STEP: scaling up the replication controller
Dec 11 05:36:58.624: INFO: scanned /root for discovery docs: <nil>
Dec 11 05:36:58.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3360'
Dec 11 05:36:59.757: INFO: stderr: ""
Dec 11 05:36:59.757: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:36:59.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:36:59.911: INFO: stderr: ""
Dec 11 05:36:59.911: INFO: stdout: "update-demo-nautilus-fgbfz update-demo-nautilus-sr5cb "
Dec 11 05:36:59.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-fgbfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:37:00.072: INFO: stderr: ""
Dec 11 05:37:00.072: INFO: stdout: ""
Dec 11 05:37:00.072: INFO: update-demo-nautilus-fgbfz is created but not running
Dec 11 05:37:05.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3360'
Dec 11 05:37:05.182: INFO: stderr: ""
Dec 11 05:37:05.182: INFO: stdout: "update-demo-nautilus-fgbfz update-demo-nautilus-sr5cb "
Dec 11 05:37:05.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-fgbfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:37:05.294: INFO: stderr: ""
Dec 11 05:37:05.294: INFO: stdout: "true"
Dec 11 05:37:05.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-fgbfz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:37:05.397: INFO: stderr: ""
Dec 11 05:37:05.397: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:37:05.397: INFO: validating pod update-demo-nautilus-fgbfz
Dec 11 05:37:05.406: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:37:05.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:37:05.406: INFO: update-demo-nautilus-fgbfz is verified up and running
Dec 11 05:37:05.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:37:05.509: INFO: stderr: ""
Dec 11 05:37:05.509: INFO: stdout: "true"
Dec 11 05:37:05.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-sr5cb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3360'
Dec 11 05:37:05.635: INFO: stderr: ""
Dec 11 05:37:05.635: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:37:05.635: INFO: validating pod update-demo-nautilus-sr5cb
Dec 11 05:37:05.640: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:37:05.640: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:37:05.640: INFO: update-demo-nautilus-sr5cb is verified up and running
STEP: using delete to clean up resources
Dec 11 05:37:05.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-3360'
Dec 11 05:37:05.739: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 05:37:05.739: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 11 05:37:05.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3360'
Dec 11 05:37:05.843: INFO: stderr: "No resources found.\n"
Dec 11 05:37:05.843: INFO: stdout: ""
Dec 11 05:37:05.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=update-demo --namespace=kubectl-3360 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:37:05.960: INFO: stderr: ""
Dec 11 05:37:05.960: INFO: stdout: "update-demo-nautilus-fgbfz\nupdate-demo-nautilus-sr5cb\n"
Dec 11 05:37:06.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3360'
Dec 11 05:37:06.623: INFO: stderr: "No resources found.\n"
Dec 11 05:37:06.623: INFO: stdout: ""
Dec 11 05:37:06.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=update-demo --namespace=kubectl-3360 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:37:06.713: INFO: stderr: ""
Dec 11 05:37:06.713: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:37:06.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3360" for this suite.
Dec 11 05:37:12.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:37:12.794: INFO: namespace kubectl-3360 deletion completed in 6.075923846s

• [SLOW TEST:26.789 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:37:12.795: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 11 05:37:12.831: INFO: Waiting up to 5m0s for pod "pod-2a584187-b912-4d3a-abf2-f23f26ea366a" in namespace "emptydir-6224" to be "success or failure"
Dec 11 05:37:12.835: INFO: Pod "pod-2a584187-b912-4d3a-abf2-f23f26ea366a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246916ms
Dec 11 05:37:14.839: INFO: Pod "pod-2a584187-b912-4d3a-abf2-f23f26ea366a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007788806s
Dec 11 05:37:16.846: INFO: Pod "pod-2a584187-b912-4d3a-abf2-f23f26ea366a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01505109s
STEP: Saw pod success
Dec 11 05:37:16.846: INFO: Pod "pod-2a584187-b912-4d3a-abf2-f23f26ea366a" satisfied condition "success or failure"
Dec 11 05:37:16.849: INFO: Trying to get logs from node 192.168.5.21 pod pod-2a584187-b912-4d3a-abf2-f23f26ea366a container test-container: <nil>
STEP: delete the pod
Dec 11 05:37:16.873: INFO: Waiting for pod pod-2a584187-b912-4d3a-abf2-f23f26ea366a to disappear
Dec 11 05:37:16.878: INFO: Pod pod-2a584187-b912-4d3a-abf2-f23f26ea366a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:37:16.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6224" for this suite.
Dec 11 05:37:22.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:37:22.958: INFO: namespace emptydir-6224 deletion completed in 6.076991263s

• [SLOW TEST:10.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:37:22.959: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-4663ec85-472e-4cf5-8343-61278cb9f46e
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:37:22.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2758" for this suite.
Dec 11 05:37:28.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:37:29.063: INFO: namespace configmap-2758 deletion completed in 6.072580255s

• [SLOW TEST:6.104 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:37:29.063: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 11 05:37:29.150: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172567,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 11 05:37:29.151: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172568,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 11 05:37:29.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172569,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 11 05:37:39.185: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172586,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 05:37:39.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172587,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 11 05:37:39.186: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-983,SelfLink:/api/v1/namespaces/watch-983/configmaps/e2e-watch-test-label-changed,UID:b652bbce-90c3-442b-885f-bd698a71cf40,ResourceVersion:172588,Generation:0,CreationTimestamp:2019-12-11 05:37:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:37:39.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-983" for this suite.
Dec 11 05:37:45.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:37:45.279: INFO: namespace watch-983 deletion completed in 6.088059376s

• [SLOW TEST:16.216 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:37:45.280: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 11 05:37:45.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-3242'
Dec 11 05:37:45.623: INFO: stderr: ""
Dec 11 05:37:45.623: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 11 05:37:45.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3242'
Dec 11 05:37:45.750: INFO: stderr: ""
Dec 11 05:37:45.750: INFO: stdout: "update-demo-nautilus-88phj update-demo-nautilus-ldg6b "
Dec 11 05:37:45.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-88phj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3242'
Dec 11 05:37:45.873: INFO: stderr: ""
Dec 11 05:37:45.873: INFO: stdout: ""
Dec 11 05:37:45.873: INFO: update-demo-nautilus-88phj is created but not running
Dec 11 05:37:50.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3242'
Dec 11 05:37:50.986: INFO: stderr: ""
Dec 11 05:37:50.986: INFO: stdout: "update-demo-nautilus-88phj update-demo-nautilus-ldg6b "
Dec 11 05:37:50.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-88phj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3242'
Dec 11 05:37:51.082: INFO: stderr: ""
Dec 11 05:37:51.082: INFO: stdout: "true"
Dec 11 05:37:51.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-88phj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3242'
Dec 11 05:37:51.183: INFO: stderr: ""
Dec 11 05:37:51.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:37:51.183: INFO: validating pod update-demo-nautilus-88phj
Dec 11 05:37:51.189: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:37:51.189: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:37:51.189: INFO: update-demo-nautilus-88phj is verified up and running
Dec 11 05:37:51.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-ldg6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3242'
Dec 11 05:37:51.289: INFO: stderr: ""
Dec 11 05:37:51.289: INFO: stdout: "true"
Dec 11 05:37:51.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods update-demo-nautilus-ldg6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3242'
Dec 11 05:37:51.390: INFO: stderr: ""
Dec 11 05:37:51.390: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 11 05:37:51.390: INFO: validating pod update-demo-nautilus-ldg6b
Dec 11 05:37:51.394: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 11 05:37:51.394: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 11 05:37:51.394: INFO: update-demo-nautilus-ldg6b is verified up and running
STEP: using delete to clean up resources
Dec 11 05:37:51.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-3242'
Dec 11 05:37:51.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 05:37:51.490: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 11 05:37:51.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3242'
Dec 11 05:37:51.591: INFO: stderr: "No resources found.\n"
Dec 11 05:37:51.591: INFO: stdout: ""
Dec 11 05:37:51.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=update-demo --namespace=kubectl-3242 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:37:51.692: INFO: stderr: ""
Dec 11 05:37:51.692: INFO: stdout: "update-demo-nautilus-88phj\nupdate-demo-nautilus-ldg6b\n"
Dec 11 05:37:52.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3242'
Dec 11 05:37:52.324: INFO: stderr: "No resources found.\n"
Dec 11 05:37:52.324: INFO: stdout: ""
Dec 11 05:37:52.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=update-demo --namespace=kubectl-3242 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:37:52.429: INFO: stderr: ""
Dec 11 05:37:52.429: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:37:52.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3242" for this suite.
Dec 11 05:38:14.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:38:14.523: INFO: namespace kubectl-3242 deletion completed in 22.084577697s

• [SLOW TEST:29.246 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:38:14.532: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 11 05:38:14.562: INFO: Waiting up to 5m0s for pod "downward-api-69e2da30-769a-4b17-b244-c169c224db70" in namespace "downward-api-2617" to be "success or failure"
Dec 11 05:38:14.565: INFO: Pod "downward-api-69e2da30-769a-4b17-b244-c169c224db70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.835432ms
Dec 11 05:38:16.569: INFO: Pod "downward-api-69e2da30-769a-4b17-b244-c169c224db70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007130725s
Dec 11 05:38:18.572: INFO: Pod "downward-api-69e2da30-769a-4b17-b244-c169c224db70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010505999s
STEP: Saw pod success
Dec 11 05:38:18.572: INFO: Pod "downward-api-69e2da30-769a-4b17-b244-c169c224db70" satisfied condition "success or failure"
Dec 11 05:38:18.574: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-69e2da30-769a-4b17-b244-c169c224db70 container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:38:18.589: INFO: Waiting for pod downward-api-69e2da30-769a-4b17-b244-c169c224db70 to disappear
Dec 11 05:38:18.591: INFO: Pod downward-api-69e2da30-769a-4b17-b244-c169c224db70 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:38:18.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2617" for this suite.
Dec 11 05:38:24.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:38:24.678: INFO: namespace downward-api-2617 deletion completed in 6.082932773s

• [SLOW TEST:10.148 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:38:24.689: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Dec 11 05:38:24.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 api-versions'
Dec 11 05:38:24.824: INFO: stderr: ""
Dec 11 05:38:24.824: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:38:24.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7678" for this suite.
Dec 11 05:38:30.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:38:30.905: INFO: namespace kubectl-7678 deletion completed in 6.074951712s

• [SLOW TEST:6.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:38:30.905: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-eb70633a-12b8-4130-b406-4611c6084c93
STEP: Creating a pod to test consume configMaps
Dec 11 05:38:30.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2" in namespace "configmap-6373" to be "success or failure"
Dec 11 05:38:30.944: INFO: Pod "pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119219ms
Dec 11 05:38:32.947: INFO: Pod "pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004925684s
Dec 11 05:38:34.950: INFO: Pod "pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00835824s
STEP: Saw pod success
Dec 11 05:38:34.950: INFO: Pod "pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2" satisfied condition "success or failure"
Dec 11 05:38:34.952: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:38:34.969: INFO: Waiting for pod pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2 to disappear
Dec 11 05:38:34.971: INFO: Pod pod-configmaps-6dbdedb4-f68f-41fd-97a5-6e10c83de8f2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:38:34.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6373" for this suite.
Dec 11 05:38:40.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:38:41.052: INFO: namespace configmap-6373 deletion completed in 6.077543538s

• [SLOW TEST:10.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:38:41.053: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:38:41.090: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7" in namespace "downward-api-2087" to be "success or failure"
Dec 11 05:38:41.092: INFO: Pod "downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399128ms
Dec 11 05:38:43.096: INFO: Pod "downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006639412s
Dec 11 05:38:45.100: INFO: Pod "downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010646761s
STEP: Saw pod success
Dec 11 05:38:45.100: INFO: Pod "downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7" satisfied condition "success or failure"
Dec 11 05:38:45.104: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7 container client-container: <nil>
STEP: delete the pod
Dec 11 05:38:45.120: INFO: Waiting for pod downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7 to disappear
Dec 11 05:38:45.122: INFO: Pod downwardapi-volume-4dd855d2-cf51-4b60-a1fc-54efcea27fb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:38:45.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2087" for this suite.
Dec 11 05:38:51.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:38:51.198: INFO: namespace downward-api-2087 deletion completed in 6.073206685s

• [SLOW TEST:10.145 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:38:51.205: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 11 05:39:21.760: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1211 05:39:21.760358      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:39:21.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1047" for this suite.
Dec 11 05:39:27.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:39:27.857: INFO: namespace gc-1047 deletion completed in 6.091668692s

• [SLOW TEST:36.654 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:39:27.862: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-30fb17fa-f441-4c7d-8bc5-b7b56b51823b
STEP: Creating a pod to test consume configMaps
Dec 11 05:39:27.897: INFO: Waiting up to 5m0s for pod "pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe" in namespace "configmap-9175" to be "success or failure"
Dec 11 05:39:27.899: INFO: Pod "pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.633105ms
Dec 11 05:39:29.902: INFO: Pod "pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005527252s
STEP: Saw pod success
Dec 11 05:39:29.902: INFO: Pod "pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe" satisfied condition "success or failure"
Dec 11 05:39:29.905: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:39:29.958: INFO: Waiting for pod pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe to disappear
Dec 11 05:39:29.960: INFO: Pod pod-configmaps-99053811-93dd-413c-9043-1a22da7af5fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:39:29.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9175" for this suite.
Dec 11 05:39:35.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:39:36.040: INFO: namespace configmap-9175 deletion completed in 6.076998087s

• [SLOW TEST:8.178 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:39:36.040: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-54ba7ed7-8f5c-409e-b2a4-14179042fd74
STEP: Creating secret with name s-test-opt-upd-bc1e318f-e956-495f-8fec-98f3216f9738
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-54ba7ed7-8f5c-409e-b2a4-14179042fd74
STEP: Updating secret s-test-opt-upd-bc1e318f-e956-495f-8fec-98f3216f9738
STEP: Creating secret with name s-test-opt-create-21d1aea0-85a6-44fc-a3fa-f099e3a89277
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:39:44.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3646" for this suite.
Dec 11 05:40:06.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:40:06.234: INFO: namespace secrets-3646 deletion completed in 22.078875468s

• [SLOW TEST:30.194 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:40:06.234: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 11 05:40:06.261: INFO: namespace kubectl-3441
Dec 11 05:40:06.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-3441'
Dec 11 05:40:06.607: INFO: stderr: ""
Dec 11 05:40:06.607: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 11 05:40:07.611: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:40:07.611: INFO: Found 0 / 1
Dec 11 05:40:08.611: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:40:08.611: INFO: Found 0 / 1
Dec 11 05:40:09.614: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:40:09.614: INFO: Found 1 / 1
Dec 11 05:40:09.614: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 11 05:40:09.617: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:40:09.617: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 11 05:40:09.617: INFO: wait on redis-master startup in kubectl-3441 
Dec 11 05:40:09.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-86wvz redis-master --namespace=kubectl-3441'
Dec 11 05:40:09.730: INFO: stderr: ""
Dec 11 05:40:09.730: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 05:40:08.029 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 05:40:08.029 # Server started, Redis version 3.2.12\n1:M 11 Dec 05:40:08.030 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 05:40:08.030 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 11 05:40:09.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3441'
Dec 11 05:40:09.851: INFO: stderr: ""
Dec 11 05:40:09.851: INFO: stdout: "service/rm2 exposed\n"
Dec 11 05:40:09.856: INFO: Service rm2 in namespace kubectl-3441 found.
STEP: exposing service
Dec 11 05:40:11.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3441'
Dec 11 05:40:12.002: INFO: stderr: ""
Dec 11 05:40:12.002: INFO: stdout: "service/rm3 exposed\n"
Dec 11 05:40:12.007: INFO: Service rm3 in namespace kubectl-3441 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:40:14.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3441" for this suite.
Dec 11 05:40:36.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:40:36.094: INFO: namespace kubectl-3441 deletion completed in 22.079639281s

• [SLOW TEST:29.861 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:40:36.104: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 11 05:40:40.661: INFO: Successfully updated pod "annotationupdated76aa727-d0e7-4871-8aaf-5edc80588bbb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:40:42.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4610" for this suite.
Dec 11 05:41:04.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:41:04.756: INFO: namespace downward-api-4610 deletion completed in 22.071548531s

• [SLOW TEST:28.652 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:41:04.756: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-7beab4a4-e397-4fae-95d6-50c130a9844d in namespace container-probe-8846
Dec 11 05:41:08.797: INFO: Started pod test-webserver-7beab4a4-e397-4fae-95d6-50c130a9844d in namespace container-probe-8846
STEP: checking the pod's current state and verifying that restartCount is present
Dec 11 05:41:08.800: INFO: Initial restart count of pod test-webserver-7beab4a4-e397-4fae-95d6-50c130a9844d is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:45:09.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8846" for this suite.
Dec 11 05:45:15.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:45:15.359: INFO: namespace container-probe-8846 deletion completed in 6.082971146s

• [SLOW TEST:250.607 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:45:15.367: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:45:15.405: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 11 05:45:17.427: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:45:18.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-599" for this suite.
Dec 11 05:45:24.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:45:24.518: INFO: namespace replication-controller-599 deletion completed in 6.077611039s

• [SLOW TEST:9.151 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:45:24.521: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-brx6
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 05:45:24.561: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-brx6" in namespace "subpath-9492" to be "success or failure"
Dec 11 05:45:24.563: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.379925ms
Dec 11 05:45:26.566: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00531782s
Dec 11 05:45:28.570: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 4.00887416s
Dec 11 05:45:30.573: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 6.01257548s
Dec 11 05:45:32.577: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 8.016045862s
Dec 11 05:45:34.580: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 10.019609068s
Dec 11 05:45:36.583: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 12.022358039s
Dec 11 05:45:38.587: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 14.025818504s
Dec 11 05:45:40.590: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 16.029349667s
Dec 11 05:45:42.593: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 18.032734473s
Dec 11 05:45:44.598: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 20.037488008s
Dec 11 05:45:46.601: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Running", Reason="", readiness=true. Elapsed: 22.040729561s
Dec 11 05:45:48.605: INFO: Pod "pod-subpath-test-secret-brx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043949895s
STEP: Saw pod success
Dec 11 05:45:48.605: INFO: Pod "pod-subpath-test-secret-brx6" satisfied condition "success or failure"
Dec 11 05:45:48.607: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-secret-brx6 container test-container-subpath-secret-brx6: <nil>
STEP: delete the pod
Dec 11 05:45:48.626: INFO: Waiting for pod pod-subpath-test-secret-brx6 to disappear
Dec 11 05:45:48.628: INFO: Pod pod-subpath-test-secret-brx6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-brx6
Dec 11 05:45:48.628: INFO: Deleting pod "pod-subpath-test-secret-brx6" in namespace "subpath-9492"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:45:48.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9492" for this suite.
Dec 11 05:45:54.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:45:54.711: INFO: namespace subpath-9492 deletion completed in 6.07812626s

• [SLOW TEST:30.191 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:45:54.712: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-178848fa-07b3-423b-ac11-d2888f89e8fa
STEP: Creating a pod to test consume secrets
Dec 11 05:45:54.758: INFO: Waiting up to 5m0s for pod "pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78" in namespace "secrets-8379" to be "success or failure"
Dec 11 05:45:54.768: INFO: Pod "pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78": Phase="Pending", Reason="", readiness=false. Elapsed: 3.784203ms
Dec 11 05:45:56.771: INFO: Pod "pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006746176s
Dec 11 05:45:58.774: INFO: Pod "pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01001333s
STEP: Saw pod success
Dec 11 05:45:58.774: INFO: Pod "pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78" satisfied condition "success or failure"
Dec 11 05:45:58.776: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:45:58.799: INFO: Waiting for pod pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78 to disappear
Dec 11 05:45:58.801: INFO: Pod pod-secrets-da13d0b4-bfc9-4780-a19c-833ab6200d78 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:45:58.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8379" for this suite.
Dec 11 05:46:04.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:46:04.885: INFO: namespace secrets-8379 deletion completed in 6.080763969s

• [SLOW TEST:10.173 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:46:04.885: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 11 05:46:04.937: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 11 05:46:04.942: INFO: Number of nodes with available pods: 0
Dec 11 05:46:04.943: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 11 05:46:04.956: INFO: Number of nodes with available pods: 0
Dec 11 05:46:04.956: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:05.959: INFO: Number of nodes with available pods: 0
Dec 11 05:46:05.959: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:06.960: INFO: Number of nodes with available pods: 0
Dec 11 05:46:06.960: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:07.959: INFO: Number of nodes with available pods: 1
Dec 11 05:46:07.959: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 11 05:46:07.971: INFO: Number of nodes with available pods: 1
Dec 11 05:46:07.971: INFO: Number of running nodes: 0, number of available pods: 1
Dec 11 05:46:08.975: INFO: Number of nodes with available pods: 0
Dec 11 05:46:08.975: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 11 05:46:08.981: INFO: Number of nodes with available pods: 0
Dec 11 05:46:08.981: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:09.986: INFO: Number of nodes with available pods: 0
Dec 11 05:46:09.986: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:10.986: INFO: Number of nodes with available pods: 0
Dec 11 05:46:10.986: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:11.984: INFO: Number of nodes with available pods: 0
Dec 11 05:46:11.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:12.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:12.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:13.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:13.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:14.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:14.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:15.984: INFO: Number of nodes with available pods: 0
Dec 11 05:46:15.984: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:16.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:16.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:17.984: INFO: Number of nodes with available pods: 0
Dec 11 05:46:17.984: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:18.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:18.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:19.989: INFO: Number of nodes with available pods: 0
Dec 11 05:46:19.989: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:20.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:20.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:21.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:21.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:22.985: INFO: Number of nodes with available pods: 0
Dec 11 05:46:22.985: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:46:23.984: INFO: Number of nodes with available pods: 1
Dec 11 05:46:23.984: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3916, will wait for the garbage collector to delete the pods
Dec 11 05:46:24.048: INFO: Deleting DaemonSet.extensions daemon-set took: 5.903072ms
Dec 11 05:46:24.448: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.251835ms
Dec 11 05:46:28.051: INFO: Number of nodes with available pods: 0
Dec 11 05:46:28.051: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 05:46:28.053: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3916/daemonsets","resourceVersion":"173789"},"items":null}

Dec 11 05:46:28.055: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3916/pods","resourceVersion":"173789"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:46:28.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3916" for this suite.
Dec 11 05:46:34.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:46:34.148: INFO: namespace daemonsets-3916 deletion completed in 6.077388193s

• [SLOW TEST:29.263 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:46:34.152: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-88b261bb-60f0-41cc-8507-e791361dc36a
STEP: Creating a pod to test consume secrets
Dec 11 05:46:34.184: INFO: Waiting up to 5m0s for pod "pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a" in namespace "secrets-3248" to be "success or failure"
Dec 11 05:46:34.186: INFO: Pod "pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102725ms
Dec 11 05:46:36.191: INFO: Pod "pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00688637s
Dec 11 05:46:38.195: INFO: Pod "pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010526185s
STEP: Saw pod success
Dec 11 05:46:38.195: INFO: Pod "pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a" satisfied condition "success or failure"
Dec 11 05:46:38.197: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:46:38.218: INFO: Waiting for pod pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a to disappear
Dec 11 05:46:38.220: INFO: Pod pod-secrets-b08bd3a5-9a6f-4c6c-b4f0-b69034995f3a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:46:38.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3248" for this suite.
Dec 11 05:46:44.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:46:44.314: INFO: namespace secrets-3248 deletion completed in 6.090967481s

• [SLOW TEST:10.163 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:46:44.316: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:46:44.350: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91" in namespace "downward-api-8998" to be "success or failure"
Dec 11 05:46:44.353: INFO: Pod "downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106303ms
Dec 11 05:46:46.356: INFO: Pod "downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005764585s
Dec 11 05:46:48.361: INFO: Pod "downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010459238s
STEP: Saw pod success
Dec 11 05:46:48.361: INFO: Pod "downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91" satisfied condition "success or failure"
Dec 11 05:46:48.364: INFO: Trying to get logs from node 192.168.5.23 pod downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91 container client-container: <nil>
STEP: delete the pod
Dec 11 05:46:48.378: INFO: Waiting for pod downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91 to disappear
Dec 11 05:46:48.381: INFO: Pod downwardapi-volume-2302d105-6940-4bed-8099-4ff88ff2da91 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:46:48.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8998" for this suite.
Dec 11 05:46:54.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:46:54.458: INFO: namespace downward-api-8998 deletion completed in 6.073675484s

• [SLOW TEST:10.142 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:46:54.459: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:46:59.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7378" for this suite.
Dec 11 05:47:06.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:47:06.186: INFO: namespace watch-7378 deletion completed in 6.168914432s

• [SLOW TEST:11.727 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:47:06.188: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-2775427e-928c-40d7-85fe-5e4b08a94462
STEP: Creating a pod to test consume secrets
Dec 11 05:47:06.226: INFO: Waiting up to 5m0s for pod "pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033" in namespace "secrets-3033" to be "success or failure"
Dec 11 05:47:06.228: INFO: Pod "pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077748ms
Dec 11 05:47:08.231: INFO: Pod "pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033": Phase="Running", Reason="", readiness=true. Elapsed: 2.00520345s
Dec 11 05:47:10.235: INFO: Pod "pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008597719s
STEP: Saw pod success
Dec 11 05:47:10.235: INFO: Pod "pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033" satisfied condition "success or failure"
Dec 11 05:47:10.238: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033 container secret-volume-test: <nil>
STEP: delete the pod
Dec 11 05:47:10.252: INFO: Waiting for pod pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033 to disappear
Dec 11 05:47:10.254: INFO: Pod pod-secrets-31d64115-c345-4dbe-95ea-47b4c2f71033 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:47:10.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3033" for this suite.
Dec 11 05:47:16.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:47:16.334: INFO: namespace secrets-3033 deletion completed in 6.077766673s

• [SLOW TEST:10.147 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:47:16.335: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 11 05:47:16.383: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:16.383: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:16.383: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:16.385: INFO: Number of nodes with available pods: 0
Dec 11 05:47:16.385: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:47:17.390: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:17.390: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:17.390: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:17.394: INFO: Number of nodes with available pods: 0
Dec 11 05:47:17.394: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:47:18.391: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:18.391: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:18.391: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:18.396: INFO: Number of nodes with available pods: 0
Dec 11 05:47:18.396: INFO: Node 192.168.5.21 is running more than one daemon pod
Dec 11 05:47:19.391: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.391: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.391: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.394: INFO: Number of nodes with available pods: 2
Dec 11 05:47:19.394: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 11 05:47:19.406: INFO: DaemonSet pods can't tolerate node 192.168.5.11 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.406: INFO: DaemonSet pods can't tolerate node 192.168.5.7 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.406: INFO: DaemonSet pods can't tolerate node 192.168.5.9 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 11 05:47:19.409: INFO: Number of nodes with available pods: 2
Dec 11 05:47:19.409: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2362, will wait for the garbage collector to delete the pods
Dec 11 05:47:20.479: INFO: Deleting DaemonSet.extensions daemon-set took: 5.3457ms
Dec 11 05:47:20.879: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.313194ms
Dec 11 05:48:51.883: INFO: Number of nodes with available pods: 0
Dec 11 05:48:51.883: INFO: Number of running nodes: 0, number of available pods: 0
Dec 11 05:48:51.886: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2362/daemonsets","resourceVersion":"174228"},"items":null}

Dec 11 05:48:51.888: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2362/pods","resourceVersion":"174228"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:48:51.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2362" for this suite.
Dec 11 05:48:57.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:48:57.976: INFO: namespace daemonsets-2362 deletion completed in 6.078233319s

• [SLOW TEST:101.642 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:48:57.979: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 11 05:48:58.013: INFO: Waiting up to 5m0s for pod "pod-7c60b503-8e53-424a-b6dc-f98f83764b63" in namespace "emptydir-3582" to be "success or failure"
Dec 11 05:48:58.016: INFO: Pod "pod-7c60b503-8e53-424a-b6dc-f98f83764b63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.852175ms
Dec 11 05:49:00.020: INFO: Pod "pod-7c60b503-8e53-424a-b6dc-f98f83764b63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007404849s
Dec 11 05:49:02.024: INFO: Pod "pod-7c60b503-8e53-424a-b6dc-f98f83764b63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010829892s
STEP: Saw pod success
Dec 11 05:49:02.024: INFO: Pod "pod-7c60b503-8e53-424a-b6dc-f98f83764b63" satisfied condition "success or failure"
Dec 11 05:49:02.026: INFO: Trying to get logs from node 192.168.5.21 pod pod-7c60b503-8e53-424a-b6dc-f98f83764b63 container test-container: <nil>
STEP: delete the pod
Dec 11 05:49:02.043: INFO: Waiting for pod pod-7c60b503-8e53-424a-b6dc-f98f83764b63 to disappear
Dec 11 05:49:02.045: INFO: Pod pod-7c60b503-8e53-424a-b6dc-f98f83764b63 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:49:02.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3582" for this suite.
Dec 11 05:49:08.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:49:08.119: INFO: namespace emptydir-3582 deletion completed in 6.07135844s

• [SLOW TEST:10.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:49:08.120: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-73f00a3c-df6d-4adc-997e-dca2b47dfaff
STEP: Creating a pod to test consume configMaps
Dec 11 05:49:08.158: INFO: Waiting up to 5m0s for pod "pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd" in namespace "configmap-2756" to be "success or failure"
Dec 11 05:49:08.160: INFO: Pod "pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074617ms
Dec 11 05:49:10.163: INFO: Pod "pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005056846s
Dec 11 05:49:12.167: INFO: Pod "pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009351007s
STEP: Saw pod success
Dec 11 05:49:12.167: INFO: Pod "pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd" satisfied condition "success or failure"
Dec 11 05:49:12.170: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd container configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:49:12.187: INFO: Waiting for pod pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd to disappear
Dec 11 05:49:12.189: INFO: Pod pod-configmaps-a4e9d434-68fe-46d9-8c00-a5d3bd7584cd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:49:12.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2756" for this suite.
Dec 11 05:49:18.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:49:18.267: INFO: namespace configmap-2756 deletion completed in 6.075255746s

• [SLOW TEST:10.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:49:18.270: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-9c614038-3606-4e0e-aeee-9ca6300a5d94
STEP: Creating configMap with name cm-test-opt-upd-cb68c899-9bf1-42ce-b8a3-c1ed0f4c327f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9c614038-3606-4e0e-aeee-9ca6300a5d94
STEP: Updating configmap cm-test-opt-upd-cb68c899-9bf1-42ce-b8a3-c1ed0f4c327f
STEP: Creating configMap with name cm-test-opt-create-8bc3d00e-a362-4655-827f-37fa8c47de41
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:49:22.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7439" for this suite.
Dec 11 05:49:44.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:49:44.481: INFO: namespace configmap-7439 deletion completed in 22.074376581s

• [SLOW TEST:26.212 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:49:44.482: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8295
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 11 05:49:44.524: INFO: Found 0 stateful pods, waiting for 3
Dec 11 05:49:54.530: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:49:54.530: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:49:54.530: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 11 05:49:54.554: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 11 05:50:04.585: INFO: Updating stateful set ss2
Dec 11 05:50:04.591: INFO: Waiting for Pod statefulset-8295/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Dec 11 05:50:14.627: INFO: Found 2 stateful pods, waiting for 3
Dec 11 05:50:24.632: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:50:24.633: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 11 05:50:24.633: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 11 05:50:24.654: INFO: Updating stateful set ss2
Dec 11 05:50:24.658: INFO: Waiting for Pod statefulset-8295/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 11 05:50:34.683: INFO: Updating stateful set ss2
Dec 11 05:50:34.690: INFO: Waiting for StatefulSet statefulset-8295/ss2 to complete update
Dec 11 05:50:34.690: INFO: Waiting for Pod statefulset-8295/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 11 05:50:44.698: INFO: Deleting all statefulset in ns statefulset-8295
Dec 11 05:50:44.700: INFO: Scaling statefulset ss2 to 0
Dec 11 05:51:14.714: INFO: Waiting for statefulset status.replicas updated to 0
Dec 11 05:51:14.723: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:51:14.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8295" for this suite.
Dec 11 05:51:20.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:51:20.822: INFO: namespace statefulset-8295 deletion completed in 6.084311258s

• [SLOW TEST:96.340 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:51:20.823: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Dec 11 05:51:20.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 create -f - --namespace=kubectl-8380'
Dec 11 05:51:21.228: INFO: stderr: ""
Dec 11 05:51:21.228: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Dec 11 05:51:22.231: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:51:22.231: INFO: Found 0 / 1
Dec 11 05:51:23.231: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:51:23.231: INFO: Found 0 / 1
Dec 11 05:51:24.231: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:51:24.232: INFO: Found 1 / 1
Dec 11 05:51:24.232: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 11 05:51:24.238: INFO: Selector matched 1 pods for map[app:redis]
Dec 11 05:51:24.238: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 11 05:51:24.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380'
Dec 11 05:51:24.372: INFO: stderr: ""
Dec 11 05:51:24.373: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 05:51:22.555 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 05:51:22.555 # Server started, Redis version 3.2.12\n1:M 11 Dec 05:51:22.555 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 05:51:22.555 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 11 05:51:24.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380 --tail=1'
Dec 11 05:51:24.484: INFO: stderr: ""
Dec 11 05:51:24.484: INFO: stdout: "1:M 11 Dec 05:51:22.555 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 11 05:51:24.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380 --limit-bytes=1'
Dec 11 05:51:24.589: INFO: stderr: ""
Dec 11 05:51:24.589: INFO: stdout: " "
STEP: exposing timestamps
Dec 11 05:51:24.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380 --tail=1 --timestamps'
Dec 11 05:51:24.695: INFO: stderr: ""
Dec 11 05:51:24.695: INFO: stdout: "2019-12-11T05:51:22.55615742Z 1:M 11 Dec 05:51:22.555 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 11 05:51:27.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380 --since=1s'
Dec 11 05:51:27.326: INFO: stderr: ""
Dec 11 05:51:27.326: INFO: stdout: ""
Dec 11 05:51:27.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 logs redis-master-4vrdz redis-master --namespace=kubectl-8380 --since=24h'
Dec 11 05:51:27.444: INFO: stderr: ""
Dec 11 05:51:27.444: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 11 Dec 05:51:22.555 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 11 Dec 05:51:22.555 # Server started, Redis version 3.2.12\n1:M 11 Dec 05:51:22.555 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 11 Dec 05:51:22.555 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Dec 11 05:51:27.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 delete --grace-period=0 --force -f - --namespace=kubectl-8380'
Dec 11 05:51:27.538: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 11 05:51:27.538: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 11 05:51:27.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get rc,svc -l name=nginx --no-headers --namespace=kubectl-8380'
Dec 11 05:51:27.661: INFO: stderr: "No resources found.\n"
Dec 11 05:51:27.661: INFO: stdout: ""
Dec 11 05:51:27.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-018278524 get pods -l name=nginx --namespace=kubectl-8380 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 11 05:51:27.803: INFO: stderr: ""
Dec 11 05:51:27.803: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:51:27.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8380" for this suite.
Dec 11 05:51:33.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:51:33.887: INFO: namespace kubectl-8380 deletion completed in 6.079687887s

• [SLOW TEST:13.064 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:51:33.888: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 11 05:51:38.436: INFO: Successfully updated pod "pod-update-1f8db961-536b-43a5-85ed-1232e4723ea5"
STEP: verifying the updated pod is in kubernetes
Dec 11 05:51:38.440: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:51:38.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-416" for this suite.
Dec 11 05:52:00.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:52:00.527: INFO: namespace pods-416 deletion completed in 22.083532529s

• [SLOW TEST:26.639 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:52:00.529: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-wn72
STEP: Creating a pod to test atomic-volume-subpath
Dec 11 05:52:00.567: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wn72" in namespace "subpath-7017" to be "success or failure"
Dec 11 05:52:00.569: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.344371ms
Dec 11 05:52:02.572: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005786912s
Dec 11 05:52:04.576: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 4.009780002s
Dec 11 05:52:06.580: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 6.013401907s
Dec 11 05:52:08.583: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 8.016442937s
Dec 11 05:52:10.588: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 10.021599434s
Dec 11 05:52:12.592: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 12.024825277s
Dec 11 05:52:14.595: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 14.028216104s
Dec 11 05:52:16.599: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 16.032309129s
Dec 11 05:52:18.603: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 18.036149191s
Dec 11 05:52:20.606: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 20.039636737s
Dec 11 05:52:22.610: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Running", Reason="", readiness=true. Elapsed: 22.043114316s
Dec 11 05:52:24.613: INFO: Pod "pod-subpath-test-downwardapi-wn72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046276813s
STEP: Saw pod success
Dec 11 05:52:24.613: INFO: Pod "pod-subpath-test-downwardapi-wn72" satisfied condition "success or failure"
Dec 11 05:52:24.618: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-downwardapi-wn72 container test-container-subpath-downwardapi-wn72: <nil>
STEP: delete the pod
Dec 11 05:52:24.633: INFO: Waiting for pod pod-subpath-test-downwardapi-wn72 to disappear
Dec 11 05:52:24.635: INFO: Pod pod-subpath-test-downwardapi-wn72 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wn72
Dec 11 05:52:24.635: INFO: Deleting pod "pod-subpath-test-downwardapi-wn72" in namespace "subpath-7017"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:52:24.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7017" for this suite.
Dec 11 05:52:30.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:52:30.715: INFO: namespace subpath-7017 deletion completed in 6.074106279s

• [SLOW TEST:30.186 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:52:30.716: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 11 05:52:30.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-resource-version,UID:c5f201c6-3f7d-4ed7-948f-5eef4dc589e7,ResourceVersion:174858,Generation:0,CreationTimestamp:2019-12-11 05:52:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 11 05:52:30.757: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3688,SelfLink:/api/v1/namespaces/watch-3688/configmaps/e2e-watch-test-resource-version,UID:c5f201c6-3f7d-4ed7-948f-5eef4dc589e7,ResourceVersion:174859,Generation:0,CreationTimestamp:2019-12-11 05:52:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:52:30.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3688" for this suite.
Dec 11 05:52:36.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:52:36.841: INFO: namespace watch-3688 deletion completed in 6.080891452s

• [SLOW TEST:6.129 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:52:36.846: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 11 05:52:36.880: INFO: Waiting up to 5m0s for pod "pod-f204610b-1b82-4f1f-811e-05550c219699" in namespace "emptydir-2596" to be "success or failure"
Dec 11 05:52:36.882: INFO: Pod "pod-f204610b-1b82-4f1f-811e-05550c219699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.398787ms
Dec 11 05:52:38.885: INFO: Pod "pod-f204610b-1b82-4f1f-811e-05550c219699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005223812s
Dec 11 05:52:40.889: INFO: Pod "pod-f204610b-1b82-4f1f-811e-05550c219699": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009001724s
STEP: Saw pod success
Dec 11 05:52:40.889: INFO: Pod "pod-f204610b-1b82-4f1f-811e-05550c219699" satisfied condition "success or failure"
Dec 11 05:52:40.892: INFO: Trying to get logs from node 192.168.5.21 pod pod-f204610b-1b82-4f1f-811e-05550c219699 container test-container: <nil>
STEP: delete the pod
Dec 11 05:52:40.909: INFO: Waiting for pod pod-f204610b-1b82-4f1f-811e-05550c219699 to disappear
Dec 11 05:52:40.911: INFO: Pod pod-f204610b-1b82-4f1f-811e-05550c219699 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:52:40.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2596" for this suite.
Dec 11 05:52:46.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:52:46.996: INFO: namespace emptydir-2596 deletion completed in 6.082594642s

• [SLOW TEST:10.151 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:52:47.005: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:52:51.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2921" for this suite.
Dec 11 05:52:57.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:52:57.152: INFO: namespace emptydir-wrapper-2921 deletion completed in 6.076369922s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:52:57.155: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-3f8e017c-fbe0-4df8-bb39-97cd39dfd7fa
STEP: Creating a pod to test consume configMaps
Dec 11 05:52:57.189: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa" in namespace "projected-459" to be "success or failure"
Dec 11 05:52:57.192: INFO: Pod "pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.234482ms
Dec 11 05:52:59.195: INFO: Pod "pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006599803s
Dec 11 05:53:01.199: INFO: Pod "pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01064021s
STEP: Saw pod success
Dec 11 05:53:01.199: INFO: Pod "pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa" satisfied condition "success or failure"
Dec 11 05:53:01.202: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:53:01.218: INFO: Waiting for pod pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa to disappear
Dec 11 05:53:01.220: INFO: Pod pod-projected-configmaps-61a42484-e06c-47f5-b879-102e393247fa no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:53:01.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-459" for this suite.
Dec 11 05:53:07.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:53:07.300: INFO: namespace projected-459 deletion completed in 6.077016126s

• [SLOW TEST:10.146 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:53:07.302: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 11 05:53:07.342: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587" in namespace "downward-api-2423" to be "success or failure"
Dec 11 05:53:07.345: INFO: Pod "downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587": Phase="Pending", Reason="", readiness=false. Elapsed: 2.288265ms
Dec 11 05:53:09.349: INFO: Pod "downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006063692s
Dec 11 05:53:11.357: INFO: Pod "downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014149511s
STEP: Saw pod success
Dec 11 05:53:11.357: INFO: Pod "downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587" satisfied condition "success or failure"
Dec 11 05:53:11.359: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587 container client-container: <nil>
STEP: delete the pod
Dec 11 05:53:11.381: INFO: Waiting for pod downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587 to disappear
Dec 11 05:53:11.384: INFO: Pod downwardapi-volume-a1eb4d3b-5898-4253-b62c-9c8d510c9587 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:53:11.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2423" for this suite.
Dec 11 05:53:17.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:53:17.470: INFO: namespace downward-api-2423 deletion completed in 6.081850314s

• [SLOW TEST:10.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:53:17.475: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 11 05:53:17.506: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:53:20.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5407" for this suite.
Dec 11 05:53:26.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:53:26.767: INFO: namespace init-container-5407 deletion completed in 6.084738103s

• [SLOW TEST:9.299 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:53:26.778: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-526c5338-6ab7-4de3-a5a5-5ee484fec834
STEP: Creating a pod to test consume configMaps
Dec 11 05:53:26.821: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7" in namespace "projected-5699" to be "success or failure"
Dec 11 05:53:26.827: INFO: Pod "pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.316186ms
Dec 11 05:53:28.830: INFO: Pod "pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006182031s
Dec 11 05:53:30.833: INFO: Pod "pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009676961s
STEP: Saw pod success
Dec 11 05:53:30.833: INFO: Pod "pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7" satisfied condition "success or failure"
Dec 11 05:53:30.835: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:53:30.850: INFO: Waiting for pod pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7 to disappear
Dec 11 05:53:30.852: INFO: Pod pod-projected-configmaps-4efa3f0e-f57e-4a46-84e7-1d7e0593c7d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:53:30.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5699" for this suite.
Dec 11 05:53:36.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:53:36.929: INFO: namespace projected-5699 deletion completed in 6.072891802s

• [SLOW TEST:10.151 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:53:36.930: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-c4bd20d4-7039-41f0-af23-37859b6af4f9
STEP: Creating a pod to test consume configMaps
Dec 11 05:53:36.960: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138" in namespace "projected-7299" to be "success or failure"
Dec 11 05:53:36.963: INFO: Pod "pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138": Phase="Pending", Reason="", readiness=false. Elapsed: 2.56093ms
Dec 11 05:53:38.966: INFO: Pod "pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005847656s
Dec 11 05:53:40.970: INFO: Pod "pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009836864s
STEP: Saw pod success
Dec 11 05:53:40.970: INFO: Pod "pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138" satisfied condition "success or failure"
Dec 11 05:53:40.972: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 11 05:53:40.992: INFO: Waiting for pod pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138 to disappear
Dec 11 05:53:40.994: INFO: Pod pod-projected-configmaps-ee0fa3a5-0d46-4a74-9f09-f136407ef138 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:53:40.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7299" for this suite.
Dec 11 05:53:47.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:53:47.073: INFO: namespace projected-7299 deletion completed in 6.076235931s

• [SLOW TEST:10.143 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:53:47.074: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:54:14.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-345" for this suite.
Dec 11 05:54:20.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:54:20.400: INFO: namespace container-runtime-345 deletion completed in 6.092656727s

• [SLOW TEST:33.326 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 11 05:54:20.401: INFO: >>> kubeConfig: /tmp/kubeconfig-018278524
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 11 05:54:20.443: INFO: Waiting up to 5m0s for pod "downward-api-52617057-b971-4b8d-b385-2a8892ca28c6" in namespace "downward-api-1706" to be "success or failure"
Dec 11 05:54:20.450: INFO: Pod "downward-api-52617057-b971-4b8d-b385-2a8892ca28c6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.602158ms
Dec 11 05:54:22.455: INFO: Pod "downward-api-52617057-b971-4b8d-b385-2a8892ca28c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011148623s
Dec 11 05:54:24.458: INFO: Pod "downward-api-52617057-b971-4b8d-b385-2a8892ca28c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014526627s
STEP: Saw pod success
Dec 11 05:54:24.458: INFO: Pod "downward-api-52617057-b971-4b8d-b385-2a8892ca28c6" satisfied condition "success or failure"
Dec 11 05:54:24.461: INFO: Trying to get logs from node 192.168.5.23 pod downward-api-52617057-b971-4b8d-b385-2a8892ca28c6 container dapi-container: <nil>
STEP: delete the pod
Dec 11 05:54:24.477: INFO: Waiting for pod downward-api-52617057-b971-4b8d-b385-2a8892ca28c6 to disappear
Dec 11 05:54:24.480: INFO: Pod downward-api-52617057-b971-4b8d-b385-2a8892ca28c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 11 05:54:24.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1706" for this suite.
Dec 11 05:54:30.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 11 05:54:30.557: INFO: namespace downward-api-1706 deletion completed in 6.07133839s

• [SLOW TEST:10.157 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSDec 11 05:54:30.559: INFO: Running AfterSuite actions on all nodes
Dec 11 05:54:30.559: INFO: Running AfterSuite actions on node 1
Dec 11 05:54:30.559: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5458.428 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h30m59.889166506s
Test Suite Passed
