I0228 18:57:25.329075      17 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-779692974
I0228 18:57:25.329371      17 e2e.go:243] Starting e2e run "69d072cb-d8aa-4a05-a680-b5245d2e360a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582916244 - Will randomize all specs
Will run 215 of 4412 specs

Feb 28 18:57:25.452: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 18:57:25.456: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 28 18:57:25.474: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 28 18:57:25.521: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 28 18:57:25.521: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 28 18:57:25.521: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 28 18:57:25.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 28 18:57:25.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'chiwen-agent' (0 seconds elapsed)
Feb 28 18:57:25.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'chiwen-ingress-controller' (0 seconds elapsed)
Feb 28 18:57:25.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'chiwen-volume-plugin' (0 seconds elapsed)
Feb 28 18:57:25.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Feb 28 18:57:25.530: INFO: e2e test version: v1.15.9
Feb 28 18:57:25.531: INFO: kube-apiserver version: v1.15.9
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 18:57:25.531: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
Feb 28 18:57:25.559: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 18:57:25.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 version'
Feb 28 18:57:25.650: INFO: stderr: ""
Feb 28 18:57:25.650: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.9\", GitCommit:\"2e808b7cb054ee242b68e62455323aa783991f03\", GitTreeState:\"clean\", BuildDate:\"2020-01-18T23:33:14Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.9\", GitCommit:\"2e808b7cb054ee242b68e62455323aa783991f03\", GitTreeState:\"clean\", BuildDate:\"2020-01-18T23:24:23Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 18:57:25.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5885" for this suite.
Feb 28 18:57:31.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 18:57:31.755: INFO: namespace kubectl-5885 deletion completed in 6.100685548s

• [SLOW TEST:6.224 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 18:57:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-203cfac5-7aa3-417f-8f71-86727e3899da
STEP: Creating a pod to test consume secrets
Feb 28 18:57:31.809: INFO: Waiting up to 5m0s for pod "pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922" in namespace "secrets-6223" to be "success or failure"
Feb 28 18:57:31.813: INFO: Pod "pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922": Phase="Pending", Reason="", readiness=false. Elapsed: 3.709401ms
Feb 28 18:57:33.817: INFO: Pod "pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007552778s
Feb 28 18:57:35.827: INFO: Pod "pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01774289s
STEP: Saw pod success
Feb 28 18:57:35.827: INFO: Pod "pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922" satisfied condition "success or failure"
Feb 28 18:57:35.831: INFO: Trying to get logs from node wenjun192 pod pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922 container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 18:57:35.950: INFO: Waiting for pod pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922 to disappear
Feb 28 18:57:35.954: INFO: Pod pod-secrets-fd84f0b7-27a2-43dd-b2c2-f74e71763922 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 18:57:35.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6223" for this suite.
Feb 28 18:57:41.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 18:57:42.071: INFO: namespace secrets-6223 deletion completed in 6.11078783s

• [SLOW TEST:10.316 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 18:57:42.072: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9654
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 28 18:57:42.132: INFO: Found 0 stateful pods, waiting for 3
Feb 28 18:57:52.141: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 18:57:52.141: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 18:57:52.141: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 28 18:57:52.180: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 28 18:58:02.213: INFO: Updating stateful set ss2
Feb 28 18:58:02.219: INFO: Waiting for Pod statefulset-9654/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Feb 28 18:58:12.335: INFO: Found 2 stateful pods, waiting for 3
Feb 28 18:58:22.343: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 18:58:22.343: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 18:58:22.343: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 28 18:58:22.372: INFO: Updating stateful set ss2
Feb 28 18:58:22.388: INFO: Waiting for Pod statefulset-9654/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 18:58:32.396: INFO: Waiting for Pod statefulset-9654/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 18:58:42.420: INFO: Updating stateful set ss2
Feb 28 18:58:42.432: INFO: Waiting for StatefulSet statefulset-9654/ss2 to complete update
Feb 28 18:58:42.433: INFO: Waiting for Pod statefulset-9654/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 28 18:58:52.441: INFO: Deleting all statefulset in ns statefulset-9654
Feb 28 18:58:52.445: INFO: Scaling statefulset ss2 to 0
Feb 28 18:59:12.474: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 18:59:12.479: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 18:59:12.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9654" for this suite.
Feb 28 18:59:18.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 18:59:18.655: INFO: namespace statefulset-9654 deletion completed in 6.142379122s

• [SLOW TEST:96.583 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 18:59:18.656: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 28 18:59:18.714: INFO: Waiting up to 5m0s for pod "pod-74b4f706-5ff9-42a9-a2f3-2252046cb361" in namespace "emptydir-992" to be "success or failure"
Feb 28 18:59:18.717: INFO: Pod "pod-74b4f706-5ff9-42a9-a2f3-2252046cb361": Phase="Pending", Reason="", readiness=false. Elapsed: 2.973712ms
Feb 28 18:59:20.721: INFO: Pod "pod-74b4f706-5ff9-42a9-a2f3-2252046cb361": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00713974s
STEP: Saw pod success
Feb 28 18:59:20.721: INFO: Pod "pod-74b4f706-5ff9-42a9-a2f3-2252046cb361" satisfied condition "success or failure"
Feb 28 18:59:20.727: INFO: Trying to get logs from node wenjun192 pod pod-74b4f706-5ff9-42a9-a2f3-2252046cb361 container test-container: <nil>
STEP: delete the pod
Feb 28 18:59:20.750: INFO: Waiting for pod pod-74b4f706-5ff9-42a9-a2f3-2252046cb361 to disappear
Feb 28 18:59:20.754: INFO: Pod pod-74b4f706-5ff9-42a9-a2f3-2252046cb361 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 18:59:20.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-992" for this suite.
Feb 28 18:59:26.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 18:59:26.876: INFO: namespace emptydir-992 deletion completed in 6.116105057s

• [SLOW TEST:8.220 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 18:59:26.876: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 28 18:59:30.933: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3bbf6e50-e078-47fd-b7ae-2e33a0078602,GenerateName:,Namespace:events-3827,SelfLink:/api/v1/namespaces/events-3827/pods/send-events-3bbf6e50-e078-47fd-b7ae-2e33a0078602,UID:105d2221-3ef1-4a61-bce0-4374fa56ba52,ResourceVersion:1721,Generation:0,CreationTimestamp:2020-02-28 18:59:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 908420683,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gnh92 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gnh92,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gnh92 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000442740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004427b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 18:59:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 18:59:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 18:59:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 18:59:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.12,StartTime:2020-02-28 18:59:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-02-28 18:59:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://05c546628c0a3c92fc096b2fbac811115819233cbc2f1e4424fa5819c8327d62}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 28 18:59:32.938: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 28 18:59:34.943: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 18:59:34.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3827" for this suite.
Feb 28 19:00:20.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:00:21.092: INFO: namespace events-3827 deletion completed in 46.135194012s

• [SLOW TEST:54.216 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:00:21.094: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-a5b884a7-80fe-45af-b921-b251b1a8b927
STEP: Creating a pod to test consume configMaps
Feb 28 19:00:21.198: INFO: Waiting up to 5m0s for pod "pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db" in namespace "configmap-1362" to be "success or failure"
Feb 28 19:00:21.203: INFO: Pod "pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db": Phase="Pending", Reason="", readiness=false. Elapsed: 5.714123ms
Feb 28 19:00:23.208: INFO: Pod "pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010382898s
Feb 28 19:00:25.212: INFO: Pod "pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013796168s
STEP: Saw pod success
Feb 28 19:00:25.212: INFO: Pod "pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db" satisfied condition "success or failure"
Feb 28 19:00:25.218: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:00:25.241: INFO: Waiting for pod pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db to disappear
Feb 28 19:00:25.244: INFO: Pod pod-configmaps-09ff095c-8cb0-4d7a-9e82-7f69a12ba8db no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:00:25.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1362" for this suite.
Feb 28 19:00:31.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:00:31.347: INFO: namespace configmap-1362 deletion completed in 6.097024926s

• [SLOW TEST:10.253 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:00:31.347: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-19d64146-4f04-4c61-993b-72fa19658c49
STEP: Creating secret with name s-test-opt-upd-dbd98141-aa84-4bde-aaf8-3a67cff951e5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-19d64146-4f04-4c61-993b-72fa19658c49
STEP: Updating secret s-test-opt-upd-dbd98141-aa84-4bde-aaf8-3a67cff951e5
STEP: Creating secret with name s-test-opt-create-2823b280-7cb6-4cc5-8898-b85a60643e9b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:01:57.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7976" for this suite.
Feb 28 19:02:20.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:02:20.137: INFO: namespace secrets-7976 deletion completed in 22.137575032s

• [SLOW TEST:108.789 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:02:20.138: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:02:20.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4196" for this suite.
Feb 28 19:02:26.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:02:26.341: INFO: namespace kubelet-test-4196 deletion completed in 6.11423051s

• [SLOW TEST:6.203 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:02:26.341: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 28 19:02:28.934: INFO: Successfully updated pod "annotationupdate5f7b3b08-25d0-4bb2-b46b-6e12ec4d51bb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:02:30.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9598" for this suite.
Feb 28 19:02:52.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:02:53.071: INFO: namespace projected-9598 deletion completed in 22.11255754s

• [SLOW TEST:26.730 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:02:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:02:53.166: INFO: Waiting up to 5m0s for pod "downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57" in namespace "projected-9344" to be "success or failure"
Feb 28 19:02:53.175: INFO: Pod "downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57": Phase="Pending", Reason="", readiness=false. Elapsed: 9.025088ms
Feb 28 19:02:55.180: INFO: Pod "downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014014396s
STEP: Saw pod success
Feb 28 19:02:55.180: INFO: Pod "downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57" satisfied condition "success or failure"
Feb 28 19:02:55.185: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57 container client-container: <nil>
STEP: delete the pod
Feb 28 19:02:55.219: INFO: Waiting for pod downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57 to disappear
Feb 28 19:02:55.225: INFO: Pod downwardapi-volume-948f0977-2da8-40a0-b327-612a421c9b57 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:02:55.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9344" for this suite.
Feb 28 19:03:01.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:03:01.362: INFO: namespace projected-9344 deletion completed in 6.120355661s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:03:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Feb 28 19:03:11.447: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:03:11.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0228 19:03:11.447320      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5953" for this suite.
Feb 28 19:03:17.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:03:17.584: INFO: namespace gc-5953 deletion completed in 6.129801583s

• [SLOW TEST:16.220 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:03:17.586: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-145ccf95-1786-4440-9922-d10084c733ae
STEP: Creating a pod to test consume secrets
Feb 28 19:03:17.637: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6" in namespace "projected-1316" to be "success or failure"
Feb 28 19:03:17.642: INFO: Pod "pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.264119ms
Feb 28 19:03:19.646: INFO: Pod "pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008634069s
Feb 28 19:03:21.650: INFO: Pod "pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012580042s
STEP: Saw pod success
Feb 28 19:03:21.650: INFO: Pod "pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6" satisfied condition "success or failure"
Feb 28 19:03:21.653: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:03:21.676: INFO: Waiting for pod pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6 to disappear
Feb 28 19:03:21.678: INFO: Pod pod-projected-secrets-5f0531f8-a023-4760-bb8f-4a17eb3787c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:03:21.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1316" for this suite.
Feb 28 19:03:27.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:03:27.832: INFO: namespace projected-1316 deletion completed in 6.150283927s

• [SLOW TEST:10.246 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:03:27.834: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-2ktj
STEP: Creating a pod to test atomic-volume-subpath
Feb 28 19:03:27.903: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2ktj" in namespace "subpath-6937" to be "success or failure"
Feb 28 19:03:27.908: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.971432ms
Feb 28 19:03:29.912: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 2.008315207s
Feb 28 19:03:31.916: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 4.012142142s
Feb 28 19:03:33.920: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 6.016115212s
Feb 28 19:03:35.930: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 8.026914112s
Feb 28 19:03:37.934: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 10.030332133s
Feb 28 19:03:39.938: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 12.034229231s
Feb 28 19:03:41.943: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 14.03914819s
Feb 28 19:03:43.946: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 16.042786158s
Feb 28 19:03:45.951: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 18.047455453s
Feb 28 19:03:47.955: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 20.051969562s
Feb 28 19:03:49.960: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Running", Reason="", readiness=true. Elapsed: 22.056421159s
Feb 28 19:03:51.966: INFO: Pod "pod-subpath-test-secret-2ktj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.062446758s
STEP: Saw pod success
Feb 28 19:03:51.966: INFO: Pod "pod-subpath-test-secret-2ktj" satisfied condition "success or failure"
Feb 28 19:03:51.969: INFO: Trying to get logs from node wenjun192 pod pod-subpath-test-secret-2ktj container test-container-subpath-secret-2ktj: <nil>
STEP: delete the pod
Feb 28 19:03:52.014: INFO: Waiting for pod pod-subpath-test-secret-2ktj to disappear
Feb 28 19:03:52.017: INFO: Pod pod-subpath-test-secret-2ktj no longer exists
STEP: Deleting pod pod-subpath-test-secret-2ktj
Feb 28 19:03:52.017: INFO: Deleting pod "pod-subpath-test-secret-2ktj" in namespace "subpath-6937"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:03:52.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6937" for this suite.
Feb 28 19:03:58.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:03:58.142: INFO: namespace subpath-6937 deletion completed in 6.117842647s

• [SLOW TEST:30.309 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:03:58.144: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 28 19:03:58.193: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 28 19:03:58.207: INFO: Waiting for terminating namespaces to be deleted...
Feb 28 19:03:58.212: INFO: 
Logging pods the kubelet thinks is on node wenjun191 before test
Feb 28 19:03:58.224: INFO: calico-node-xxbcr from kube-system started at 2020-02-28 18:55:09 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 19:03:58.224: INFO: node-exporter-m7r4n from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 19:03:58.224: INFO: custom-metrics-apiserver-7bf8c988f9-7rz52 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container custom-metrics-apiserver ready: true, restart count 0
Feb 28 19:03:58.224: INFO: chiwen-agent-9k95q from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 19:03:58.224: INFO: chiwen-volume-plugin-2jmh7 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container chiwen-volume-plugin ready: true, restart count 0
Feb 28 19:03:58.224: INFO: prometheus-deployment-55cfdd8597-pw6tt from kube-system started at 2020-02-28 18:55:10 +0000 UTC (4 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container alertmanager ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container prometheus ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container watch-alertmanager ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container watch-prometheus ready: true, restart count 0
Feb 28 19:03:58.224: INFO: etcd-wenjun191 from kube-system started at 2020-02-28 18:54:44 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container etcd ready: true, restart count 0
Feb 28 19:03:58.224: INFO: kube-scheduler-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container kube-scheduler ready: true, restart count 0
Feb 28 19:03:58.224: INFO: kube-apiserver-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container kube-apiserver ready: true, restart count 0
Feb 28 19:03:58.224: INFO: chiwen-k8s-agent-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container chiwen-k8s-agent ready: true, restart count 0
Feb 28 19:03:58.224: INFO: coredns-6879c49cff-wmp8f from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container coredns ready: true, restart count 0
Feb 28 19:03:58.224: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-wsn2d from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 28 19:03:58.224: INFO: calico-kube-controllers-5c94f45bd8-jpk5k from kube-system started at 2020-02-28 18:55:09 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 28 19:03:58.224: INFO: chiwen-ingress-controller-9n2n2 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 19:03:58.224: INFO: kube-controller-manager-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container kube-controller-manager ready: true, restart count 0
Feb 28 19:03:58.224: INFO: kube-state-metrics-6b5897fbb8-wfksz from kube-system started at 2020-02-28 18:55:23 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.224: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 28 19:03:58.224: INFO: 
Logging pods the kubelet thinks is on node wenjun192 before test
Feb 28 19:03:58.234: INFO: chiwen-volume-plugin-76hr8 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container chiwen-volume-plugin ready: true, restart count 0
Feb 28 19:03:58.234: INFO: sonobuoy-e2e-job-bb5a8e1744304000 from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container e2e ready: true, restart count 0
Feb 28 19:03:58.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 28 19:03:58.234: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-rfdrn from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 28 19:03:58.234: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 28 19:03:58.234: INFO: calico-node-8flfd from kube-system started at 2020-02-28 18:56:23 +0000 UTC (2 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 19:03:58.234: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 19:03:58.234: INFO: chiwen-agent-5fbpv from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 19:03:58.234: INFO: node-exporter-mfl29 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 19:03:58.234: INFO: chiwen-ingress-controller-9ccwn from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 19:03:58.234: INFO: sonobuoy from sonobuoy started at 2020-02-28 18:57:12 +0000 UTC (1 container statuses recorded)
Feb 28 19:03:58.234: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node wenjun191
STEP: verifying the node has the label node wenjun192
Feb 28 19:03:58.280: INFO: Pod calico-kube-controllers-5c94f45bd8-jpk5k requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.280: INFO: Pod calico-node-8flfd requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.280: INFO: Pod calico-node-xxbcr requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.280: INFO: Pod chiwen-agent-5fbpv requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.280: INFO: Pod chiwen-agent-9k95q requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.280: INFO: Pod chiwen-ingress-controller-9ccwn requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.280: INFO: Pod chiwen-ingress-controller-9n2n2 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod chiwen-k8s-agent-wenjun191 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod chiwen-volume-plugin-2jmh7 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod chiwen-volume-plugin-76hr8 requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.281: INFO: Pod coredns-6879c49cff-wmp8f requesting resource cpu=100m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod custom-metrics-apiserver-7bf8c988f9-7rz52 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod etcd-wenjun191 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod kube-apiserver-wenjun191 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod kube-controller-manager-wenjun191 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod kube-scheduler-wenjun191 requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod kube-state-metrics-6b5897fbb8-wfksz requesting resource cpu=101m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod node-exporter-m7r4n requesting resource cpu=0m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod node-exporter-mfl29 requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.281: INFO: Pod prometheus-deployment-55cfdd8597-pw6tt requesting resource cpu=250m on Node wenjun191
Feb 28 19:03:58.281: INFO: Pod sonobuoy requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.281: INFO: Pod sonobuoy-e2e-job-bb5a8e1744304000 requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.281: INFO: Pod sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-rfdrn requesting resource cpu=0m on Node wenjun192
Feb 28 19:03:58.281: INFO: Pod sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-wsn2d requesting resource cpu=0m on Node wenjun191
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db.15f7a64bc042147e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-268/filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db to wenjun192]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db.15f7a64c076e4687], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db.15f7a64c0b68915d], Reason = [Created], Message = [Created container filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db.15f7a64c193b46eb], Reason = [Started], Message = [Started container filler-pod-2f06ab10-178e-4e8d-83d9-dbcdb18316db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68.15f7a64bbf000db9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-268/filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68 to wenjun191]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68.15f7a64c0beadf8b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68.15f7a64c0f3305a2], Reason = [Created], Message = [Created container filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68.15f7a64c1c50a3c0], Reason = [Started], Message = [Started container filler-pod-d2af090c-bfb2-481b-a69c-e5b3c8e63f68]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f7a64caea8d33c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node wenjun191
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node wenjun192
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:04:03.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-268" for this suite.
Feb 28 19:04:09.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:04:09.556: INFO: namespace sched-pred-268 deletion completed in 6.153561498s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.413 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:04:09.557: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Feb 28 19:04:09.611: INFO: Waiting up to 5m0s for pod "client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b" in namespace "containers-7072" to be "success or failure"
Feb 28 19:04:09.622: INFO: Pod "client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.304883ms
Feb 28 19:04:11.628: INFO: Pod "client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016471954s
Feb 28 19:04:13.639: INFO: Pod "client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028070438s
STEP: Saw pod success
Feb 28 19:04:13.639: INFO: Pod "client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b" satisfied condition "success or failure"
Feb 28 19:04:13.643: INFO: Trying to get logs from node wenjun192 pod client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b container test-container: <nil>
STEP: delete the pod
Feb 28 19:04:13.667: INFO: Waiting for pod client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b to disappear
Feb 28 19:04:13.675: INFO: Pod client-containers-d2adf7b4-2e21-47c2-8cd5-f9ee78e5499b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:04:13.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7072" for this suite.
Feb 28 19:04:19.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:04:19.795: INFO: namespace containers-7072 deletion completed in 6.115774462s

• [SLOW TEST:10.239 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:04:19.798: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-7588/secret-test-d51a04ca-1f1f-44b5-b96a-b3715a996169
STEP: Creating a pod to test consume secrets
Feb 28 19:04:19.866: INFO: Waiting up to 5m0s for pod "pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612" in namespace "secrets-7588" to be "success or failure"
Feb 28 19:04:19.871: INFO: Pod "pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612": Phase="Pending", Reason="", readiness=false. Elapsed: 4.682374ms
Feb 28 19:04:21.874: INFO: Pod "pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008172409s
STEP: Saw pod success
Feb 28 19:04:21.874: INFO: Pod "pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612" satisfied condition "success or failure"
Feb 28 19:04:21.877: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612 container env-test: <nil>
STEP: delete the pod
Feb 28 19:04:21.905: INFO: Waiting for pod pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612 to disappear
Feb 28 19:04:21.909: INFO: Pod pod-configmaps-de66a32e-bff0-4f30-9202-4e20a01e4612 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:04:21.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7588" for this suite.
Feb 28 19:04:27.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:04:28.017: INFO: namespace secrets-7588 deletion completed in 6.099655258s

• [SLOW TEST:8.219 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:04:28.017: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Feb 28 19:04:28.059: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779692974 proxy --unix-socket=/tmp/kubectl-proxy-unix438185269/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:04:28.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5126" for this suite.
Feb 28 19:04:34.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:04:34.269: INFO: namespace kubectl-5126 deletion completed in 6.120006314s

• [SLOW TEST:6.252 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:04:34.270: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:04:34.311: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:04:36.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9270" for this suite.
Feb 28 19:05:22.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:05:22.481: INFO: namespace pods-9270 deletion completed in 46.12548283s

• [SLOW TEST:48.211 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:05:22.483: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-8402
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 28 19:05:22.531: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 28 19:05:50.658: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.34.187.24:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8402 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:05:50.658: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:05:50.810: INFO: Found all expected endpoints: [netserver-0]
Feb 28 19:05:50.814: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.35.253.75:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8402 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:05:50.814: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:05:50.947: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:05:50.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8402" for this suite.
Feb 28 19:06:12.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:06:13.062: INFO: namespace pod-network-test-8402 deletion completed in 22.111147644s

• [SLOW TEST:50.579 seconds]
[sig-network] Networking
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:06:13.064: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-85df7b56-91be-4480-922b-b97cf7e919b8
STEP: Creating a pod to test consume secrets
Feb 28 19:06:13.114: INFO: Waiting up to 5m0s for pod "pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4" in namespace "secrets-3007" to be "success or failure"
Feb 28 19:06:13.120: INFO: Pod "pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.636436ms
Feb 28 19:06:15.124: INFO: Pod "pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009933021s
Feb 28 19:06:17.129: INFO: Pod "pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014426963s
STEP: Saw pod success
Feb 28 19:06:17.129: INFO: Pod "pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4" satisfied condition "success or failure"
Feb 28 19:06:17.132: INFO: Trying to get logs from node wenjun192 pod pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4 container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:06:17.161: INFO: Waiting for pod pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4 to disappear
Feb 28 19:06:17.164: INFO: Pod pod-secrets-d82e6690-c24b-445a-9c9d-54cf2b43b5e4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:06:17.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3007" for this suite.
Feb 28 19:06:23.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:06:23.316: INFO: namespace secrets-3007 deletion completed in 6.144085221s

• [SLOW TEST:10.253 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:06:23.318: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Feb 28 19:06:23.377: INFO: Waiting up to 5m0s for pod "client-containers-7f879a60-ee86-4e5f-995e-8af12005a841" in namespace "containers-7160" to be "success or failure"
Feb 28 19:06:23.385: INFO: Pod "client-containers-7f879a60-ee86-4e5f-995e-8af12005a841": Phase="Pending", Reason="", readiness=false. Elapsed: 7.470765ms
Feb 28 19:06:25.390: INFO: Pod "client-containers-7f879a60-ee86-4e5f-995e-8af12005a841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012912094s
Feb 28 19:06:27.393: INFO: Pod "client-containers-7f879a60-ee86-4e5f-995e-8af12005a841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016338663s
STEP: Saw pod success
Feb 28 19:06:27.393: INFO: Pod "client-containers-7f879a60-ee86-4e5f-995e-8af12005a841" satisfied condition "success or failure"
Feb 28 19:06:27.397: INFO: Trying to get logs from node wenjun192 pod client-containers-7f879a60-ee86-4e5f-995e-8af12005a841 container test-container: <nil>
STEP: delete the pod
Feb 28 19:06:27.424: INFO: Waiting for pod client-containers-7f879a60-ee86-4e5f-995e-8af12005a841 to disappear
Feb 28 19:06:27.429: INFO: Pod client-containers-7f879a60-ee86-4e5f-995e-8af12005a841 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:06:27.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7160" for this suite.
Feb 28 19:06:33.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:06:33.527: INFO: namespace containers-7160 deletion completed in 6.09351997s

• [SLOW TEST:10.209 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:06:33.528: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:06:33.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e" in namespace "projected-9075" to be "success or failure"
Feb 28 19:06:33.567: INFO: Pod "downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.551811ms
Feb 28 19:06:35.572: INFO: Pod "downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e": Phase="Running", Reason="", readiness=true. Elapsed: 2.007307651s
Feb 28 19:06:37.576: INFO: Pod "downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01096003s
STEP: Saw pod success
Feb 28 19:06:37.576: INFO: Pod "downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e" satisfied condition "success or failure"
Feb 28 19:06:37.579: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e container client-container: <nil>
STEP: delete the pod
Feb 28 19:06:37.600: INFO: Waiting for pod downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e to disappear
Feb 28 19:06:37.602: INFO: Pod downwardapi-volume-3a02a7a4-d795-41c9-8e89-1353486fd60e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:06:37.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9075" for this suite.
Feb 28 19:06:43.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:06:43.823: INFO: namespace projected-9075 deletion completed in 6.216640979s

• [SLOW TEST:10.295 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:06:43.823: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Feb 28 19:06:43.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 api-versions'
Feb 28 19:06:44.015: INFO: stderr: ""
Feb 28 19:06:44.015: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncustom.metrics.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmiaoyun.io/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:06:44.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1225" for this suite.
Feb 28 19:06:50.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:06:50.110: INFO: namespace kubectl-1225 deletion completed in 6.089979256s

• [SLOW TEST:6.287 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:06:50.111: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 19:06:50.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-483'
Feb 28 19:06:50.436: INFO: stderr: ""
Feb 28 19:06:50.436: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 28 19:06:55.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pod e2e-test-nginx-pod --namespace=kubectl-483 -o json'
Feb 28 19:06:55.591: INFO: stderr: ""
Feb 28 19:06:55.591: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-02-28T19:06:50Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-483\",\n        \"resourceVersion\": \"3380\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-483/pods/e2e-test-nginx-pod\",\n        \"uid\": \"93305a93-2ef6-4af7-948c-0d8c0eb29143\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sjq8g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"wenjun192\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sjq8g\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sjq8g\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-28T19:06:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-28T19:06:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-28T19:06:52Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-28T19:06:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://e1326043c7c00aede6846186840b8c233e9568d58e55f8b9f115a2f1b6566bad\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-28T19:06:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.1.192\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.34.187.29\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-28T19:06:50Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 28 19:06:55.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 replace -f - --namespace=kubectl-483'
Feb 28 19:06:55.874: INFO: stderr: ""
Feb 28 19:06:55.874: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Feb 28 19:06:55.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete pods e2e-test-nginx-pod --namespace=kubectl-483'
Feb 28 19:06:58.399: INFO: stderr: ""
Feb 28 19:06:58.399: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:06:58.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-483" for this suite.
Feb 28 19:07:04.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:07:04.543: INFO: namespace kubectl-483 deletion completed in 6.137725876s

• [SLOW TEST:14.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:07:04.544: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 28 19:07:04.598: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3436,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 28 19:07:04.599: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3437,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 28 19:07:04.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3438,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 28 19:07:14.642: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3462,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 28 19:07:14.642: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3463,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 28 19:07:14.642: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2868,SelfLink:/api/v1/namespaces/watch-2868/configmaps/e2e-watch-test-label-changed,UID:dde19ea3-ba38-4307-96fa-9510b23e9ad7,ResourceVersion:3464,Generation:0,CreationTimestamp:2020-02-28 19:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:07:14.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2868" for this suite.
Feb 28 19:07:20.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:07:20.743: INFO: namespace watch-2868 deletion completed in 6.094236419s

• [SLOW TEST:16.199 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:07:20.744: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Feb 28 19:07:20.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-1304'
Feb 28 19:07:21.085: INFO: stderr: ""
Feb 28 19:07:21.085: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Feb 28 19:07:22.089: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:07:22.090: INFO: Found 0 / 1
Feb 28 19:07:23.089: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:07:23.089: INFO: Found 0 / 1
Feb 28 19:07:24.091: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:07:24.091: INFO: Found 0 / 1
Feb 28 19:07:25.088: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:07:25.088: INFO: Found 1 / 1
Feb 28 19:07:25.089: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 28 19:07:25.093: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:07:25.093: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 28 19:07:25.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304'
Feb 28 19:07:25.204: INFO: stderr: ""
Feb 28 19:07:25.204: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Feb 19:07:24.012 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Feb 19:07:24.012 # Server started, Redis version 3.2.12\n1:M 28 Feb 19:07:24.012 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Feb 19:07:24.012 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 28 19:07:25.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304 --tail=1'
Feb 28 19:07:25.311: INFO: stderr: ""
Feb 28 19:07:25.311: INFO: stdout: "1:M 28 Feb 19:07:24.012 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 28 19:07:25.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304 --limit-bytes=1'
Feb 28 19:07:25.419: INFO: stderr: ""
Feb 28 19:07:25.419: INFO: stdout: " "
STEP: exposing timestamps
Feb 28 19:07:25.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304 --tail=1 --timestamps'
Feb 28 19:07:25.520: INFO: stderr: ""
Feb 28 19:07:25.520: INFO: stdout: "2020-02-28T19:07:24.012820299Z 1:M 28 Feb 19:07:24.012 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 28 19:07:28.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304 --since=1s'
Feb 28 19:07:28.117: INFO: stderr: ""
Feb 28 19:07:28.117: INFO: stdout: ""
Feb 28 19:07:28.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-2nm2m redis-master --namespace=kubectl-1304 --since=24h'
Feb 28 19:07:28.232: INFO: stderr: ""
Feb 28 19:07:28.232: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Feb 19:07:24.012 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Feb 19:07:24.012 # Server started, Redis version 3.2.12\n1:M 28 Feb 19:07:24.012 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Feb 19:07:24.012 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Feb 28 19:07:28.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-1304'
Feb 28 19:07:28.340: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:07:28.340: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 28 19:07:28.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=nginx --no-headers --namespace=kubectl-1304'
Feb 28 19:07:28.461: INFO: stderr: "No resources found.\n"
Feb 28 19:07:28.461: INFO: stdout: ""
Feb 28 19:07:28.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=nginx --namespace=kubectl-1304 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 19:07:28.562: INFO: stderr: ""
Feb 28 19:07:28.562: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:07:28.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1304" for this suite.
Feb 28 19:07:50.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:07:50.691: INFO: namespace kubectl-1304 deletion completed in 22.115186224s

• [SLOW TEST:29.948 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:07:50.692: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5046
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 28 19:07:50.730: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 28 19:08:12.826: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.34.187.32:8080/dial?request=hostName&protocol=http&host=10.34.187.31&port=8080&tries=1'] Namespace:pod-network-test-5046 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:08:12.827: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:08:12.983: INFO: Waiting for endpoints: map[]
Feb 28 19:08:12.987: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.34.187.32:8080/dial?request=hostName&protocol=http&host=10.35.253.76&port=8080&tries=1'] Namespace:pod-network-test-5046 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:08:12.987: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:08:13.110: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:08:13.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5046" for this suite.
Feb 28 19:08:35.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:08:35.249: INFO: namespace pod-network-test-5046 deletion completed in 22.133896791s

• [SLOW TEST:44.557 seconds]
[sig-network] Networking
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:08:35.253: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 19:08:35.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3427'
Feb 28 19:08:35.402: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 28 19:08:35.402: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Feb 28 19:08:37.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3427'
Feb 28 19:08:37.514: INFO: stderr: ""
Feb 28 19:08:37.514: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:08:37.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3427" for this suite.
Feb 28 19:08:59.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:08:59.618: INFO: namespace kubectl-3427 deletion completed in 22.09872377s

• [SLOW TEST:24.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:08:59.620: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Feb 28 19:08:59.665: INFO: Waiting up to 5m0s for pod "var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7" in namespace "var-expansion-9132" to be "success or failure"
Feb 28 19:08:59.668: INFO: Pod "var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723868ms
Feb 28 19:09:01.673: INFO: Pod "var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007642704s
STEP: Saw pod success
Feb 28 19:09:01.673: INFO: Pod "var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7" satisfied condition "success or failure"
Feb 28 19:09:01.676: INFO: Trying to get logs from node wenjun192 pod var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7 container dapi-container: <nil>
STEP: delete the pod
Feb 28 19:09:01.695: INFO: Waiting for pod var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7 to disappear
Feb 28 19:09:01.699: INFO: Pod var-expansion-3f38960c-dfd1-42d0-8865-f07dccb937e7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:09:01.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9132" for this suite.
Feb 28 19:09:07.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:09:07.835: INFO: namespace var-expansion-9132 deletion completed in 6.124537402s

• [SLOW TEST:8.215 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:09:07.837: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:09:07.933: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 28 19:09:07.943: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 28 19:09:12.948: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 28 19:09:12.948: INFO: Creating deployment "test-rolling-update-deployment"
Feb 28 19:09:12.959: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 28 19:09:12.964: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 28 19:09:14.976: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 28 19:09:14.981: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 28 19:09:14.991: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-2503,SelfLink:/apis/apps/v1/namespaces/deployment-2503/deployments/test-rolling-update-deployment,UID:196c8534-1dd8-4f22-81ac-144d4a3dee02,ResourceVersion:3987,Generation:1,CreationTimestamp:2020-02-28 19:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-28 19:09:12 +0000 UTC 2020-02-28 19:09:12 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-28 19:09:14 +0000 UTC 2020-02-28 19:09:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 28 19:09:14.997: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-2503,SelfLink:/apis/apps/v1/namespaces/deployment-2503/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:70b14cfe-dd70-4607-a5c4-4d62b87e0ff7,ResourceVersion:3976,Generation:1,CreationTimestamp:2020-02-28 19:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 196c8534-1dd8-4f22-81ac-144d4a3dee02 0xc003231937 0xc003231938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 28 19:09:14.997: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 28 19:09:14.997: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-2503,SelfLink:/apis/apps/v1/namespaces/deployment-2503/replicasets/test-rolling-update-controller,UID:df19951e-431a-4b0d-a87c-766e9bc94731,ResourceVersion:3986,Generation:2,CreationTimestamp:2020-02-28 19:09:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 196c8534-1dd8-4f22-81ac-144d4a3dee02 0xc00323185f 0xc003231870}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 19:09:15.001: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-xgb9z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-xgb9z,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-2503,SelfLink:/api/v1/namespaces/deployment-2503/pods/test-rolling-update-deployment-79f6b9d75c-xgb9z,UID:96aa8a1a-7f3a-4cb8-8970-cbb30ba11f49,ResourceVersion:3975,Generation:0,CreationTimestamp:2020-02-28 19:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 70b14cfe-dd70-4607-a5c4-4d62b87e0ff7 0xc002abc217 0xc002abc218}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-v9bzz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v9bzz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-v9bzz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002abc290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002abc2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:09:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:09:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:09:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:09:12 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.36,StartTime:2020-02-28 19:09:13 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-28 19:09:14 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f0d4b2f6b375e9ad8d4fbb2856a7c0e86236ddb15c53dea6e81df3413f06b9ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:09:15.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2503" for this suite.
Feb 28 19:09:21.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:09:21.145: INFO: namespace deployment-2503 deletion completed in 6.139661675s

• [SLOW TEST:13.309 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:09:21.146: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-c17ac621-adb9-4f70-8207-a691104b0819
STEP: Creating a pod to test consume configMaps
Feb 28 19:09:21.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c" in namespace "projected-206" to be "success or failure"
Feb 28 19:09:21.206: INFO: Pod "pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933886ms
Feb 28 19:09:23.211: INFO: Pod "pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008597771s
STEP: Saw pod success
Feb 28 19:09:23.211: INFO: Pod "pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c" satisfied condition "success or failure"
Feb 28 19:09:23.216: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:09:23.245: INFO: Waiting for pod pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c to disappear
Feb 28 19:09:23.249: INFO: Pod pod-projected-configmaps-9507c3ac-56ff-4703-bed9-f20934b8ed0c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:09:23.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-206" for this suite.
Feb 28 19:09:29.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:09:29.357: INFO: namespace projected-206 deletion completed in 6.103243675s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:09:29.357: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 28 19:09:29.398: INFO: PodSpec: initContainers in spec.initContainers
Feb 28 19:10:19.969: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-cf98c119-8e05-4e2c-9cbf-822f72469a77", GenerateName:"", Namespace:"init-container-3688", SelfLink:"/api/v1/namespaces/init-container-3688/pods/pod-init-cf98c119-8e05-4e2c-9cbf-822f72469a77", UID:"d06cbcdd-39ef-449c-9f46-d70f10a47342", ResourceVersion:"4229", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718513769, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"398127219"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-nn4ws", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001953fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nn4ws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nn4ws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-nn4ws", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00034d868), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"wenjun192", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0027b8600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00034dfb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0005a6010)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0005a6018), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0005a601c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718513769, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718513769, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718513769, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718513769, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.1.192", PodIP:"10.34.187.38", StartTime:(*v1.Time)(0xc0015f07c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002bc71f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002bc7260)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://20704b6a29f4cb92b365ad05545870f95a4d4f6d8c3e7686458350a52713bcc8"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0015f0800), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0015f07e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:10:19.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3688" for this suite.
Feb 28 19:10:41.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:10:42.089: INFO: namespace init-container-3688 deletion completed in 22.111084963s

• [SLOW TEST:72.733 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:10:42.091: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-bd42f574-bc71-45ae-9d6c-3b6a8bbbbbcd
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-bd42f574-bc71-45ae-9d6c-3b6a8bbbbbcd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:12:16.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1389" for this suite.
Feb 28 19:12:38.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:12:38.911: INFO: namespace configmap-1389 deletion completed in 22.155085751s

• [SLOW TEST:116.820 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:12:38.912: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:12:38.960: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 28 19:12:43.964: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 28 19:12:43.964: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 28 19:12:45.996: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4051,SelfLink:/apis/apps/v1/namespaces/deployment-4051/deployments/test-cleanup-deployment,UID:6543e2b1-7e6c-401c-96ce-098c291bdb61,ResourceVersion:4646,Generation:1,CreationTimestamp:2020-02-28 19:12:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-28 19:12:43 +0000 UTC 2020-02-28 19:12:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-28 19:12:45 +0000 UTC 2020-02-28 19:12:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 28 19:12:45.999: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-4051,SelfLink:/apis/apps/v1/namespaces/deployment-4051/replicasets/test-cleanup-deployment-55bbcbc84c,UID:a35a5e3e-841b-4159-9a9f-c7c561071144,ResourceVersion:4635,Generation:1,CreationTimestamp:2020-02-28 19:12:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6543e2b1-7e6c-401c-96ce-098c291bdb61 0xc000662ad7 0xc000662ad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 28 19:12:46.003: INFO: Pod "test-cleanup-deployment-55bbcbc84c-kzl6l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-kzl6l,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-4051,SelfLink:/api/v1/namespaces/deployment-4051/pods/test-cleanup-deployment-55bbcbc84c-kzl6l,UID:48de409b-2fea-4749-91ad-dfa422e8d8de,ResourceVersion:4634,Generation:0,CreationTimestamp:2020-02-28 19:12:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c a35a5e3e-841b-4159-9a9f-c7c561071144 0xc001e7be07 0xc001e7be08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5vv4p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5vv4p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5vv4p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e7be80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e7bea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:12:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:12:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:12:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 19:12:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.41,StartTime:2020-02-28 19:12:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-28 19:12:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6357182c56202bb5423bb41c67794f2ef3b8781dd3cea2f2bd956d1c6ad1e28a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:12:46.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4051" for this suite.
Feb 28 19:12:52.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:12:52.125: INFO: namespace deployment-4051 deletion completed in 6.115832549s

• [SLOW TEST:13.213 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:12:52.126: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:12:52.188: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12" in namespace "projected-4421" to be "success or failure"
Feb 28 19:12:52.196: INFO: Pod "downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.88695ms
Feb 28 19:12:54.202: INFO: Pod "downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01167436s
STEP: Saw pod success
Feb 28 19:12:54.202: INFO: Pod "downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12" satisfied condition "success or failure"
Feb 28 19:12:54.206: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12 container client-container: <nil>
STEP: delete the pod
Feb 28 19:12:54.248: INFO: Waiting for pod downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12 to disappear
Feb 28 19:12:54.252: INFO: Pod downwardapi-volume-a7149e35-47cd-46d1-9684-b4c2c0d51b12 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:12:54.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4421" for this suite.
Feb 28 19:13:00.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:00.353: INFO: namespace projected-4421 deletion completed in 6.098475884s

• [SLOW TEST:8.227 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:00.355: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f7aec50e-dae0-4db9-ad0d-ac873f53d0b8
STEP: Creating a pod to test consume configMaps
Feb 28 19:13:00.401: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6" in namespace "projected-406" to be "success or failure"
Feb 28 19:13:00.406: INFO: Pod "pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.806364ms
Feb 28 19:13:02.410: INFO: Pod "pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00887415s
STEP: Saw pod success
Feb 28 19:13:02.410: INFO: Pod "pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6" satisfied condition "success or failure"
Feb 28 19:13:02.413: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:13:02.443: INFO: Waiting for pod pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6 to disappear
Feb 28 19:13:02.445: INFO: Pod pod-projected-configmaps-39194207-d3d6-4438-b62a-2f2d9fd18ff6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:13:02.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-406" for this suite.
Feb 28 19:13:08.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:08.562: INFO: namespace projected-406 deletion completed in 6.113151492s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:08.563: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5832a4e2-ac56-453a-8bd2-c81c0a13c3f8
STEP: Creating a pod to test consume secrets
Feb 28 19:13:08.678: INFO: Waiting up to 5m0s for pod "pod-secrets-630f5499-e30a-4076-896d-25521c50bafd" in namespace "secrets-2950" to be "success or failure"
Feb 28 19:13:08.683: INFO: Pod "pod-secrets-630f5499-e30a-4076-896d-25521c50bafd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.580492ms
Feb 28 19:13:10.687: INFO: Pod "pod-secrets-630f5499-e30a-4076-896d-25521c50bafd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009543045s
STEP: Saw pod success
Feb 28 19:13:10.687: INFO: Pod "pod-secrets-630f5499-e30a-4076-896d-25521c50bafd" satisfied condition "success or failure"
Feb 28 19:13:10.690: INFO: Trying to get logs from node wenjun192 pod pod-secrets-630f5499-e30a-4076-896d-25521c50bafd container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:13:10.709: INFO: Waiting for pod pod-secrets-630f5499-e30a-4076-896d-25521c50bafd to disappear
Feb 28 19:13:10.713: INFO: Pod pod-secrets-630f5499-e30a-4076-896d-25521c50bafd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:13:10.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2950" for this suite.
Feb 28 19:13:16.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:16.807: INFO: namespace secrets-2950 deletion completed in 6.08920145s
STEP: Destroying namespace "secret-namespace-6913" for this suite.
Feb 28 19:13:22.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:22.928: INFO: namespace secret-namespace-6913 deletion completed in 6.120970248s

• [SLOW TEST:14.365 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:22.929: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Feb 28 19:13:22.980: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779692974 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:13:23.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1805" for this suite.
Feb 28 19:13:29.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:29.188: INFO: namespace kubectl-1805 deletion completed in 6.115445376s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:29.188: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:13:29.225: INFO: Creating ReplicaSet my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f
Feb 28 19:13:29.235: INFO: Pod name my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f: Found 0 pods out of 1
Feb 28 19:13:34.240: INFO: Pod name my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f: Found 1 pods out of 1
Feb 28 19:13:34.240: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f" is running
Feb 28 19:13:34.246: INFO: Pod "my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f-k57wp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:13:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:13:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:13:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:13:29 +0000 UTC Reason: Message:}])
Feb 28 19:13:34.246: INFO: Trying to dial the pod
Feb 28 19:13:39.272: INFO: Controller my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f: Got expected result from replica 1 [my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f-k57wp]: "my-hostname-basic-f1833ea2-681c-41df-8684-90c038cd1f7f-k57wp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:13:39.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5017" for this suite.
Feb 28 19:13:45.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:45.389: INFO: namespace replicaset-5017 deletion completed in 6.111073671s

• [SLOW TEST:16.201 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:45.389: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 28 19:13:47.452: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:13:47.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-265" for this suite.
Feb 28 19:13:53.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:13:53.598: INFO: namespace container-runtime-265 deletion completed in 6.105386521s

• [SLOW TEST:8.209 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:13:53.602: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2348
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 28 19:13:53.676: INFO: Found 0 stateful pods, waiting for 3
Feb 28 19:14:03.683: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 19:14:03.683: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 19:14:03.683: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 19:14:03.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-2348 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:14:04.074: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:14:04.074: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:14:04.074: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 28 19:14:14.116: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 28 19:14:24.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-2348 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:14:24.441: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:14:24.441: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:14:24.441: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:14:34.462: INFO: Waiting for StatefulSet statefulset-2348/ss2 to complete update
Feb 28 19:14:34.462: INFO: Waiting for Pod statefulset-2348/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:14:34.462: INFO: Waiting for Pod statefulset-2348/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:14:34.462: INFO: Waiting for Pod statefulset-2348/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:14:44.473: INFO: Waiting for StatefulSet statefulset-2348/ss2 to complete update
Feb 28 19:14:44.473: INFO: Waiting for Pod statefulset-2348/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:14:44.473: INFO: Waiting for Pod statefulset-2348/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:14:54.469: INFO: Waiting for StatefulSet statefulset-2348/ss2 to complete update
Feb 28 19:14:54.469: INFO: Waiting for Pod statefulset-2348/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 28 19:15:04.470: INFO: Waiting for StatefulSet statefulset-2348/ss2 to complete update
Feb 28 19:15:04.470: INFO: Waiting for Pod statefulset-2348/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Feb 28 19:15:14.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-2348 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:15:14.813: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:15:14.814: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:15:14.814: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 19:15:24.849: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 28 19:15:34.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-2348 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:15:35.168: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:15:35.168: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:15:35.168: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:16:05.193: INFO: Waiting for StatefulSet statefulset-2348/ss2 to complete update
Feb 28 19:16:05.193: INFO: Waiting for Pod statefulset-2348/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 28 19:16:15.207: INFO: Deleting all statefulset in ns statefulset-2348
Feb 28 19:16:15.212: INFO: Scaling statefulset ss2 to 0
Feb 28 19:16:35.234: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 19:16:35.241: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:16:35.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2348" for this suite.
Feb 28 19:16:41.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:16:41.364: INFO: namespace statefulset-2348 deletion completed in 6.096674906s

• [SLOW TEST:167.763 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:16:41.365: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Feb 28 19:16:41.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 cluster-info'
Feb 28 19:16:41.514: INFO: stderr: ""
Feb 28 19:16:41.514: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:16:41.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3556" for this suite.
Feb 28 19:16:47.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:16:47.629: INFO: namespace kubectl-3556 deletion completed in 6.109392746s

• [SLOW TEST:6.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:16:47.631: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-068d7e48-8592-42ad-b952-8cfd0761ba83
STEP: Creating a pod to test consume secrets
Feb 28 19:16:47.683: INFO: Waiting up to 5m0s for pod "pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82" in namespace "secrets-5791" to be "success or failure"
Feb 28 19:16:47.689: INFO: Pod "pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82": Phase="Pending", Reason="", readiness=false. Elapsed: 5.872964ms
Feb 28 19:16:49.694: INFO: Pod "pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010795387s
STEP: Saw pod success
Feb 28 19:16:49.694: INFO: Pod "pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82" satisfied condition "success or failure"
Feb 28 19:16:49.697: INFO: Trying to get logs from node wenjun192 pod pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82 container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:16:49.732: INFO: Waiting for pod pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82 to disappear
Feb 28 19:16:49.736: INFO: Pod pod-secrets-f72ebdbe-40fa-4747-b75f-b67324378a82 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:16:49.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5791" for this suite.
Feb 28 19:16:55.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:16:55.885: INFO: namespace secrets-5791 deletion completed in 6.14565158s

• [SLOW TEST:8.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:16:55.888: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 28 19:16:55.935: INFO: Waiting up to 5m0s for pod "pod-5202a50e-e3e8-466d-a151-5c87bb9f850b" in namespace "emptydir-4909" to be "success or failure"
Feb 28 19:16:55.941: INFO: Pod "pod-5202a50e-e3e8-466d-a151-5c87bb9f850b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.923392ms
Feb 28 19:16:57.945: INFO: Pod "pod-5202a50e-e3e8-466d-a151-5c87bb9f850b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010409685s
STEP: Saw pod success
Feb 28 19:16:57.945: INFO: Pod "pod-5202a50e-e3e8-466d-a151-5c87bb9f850b" satisfied condition "success or failure"
Feb 28 19:16:57.948: INFO: Trying to get logs from node wenjun192 pod pod-5202a50e-e3e8-466d-a151-5c87bb9f850b container test-container: <nil>
STEP: delete the pod
Feb 28 19:16:57.973: INFO: Waiting for pod pod-5202a50e-e3e8-466d-a151-5c87bb9f850b to disappear
Feb 28 19:16:57.977: INFO: Pod pod-5202a50e-e3e8-466d-a151-5c87bb9f850b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:16:57.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4909" for this suite.
Feb 28 19:17:03.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:04.091: INFO: namespace emptydir-4909 deletion completed in 6.107723765s

• [SLOW TEST:8.203 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:04.091: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 28 19:17:06.145: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:06.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7565" for this suite.
Feb 28 19:17:12.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:12.312: INFO: namespace container-runtime-7565 deletion completed in 6.132470392s

• [SLOW TEST:8.220 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:12.314: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-4614/configmap-test-753b308d-f516-4043-9913-4cd01743ee1e
STEP: Creating a pod to test consume configMaps
Feb 28 19:17:12.369: INFO: Waiting up to 5m0s for pod "pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd" in namespace "configmap-4614" to be "success or failure"
Feb 28 19:17:12.371: INFO: Pod "pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.645084ms
Feb 28 19:17:14.375: INFO: Pod "pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006368318s
STEP: Saw pod success
Feb 28 19:17:14.375: INFO: Pod "pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd" satisfied condition "success or failure"
Feb 28 19:17:14.379: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd container env-test: <nil>
STEP: delete the pod
Feb 28 19:17:14.401: INFO: Waiting for pod pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd to disappear
Feb 28 19:17:14.404: INFO: Pod pod-configmaps-35494ee7-9d87-4cef-b6b8-b3f5022e8bdd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:14.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4614" for this suite.
Feb 28 19:17:20.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:20.526: INFO: namespace configmap-4614 deletion completed in 6.117869625s

• [SLOW TEST:8.212 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:20.527: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:17:20.579: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6" in namespace "downward-api-1961" to be "success or failure"
Feb 28 19:17:20.583: INFO: Pod "downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.670384ms
Feb 28 19:17:22.589: INFO: Pod "downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009875118s
STEP: Saw pod success
Feb 28 19:17:22.589: INFO: Pod "downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6" satisfied condition "success or failure"
Feb 28 19:17:22.603: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6 container client-container: <nil>
STEP: delete the pod
Feb 28 19:17:22.623: INFO: Waiting for pod downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6 to disappear
Feb 28 19:17:22.626: INFO: Pod downwardapi-volume-fe6aa207-94a3-4956-aa70-f22a73ecbca6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:22.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1961" for this suite.
Feb 28 19:17:28.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:28.779: INFO: namespace downward-api-1961 deletion completed in 6.14896358s

• [SLOW TEST:8.252 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:28.780: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 28 19:17:28.841: INFO: Waiting up to 5m0s for pod "downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776" in namespace "downward-api-4413" to be "success or failure"
Feb 28 19:17:28.843: INFO: Pod "downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729424ms
Feb 28 19:17:30.849: INFO: Pod "downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008560944s
STEP: Saw pod success
Feb 28 19:17:30.849: INFO: Pod "downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776" satisfied condition "success or failure"
Feb 28 19:17:30.856: INFO: Trying to get logs from node wenjun192 pod downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776 container dapi-container: <nil>
STEP: delete the pod
Feb 28 19:17:30.884: INFO: Waiting for pod downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776 to disappear
Feb 28 19:17:30.921: INFO: Pod downward-api-954b99b3-f25c-4b71-ac23-f6171c8fc776 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:30.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4413" for this suite.
Feb 28 19:17:36.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:37.037: INFO: namespace downward-api-4413 deletion completed in 6.109868523s

• [SLOW TEST:8.257 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:37.038: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:17:37.088: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5" in namespace "projected-9602" to be "success or failure"
Feb 28 19:17:37.111: INFO: Pod "downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.175707ms
Feb 28 19:17:39.122: INFO: Pod "downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033571662s
Feb 28 19:17:41.126: INFO: Pod "downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037635937s
STEP: Saw pod success
Feb 28 19:17:41.126: INFO: Pod "downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5" satisfied condition "success or failure"
Feb 28 19:17:41.129: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5 container client-container: <nil>
STEP: delete the pod
Feb 28 19:17:41.154: INFO: Waiting for pod downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5 to disappear
Feb 28 19:17:41.157: INFO: Pod downwardapi-volume-1c46006b-c475-4f39-8166-ef5e0e56dbb5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:41.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9602" for this suite.
Feb 28 19:17:47.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:47.270: INFO: namespace projected-9602 deletion completed in 6.109907407s

• [SLOW TEST:10.232 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:47.271: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:17:47.319: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 28 19:17:49.369: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:17:50.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1964" for this suite.
Feb 28 19:17:56.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:17:56.582: INFO: namespace replication-controller-1964 deletion completed in 6.120794156s

• [SLOW TEST:9.311 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:17:56.583: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:18:02.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1619" for this suite.
Feb 28 19:18:08.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:18:08.403: INFO: namespace watch-1619 deletion completed in 6.212060137s

• [SLOW TEST:11.820 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:18:08.406: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-1141
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1141 to expose endpoints map[]
Feb 28 19:18:08.480: INFO: Get endpoints failed (12.407155ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 28 19:18:09.483: INFO: successfully validated that service endpoint-test2 in namespace services-1141 exposes endpoints map[] (1.015870591s elapsed)
STEP: Creating pod pod1 in namespace services-1141
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1141 to expose endpoints map[pod1:[80]]
Feb 28 19:18:12.530: INFO: successfully validated that service endpoint-test2 in namespace services-1141 exposes endpoints map[pod1:[80]] (3.037204435s elapsed)
STEP: Creating pod pod2 in namespace services-1141
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1141 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 28 19:18:15.603: INFO: successfully validated that service endpoint-test2 in namespace services-1141 exposes endpoints map[pod1:[80] pod2:[80]] (3.055065607s elapsed)
STEP: Deleting pod pod1 in namespace services-1141
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1141 to expose endpoints map[pod2:[80]]
Feb 28 19:18:16.626: INFO: successfully validated that service endpoint-test2 in namespace services-1141 exposes endpoints map[pod2:[80]] (1.017655672s elapsed)
STEP: Deleting pod pod2 in namespace services-1141
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1141 to expose endpoints map[]
Feb 28 19:18:17.644: INFO: successfully validated that service endpoint-test2 in namespace services-1141 exposes endpoints map[] (1.013220885s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:18:17.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1141" for this suite.
Feb 28 19:18:39.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:18:39.861: INFO: namespace services-1141 deletion completed in 22.182741268s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.455 seconds]
[sig-network] Services
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:18:39.862: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:18:43.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6890" for this suite.
Feb 28 19:18:49.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:18:50.035: INFO: namespace kubelet-test-6890 deletion completed in 6.11136452s

• [SLOW TEST:10.173 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:18:50.036: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 28 19:18:50.093: INFO: Waiting up to 5m0s for pod "downward-api-622011f9-99fc-4c49-a9a7-90df82590a10" in namespace "downward-api-4912" to be "success or failure"
Feb 28 19:18:50.098: INFO: Pod "downward-api-622011f9-99fc-4c49-a9a7-90df82590a10": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346757ms
Feb 28 19:18:52.101: INFO: Pod "downward-api-622011f9-99fc-4c49-a9a7-90df82590a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007839329s
STEP: Saw pod success
Feb 28 19:18:52.101: INFO: Pod "downward-api-622011f9-99fc-4c49-a9a7-90df82590a10" satisfied condition "success or failure"
Feb 28 19:18:52.106: INFO: Trying to get logs from node wenjun192 pod downward-api-622011f9-99fc-4c49-a9a7-90df82590a10 container dapi-container: <nil>
STEP: delete the pod
Feb 28 19:18:52.171: INFO: Waiting for pod downward-api-622011f9-99fc-4c49-a9a7-90df82590a10 to disappear
Feb 28 19:18:52.176: INFO: Pod downward-api-622011f9-99fc-4c49-a9a7-90df82590a10 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:18:52.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4912" for this suite.
Feb 28 19:18:58.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:18:58.293: INFO: namespace downward-api-4912 deletion completed in 6.112091154s

• [SLOW TEST:8.258 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:18:58.294: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 28 19:19:02.392: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 28 19:19:02.396: INFO: Pod pod-with-prestop-http-hook still exists
Feb 28 19:19:04.396: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 28 19:19:04.401: INFO: Pod pod-with-prestop-http-hook still exists
Feb 28 19:19:06.396: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 28 19:19:06.400: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:19:06.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1548" for this suite.
Feb 28 19:19:28.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:19:28.536: INFO: namespace container-lifecycle-hook-1548 deletion completed in 22.118966436s

• [SLOW TEST:30.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:19:28.538: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Feb 28 19:19:28.592: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 28 19:19:28.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:29.077: INFO: stderr: ""
Feb 28 19:19:29.077: INFO: stdout: "service/redis-slave created\n"
Feb 28 19:19:29.078: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 28 19:19:29.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:29.288: INFO: stderr: ""
Feb 28 19:19:29.288: INFO: stdout: "service/redis-master created\n"
Feb 28 19:19:29.289: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 28 19:19:29.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:29.514: INFO: stderr: ""
Feb 28 19:19:29.514: INFO: stdout: "service/frontend created\n"
Feb 28 19:19:29.516: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 28 19:19:29.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:29.698: INFO: stderr: ""
Feb 28 19:19:29.699: INFO: stdout: "deployment.apps/frontend created\n"
Feb 28 19:19:29.699: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 28 19:19:29.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:29.896: INFO: stderr: ""
Feb 28 19:19:29.896: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 28 19:19:29.897: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 28 19:19:29.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6112'
Feb 28 19:19:30.105: INFO: stderr: ""
Feb 28 19:19:30.105: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 28 19:19:30.105: INFO: Waiting for all frontend pods to be Running.
Feb 28 19:19:35.157: INFO: Waiting for frontend to serve content.
Feb 28 19:19:40.194: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 28 19:19:45.220: INFO: Trying to add a new entry to the guestbook.
Feb 28 19:19:45.235: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 28 19:19:45.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.376: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.376: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 28 19:19:45.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.532: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.532: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 28 19:19:45.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.643: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.643: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 28 19:19:45.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.740: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.740: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 28 19:19:45.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.827: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.827: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 28 19:19:45.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6112'
Feb 28 19:19:45.925: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:19:45.925: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:19:45.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6112" for this suite.
Feb 28 19:20:27.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:20:28.057: INFO: namespace kubectl-6112 deletion completed in 42.126506576s

• [SLOW TEST:59.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:20:28.058: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-197728bf-94b6-4a1b-9129-47e05d593603
STEP: Creating a pod to test consume secrets
Feb 28 19:20:28.109: INFO: Waiting up to 5m0s for pod "pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80" in namespace "secrets-2141" to be "success or failure"
Feb 28 19:20:28.128: INFO: Pod "pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80": Phase="Pending", Reason="", readiness=false. Elapsed: 19.043748ms
Feb 28 19:20:30.133: INFO: Pod "pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023128635s
STEP: Saw pod success
Feb 28 19:20:30.133: INFO: Pod "pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80" satisfied condition "success or failure"
Feb 28 19:20:30.140: INFO: Trying to get logs from node wenjun192 pod pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80 container secret-env-test: <nil>
STEP: delete the pod
Feb 28 19:20:30.162: INFO: Waiting for pod pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80 to disappear
Feb 28 19:20:30.167: INFO: Pod pod-secrets-0972ffca-f50f-4204-89c6-d52c7186da80 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:20:30.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2141" for this suite.
Feb 28 19:20:36.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:20:36.306: INFO: namespace secrets-2141 deletion completed in 6.133903025s

• [SLOW TEST:8.248 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:20:36.308: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 28 19:20:38.887: INFO: Successfully updated pod "annotationupdateb38778fe-e067-45d8-a0f6-ebb3f26a0ee7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:20:40.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-527" for this suite.
Feb 28 19:21:02.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:21:03.055: INFO: namespace downward-api-527 deletion completed in 22.137679999s

• [SLOW TEST:26.747 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:21:03.057: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-zg56r in namespace proxy-3888
I0228 19:21:03.139124      17 runners.go:180] Created replication controller with name: proxy-service-zg56r, namespace: proxy-3888, replica count: 1
I0228 19:21:04.189858      17 runners.go:180] proxy-service-zg56r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0228 19:21:05.190210      17 runners.go:180] proxy-service-zg56r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0228 19:21:06.190644      17 runners.go:180] proxy-service-zg56r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0228 19:21:07.191030      17 runners.go:180] proxy-service-zg56r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0228 19:21:08.191496      17 runners.go:180] proxy-service-zg56r Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 28 19:21:08.196: INFO: setup took 5.09320443s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 28 19:21:08.209: INFO: (0) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 13.302286ms)
Feb 28 19:21:08.209: INFO: (0) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 12.793817ms)
Feb 28 19:21:08.214: INFO: (0) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 17.950927ms)
Feb 28 19:21:08.214: INFO: (0) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 17.876653ms)
Feb 28 19:21:08.214: INFO: (0) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 17.724175ms)
Feb 28 19:21:08.214: INFO: (0) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 17.698097ms)
Feb 28 19:21:08.219: INFO: (0) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 22.926775ms)
Feb 28 19:21:08.225: INFO: (0) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 29.041846ms)
Feb 28 19:21:08.225: INFO: (0) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 29.186863ms)
Feb 28 19:21:08.225: INFO: (0) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 29.501414ms)
Feb 28 19:21:08.225: INFO: (0) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 29.422987ms)
Feb 28 19:21:08.225: INFO: (0) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 29.746205ms)
Feb 28 19:21:08.234: INFO: (0) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 38.05153ms)
Feb 28 19:21:08.234: INFO: (0) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 38.261428ms)
Feb 28 19:21:08.235: INFO: (0) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 38.521718ms)
Feb 28 19:21:08.235: INFO: (0) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 38.733439ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 10.427976ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.202371ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 11.772618ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.110769ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.305306ms)
Feb 28 19:21:08.247: INFO: (1) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 10.831825ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 12.775336ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 11.47098ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 12.594133ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 12.00202ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 11.241652ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 12.81876ms)
Feb 28 19:21:08.248: INFO: (1) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 12.363242ms)
Feb 28 19:21:08.249: INFO: (1) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 13.073061ms)
Feb 28 19:21:08.249: INFO: (1) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 12.401311ms)
Feb 28 19:21:08.249: INFO: (1) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 12.982192ms)
Feb 28 19:21:08.255: INFO: (2) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 5.771514ms)
Feb 28 19:21:08.255: INFO: (2) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 5.443405ms)
Feb 28 19:21:08.255: INFO: (2) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 6.085792ms)
Feb 28 19:21:08.255: INFO: (2) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 5.577528ms)
Feb 28 19:21:08.266: INFO: (2) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 16.262856ms)
Feb 28 19:21:08.269: INFO: (2) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 18.96965ms)
Feb 28 19:21:08.270: INFO: (2) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 20.379671ms)
Feb 28 19:21:08.270: INFO: (2) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 21.48654ms)
Feb 28 19:21:08.270: INFO: (2) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 19.732617ms)
Feb 28 19:21:08.271: INFO: (2) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 19.396765ms)
Feb 28 19:21:08.271: INFO: (2) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 19.892659ms)
Feb 28 19:21:08.271: INFO: (2) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 20.371068ms)
Feb 28 19:21:08.272: INFO: (2) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 20.239425ms)
Feb 28 19:21:08.272: INFO: (2) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 21.648948ms)
Feb 28 19:21:08.272: INFO: (2) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 20.807524ms)
Feb 28 19:21:08.273: INFO: (2) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 23.028091ms)
Feb 28 19:21:08.287: INFO: (3) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 13.244835ms)
Feb 28 19:21:08.287: INFO: (3) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 13.468821ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 14.731214ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 14.86521ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 14.042077ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 14.569868ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 14.332718ms)
Feb 28 19:21:08.288: INFO: (3) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 15.01849ms)
Feb 28 19:21:08.292: INFO: (3) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 18.9922ms)
Feb 28 19:21:08.293: INFO: (3) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 19.293534ms)
Feb 28 19:21:08.301: INFO: (3) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 26.844968ms)
Feb 28 19:21:08.303: INFO: (3) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 29.576377ms)
Feb 28 19:21:08.303: INFO: (3) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 29.81992ms)
Feb 28 19:21:08.305: INFO: (3) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 31.357351ms)
Feb 28 19:21:08.305: INFO: (3) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 31.545406ms)
Feb 28 19:21:08.306: INFO: (3) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 31.942339ms)
Feb 28 19:21:08.321: INFO: (4) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 12.99322ms)
Feb 28 19:21:08.321: INFO: (4) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 15.588048ms)
Feb 28 19:21:08.321: INFO: (4) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 15.250386ms)
Feb 28 19:21:08.322: INFO: (4) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 15.805233ms)
Feb 28 19:21:08.323: INFO: (4) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 16.047665ms)
Feb 28 19:21:08.323: INFO: (4) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 16.453733ms)
Feb 28 19:21:08.323: INFO: (4) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 15.75882ms)
Feb 28 19:21:08.324: INFO: (4) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 16.375065ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 23.884394ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 23.295975ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 22.98633ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 24.195388ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 24.529281ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 24.827132ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 24.407765ms)
Feb 28 19:21:08.331: INFO: (4) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 23.882525ms)
Feb 28 19:21:08.342: INFO: (5) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.957633ms)
Feb 28 19:21:08.343: INFO: (5) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 10.206072ms)
Feb 28 19:21:08.343: INFO: (5) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 9.517024ms)
Feb 28 19:21:08.346: INFO: (5) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 11.645231ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 15.152967ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 13.660973ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 14.612628ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 13.37144ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 14.460929ms)
Feb 28 19:21:08.347: INFO: (5) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 14.07958ms)
Feb 28 19:21:08.348: INFO: (5) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 14.313628ms)
Feb 28 19:21:08.348: INFO: (5) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 15.445543ms)
Feb 28 19:21:08.348: INFO: (5) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 13.835536ms)
Feb 28 19:21:08.348: INFO: (5) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 14.972544ms)
Feb 28 19:21:08.348: INFO: (5) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 16.103437ms)
Feb 28 19:21:08.349: INFO: (5) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 15.35192ms)
Feb 28 19:21:08.359: INFO: (6) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 10.082523ms)
Feb 28 19:21:08.360: INFO: (6) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 10.778147ms)
Feb 28 19:21:08.360: INFO: (6) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 11.181517ms)
Feb 28 19:21:08.360: INFO: (6) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 10.272813ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 11.489876ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.646739ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.889534ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 11.404544ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 11.591456ms)
Feb 28 19:21:08.362: INFO: (6) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.701721ms)
Feb 28 19:21:08.363: INFO: (6) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 13.678021ms)
Feb 28 19:21:08.363: INFO: (6) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 13.30432ms)
Feb 28 19:21:08.363: INFO: (6) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 13.630537ms)
Feb 28 19:21:08.364: INFO: (6) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 13.182064ms)
Feb 28 19:21:08.365: INFO: (6) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 15.050141ms)
Feb 28 19:21:08.366: INFO: (6) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 15.547157ms)
Feb 28 19:21:08.371: INFO: (7) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 4.972085ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 9.538079ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 9.48334ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 9.549715ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 9.798378ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 9.360417ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.673867ms)
Feb 28 19:21:08.376: INFO: (7) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.976332ms)
Feb 28 19:21:08.377: INFO: (7) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 10.510905ms)
Feb 28 19:21:08.377: INFO: (7) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 10.863708ms)
Feb 28 19:21:08.377: INFO: (7) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 10.489262ms)
Feb 28 19:21:08.378: INFO: (7) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 11.184472ms)
Feb 28 19:21:08.378: INFO: (7) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 10.93116ms)
Feb 28 19:21:08.378: INFO: (7) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 10.997862ms)
Feb 28 19:21:08.378: INFO: (7) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 11.151941ms)
Feb 28 19:21:08.380: INFO: (7) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 12.817065ms)
Feb 28 19:21:08.385: INFO: (8) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 5.323434ms)
Feb 28 19:21:08.385: INFO: (8) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 5.281079ms)
Feb 28 19:21:08.386: INFO: (8) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 6.27738ms)
Feb 28 19:21:08.387: INFO: (8) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 6.156561ms)
Feb 28 19:21:08.389: INFO: (8) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 7.857503ms)
Feb 28 19:21:08.389: INFO: (8) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 8.538509ms)
Feb 28 19:21:08.390: INFO: (8) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 9.193541ms)
Feb 28 19:21:08.390: INFO: (8) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 9.582302ms)
Feb 28 19:21:08.391: INFO: (8) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 10.958925ms)
Feb 28 19:21:08.391: INFO: (8) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 11.165543ms)
Feb 28 19:21:08.392: INFO: (8) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.579972ms)
Feb 28 19:21:08.393: INFO: (8) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 12.842199ms)
Feb 28 19:21:08.393: INFO: (8) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 12.473411ms)
Feb 28 19:21:08.395: INFO: (8) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 14.16596ms)
Feb 28 19:21:08.395: INFO: (8) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 13.594952ms)
Feb 28 19:21:08.396: INFO: (8) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 14.791754ms)
Feb 28 19:21:08.405: INFO: (9) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 9.335749ms)
Feb 28 19:21:08.406: INFO: (9) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 9.423693ms)
Feb 28 19:21:08.406: INFO: (9) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 9.52443ms)
Feb 28 19:21:08.406: INFO: (9) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 10.095567ms)
Feb 28 19:21:08.406: INFO: (9) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 10.16608ms)
Feb 28 19:21:08.408: INFO: (9) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 11.415513ms)
Feb 28 19:21:08.408: INFO: (9) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 12.032647ms)
Feb 28 19:21:08.409: INFO: (9) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 12.893431ms)
Feb 28 19:21:08.409: INFO: (9) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 13.064335ms)
Feb 28 19:21:08.410: INFO: (9) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 13.315271ms)
Feb 28 19:21:08.410: INFO: (9) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 13.443213ms)
Feb 28 19:21:08.410: INFO: (9) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 14.196951ms)
Feb 28 19:21:08.410: INFO: (9) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 14.015047ms)
Feb 28 19:21:08.410: INFO: (9) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 14.36283ms)
Feb 28 19:21:08.411: INFO: (9) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 14.626959ms)
Feb 28 19:21:08.411: INFO: (9) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 14.818826ms)
Feb 28 19:21:08.418: INFO: (10) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 6.35954ms)
Feb 28 19:21:08.419: INFO: (10) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 7.39846ms)
Feb 28 19:21:08.420: INFO: (10) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 8.649924ms)
Feb 28 19:21:08.420: INFO: (10) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 8.863064ms)
Feb 28 19:21:08.421: INFO: (10) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 8.580782ms)
Feb 28 19:21:08.421: INFO: (10) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 9.325174ms)
Feb 28 19:21:08.422: INFO: (10) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.195319ms)
Feb 28 19:21:08.423: INFO: (10) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 11.25697ms)
Feb 28 19:21:08.427: INFO: (10) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 14.603378ms)
Feb 28 19:21:08.427: INFO: (10) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 14.837254ms)
Feb 28 19:21:08.429: INFO: (10) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 16.130185ms)
Feb 28 19:21:08.429: INFO: (10) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 16.460348ms)
Feb 28 19:21:08.429: INFO: (10) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 17.218144ms)
Feb 28 19:21:08.430: INFO: (10) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 17.977125ms)
Feb 28 19:21:08.430: INFO: (10) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 17.663419ms)
Feb 28 19:21:08.430: INFO: (10) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 18.173198ms)
Feb 28 19:21:08.441: INFO: (11) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 10.266203ms)
Feb 28 19:21:08.441: INFO: (11) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 10.522055ms)
Feb 28 19:21:08.442: INFO: (11) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 11.368887ms)
Feb 28 19:21:08.442: INFO: (11) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.520508ms)
Feb 28 19:21:08.442: INFO: (11) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 11.215397ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 12.655947ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 12.02449ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 13.026213ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 12.974456ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 13.245984ms)
Feb 28 19:21:08.443: INFO: (11) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 13.071894ms)
Feb 28 19:21:08.444: INFO: (11) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 13.694028ms)
Feb 28 19:21:08.446: INFO: (11) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 14.817247ms)
Feb 28 19:21:08.448: INFO: (11) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 18.13171ms)
Feb 28 19:21:08.448: INFO: (11) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 17.804098ms)
Feb 28 19:21:08.448: INFO: (11) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 18.013875ms)
Feb 28 19:21:08.456: INFO: (12) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 7.329604ms)
Feb 28 19:21:08.456: INFO: (12) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 7.198328ms)
Feb 28 19:21:08.456: INFO: (12) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 7.081299ms)
Feb 28 19:21:08.457: INFO: (12) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 7.82344ms)
Feb 28 19:21:08.460: INFO: (12) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 9.981867ms)
Feb 28 19:21:08.461: INFO: (12) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 11.060756ms)
Feb 28 19:21:08.461: INFO: (12) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 10.947098ms)
Feb 28 19:21:08.462: INFO: (12) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 12.265025ms)
Feb 28 19:21:08.462: INFO: (12) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.184678ms)
Feb 28 19:21:08.463: INFO: (12) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 13.37097ms)
Feb 28 19:21:08.463: INFO: (12) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 12.415972ms)
Feb 28 19:21:08.463: INFO: (12) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 14.205394ms)
Feb 28 19:21:08.463: INFO: (12) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 12.857787ms)
Feb 28 19:21:08.466: INFO: (12) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 15.809136ms)
Feb 28 19:21:08.466: INFO: (12) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 16.235517ms)
Feb 28 19:21:08.466: INFO: (12) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 15.712904ms)
Feb 28 19:21:08.473: INFO: (13) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 6.690397ms)
Feb 28 19:21:08.473: INFO: (13) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 6.950944ms)
Feb 28 19:21:08.474: INFO: (13) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 7.833627ms)
Feb 28 19:21:08.476: INFO: (13) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 9.062505ms)
Feb 28 19:21:08.476: INFO: (13) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 9.278099ms)
Feb 28 19:21:08.477: INFO: (13) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 10.148024ms)
Feb 28 19:21:08.478: INFO: (13) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 11.784348ms)
Feb 28 19:21:08.479: INFO: (13) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 12.502057ms)
Feb 28 19:21:08.480: INFO: (13) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 13.076472ms)
Feb 28 19:21:08.480: INFO: (13) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 13.592858ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 18.068807ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 17.700529ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 18.068931ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 17.833311ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 17.804697ms)
Feb 28 19:21:08.485: INFO: (13) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 18.524736ms)
Feb 28 19:21:08.492: INFO: (14) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 7.13678ms)
Feb 28 19:21:08.492: INFO: (14) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 6.983771ms)
Feb 28 19:21:08.496: INFO: (14) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 9.034073ms)
Feb 28 19:21:08.496: INFO: (14) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 10.60834ms)
Feb 28 19:21:08.497: INFO: (14) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.600735ms)
Feb 28 19:21:08.497: INFO: (14) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 10.277289ms)
Feb 28 19:21:08.498: INFO: (14) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.714526ms)
Feb 28 19:21:08.498: INFO: (14) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 11.719967ms)
Feb 28 19:21:08.498: INFO: (14) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.524407ms)
Feb 28 19:21:08.500: INFO: (14) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 15.162198ms)
Feb 28 19:21:08.500: INFO: (14) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 14.204661ms)
Feb 28 19:21:08.501: INFO: (14) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 15.516269ms)
Feb 28 19:21:08.502: INFO: (14) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 14.739874ms)
Feb 28 19:21:08.502: INFO: (14) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 16.224122ms)
Feb 28 19:21:08.502: INFO: (14) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 15.410349ms)
Feb 28 19:21:08.502: INFO: (14) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 15.778113ms)
Feb 28 19:21:08.511: INFO: (15) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 7.77226ms)
Feb 28 19:21:08.516: INFO: (15) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 11.50867ms)
Feb 28 19:21:08.516: INFO: (15) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 10.952524ms)
Feb 28 19:21:08.517: INFO: (15) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 12.349151ms)
Feb 28 19:21:08.517: INFO: (15) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.227167ms)
Feb 28 19:21:08.517: INFO: (15) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 14.722393ms)
Feb 28 19:21:08.518: INFO: (15) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 13.805679ms)
Feb 28 19:21:08.518: INFO: (15) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 13.480853ms)
Feb 28 19:21:08.518: INFO: (15) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 14.697646ms)
Feb 28 19:21:08.518: INFO: (15) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 12.960505ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 13.215381ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 14.732147ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 16.166327ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 15.504748ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 14.574975ms)
Feb 28 19:21:08.519: INFO: (15) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 14.074892ms)
Feb 28 19:21:08.526: INFO: (16) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 6.707439ms)
Feb 28 19:21:08.527: INFO: (16) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 7.427267ms)
Feb 28 19:21:08.528: INFO: (16) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 8.102207ms)
Feb 28 19:21:08.529: INFO: (16) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.312903ms)
Feb 28 19:21:08.529: INFO: (16) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 9.208066ms)
Feb 28 19:21:08.529: INFO: (16) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.683198ms)
Feb 28 19:21:08.529: INFO: (16) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 10.088682ms)
Feb 28 19:21:08.530: INFO: (16) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 10.341191ms)
Feb 28 19:21:08.530: INFO: (16) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 10.421541ms)
Feb 28 19:21:08.532: INFO: (16) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 12.649891ms)
Feb 28 19:21:08.533: INFO: (16) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 12.96189ms)
Feb 28 19:21:08.533: INFO: (16) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 13.179558ms)
Feb 28 19:21:08.533: INFO: (16) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 13.655893ms)
Feb 28 19:21:08.533: INFO: (16) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 13.715283ms)
Feb 28 19:21:08.533: INFO: (16) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 14.075353ms)
Feb 28 19:21:08.534: INFO: (16) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 14.443265ms)
Feb 28 19:21:08.542: INFO: (17) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 8.032968ms)
Feb 28 19:21:08.544: INFO: (17) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 9.30928ms)
Feb 28 19:21:08.544: INFO: (17) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 9.459148ms)
Feb 28 19:21:08.544: INFO: (17) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 9.438392ms)
Feb 28 19:21:08.545: INFO: (17) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 9.97174ms)
Feb 28 19:21:08.545: INFO: (17) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 11.193015ms)
Feb 28 19:21:08.545: INFO: (17) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 9.852659ms)
Feb 28 19:21:08.547: INFO: (17) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 12.063813ms)
Feb 28 19:21:08.547: INFO: (17) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.779129ms)
Feb 28 19:21:08.547: INFO: (17) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.083676ms)
Feb 28 19:21:08.547: INFO: (17) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 13.025261ms)
Feb 28 19:21:08.548: INFO: (17) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 13.826979ms)
Feb 28 19:21:08.554: INFO: (17) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 18.298511ms)
Feb 28 19:21:08.554: INFO: (17) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 19.284916ms)
Feb 28 19:21:08.554: INFO: (17) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 18.956159ms)
Feb 28 19:21:08.554: INFO: (17) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 18.93321ms)
Feb 28 19:21:08.559: INFO: (18) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 4.98464ms)
Feb 28 19:21:08.559: INFO: (18) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 4.848966ms)
Feb 28 19:21:08.563: INFO: (18) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 7.600704ms)
Feb 28 19:21:08.563: INFO: (18) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 8.196134ms)
Feb 28 19:21:08.564: INFO: (18) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 8.944224ms)
Feb 28 19:21:08.564: INFO: (18) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 7.834631ms)
Feb 28 19:21:08.564: INFO: (18) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 9.558967ms)
Feb 28 19:21:08.564: INFO: (18) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 9.095874ms)
Feb 28 19:21:08.565: INFO: (18) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 9.691119ms)
Feb 28 19:21:08.566: INFO: (18) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 11.229147ms)
Feb 28 19:21:08.566: INFO: (18) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 10.691473ms)
Feb 28 19:21:08.566: INFO: (18) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 10.570462ms)
Feb 28 19:21:08.566: INFO: (18) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 10.824112ms)
Feb 28 19:21:08.567: INFO: (18) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 11.653201ms)
Feb 28 19:21:08.567: INFO: (18) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.092818ms)
Feb 28 19:21:08.567: INFO: (18) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 12.536456ms)
Feb 28 19:21:08.578: INFO: (19) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:462/proxy/: tls qux (200; 10.294412ms)
Feb 28 19:21:08.579: INFO: (19) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2/proxy/rewriteme">test</a> (200; 10.298778ms)
Feb 28 19:21:08.579: INFO: (19) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 10.918522ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:443/proxy/tlsrewritem... (200; 11.708963ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">... (200; 12.313341ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 12.750713ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/: <a href="/api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:1080/proxy/rewriteme">test<... (200; 12.559749ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/proxy-service-zg56r-4c2p2:162/proxy/: bar (200; 12.167353ms)
Feb 28 19:21:08.580: INFO: (19) /api/v1/namespaces/proxy-3888/pods/https:proxy-service-zg56r-4c2p2:460/proxy/: tls baz (200; 12.962305ms)
Feb 28 19:21:08.581: INFO: (19) /api/v1/namespaces/proxy-3888/pods/http:proxy-service-zg56r-4c2p2:160/proxy/: foo (200; 12.563688ms)
Feb 28 19:21:08.581: INFO: (19) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname1/proxy/: foo (200; 12.449003ms)
Feb 28 19:21:08.582: INFO: (19) /api/v1/namespaces/proxy-3888/services/http:proxy-service-zg56r:portname2/proxy/: bar (200; 14.094118ms)
Feb 28 19:21:08.584: INFO: (19) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname1/proxy/: tls baz (200; 15.702502ms)
Feb 28 19:21:08.584: INFO: (19) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname2/proxy/: bar (200; 15.75296ms)
Feb 28 19:21:08.584: INFO: (19) /api/v1/namespaces/proxy-3888/services/proxy-service-zg56r:portname1/proxy/: foo (200; 15.884772ms)
Feb 28 19:21:08.584: INFO: (19) /api/v1/namespaces/proxy-3888/services/https:proxy-service-zg56r:tlsportname2/proxy/: tls qux (200; 16.427767ms)
STEP: deleting ReplicationController proxy-service-zg56r in namespace proxy-3888, will wait for the garbage collector to delete the pods
Feb 28 19:21:08.652: INFO: Deleting ReplicationController proxy-service-zg56r took: 14.029704ms
Feb 28 19:21:09.054: INFO: Terminating ReplicationController proxy-service-zg56r pods took: 401.828681ms
[AfterEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:21:18.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3888" for this suite.
Feb 28 19:21:24.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:21:24.281: INFO: namespace proxy-3888 deletion completed in 6.117527325s

• [SLOW TEST:21.225 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:21:24.282: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Feb 28 19:21:25.394: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0228 19:21:25.394124      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:21:25.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-686" for this suite.
Feb 28 19:21:31.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:21:31.499: INFO: namespace gc-686 deletion completed in 6.099109963s

• [SLOW TEST:7.217 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:21:31.501: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:21:31.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a" in namespace "projected-8634" to be "success or failure"
Feb 28 19:21:31.557: INFO: Pod "downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.810233ms
Feb 28 19:21:33.561: INFO: Pod "downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a": Phase="Running", Reason="", readiness=true. Elapsed: 2.008679544s
Feb 28 19:21:35.564: INFO: Pod "downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011983327s
STEP: Saw pod success
Feb 28 19:21:35.564: INFO: Pod "downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a" satisfied condition "success or failure"
Feb 28 19:21:35.567: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a container client-container: <nil>
STEP: delete the pod
Feb 28 19:21:35.587: INFO: Waiting for pod downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a to disappear
Feb 28 19:21:35.590: INFO: Pod downwardapi-volume-6633df3c-dab6-4d13-843e-ae53f4b7fa8a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:21:35.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8634" for this suite.
Feb 28 19:21:41.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:21:41.695: INFO: namespace projected-8634 deletion completed in 6.099820838s

• [SLOW TEST:10.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:21:41.695: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:21:45.785: INFO: Waiting up to 5m0s for pod "client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c" in namespace "pods-7738" to be "success or failure"
Feb 28 19:21:45.812: INFO: Pod "client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c": Phase="Pending", Reason="", readiness=false. Elapsed: 27.096695ms
Feb 28 19:21:47.816: INFO: Pod "client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03159784s
Feb 28 19:21:49.821: INFO: Pod "client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036023549s
STEP: Saw pod success
Feb 28 19:21:49.821: INFO: Pod "client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c" satisfied condition "success or failure"
Feb 28 19:21:49.824: INFO: Trying to get logs from node wenjun192 pod client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c container env3cont: <nil>
STEP: delete the pod
Feb 28 19:21:49.851: INFO: Waiting for pod client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c to disappear
Feb 28 19:21:49.855: INFO: Pod client-envvars-037bba54-c6ff-4d4b-bc5c-5234f2d6761c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:21:49.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7738" for this suite.
Feb 28 19:22:39.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:22:39.968: INFO: namespace pods-7738 deletion completed in 50.106356499s

• [SLOW TEST:58.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:22:39.971: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-b2lv
STEP: Creating a pod to test atomic-volume-subpath
Feb 28 19:22:40.040: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-b2lv" in namespace "subpath-7659" to be "success or failure"
Feb 28 19:22:40.044: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.174451ms
Feb 28 19:22:42.048: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312027s
Feb 28 19:22:44.052: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 4.011886247s
Feb 28 19:22:46.055: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 6.015402072s
Feb 28 19:22:48.060: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 8.019967947s
Feb 28 19:22:50.064: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 10.024323143s
Feb 28 19:22:52.070: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 12.030052872s
Feb 28 19:22:54.074: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 14.033746121s
Feb 28 19:22:56.077: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 16.036842485s
Feb 28 19:22:58.083: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 18.042594281s
Feb 28 19:23:00.086: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Running", Reason="", readiness=true. Elapsed: 20.046392602s
Feb 28 19:23:02.096: INFO: Pod "pod-subpath-test-downwardapi-b2lv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.056034952s
STEP: Saw pod success
Feb 28 19:23:02.096: INFO: Pod "pod-subpath-test-downwardapi-b2lv" satisfied condition "success or failure"
Feb 28 19:23:02.098: INFO: Trying to get logs from node wenjun192 pod pod-subpath-test-downwardapi-b2lv container test-container-subpath-downwardapi-b2lv: <nil>
STEP: delete the pod
Feb 28 19:23:02.129: INFO: Waiting for pod pod-subpath-test-downwardapi-b2lv to disappear
Feb 28 19:23:02.147: INFO: Pod pod-subpath-test-downwardapi-b2lv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-b2lv
Feb 28 19:23:02.148: INFO: Deleting pod "pod-subpath-test-downwardapi-b2lv" in namespace "subpath-7659"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:23:02.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7659" for this suite.
Feb 28 19:23:08.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:23:08.350: INFO: namespace subpath-7659 deletion completed in 6.190816351s

• [SLOW TEST:28.379 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:23:08.351: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-8998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8998 to expose endpoints map[]
Feb 28 19:23:08.437: INFO: Get endpoints failed (4.434141ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 28 19:23:09.440: INFO: successfully validated that service multi-endpoint-test in namespace services-8998 exposes endpoints map[] (1.007303888s elapsed)
STEP: Creating pod pod1 in namespace services-8998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8998 to expose endpoints map[pod1:[100]]
Feb 28 19:23:11.485: INFO: successfully validated that service multi-endpoint-test in namespace services-8998 exposes endpoints map[pod1:[100]] (2.03216691s elapsed)
STEP: Creating pod pod2 in namespace services-8998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8998 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 28 19:23:13.523: INFO: successfully validated that service multi-endpoint-test in namespace services-8998 exposes endpoints map[pod1:[100] pod2:[101]] (2.033095124s elapsed)
STEP: Deleting pod pod1 in namespace services-8998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8998 to expose endpoints map[pod2:[101]]
Feb 28 19:23:13.560: INFO: successfully validated that service multi-endpoint-test in namespace services-8998 exposes endpoints map[pod2:[101]] (28.871541ms elapsed)
STEP: Deleting pod pod2 in namespace services-8998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8998 to expose endpoints map[]
Feb 28 19:23:13.578: INFO: successfully validated that service multi-endpoint-test in namespace services-8998 exposes endpoints map[] (4.015502ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:23:13.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8998" for this suite.
Feb 28 19:23:35.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:23:35.851: INFO: namespace services-8998 deletion completed in 22.163267093s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:27.500 seconds]
[sig-network] Services
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:23:35.853: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Feb 28 19:23:39.937: INFO: Pod pod-hostip-c46b180a-8ac7-404b-83db-c8376e840c01 has hostIP: 10.10.1.192
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:23:39.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5499" for this suite.
Feb 28 19:24:01.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:24:02.050: INFO: namespace pods-5499 deletion completed in 22.107687582s

• [SLOW TEST:26.197 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:24:02.051: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:24:02.086: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:24:04.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-828" for this suite.
Feb 28 19:24:50.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:24:50.513: INFO: namespace pods-828 deletion completed in 46.23672296s

• [SLOW TEST:48.463 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:24:50.516: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Feb 28 19:24:50.586: INFO: Waiting up to 5m0s for pod "var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405" in namespace "var-expansion-9625" to be "success or failure"
Feb 28 19:24:50.592: INFO: Pod "var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202939ms
Feb 28 19:24:52.598: INFO: Pod "var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011882302s
STEP: Saw pod success
Feb 28 19:24:52.598: INFO: Pod "var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405" satisfied condition "success or failure"
Feb 28 19:24:52.601: INFO: Trying to get logs from node wenjun192 pod var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405 container dapi-container: <nil>
STEP: delete the pod
Feb 28 19:24:52.627: INFO: Waiting for pod var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405 to disappear
Feb 28 19:24:52.630: INFO: Pod var-expansion-36f58b8e-ffcf-4b74-b3d4-adf9a7cae405 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:24:52.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9625" for this suite.
Feb 28 19:24:58.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:24:58.792: INFO: namespace var-expansion-9625 deletion completed in 6.155676659s

• [SLOW TEST:8.277 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:24:58.794: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 19:24:58.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2872'
Feb 28 19:24:58.988: INFO: stderr: ""
Feb 28 19:24:58.988: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Feb 28 19:24:58.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete pods e2e-test-nginx-pod --namespace=kubectl-2872'
Feb 28 19:25:08.144: INFO: stderr: ""
Feb 28 19:25:08.144: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:25:08.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2872" for this suite.
Feb 28 19:25:14.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:25:14.262: INFO: namespace kubectl-2872 deletion completed in 6.112555418s

• [SLOW TEST:15.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:25:14.264: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Feb 28 19:25:14.316: INFO: Waiting up to 5m0s for pod "client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3" in namespace "containers-580" to be "success or failure"
Feb 28 19:25:14.319: INFO: Pod "client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113773ms
Feb 28 19:25:16.323: INFO: Pod "client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006756857s
STEP: Saw pod success
Feb 28 19:25:16.323: INFO: Pod "client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3" satisfied condition "success or failure"
Feb 28 19:25:16.326: INFO: Trying to get logs from node wenjun192 pod client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3 container test-container: <nil>
STEP: delete the pod
Feb 28 19:25:16.352: INFO: Waiting for pod client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3 to disappear
Feb 28 19:25:16.354: INFO: Pod client-containers-1474f8cd-1ea8-42a8-933f-881959efcee3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:25:16.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-580" for this suite.
Feb 28 19:25:22.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:25:22.475: INFO: namespace containers-580 deletion completed in 6.116170139s

• [SLOW TEST:8.211 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:25:22.476: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 28 19:25:28.726: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0228 19:25:28.725970      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:25:28.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2132" for this suite.
Feb 28 19:25:34.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:25:34.872: INFO: namespace gc-2132 deletion completed in 6.120596421s

• [SLOW TEST:12.396 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:25:34.874: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5823
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 28 19:25:34.918: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 28 19:25:58.989: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.34.187.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5823 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:25:58.989: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:26:00.156: INFO: Found all expected endpoints: [netserver-0]
Feb 28 19:26:00.160: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.35.253.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5823 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:26:00.160: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:26:01.290: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:26:01.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5823" for this suite.
Feb 28 19:26:23.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:26:23.437: INFO: namespace pod-network-test-5823 deletion completed in 22.140740093s

• [SLOW TEST:48.563 seconds]
[sig-network] Networking
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:26:23.440: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:26:23.480: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:26:24.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4448" for this suite.
Feb 28 19:26:30.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:26:30.648: INFO: namespace custom-resource-definition-4448 deletion completed in 6.105904148s

• [SLOW TEST:7.209 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:26:30.649: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:26:36.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-151" for this suite.
Feb 28 19:26:42.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:26:42.899: INFO: namespace namespaces-151 deletion completed in 6.107471495s
STEP: Destroying namespace "nsdeletetest-1814" for this suite.
Feb 28 19:26:42.901: INFO: Namespace nsdeletetest-1814 was already deleted
STEP: Destroying namespace "nsdeletetest-9676" for this suite.
Feb 28 19:26:48.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:26:48.993: INFO: namespace nsdeletetest-9676 deletion completed in 6.091390687s

• [SLOW TEST:18.344 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:26:48.996: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-23d08b1f-c07b-448a-81f1-227cf54ed049
STEP: Creating a pod to test consume secrets
Feb 28 19:26:49.047: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e" in namespace "projected-3388" to be "success or failure"
Feb 28 19:26:49.053: INFO: Pod "pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.490596ms
Feb 28 19:26:51.058: INFO: Pod "pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01123028s
STEP: Saw pod success
Feb 28 19:26:51.058: INFO: Pod "pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e" satisfied condition "success or failure"
Feb 28 19:26:51.062: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:26:51.088: INFO: Waiting for pod pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e to disappear
Feb 28 19:26:51.091: INFO: Pod pod-projected-secrets-0bc7396a-8973-4b4a-8e50-20d48ef2cd9e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:26:51.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3388" for this suite.
Feb 28 19:26:57.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:26:57.203: INFO: namespace projected-3388 deletion completed in 6.106780033s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:26:57.203: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:26:57.252: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8" in namespace "downward-api-119" to be "success or failure"
Feb 28 19:26:57.263: INFO: Pod "downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.358923ms
Feb 28 19:26:59.266: INFO: Pod "downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01428948s
STEP: Saw pod success
Feb 28 19:26:59.267: INFO: Pod "downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8" satisfied condition "success or failure"
Feb 28 19:26:59.269: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8 container client-container: <nil>
STEP: delete the pod
Feb 28 19:26:59.292: INFO: Waiting for pod downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8 to disappear
Feb 28 19:26:59.295: INFO: Pod downwardapi-volume-90a53349-c5c9-450e-bb62-488bcea2bfe8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:26:59.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-119" for this suite.
Feb 28 19:27:05.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:27:05.410: INFO: namespace downward-api-119 deletion completed in 6.110729351s

• [SLOW TEST:8.207 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:27:05.413: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 28 19:27:05.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-9882'
Feb 28 19:27:05.679: INFO: stderr: ""
Feb 28 19:27:05.679: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 19:27:05.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:05.784: INFO: stderr: ""
Feb 28 19:27:05.784: INFO: stdout: "update-demo-nautilus-bspkz update-demo-nautilus-mcqzh "
Feb 28 19:27:05.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-bspkz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:05.876: INFO: stderr: ""
Feb 28 19:27:05.876: INFO: stdout: ""
Feb 28 19:27:05.876: INFO: update-demo-nautilus-bspkz is created but not running
Feb 28 19:27:10.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:10.979: INFO: stderr: ""
Feb 28 19:27:10.980: INFO: stdout: "update-demo-nautilus-bspkz update-demo-nautilus-mcqzh "
Feb 28 19:27:10.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-bspkz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:11.076: INFO: stderr: ""
Feb 28 19:27:11.076: INFO: stdout: "true"
Feb 28 19:27:11.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-bspkz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:11.176: INFO: stderr: ""
Feb 28 19:27:11.176: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:27:11.176: INFO: validating pod update-demo-nautilus-bspkz
Feb 28 19:27:11.184: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:27:11.184: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:27:11.184: INFO: update-demo-nautilus-bspkz is verified up and running
Feb 28 19:27:11.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:11.294: INFO: stderr: ""
Feb 28 19:27:11.294: INFO: stdout: "true"
Feb 28 19:27:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:11.382: INFO: stderr: ""
Feb 28 19:27:11.382: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:27:11.382: INFO: validating pod update-demo-nautilus-mcqzh
Feb 28 19:27:11.389: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:27:11.389: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:27:11.389: INFO: update-demo-nautilus-mcqzh is verified up and running
STEP: scaling down the replication controller
Feb 28 19:27:11.397: INFO: scanned /root for discovery docs: <nil>
Feb 28 19:27:11.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9882'
Feb 28 19:27:12.553: INFO: stderr: ""
Feb 28 19:27:12.553: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 19:27:12.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:12.667: INFO: stderr: ""
Feb 28 19:27:12.667: INFO: stdout: "update-demo-nautilus-bspkz update-demo-nautilus-mcqzh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 28 19:27:17.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:17.791: INFO: stderr: ""
Feb 28 19:27:17.791: INFO: stdout: "update-demo-nautilus-bspkz update-demo-nautilus-mcqzh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 28 19:27:22.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:22.892: INFO: stderr: ""
Feb 28 19:27:22.892: INFO: stdout: "update-demo-nautilus-mcqzh "
Feb 28 19:27:22.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:22.989: INFO: stderr: ""
Feb 28 19:27:22.989: INFO: stdout: "true"
Feb 28 19:27:22.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:23.092: INFO: stderr: ""
Feb 28 19:27:23.092: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:27:23.092: INFO: validating pod update-demo-nautilus-mcqzh
Feb 28 19:27:23.099: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:27:23.100: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:27:23.100: INFO: update-demo-nautilus-mcqzh is verified up and running
STEP: scaling up the replication controller
Feb 28 19:27:23.106: INFO: scanned /root for discovery docs: <nil>
Feb 28 19:27:23.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9882'
Feb 28 19:27:24.254: INFO: stderr: ""
Feb 28 19:27:24.254: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 19:27:24.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:24.378: INFO: stderr: ""
Feb 28 19:27:24.378: INFO: stdout: "update-demo-nautilus-gnqvn update-demo-nautilus-mcqzh "
Feb 28 19:27:24.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-gnqvn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:24.478: INFO: stderr: ""
Feb 28 19:27:24.478: INFO: stdout: ""
Feb 28 19:27:24.478: INFO: update-demo-nautilus-gnqvn is created but not running
Feb 28 19:27:29.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9882'
Feb 28 19:27:29.582: INFO: stderr: ""
Feb 28 19:27:29.582: INFO: stdout: "update-demo-nautilus-gnqvn update-demo-nautilus-mcqzh "
Feb 28 19:27:29.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-gnqvn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:29.690: INFO: stderr: ""
Feb 28 19:27:29.690: INFO: stdout: "true"
Feb 28 19:27:29.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-gnqvn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:29.779: INFO: stderr: ""
Feb 28 19:27:29.779: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:27:29.779: INFO: validating pod update-demo-nautilus-gnqvn
Feb 28 19:27:29.786: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:27:29.786: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:27:29.787: INFO: update-demo-nautilus-gnqvn is verified up and running
Feb 28 19:27:29.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:29.872: INFO: stderr: ""
Feb 28 19:27:29.872: INFO: stdout: "true"
Feb 28 19:27:29.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mcqzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9882'
Feb 28 19:27:29.969: INFO: stderr: ""
Feb 28 19:27:29.969: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:27:29.969: INFO: validating pod update-demo-nautilus-mcqzh
Feb 28 19:27:29.976: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:27:29.976: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:27:29.976: INFO: update-demo-nautilus-mcqzh is verified up and running
STEP: using delete to clean up resources
Feb 28 19:27:29.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-9882'
Feb 28 19:27:30.076: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 19:27:30.076: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 28 19:27:30.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9882'
Feb 28 19:27:30.193: INFO: stderr: "No resources found.\n"
Feb 28 19:27:30.193: INFO: stdout: ""
Feb 28 19:27:30.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=update-demo --namespace=kubectl-9882 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 19:27:30.304: INFO: stderr: ""
Feb 28 19:27:30.304: INFO: stdout: "update-demo-nautilus-gnqvn\nupdate-demo-nautilus-mcqzh\n"
Feb 28 19:27:30.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9882'
Feb 28 19:27:30.932: INFO: stderr: "No resources found.\n"
Feb 28 19:27:30.933: INFO: stdout: ""
Feb 28 19:27:30.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=update-demo --namespace=kubectl-9882 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 19:27:31.051: INFO: stderr: ""
Feb 28 19:27:31.051: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:27:31.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9882" for this suite.
Feb 28 19:27:53.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:27:53.167: INFO: namespace kubectl-9882 deletion completed in 22.108505595s

• [SLOW TEST:47.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:27:53.167: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 28 19:27:53.217: INFO: Waiting up to 5m0s for pod "pod-de0cbe95-a709-458e-aa32-0c768cfa689a" in namespace "emptydir-7766" to be "success or failure"
Feb 28 19:27:53.222: INFO: Pod "pod-de0cbe95-a709-458e-aa32-0c768cfa689a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.798773ms
Feb 28 19:27:55.226: INFO: Pod "pod-de0cbe95-a709-458e-aa32-0c768cfa689a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008398551s
Feb 28 19:27:57.230: INFO: Pod "pod-de0cbe95-a709-458e-aa32-0c768cfa689a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012517171s
STEP: Saw pod success
Feb 28 19:27:57.230: INFO: Pod "pod-de0cbe95-a709-458e-aa32-0c768cfa689a" satisfied condition "success or failure"
Feb 28 19:27:57.233: INFO: Trying to get logs from node wenjun192 pod pod-de0cbe95-a709-458e-aa32-0c768cfa689a container test-container: <nil>
STEP: delete the pod
Feb 28 19:27:57.255: INFO: Waiting for pod pod-de0cbe95-a709-458e-aa32-0c768cfa689a to disappear
Feb 28 19:27:57.258: INFO: Pod pod-de0cbe95-a709-458e-aa32-0c768cfa689a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:27:57.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7766" for this suite.
Feb 28 19:28:03.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:28:03.394: INFO: namespace emptydir-7766 deletion completed in 6.130547191s

• [SLOW TEST:10.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:28:03.396: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-e35d5346-b270-49ed-a9aa-4805975e6bc3
STEP: Creating a pod to test consume configMaps
Feb 28 19:28:03.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae" in namespace "projected-3569" to be "success or failure"
Feb 28 19:28:03.449: INFO: Pod "pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290491ms
Feb 28 19:28:05.453: INFO: Pod "pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007215587s
Feb 28 19:28:07.456: INFO: Pod "pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01051888s
STEP: Saw pod success
Feb 28 19:28:07.456: INFO: Pod "pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae" satisfied condition "success or failure"
Feb 28 19:28:07.460: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:28:07.494: INFO: Waiting for pod pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae to disappear
Feb 28 19:28:07.500: INFO: Pod pod-projected-configmaps-5b2a4d23-432d-436b-8c7b-0065776529ae no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:28:07.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3569" for this suite.
Feb 28 19:28:13.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:28:13.690: INFO: namespace projected-3569 deletion completed in 6.178621333s

• [SLOW TEST:10.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:28:13.691: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 28 19:28:13.809: INFO: Number of nodes with available pods: 0
Feb 28 19:28:13.809: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:14.822: INFO: Number of nodes with available pods: 0
Feb 28 19:28:14.822: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:15.818: INFO: Number of nodes with available pods: 1
Feb 28 19:28:15.818: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:16.818: INFO: Number of nodes with available pods: 2
Feb 28 19:28:16.818: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 28 19:28:16.839: INFO: Number of nodes with available pods: 1
Feb 28 19:28:16.839: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:17.847: INFO: Number of nodes with available pods: 1
Feb 28 19:28:17.847: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:18.850: INFO: Number of nodes with available pods: 1
Feb 28 19:28:18.850: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:19.847: INFO: Number of nodes with available pods: 1
Feb 28 19:28:19.847: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:20.846: INFO: Number of nodes with available pods: 1
Feb 28 19:28:20.847: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:21.847: INFO: Number of nodes with available pods: 1
Feb 28 19:28:21.847: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:22.846: INFO: Number of nodes with available pods: 1
Feb 28 19:28:22.846: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:23.848: INFO: Number of nodes with available pods: 1
Feb 28 19:28:23.848: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:24.848: INFO: Number of nodes with available pods: 1
Feb 28 19:28:24.848: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:25.852: INFO: Number of nodes with available pods: 1
Feb 28 19:28:25.852: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:28:26.849: INFO: Number of nodes with available pods: 2
Feb 28 19:28:26.850: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-586, will wait for the garbage collector to delete the pods
Feb 28 19:28:26.918: INFO: Deleting DaemonSet.extensions daemon-set took: 8.32555ms
Feb 28 19:28:27.318: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.264736ms
Feb 28 19:28:38.222: INFO: Number of nodes with available pods: 0
Feb 28 19:28:38.222: INFO: Number of running nodes: 0, number of available pods: 0
Feb 28 19:28:38.230: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-586/daemonsets","resourceVersion":"9413"},"items":null}

Feb 28 19:28:38.232: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-586/pods","resourceVersion":"9413"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:28:38.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-586" for this suite.
Feb 28 19:28:44.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:28:44.371: INFO: namespace daemonsets-586 deletion completed in 6.122972145s

• [SLOW TEST:30.680 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:28:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 19:28:44.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-148'
Feb 28 19:28:44.526: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 28 19:28:44.526: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 28 19:28:44.534: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 28 19:28:44.550: INFO: scanned /root for discovery docs: <nil>
Feb 28 19:28:44.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-148'
Feb 28 19:28:57.397: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 28 19:28:57.397: INFO: stdout: "Created e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd\nScaling up e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 28 19:28:57.397: INFO: stdout: "Created e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd\nScaling up e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 28 19:28:57.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-148'
Feb 28 19:28:57.499: INFO: stderr: ""
Feb 28 19:28:57.499: INFO: stdout: "e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd-gfxfx e2e-test-nginx-rc-qpx7j "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Feb 28 19:29:02.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-148'
Feb 28 19:29:02.603: INFO: stderr: ""
Feb 28 19:29:02.603: INFO: stdout: "e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd-gfxfx "
Feb 28 19:29:02.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd-gfxfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-148'
Feb 28 19:29:02.700: INFO: stderr: ""
Feb 28 19:29:02.700: INFO: stdout: "true"
Feb 28 19:29:02.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd-gfxfx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-148'
Feb 28 19:29:02.796: INFO: stderr: ""
Feb 28 19:29:02.796: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 28 19:29:02.796: INFO: e2e-test-nginx-rc-a28940452ba1a4655f0a282f621d1afd-gfxfx is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Feb 28 19:29:02.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete rc e2e-test-nginx-rc --namespace=kubectl-148'
Feb 28 19:29:02.930: INFO: stderr: ""
Feb 28 19:29:02.930: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:29:02.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-148" for this suite.
Feb 28 19:29:24.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:29:25.051: INFO: namespace kubectl-148 deletion completed in 22.111258001s

• [SLOW TEST:40.680 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:29:25.052: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 28 19:29:27.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec pod-sharedvolume-ace6a5eb-01dc-4c67-b6a3-b7136802ee34 -c busybox-main-container --namespace=emptydir-3988 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 28 19:29:27.362: INFO: stderr: ""
Feb 28 19:29:27.362: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:29:27.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3988" for this suite.
Feb 28 19:29:33.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:29:33.486: INFO: namespace emptydir-3988 deletion completed in 6.117961516s

• [SLOW TEST:8.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:29:33.487: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 28 19:29:36.086: INFO: Successfully updated pod "labelsupdatec4a9bdfd-ead9-4e65-ae8f-7c16bdec48dd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:29:38.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8326" for this suite.
Feb 28 19:30:00.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:30:00.216: INFO: namespace projected-8326 deletion completed in 22.102231567s

• [SLOW TEST:26.729 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:30:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-rjmh
STEP: Creating a pod to test atomic-volume-subpath
Feb 28 19:30:00.279: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rjmh" in namespace "subpath-1903" to be "success or failure"
Feb 28 19:30:00.289: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Pending", Reason="", readiness=false. Elapsed: 9.148126ms
Feb 28 19:30:02.296: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016096986s
Feb 28 19:30:04.300: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 4.020301327s
Feb 28 19:30:06.304: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 6.024202094s
Feb 28 19:30:08.307: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 8.027778291s
Feb 28 19:30:10.312: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 10.03204338s
Feb 28 19:30:12.316: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 12.036644548s
Feb 28 19:30:14.321: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 14.041424559s
Feb 28 19:30:16.324: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 16.044600686s
Feb 28 19:30:18.332: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 18.052646126s
Feb 28 19:30:20.336: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Running", Reason="", readiness=true. Elapsed: 20.056927212s
Feb 28 19:30:22.341: INFO: Pod "pod-subpath-test-configmap-rjmh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.061504778s
STEP: Saw pod success
Feb 28 19:30:22.341: INFO: Pod "pod-subpath-test-configmap-rjmh" satisfied condition "success or failure"
Feb 28 19:30:22.344: INFO: Trying to get logs from node wenjun192 pod pod-subpath-test-configmap-rjmh container test-container-subpath-configmap-rjmh: <nil>
STEP: delete the pod
Feb 28 19:30:22.370: INFO: Waiting for pod pod-subpath-test-configmap-rjmh to disappear
Feb 28 19:30:22.374: INFO: Pod pod-subpath-test-configmap-rjmh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rjmh
Feb 28 19:30:22.374: INFO: Deleting pod "pod-subpath-test-configmap-rjmh" in namespace "subpath-1903"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:30:22.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1903" for this suite.
Feb 28 19:30:28.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:30:28.523: INFO: namespace subpath-1903 deletion completed in 6.140161851s

• [SLOW TEST:28.306 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:30:28.524: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7182
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 28 19:30:28.650: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 28 19:30:50.765: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.34.187.44:8080/dial?request=hostName&protocol=udp&host=10.35.253.93&port=8081&tries=1'] Namespace:pod-network-test-7182 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:30:50.766: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:30:50.936: INFO: Waiting for endpoints: map[]
Feb 28 19:30:50.959: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.34.187.44:8080/dial?request=hostName&protocol=udp&host=10.34.187.43&port=8081&tries=1'] Namespace:pod-network-test-7182 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:30:50.959: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:30:51.148: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:30:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7182" for this suite.
Feb 28 19:31:13.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:31:13.282: INFO: namespace pod-network-test-7182 deletion completed in 22.128599034s

• [SLOW TEST:44.758 seconds]
[sig-network] Networking
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:31:13.282: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 28 19:31:15.361: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:31:15.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2368" for this suite.
Feb 28 19:31:21.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:31:21.543: INFO: namespace container-runtime-2368 deletion completed in 6.140281366s

• [SLOW TEST:8.261 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:31:21.546: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-91a74498-ab92-4f4d-a5cc-e9a83b3e7b5f
STEP: Creating configMap with name cm-test-opt-upd-866ed817-2fc4-46ed-98e9-2cf77ce8f5ec
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-91a74498-ab92-4f4d-a5cc-e9a83b3e7b5f
STEP: Updating configmap cm-test-opt-upd-866ed817-2fc4-46ed-98e9-2cf77ce8f5ec
STEP: Creating configMap with name cm-test-opt-create-66f89a38-2e12-4c04-8505-d22627c1a11c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:32:44.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5261" for this suite.
Feb 28 19:34:40.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:34:40.335: INFO: namespace projected-5261 deletion completed in 1m54.71801907s

• [SLOW TEST:198.790 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:34:40.336: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-79c84a0f-ec4f-4788-82fc-104a0ca37890
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:34:42.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-676" for this suite.
Feb 28 19:35:04.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:35:04.536: INFO: namespace configmap-676 deletion completed in 22.105580946s

• [SLOW TEST:24.201 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:35:04.537: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:35:04.584: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448" in namespace "downward-api-4021" to be "success or failure"
Feb 28 19:35:04.588: INFO: Pod "downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613022ms
Feb 28 19:35:06.592: INFO: Pod "downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007968943s
Feb 28 19:35:08.596: INFO: Pod "downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012147813s
STEP: Saw pod success
Feb 28 19:35:08.596: INFO: Pod "downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448" satisfied condition "success or failure"
Feb 28 19:35:08.599: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448 container client-container: <nil>
STEP: delete the pod
Feb 28 19:35:08.633: INFO: Waiting for pod downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448 to disappear
Feb 28 19:35:08.639: INFO: Pod downwardapi-volume-e6dbaaad-73cb-479d-8ada-1da530ed5448 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:35:08.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4021" for this suite.
Feb 28 19:35:14.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:35:14.763: INFO: namespace downward-api-4021 deletion completed in 6.11710572s

• [SLOW TEST:10.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:35:14.765: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 28 19:35:17.381: INFO: Successfully updated pod "labelsupdate3a46e9a5-44d7-412d-925b-933c90e83013"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:35:19.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3536" for this suite.
Feb 28 19:35:41.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:35:41.537: INFO: namespace downward-api-3536 deletion completed in 22.109037549s

• [SLOW TEST:26.773 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:35:41.540: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 28 19:35:41.579: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:35:45.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1909" for this suite.
Feb 28 19:35:51.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:35:51.635: INFO: namespace init-container-1909 deletion completed in 6.127590231s

• [SLOW TEST:10.095 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:35:51.637: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-f3dfad11-575c-4f9b-92e0-8737ae3cea65
STEP: Creating secret with name s-test-opt-upd-145e7f79-e8bd-4a85-92b9-367183e6963f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f3dfad11-575c-4f9b-92e0-8737ae3cea65
STEP: Updating secret s-test-opt-upd-145e7f79-e8bd-4a85-92b9-367183e6963f
STEP: Creating secret with name s-test-opt-create-7ed455f9-e2bb-4ff1-a035-522664e379cd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:35:55.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1715" for this suite.
Feb 28 19:36:17.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:36:18.013: INFO: namespace projected-1715 deletion completed in 22.192943906s

• [SLOW TEST:26.376 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:36:18.013: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 28 19:36:18.080: INFO: Waiting up to 5m0s for pod "downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34" in namespace "downward-api-6777" to be "success or failure"
Feb 28 19:36:18.085: INFO: Pod "downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34": Phase="Pending", Reason="", readiness=false. Elapsed: 4.883025ms
Feb 28 19:36:20.088: INFO: Pod "downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008248411s
STEP: Saw pod success
Feb 28 19:36:20.088: INFO: Pod "downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34" satisfied condition "success or failure"
Feb 28 19:36:20.092: INFO: Trying to get logs from node wenjun192 pod downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34 container dapi-container: <nil>
STEP: delete the pod
Feb 28 19:36:20.126: INFO: Waiting for pod downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34 to disappear
Feb 28 19:36:20.129: INFO: Pod downward-api-4d5ebf0f-8206-482c-958b-dd39b4186d34 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:36:20.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6777" for this suite.
Feb 28 19:36:26.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:36:26.284: INFO: namespace downward-api-6777 deletion completed in 6.149026825s

• [SLOW TEST:8.270 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:36:26.284: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Feb 28 19:36:26.328: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Feb 28 19:36:26.963: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 28 19:36:29.051: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 19:36:31.055: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 19:36:33.057: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 19:36:35.056: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 19:36:37.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718515386, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 19:36:40.291: INFO: Waited 1.226772789s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:36:40.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7890" for this suite.
Feb 28 19:36:46.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:36:47.018: INFO: namespace aggregator-7890 deletion completed in 6.125895313s

• [SLOW TEST:20.734 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:36:47.019: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6030, will wait for the garbage collector to delete the pods
Feb 28 19:36:49.180: INFO: Deleting Job.batch foo took: 6.771585ms
Feb 28 19:36:49.281: INFO: Terminating Job.batch foo pods took: 100.386153ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:37:28.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6030" for this suite.
Feb 28 19:37:34.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:37:34.429: INFO: namespace job-6030 deletion completed in 6.12593229s

• [SLOW TEST:47.411 seconds]
[sig-apps] Job
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:37:34.432: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-41317cfa-2d66-4a68-84f1-94d3ea866b18 in namespace container-probe-6443
Feb 28 19:37:38.518: INFO: Started pod liveness-41317cfa-2d66-4a68-84f1-94d3ea866b18 in namespace container-probe-6443
STEP: checking the pod's current state and verifying that restartCount is present
Feb 28 19:37:38.521: INFO: Initial restart count of pod liveness-41317cfa-2d66-4a68-84f1-94d3ea866b18 is 0
Feb 28 19:38:02.585: INFO: Restart count of pod container-probe-6443/liveness-41317cfa-2d66-4a68-84f1-94d3ea866b18 is now 1 (24.064131313s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:38:02.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6443" for this suite.
Feb 28 19:38:08.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:38:08.754: INFO: namespace container-probe-6443 deletion completed in 6.132978481s

• [SLOW TEST:34.322 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:38:08.755: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 28 19:38:08.791: INFO: namespace kubectl-3898
Feb 28 19:38:08.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-3898'
Feb 28 19:38:09.277: INFO: stderr: ""
Feb 28 19:38:09.277: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 28 19:38:10.281: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:38:10.281: INFO: Found 0 / 1
Feb 28 19:38:11.282: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:38:11.282: INFO: Found 0 / 1
Feb 28 19:38:12.283: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:38:12.283: INFO: Found 1 / 1
Feb 28 19:38:12.283: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 28 19:38:12.287: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:38:12.287: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 28 19:38:12.287: INFO: wait on redis-master startup in kubectl-3898 
Feb 28 19:38:12.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs redis-master-47qjn redis-master --namespace=kubectl-3898'
Feb 28 19:38:12.411: INFO: stderr: ""
Feb 28 19:38:12.411: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Feb 19:38:10.700 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Feb 19:38:10.700 # Server started, Redis version 3.2.12\n1:M 28 Feb 19:38:10.700 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Feb 19:38:10.700 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 28 19:38:12.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3898'
Feb 28 19:38:12.582: INFO: stderr: ""
Feb 28 19:38:12.582: INFO: stdout: "service/rm2 exposed\n"
Feb 28 19:38:12.590: INFO: Service rm2 in namespace kubectl-3898 found.
STEP: exposing service
Feb 28 19:38:14.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3898'
Feb 28 19:38:14.728: INFO: stderr: ""
Feb 28 19:38:14.728: INFO: stdout: "service/rm3 exposed\n"
Feb 28 19:38:14.733: INFO: Service rm3 in namespace kubectl-3898 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:38:16.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3898" for this suite.
Feb 28 19:38:38.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:38:38.862: INFO: namespace kubectl-3898 deletion completed in 22.119559718s

• [SLOW TEST:30.108 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:38:38.865: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 28 19:38:38.903: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:38:42.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3847" for this suite.
Feb 28 19:38:48.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:38:48.236: INFO: namespace init-container-3847 deletion completed in 6.119865732s

• [SLOW TEST:9.371 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:38:48.237: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:38:48.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b" in namespace "projected-3732" to be "success or failure"
Feb 28 19:38:48.297: INFO: Pod "downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036898ms
Feb 28 19:38:50.300: INFO: Pod "downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009584467s
STEP: Saw pod success
Feb 28 19:38:50.300: INFO: Pod "downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b" satisfied condition "success or failure"
Feb 28 19:38:50.304: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b container client-container: <nil>
STEP: delete the pod
Feb 28 19:38:50.325: INFO: Waiting for pod downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b to disappear
Feb 28 19:38:50.329: INFO: Pod downwardapi-volume-dc0ef0cb-cddc-4f49-9013-e83ec0d9e52b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:38:50.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3732" for this suite.
Feb 28 19:38:56.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:38:56.479: INFO: namespace projected-3732 deletion completed in 6.136512313s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:38:56.482: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 28 19:39:00.595: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:00.599: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:02.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:02.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:04.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:04.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:06.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:06.606: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:08.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:08.608: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:10.606: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:10.613: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:12.601: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:12.605: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:14.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:14.605: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:16.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:16.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:18.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:18.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:20.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:20.605: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:22.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:22.613: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:24.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:24.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:26.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:26.604: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 28 19:39:28.600: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 28 19:39:28.616: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:39:28.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4863" for this suite.
Feb 28 19:39:40.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:39:40.797: INFO: namespace container-lifecycle-hook-4863 deletion completed in 12.123923619s

• [SLOW TEST:44.315 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:39:40.799: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-90b4a206-2458-415f-a43e-82bdd73c5a2d
STEP: Creating configMap with name cm-test-opt-upd-c4e41a20-ed38-47bc-b235-0150117464ff
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-90b4a206-2458-415f-a43e-82bdd73c5a2d
STEP: Updating configmap cm-test-opt-upd-c4e41a20-ed38-47bc-b235-0150117464ff
STEP: Creating configMap with name cm-test-opt-create-013f028d-c7f1-4afd-bcbe-656620ad9708
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:40:59.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6543" for this suite.
Feb 28 19:41:21.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:41:21.591: INFO: namespace configmap-6543 deletion completed in 22.132838044s

• [SLOW TEST:100.792 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:41:21.591: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:41:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2725" for this suite.
Feb 28 19:41:27.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:41:27.752: INFO: namespace services-2725 deletion completed in 6.1065239s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.160 seconds]
[sig-network] Services
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:41:27.753: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8rhz
STEP: Creating a pod to test atomic-volume-subpath
Feb 28 19:41:27.814: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8rhz" in namespace "subpath-9349" to be "success or failure"
Feb 28 19:41:27.819: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.187798ms
Feb 28 19:41:29.824: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 2.010368434s
Feb 28 19:41:31.829: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 4.01467023s
Feb 28 19:41:33.833: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 6.018832877s
Feb 28 19:41:35.836: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 8.022362557s
Feb 28 19:41:37.840: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 10.026107049s
Feb 28 19:41:39.844: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 12.029867649s
Feb 28 19:41:41.848: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 14.034290275s
Feb 28 19:41:43.853: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 16.039192057s
Feb 28 19:41:45.858: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 18.044260599s
Feb 28 19:41:47.862: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 20.048055382s
Feb 28 19:41:49.867: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Running", Reason="", readiness=true. Elapsed: 22.052900629s
Feb 28 19:41:51.871: INFO: Pod "pod-subpath-test-configmap-8rhz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057437575s
STEP: Saw pod success
Feb 28 19:41:51.872: INFO: Pod "pod-subpath-test-configmap-8rhz" satisfied condition "success or failure"
Feb 28 19:41:51.875: INFO: Trying to get logs from node wenjun192 pod pod-subpath-test-configmap-8rhz container test-container-subpath-configmap-8rhz: <nil>
STEP: delete the pod
Feb 28 19:41:51.912: INFO: Waiting for pod pod-subpath-test-configmap-8rhz to disappear
Feb 28 19:41:51.921: INFO: Pod pod-subpath-test-configmap-8rhz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8rhz
Feb 28 19:41:51.921: INFO: Deleting pod "pod-subpath-test-configmap-8rhz" in namespace "subpath-9349"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:41:51.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9349" for this suite.
Feb 28 19:41:57.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:41:58.048: INFO: namespace subpath-9349 deletion completed in 6.11728643s

• [SLOW TEST:30.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:41:58.049: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 28 19:42:02.179: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 28 19:42:02.183: INFO: Pod pod-with-poststart-http-hook still exists
Feb 28 19:42:04.183: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 28 19:42:04.191: INFO: Pod pod-with-poststart-http-hook still exists
Feb 28 19:42:06.183: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 28 19:42:06.199: INFO: Pod pod-with-poststart-http-hook still exists
Feb 28 19:42:08.183: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 28 19:42:08.187: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:42:08.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4655" for this suite.
Feb 28 19:42:30.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:42:30.305: INFO: namespace container-lifecycle-hook-4655 deletion completed in 22.111069306s

• [SLOW TEST:32.256 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:42:30.306: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:42:30.384: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 28 19:42:30.393: INFO: Number of nodes with available pods: 0
Feb 28 19:42:30.393: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 28 19:42:30.412: INFO: Number of nodes with available pods: 0
Feb 28 19:42:30.412: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:31.416: INFO: Number of nodes with available pods: 0
Feb 28 19:42:31.416: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:32.416: INFO: Number of nodes with available pods: 0
Feb 28 19:42:32.416: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:33.416: INFO: Number of nodes with available pods: 1
Feb 28 19:42:33.418: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 28 19:42:33.437: INFO: Number of nodes with available pods: 1
Feb 28 19:42:33.437: INFO: Number of running nodes: 0, number of available pods: 1
Feb 28 19:42:34.446: INFO: Number of nodes with available pods: 0
Feb 28 19:42:34.446: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 28 19:42:34.471: INFO: Number of nodes with available pods: 0
Feb 28 19:42:34.471: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:35.476: INFO: Number of nodes with available pods: 0
Feb 28 19:42:35.476: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:36.475: INFO: Number of nodes with available pods: 0
Feb 28 19:42:36.475: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:37.476: INFO: Number of nodes with available pods: 0
Feb 28 19:42:37.476: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:38.476: INFO: Number of nodes with available pods: 0
Feb 28 19:42:38.476: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 19:42:39.475: INFO: Number of nodes with available pods: 1
Feb 28 19:42:39.475: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3204, will wait for the garbage collector to delete the pods
Feb 28 19:42:39.545: INFO: Deleting DaemonSet.extensions daemon-set took: 6.01121ms
Feb 28 19:42:39.945: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.287151ms
Feb 28 19:42:42.948: INFO: Number of nodes with available pods: 0
Feb 28 19:42:42.948: INFO: Number of running nodes: 0, number of available pods: 0
Feb 28 19:42:42.955: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3204/daemonsets","resourceVersion":"12267"},"items":null}

Feb 28 19:42:42.957: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3204/pods","resourceVersion":"12267"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:42:42.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3204" for this suite.
Feb 28 19:42:48.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:42:49.210: INFO: namespace daemonsets-3204 deletion completed in 6.227605236s

• [SLOW TEST:18.904 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:42:49.212: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9980652d-8036-48df-ab9e-f0a138d95e8b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9980652d-8036-48df-ab9e-f0a138d95e8b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:42:53.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6410" for this suite.
Feb 28 19:43:15.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:43:15.501: INFO: namespace projected-6410 deletion completed in 22.12945679s

• [SLOW TEST:26.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:43:15.502: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Feb 28 19:43:15.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-9447'
Feb 28 19:43:15.782: INFO: stderr: ""
Feb 28 19:43:15.782: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 19:43:15.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9447'
Feb 28 19:43:15.893: INFO: stderr: ""
Feb 28 19:43:15.893: INFO: stdout: "update-demo-nautilus-mg9hd update-demo-nautilus-ncq87 "
Feb 28 19:43:15.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mg9hd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:16.002: INFO: stderr: ""
Feb 28 19:43:16.002: INFO: stdout: ""
Feb 28 19:43:16.002: INFO: update-demo-nautilus-mg9hd is created but not running
Feb 28 19:43:21.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9447'
Feb 28 19:43:21.119: INFO: stderr: ""
Feb 28 19:43:21.119: INFO: stdout: "update-demo-nautilus-mg9hd update-demo-nautilus-ncq87 "
Feb 28 19:43:21.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mg9hd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:21.214: INFO: stderr: ""
Feb 28 19:43:21.214: INFO: stdout: "true"
Feb 28 19:43:21.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-mg9hd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:21.308: INFO: stderr: ""
Feb 28 19:43:21.313: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:43:21.313: INFO: validating pod update-demo-nautilus-mg9hd
Feb 28 19:43:21.324: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:43:21.324: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:43:21.324: INFO: update-demo-nautilus-mg9hd is verified up and running
Feb 28 19:43:21.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-ncq87 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:21.419: INFO: stderr: ""
Feb 28 19:43:21.419: INFO: stdout: "true"
Feb 28 19:43:21.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-ncq87 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:21.508: INFO: stderr: ""
Feb 28 19:43:21.508: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 19:43:21.508: INFO: validating pod update-demo-nautilus-ncq87
Feb 28 19:43:21.515: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 19:43:21.515: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 19:43:21.515: INFO: update-demo-nautilus-ncq87 is verified up and running
STEP: rolling-update to new replication controller
Feb 28 19:43:21.523: INFO: scanned /root for discovery docs: <nil>
Feb 28 19:43:21.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9447'
Feb 28 19:43:44.094: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 28 19:43:44.094: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 19:43:44.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9447'
Feb 28 19:43:44.231: INFO: stderr: ""
Feb 28 19:43:44.232: INFO: stdout: "update-demo-kitten-cnxlg update-demo-kitten-mqqqg "
Feb 28 19:43:44.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-kitten-cnxlg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:44.324: INFO: stderr: ""
Feb 28 19:43:44.324: INFO: stdout: "true"
Feb 28 19:43:44.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-kitten-cnxlg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:44.420: INFO: stderr: ""
Feb 28 19:43:44.420: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 28 19:43:44.420: INFO: validating pod update-demo-kitten-cnxlg
Feb 28 19:43:44.430: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 28 19:43:44.430: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 28 19:43:44.430: INFO: update-demo-kitten-cnxlg is verified up and running
Feb 28 19:43:44.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-kitten-mqqqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:44.524: INFO: stderr: ""
Feb 28 19:43:44.524: INFO: stdout: "true"
Feb 28 19:43:44.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-kitten-mqqqg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9447'
Feb 28 19:43:44.636: INFO: stderr: ""
Feb 28 19:43:44.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 28 19:43:44.636: INFO: validating pod update-demo-kitten-mqqqg
Feb 28 19:43:44.645: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 28 19:43:44.645: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 28 19:43:44.645: INFO: update-demo-kitten-mqqqg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:43:44.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9447" for this suite.
Feb 28 19:44:06.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:44:06.761: INFO: namespace kubectl-9447 deletion completed in 22.100008326s

• [SLOW TEST:51.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:44:06.762: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 19:44:06.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1064'
Feb 28 19:44:06.974: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 28 19:44:06.974: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 28 19:44:06.994: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-t8g44]
Feb 28 19:44:06.994: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-t8g44" in namespace "kubectl-1064" to be "running and ready"
Feb 28 19:44:07.005: INFO: Pod "e2e-test-nginx-rc-t8g44": Phase="Pending", Reason="", readiness=false. Elapsed: 10.372019ms
Feb 28 19:44:09.009: INFO: Pod "e2e-test-nginx-rc-t8g44": Phase="Running", Reason="", readiness=true. Elapsed: 2.014578671s
Feb 28 19:44:09.009: INFO: Pod "e2e-test-nginx-rc-t8g44" satisfied condition "running and ready"
Feb 28 19:44:09.009: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-t8g44]
Feb 28 19:44:09.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 logs rc/e2e-test-nginx-rc --namespace=kubectl-1064'
Feb 28 19:44:09.121: INFO: stderr: ""
Feb 28 19:44:09.121: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Feb 28 19:44:09.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete rc e2e-test-nginx-rc --namespace=kubectl-1064'
Feb 28 19:44:09.227: INFO: stderr: ""
Feb 28 19:44:09.227: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:44:09.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1064" for this suite.
Feb 28 19:44:15.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:44:15.330: INFO: namespace kubectl-1064 deletion completed in 6.095982404s

• [SLOW TEST:8.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:44:15.331: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Feb 28 19:44:15.377: INFO: Waiting up to 5m0s for pod "client-containers-34b8250d-30d3-4fb6-a495-069254ec646b" in namespace "containers-9482" to be "success or failure"
Feb 28 19:44:15.383: INFO: Pod "client-containers-34b8250d-30d3-4fb6-a495-069254ec646b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.567897ms
Feb 28 19:44:17.387: INFO: Pod "client-containers-34b8250d-30d3-4fb6-a495-069254ec646b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010669662s
STEP: Saw pod success
Feb 28 19:44:17.387: INFO: Pod "client-containers-34b8250d-30d3-4fb6-a495-069254ec646b" satisfied condition "success or failure"
Feb 28 19:44:17.390: INFO: Trying to get logs from node wenjun192 pod client-containers-34b8250d-30d3-4fb6-a495-069254ec646b container test-container: <nil>
STEP: delete the pod
Feb 28 19:44:17.436: INFO: Waiting for pod client-containers-34b8250d-30d3-4fb6-a495-069254ec646b to disappear
Feb 28 19:44:17.439: INFO: Pod client-containers-34b8250d-30d3-4fb6-a495-069254ec646b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:44:17.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9482" for this suite.
Feb 28 19:44:23.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:44:23.560: INFO: namespace containers-9482 deletion completed in 6.108332223s

• [SLOW TEST:8.228 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:44:23.561: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 28 19:44:23.619: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6292,SelfLink:/api/v1/namespaces/watch-6292/configmaps/e2e-watch-test-resource-version,UID:5b30e04f-69fd-476d-aec2-691e42f531aa,ResourceVersion:12777,Generation:0,CreationTimestamp:2020-02-28 19:44:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 28 19:44:23.620: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6292,SelfLink:/api/v1/namespaces/watch-6292/configmaps/e2e-watch-test-resource-version,UID:5b30e04f-69fd-476d-aec2-691e42f531aa,ResourceVersion:12778,Generation:0,CreationTimestamp:2020-02-28 19:44:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:44:23.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6292" for this suite.
Feb 28 19:44:29.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:44:29.743: INFO: namespace watch-6292 deletion completed in 6.117927767s

• [SLOW TEST:6.181 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:44:29.743: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:44:29.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-7248'
Feb 28 19:44:30.008: INFO: stderr: ""
Feb 28 19:44:30.008: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 28 19:44:30.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-7248'
Feb 28 19:44:30.228: INFO: stderr: ""
Feb 28 19:44:30.228: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 28 19:44:31.235: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:44:31.235: INFO: Found 0 / 1
Feb 28 19:44:32.234: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:44:32.234: INFO: Found 0 / 1
Feb 28 19:44:33.232: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:44:33.233: INFO: Found 1 / 1
Feb 28 19:44:33.233: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 28 19:44:33.236: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:44:33.236: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 28 19:44:33.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 describe pod redis-master-xm6kb --namespace=kubectl-7248'
Feb 28 19:44:33.363: INFO: stderr: ""
Feb 28 19:44:33.363: INFO: stdout: "Name:           redis-master-xm6kb\nNamespace:      kubectl-7248\nPriority:       0\nNode:           wenjun192/10.10.1.192\nStart Time:     Fri, 28 Feb 2020 19:44:30 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.34.187.11\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e2648e41140902732575a642ec2fd2878a71ab0e781e95766001472b1cb84ab3\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 28 Feb 2020 19:44:31 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mqm6q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-mqm6q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mqm6q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  3s    default-scheduler   Successfully assigned kubectl-7248/redis-master-xm6kb to wenjun192\n  Normal  Pulled     2s    kubelet, wenjun192  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, wenjun192  Created container redis-master\n  Normal  Started    2s    kubelet, wenjun192  Started container redis-master\n"
Feb 28 19:44:33.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 describe rc redis-master --namespace=kubectl-7248'
Feb 28 19:44:33.489: INFO: stderr: ""
Feb 28 19:44:33.489: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7248\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-xm6kb\n"
Feb 28 19:44:33.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 describe service redis-master --namespace=kubectl-7248'
Feb 28 19:44:33.603: INFO: stderr: ""
Feb 28 19:44:33.603: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7248\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.97.155.76\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.34.187.11:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 28 19:44:33.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 describe node wenjun191'
Feb 28 19:44:33.761: INFO: stderr: ""
Feb 28 19:44:33.761: INFO: stdout: "Name:               wenjun191\nRoles:              compute,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=wenjun191\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/compute=true\n                    node-role.kubernetes.io/master=true\nAnnotations:        miaoyun.io/logical-cpus: 4\n                    miaoyun.io/physical-cpus: 0\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 28 Feb 2020 18:54:56 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 28 Feb 2020 19:44:24 +0000   Fri, 28 Feb 2020 18:54:50 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 28 Feb 2020 19:44:24 +0000   Fri, 28 Feb 2020 18:54:50 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 28 Feb 2020 19:44:24 +0000   Fri, 28 Feb 2020 18:54:50 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 28 Feb 2020 19:44:24 +0000   Fri, 28 Feb 2020 18:55:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.10.1.191\n  Hostname:    wenjun191\nCapacity:\n cpu:                4\n ephemeral-storage:  95989956Ki\n hugepages-2Mi:      0\n memory:             8174912Ki\n pods:               55\nAllocatable:\n cpu:                4\n ephemeral-storage:  95989956Ki\n hugepages-2Mi:      0\n memory:             8043840Ki\n pods:               55\nSystem Info:\n Machine ID:                 f6c2de5ea33b6cc2d2d9daca5a3c5909\n System UUID:                AA025829-7ACA-4CAA-9203-D7E20D3B5B62\n Boot ID:                    102ea624-4c8b-4c6c-881f-9c5aa43c93c3\n Kernel Version:             4.4.0-87-generic\n OS Image:                   Ubuntu 16.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.9\n Kube-Proxy Version:         v1.15.9\nPodCIDR:                     10.32.0.0/24\nNon-terminated Pods:         (16 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-kube-controllers-5c94f45bd8-jpk5k                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  kube-system                calico-node-xxbcr                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  kube-system                chiwen-agent-9k95q                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  kube-system                chiwen-ingress-controller-9n2n2                            0 (0%)        0 (0%)      100Mi (1%)       0 (0%)         49m\n  kube-system                chiwen-k8s-agent-wenjun191                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                chiwen-volume-plugin-2jmh7                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  kube-system                coredns-6879c49cff-wmp8f                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     49m\n  kube-system                custom-metrics-apiserver-7bf8c988f9-7rz52                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         49m\n  kube-system                etcd-wenjun191                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-apiserver-wenjun191                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-controller-manager-wenjun191                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-scheduler-wenjun191                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         48m\n  kube-system                kube-state-metrics-6b5897fbb8-wfksz                        101m (2%)     101m (2%)   223Mi (2%)       203Mi (2%)     49m\n  kube-system                node-exporter-m7r4n                                        0 (0%)        0 (0%)      20Mi (0%)        0 (0%)         49m\n  kube-system                prometheus-deployment-55cfdd8597-pw6tt                     250m (6%)     0 (0%)      1500Mi (19%)     0 (0%)         49m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-wsn2d    0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                451m (11%)    101m (2%)\n  memory             1913Mi (24%)  373Mi (4%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:\n  Type    Reason                   Age                From                Message\n  ----    ------                   ----               ----                -------\n  Normal  NodeHasSufficientPID     49m (x7 over 49m)  kubelet, wenjun191  Node wenjun191 status is now: NodeHasSufficientPID\n  Normal  NodeHasSufficientMemory  49m (x8 over 49m)  kubelet, wenjun191  Node wenjun191 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    49m (x8 over 49m)  kubelet, wenjun191  Node wenjun191 status is now: NodeHasNoDiskPressure\n"
Feb 28 19:44:33.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 describe namespace kubectl-7248'
Feb 28 19:44:33.874: INFO: stderr: ""
Feb 28 19:44:33.874: INFO: stdout: "Name:         kubectl-7248\nLabels:       e2e-framework=kubectl\n              e2e-run=69d072cb-d8aa-4a05-a680-b5245d2e360a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:44:33.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7248" for this suite.
Feb 28 19:44:55.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:44:55.982: INFO: namespace kubectl-7248 deletion completed in 22.10126931s

• [SLOW TEST:26.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:44:55.982: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 28 19:44:56.053: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6522,SelfLink:/api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed,UID:1d3322a7-f511-4b87-a13f-57635906d584,ResourceVersion:12910,Generation:0,CreationTimestamp:2020-02-28 19:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 28 19:44:56.053: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6522,SelfLink:/api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed,UID:1d3322a7-f511-4b87-a13f-57635906d584,ResourceVersion:12911,Generation:0,CreationTimestamp:2020-02-28 19:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 28 19:44:56.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6522,SelfLink:/api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed,UID:1d3322a7-f511-4b87-a13f-57635906d584,ResourceVersion:12912,Generation:0,CreationTimestamp:2020-02-28 19:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 28 19:44:56.068: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-6522,SelfLink:/api/v1/namespaces/watch-6522/configmaps/e2e-watch-test-watch-closed,UID:1d3322a7-f511-4b87-a13f-57635906d584,ResourceVersion:12913,Generation:0,CreationTimestamp:2020-02-28 19:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:44:56.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6522" for this suite.
Feb 28 19:45:02.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:45:02.182: INFO: namespace watch-6522 deletion completed in 6.109396058s

• [SLOW TEST:6.200 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:45:02.183: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:45:02.237: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b" in namespace "projected-9847" to be "success or failure"
Feb 28 19:45:02.254: INFO: Pod "downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.049715ms
Feb 28 19:45:04.259: INFO: Pod "downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021697918s
STEP: Saw pod success
Feb 28 19:45:04.260: INFO: Pod "downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b" satisfied condition "success or failure"
Feb 28 19:45:04.264: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b container client-container: <nil>
STEP: delete the pod
Feb 28 19:45:04.289: INFO: Waiting for pod downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b to disappear
Feb 28 19:45:04.292: INFO: Pod downwardapi-volume-17ed1e73-6b7c-49b3-af52-75306f98746b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:45:04.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9847" for this suite.
Feb 28 19:45:10.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:45:10.397: INFO: namespace projected-9847 deletion completed in 6.095397916s

• [SLOW TEST:8.214 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:45:10.398: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0228 19:45:50.487171      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 28 19:45:50.487: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:45:50.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5331" for this suite.
Feb 28 19:45:56.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:45:56.624: INFO: namespace gc-5331 deletion completed in 6.128641816s

• [SLOW TEST:46.225 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:45:56.625: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6455.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6455.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6455.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6455.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 19:46:00.783: INFO: DNS probes using dns-6455/dns-test-b63617d6-f8d0-4eaa-b417-0d8522c8d2dd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:46:00.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6455" for this suite.
Feb 28 19:46:06.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:46:06.941: INFO: namespace dns-6455 deletion completed in 6.125670065s

• [SLOW TEST:10.316 seconds]
[sig-network] DNS
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:46:06.942: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:46:06.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54" in namespace "downward-api-5984" to be "success or failure"
Feb 28 19:46:07.017: INFO: Pod "downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54": Phase="Pending", Reason="", readiness=false. Elapsed: 19.532447ms
Feb 28 19:46:09.022: INFO: Pod "downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024574979s
STEP: Saw pod success
Feb 28 19:46:09.022: INFO: Pod "downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54" satisfied condition "success or failure"
Feb 28 19:46:09.024: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54 container client-container: <nil>
STEP: delete the pod
Feb 28 19:46:09.046: INFO: Waiting for pod downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54 to disappear
Feb 28 19:46:09.049: INFO: Pod downwardapi-volume-6ff986df-6776-4db5-b33e-d9f9e6617f54 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:46:09.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5984" for this suite.
Feb 28 19:46:15.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:46:15.157: INFO: namespace downward-api-5984 deletion completed in 6.102120355s

• [SLOW TEST:8.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:46:15.157: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 28 19:46:25.264: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:46:25.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0228 19:46:25.264566      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9065" for this suite.
Feb 28 19:46:31.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:46:31.451: INFO: namespace gc-9065 deletion completed in 6.182207983s

• [SLOW TEST:16.294 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:46:31.453: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 28 19:46:35.539: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-779692974 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 28 19:46:50.639: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:46:50.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7431" for this suite.
Feb 28 19:46:56.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:46:56.782: INFO: namespace pods-7431 deletion completed in 6.133324314s

• [SLOW TEST:25.328 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:46:56.784: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 19:47:00.859: INFO: DNS probes using dns-test-a924fd09-0f59-4735-b15f-016ba0aadacb succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 19:47:04.916: INFO: File wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:04.919: INFO: File jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:04.919: INFO: Lookups using dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 failed for: [wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local]

Feb 28 19:47:09.931: INFO: File wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:09.935: INFO: File jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:09.935: INFO: Lookups using dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 failed for: [wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local]

Feb 28 19:47:14.926: INFO: File wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:14.935: INFO: File jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:14.935: INFO: Lookups using dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 failed for: [wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local]

Feb 28 19:47:19.925: INFO: File wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:19.929: INFO: File jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:19.929: INFO: Lookups using dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 failed for: [wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local]

Feb 28 19:47:24.931: INFO: File wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:24.936: INFO: File jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local from pod  dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 28 19:47:24.936: INFO: Lookups using dns-4362/dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 failed for: [wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local]

Feb 28 19:47:29.928: INFO: DNS probes using dns-test-5e793611-1eba-4d50-ae13-37aeb80ed100 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4362.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4362.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 19:47:34.052: INFO: DNS probes using dns-test-45d9ea84-f1d8-4afa-9f99-bef9eafb46dd succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:47:34.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4362" for this suite.
Feb 28 19:47:40.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:47:40.292: INFO: namespace dns-4362 deletion completed in 6.167283196s

• [SLOW TEST:43.508 seconds]
[sig-network] DNS
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:47:40.293: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 28 19:47:40.353: INFO: Waiting up to 5m0s for pod "pod-68a309aa-2928-4045-8ace-5b1ddf6492de" in namespace "emptydir-8616" to be "success or failure"
Feb 28 19:47:40.363: INFO: Pod "pod-68a309aa-2928-4045-8ace-5b1ddf6492de": Phase="Pending", Reason="", readiness=false. Elapsed: 9.72366ms
Feb 28 19:47:42.366: INFO: Pod "pod-68a309aa-2928-4045-8ace-5b1ddf6492de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013307674s
STEP: Saw pod success
Feb 28 19:47:42.366: INFO: Pod "pod-68a309aa-2928-4045-8ace-5b1ddf6492de" satisfied condition "success or failure"
Feb 28 19:47:42.370: INFO: Trying to get logs from node wenjun192 pod pod-68a309aa-2928-4045-8ace-5b1ddf6492de container test-container: <nil>
STEP: delete the pod
Feb 28 19:47:42.390: INFO: Waiting for pod pod-68a309aa-2928-4045-8ace-5b1ddf6492de to disappear
Feb 28 19:47:42.393: INFO: Pod pod-68a309aa-2928-4045-8ace-5b1ddf6492de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:47:42.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8616" for this suite.
Feb 28 19:47:48.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:47:48.509: INFO: namespace emptydir-8616 deletion completed in 6.10929124s

• [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:47:48.517: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-36d74bae-d8c8-4887-a78b-9e9461a86a6f
STEP: Creating a pod to test consume configMaps
Feb 28 19:47:48.571: INFO: Waiting up to 5m0s for pod "pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5" in namespace "configmap-6011" to be "success or failure"
Feb 28 19:47:48.585: INFO: Pod "pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.008505ms
Feb 28 19:47:50.592: INFO: Pod "pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020429225s
STEP: Saw pod success
Feb 28 19:47:50.592: INFO: Pod "pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5" satisfied condition "success or failure"
Feb 28 19:47:50.595: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:47:50.614: INFO: Waiting for pod pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5 to disappear
Feb 28 19:47:50.617: INFO: Pod pod-configmaps-56885245-08ed-4c25-a2cf-891a841e02a5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:47:50.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6011" for this suite.
Feb 28 19:47:56.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:47:56.736: INFO: namespace configmap-6011 deletion completed in 6.113265366s

• [SLOW TEST:8.219 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:47:56.736: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:47:56.789: INFO: (0) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 5.441163ms)
Feb 28 19:47:56.795: INFO: (1) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 5.342828ms)
Feb 28 19:47:56.799: INFO: (2) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.189815ms)
Feb 28 19:47:56.803: INFO: (3) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.716314ms)
Feb 28 19:47:56.807: INFO: (4) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.389396ms)
Feb 28 19:47:56.812: INFO: (5) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.779867ms)
Feb 28 19:47:56.817: INFO: (6) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.843585ms)
Feb 28 19:47:56.821: INFO: (7) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.028389ms)
Feb 28 19:47:56.825: INFO: (8) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.283361ms)
Feb 28 19:47:56.830: INFO: (9) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.527093ms)
Feb 28 19:47:56.834: INFO: (10) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.81893ms)
Feb 28 19:47:56.837: INFO: (11) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.389053ms)
Feb 28 19:47:56.842: INFO: (12) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.634584ms)
Feb 28 19:47:56.846: INFO: (13) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.214538ms)
Feb 28 19:47:56.850: INFO: (14) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.544425ms)
Feb 28 19:47:56.855: INFO: (15) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.332332ms)
Feb 28 19:47:56.858: INFO: (16) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.374872ms)
Feb 28 19:47:56.862: INFO: (17) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.837359ms)
Feb 28 19:47:56.866: INFO: (18) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.921299ms)
Feb 28 19:47:56.870: INFO: (19) /api/v1/nodes/wenjun191:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.82764ms)
[AfterEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:47:56.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4348" for this suite.
Feb 28 19:48:02.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:48:02.993: INFO: namespace proxy-4348 deletion completed in 6.11726044s

• [SLOW TEST:6.257 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:48:03.000: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-7b9f9f5e-7930-47a3-bf4a-9a0e4892c1e6
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:48:03.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7384" for this suite.
Feb 28 19:48:09.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:48:09.148: INFO: namespace configmap-7384 deletion completed in 6.107275943s

• [SLOW TEST:6.148 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:48:09.148: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 28 19:48:09.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-5488'
Feb 28 19:48:09.558: INFO: stderr: ""
Feb 28 19:48:09.558: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 28 19:48:10.563: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:48:10.563: INFO: Found 0 / 1
Feb 28 19:48:11.564: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:48:11.564: INFO: Found 0 / 1
Feb 28 19:48:12.563: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:48:12.563: INFO: Found 1 / 1
Feb 28 19:48:12.563: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 28 19:48:12.567: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:48:12.567: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 28 19:48:12.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 patch pod redis-master-ljbjf --namespace=kubectl-5488 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 28 19:48:12.683: INFO: stderr: ""
Feb 28 19:48:12.683: INFO: stdout: "pod/redis-master-ljbjf patched\n"
STEP: checking annotations
Feb 28 19:48:12.691: INFO: Selector matched 1 pods for map[app:redis]
Feb 28 19:48:12.691: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:48:12.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5488" for this suite.
Feb 28 19:48:34.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:48:34.826: INFO: namespace kubectl-5488 deletion completed in 22.129843055s

• [SLOW TEST:25.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:48:34.828: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 28 19:48:42.999: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:43.002: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:45.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:45.007: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:47.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:47.009: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:49.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:49.006: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:51.003: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:51.014: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:53.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:53.007: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:55.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:55.007: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:57.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:57.008: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:48:59.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:48:59.010: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 28 19:49:01.002: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 28 19:49:01.007: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:49:01.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7226" for this suite.
Feb 28 19:49:23.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:49:23.155: INFO: namespace container-lifecycle-hook-7226 deletion completed in 22.126119114s

• [SLOW TEST:48.328 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:49:23.158: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:49:25.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1159" for this suite.
Feb 28 19:50:19.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:50:19.353: INFO: namespace kubelet-test-1159 deletion completed in 54.117929408s

• [SLOW TEST:56.196 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:50:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:50:19.425: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e" in namespace "downward-api-5730" to be "success or failure"
Feb 28 19:50:19.429: INFO: Pod "downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.689082ms
Feb 28 19:50:21.435: INFO: Pod "downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009336705s
Feb 28 19:50:23.439: INFO: Pod "downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013138108s
STEP: Saw pod success
Feb 28 19:50:23.439: INFO: Pod "downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e" satisfied condition "success or failure"
Feb 28 19:50:23.441: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e container client-container: <nil>
STEP: delete the pod
Feb 28 19:50:23.461: INFO: Waiting for pod downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e to disappear
Feb 28 19:50:23.467: INFO: Pod downwardapi-volume-bbe6d815-334e-4d66-9cfa-76fe14a4a19e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:50:23.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5730" for this suite.
Feb 28 19:50:29.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:50:29.572: INFO: namespace downward-api-5730 deletion completed in 6.10083986s

• [SLOW TEST:10.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:50:29.578: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-11e79307-a83b-4d1e-ba74-53a1f0c9ea3d
STEP: Creating a pod to test consume configMaps
Feb 28 19:50:29.641: INFO: Waiting up to 5m0s for pod "pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802" in namespace "configmap-282" to be "success or failure"
Feb 28 19:50:29.645: INFO: Pod "pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802": Phase="Pending", Reason="", readiness=false. Elapsed: 3.350899ms
Feb 28 19:50:31.649: INFO: Pod "pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007327337s
Feb 28 19:50:33.655: INFO: Pod "pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013974982s
STEP: Saw pod success
Feb 28 19:50:33.655: INFO: Pod "pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802" satisfied condition "success or failure"
Feb 28 19:50:33.658: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:50:33.685: INFO: Waiting for pod pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802 to disappear
Feb 28 19:50:33.688: INFO: Pod pod-configmaps-e486ac7a-19b4-4b74-88fe-18758af45802 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:50:33.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-282" for this suite.
Feb 28 19:50:39.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:50:39.781: INFO: namespace configmap-282 deletion completed in 6.088909881s

• [SLOW TEST:10.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:50:39.785: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb
Feb 28 19:50:39.827: INFO: Pod name my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb: Found 0 pods out of 1
Feb 28 19:50:44.833: INFO: Pod name my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb: Found 1 pods out of 1
Feb 28 19:50:44.833: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb" are running
Feb 28 19:50:44.842: INFO: Pod "my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb-ffrr9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:50:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:50:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:50:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-28 19:50:39 +0000 UTC Reason: Message:}])
Feb 28 19:50:44.842: INFO: Trying to dial the pod
Feb 28 19:50:49.854: INFO: Controller my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb: Got expected result from replica 1 [my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb-ffrr9]: "my-hostname-basic-bedbc789-e666-4e05-8097-dbfdcf889adb-ffrr9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:50:49.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-255" for this suite.
Feb 28 19:50:55.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:50:55.978: INFO: namespace replication-controller-255 deletion completed in 6.118177138s

• [SLOW TEST:16.193 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:50:55.980: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 28 19:50:56.057: INFO: Waiting up to 5m0s for pod "pod-4bd26644-5b39-467e-822d-d915c68729ab" in namespace "emptydir-6037" to be "success or failure"
Feb 28 19:50:56.062: INFO: Pod "pod-4bd26644-5b39-467e-822d-d915c68729ab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.704789ms
Feb 28 19:50:58.073: INFO: Pod "pod-4bd26644-5b39-467e-822d-d915c68729ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016361894s
STEP: Saw pod success
Feb 28 19:50:58.073: INFO: Pod "pod-4bd26644-5b39-467e-822d-d915c68729ab" satisfied condition "success or failure"
Feb 28 19:50:58.076: INFO: Trying to get logs from node wenjun192 pod pod-4bd26644-5b39-467e-822d-d915c68729ab container test-container: <nil>
STEP: delete the pod
Feb 28 19:50:58.100: INFO: Waiting for pod pod-4bd26644-5b39-467e-822d-d915c68729ab to disappear
Feb 28 19:50:58.104: INFO: Pod pod-4bd26644-5b39-467e-822d-d915c68729ab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:50:58.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6037" for this suite.
Feb 28 19:51:04.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:51:04.223: INFO: namespace emptydir-6037 deletion completed in 6.114512116s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:51:04.223: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 28 19:51:12.311: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:12.312: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:12.492: INFO: Exec stderr: ""
Feb 28 19:51:12.492: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:12.492: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:12.622: INFO: Exec stderr: ""
Feb 28 19:51:12.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:12.622: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:12.770: INFO: Exec stderr: ""
Feb 28 19:51:12.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:12.770: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:12.920: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 28 19:51:12.920: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:12.920: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.046: INFO: Exec stderr: ""
Feb 28 19:51:13.046: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:13.046: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.178: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 28 19:51:13.178: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:13.178: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.308: INFO: Exec stderr: ""
Feb 28 19:51:13.308: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:13.308: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.446: INFO: Exec stderr: ""
Feb 28 19:51:13.446: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:13.446: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.699: INFO: Exec stderr: ""
Feb 28 19:51:13.700: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6260 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 28 19:51:13.700: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
Feb 28 19:51:13.859: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:51:13.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6260" for this suite.
Feb 28 19:51:51.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:51:51.997: INFO: namespace e2e-kubelet-etc-hosts-6260 deletion completed in 38.13176779s

• [SLOW TEST:47.774 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:51:51.998: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 28 19:51:52.050: INFO: Waiting up to 5m0s for pod "pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc" in namespace "emptydir-5411" to be "success or failure"
Feb 28 19:51:52.057: INFO: Pod "pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.073949ms
Feb 28 19:51:54.061: INFO: Pod "pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011350819s
STEP: Saw pod success
Feb 28 19:51:54.061: INFO: Pod "pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc" satisfied condition "success or failure"
Feb 28 19:51:54.065: INFO: Trying to get logs from node wenjun192 pod pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc container test-container: <nil>
STEP: delete the pod
Feb 28 19:51:54.094: INFO: Waiting for pod pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc to disappear
Feb 28 19:51:54.098: INFO: Pod pod-dc203a2e-5d00-47b0-b1cb-f514d92941dc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:51:54.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5411" for this suite.
Feb 28 19:52:00.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:52:00.228: INFO: namespace emptydir-5411 deletion completed in 6.124653638s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:52:00.232: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2d017686-d7c4-4c7a-b91a-041d2ad836d1
STEP: Creating a pod to test consume configMaps
Feb 28 19:52:00.283: INFO: Waiting up to 5m0s for pod "pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d" in namespace "configmap-6838" to be "success or failure"
Feb 28 19:52:00.286: INFO: Pod "pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.923622ms
Feb 28 19:52:02.294: INFO: Pod "pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011196791s
STEP: Saw pod success
Feb 28 19:52:02.294: INFO: Pod "pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d" satisfied condition "success or failure"
Feb 28 19:52:02.301: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 19:52:02.340: INFO: Waiting for pod pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d to disappear
Feb 28 19:52:02.343: INFO: Pod pod-configmaps-550768c1-dd3a-49fd-a166-8d659e9a223d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:52:02.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6838" for this suite.
Feb 28 19:52:08.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:52:08.500: INFO: namespace configmap-6838 deletion completed in 6.135374669s

• [SLOW TEST:8.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:52:08.503: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 19:52:32.567: INFO: Container started at 2020-02-28 19:52:09 +0000 UTC, pod became ready at 2020-02-28 19:52:31 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:52:32.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1143" for this suite.
Feb 28 19:52:54.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:52:54.712: INFO: namespace container-probe-1143 deletion completed in 22.140231668s

• [SLOW TEST:46.209 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:52:54.714: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4083.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4083.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4083.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4083.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 248.199.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.199.248_udp@PTR;check="$$(dig +tcp +noall +answer +search 248.199.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.199.248_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4083.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4083.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4083.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4083.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4083.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4083.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 248.199.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.199.248_udp@PTR;check="$$(dig +tcp +noall +answer +search 248.199.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.199.248_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 19:52:58.849: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.853: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.858: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.861: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.883: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.889: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.892: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.895: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:52:58.915: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:03.921: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.926: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.928: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.932: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.959: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.963: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.967: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.970: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:03.997: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:08.921: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.925: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.927: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.930: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.952: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.955: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.958: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.963: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:08.990: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:13.937: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:13.945: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:13.954: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:13.958: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:13.993: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:13.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:14.004: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:14.007: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:14.030: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:18.922: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.925: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.930: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.933: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.956: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.959: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.962: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:18.969: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:19.015: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:23.920: INFO: Unable to read wheezy_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.923: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.930: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.934: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.956: INFO: Unable to read jessie_udp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.961: INFO: Unable to read jessie_tcp@dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.964: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.968: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local from pod dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105: the server could not find the requested resource (get pods dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105)
Feb 28 19:53:23.986: INFO: Lookups using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 failed for: [wheezy_udp@dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@dns-test-service.dns-4083.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_udp@dns-test-service.dns-4083.svc.cluster.local jessie_tcp@dns-test-service.dns-4083.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4083.svc.cluster.local]

Feb 28 19:53:29.076: INFO: DNS probes using dns-4083/dns-test-ff8c5c8f-1ccb-4f4d-9720-516432aca105 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:53:29.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4083" for this suite.
Feb 28 19:53:35.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:53:35.394: INFO: namespace dns-4083 deletion completed in 6.152500455s

• [SLOW TEST:40.680 seconds]
[sig-network] DNS
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:53:35.395: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:53:35.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321" in namespace "downward-api-6436" to be "success or failure"
Feb 28 19:53:35.531: INFO: Pod "downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321": Phase="Pending", Reason="", readiness=false. Elapsed: 25.341095ms
Feb 28 19:53:37.536: INFO: Pod "downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030335232s
STEP: Saw pod success
Feb 28 19:53:37.536: INFO: Pod "downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321" satisfied condition "success or failure"
Feb 28 19:53:37.548: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321 container client-container: <nil>
STEP: delete the pod
Feb 28 19:53:37.574: INFO: Waiting for pod downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321 to disappear
Feb 28 19:53:37.579: INFO: Pod downwardapi-volume-e96acb25-bbce-4f36-9f69-03c03b43d321 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:53:37.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6436" for this suite.
Feb 28 19:53:43.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:53:43.781: INFO: namespace downward-api-6436 deletion completed in 6.194450941s

• [SLOW TEST:8.386 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:53:43.783: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:54:06.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4148" for this suite.
Feb 28 19:54:12.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:54:12.413: INFO: namespace container-runtime-4148 deletion completed in 6.150593799s

• [SLOW TEST:28.631 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:54:12.416: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 28 19:54:17.000: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4809 pod-service-account-4ffe06ac-e784-46ab-9a2e-6484bb0b74b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 28 19:54:17.320: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4809 pod-service-account-4ffe06ac-e784-46ab-9a2e-6484bb0b74b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 28 19:54:17.601: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4809 pod-service-account-4ffe06ac-e784-46ab-9a2e-6484bb0b74b3 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:54:17.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4809" for this suite.
Feb 28 19:54:23.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:54:23.933: INFO: namespace svcaccounts-4809 deletion completed in 6.100518307s

• [SLOW TEST:11.518 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:54:23.935: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 28 19:54:23.973: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:54:38.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-838" for this suite.
Feb 28 19:54:44.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:54:44.319: INFO: namespace pods-838 deletion completed in 6.124234189s

• [SLOW TEST:20.384 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:54:44.325: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:54:44.382: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950" in namespace "projected-8223" to be "success or failure"
Feb 28 19:54:44.388: INFO: Pod "downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950": Phase="Pending", Reason="", readiness=false. Elapsed: 6.493905ms
Feb 28 19:54:46.394: INFO: Pod "downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011847785s
STEP: Saw pod success
Feb 28 19:54:46.394: INFO: Pod "downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950" satisfied condition "success or failure"
Feb 28 19:54:46.398: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950 container client-container: <nil>
STEP: delete the pod
Feb 28 19:54:46.440: INFO: Waiting for pod downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950 to disappear
Feb 28 19:54:46.443: INFO: Pod downwardapi-volume-b611ba98-e916-4add-88b7-688cf8f66950 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:54:46.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8223" for this suite.
Feb 28 19:54:52.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:54:52.591: INFO: namespace projected-8223 deletion completed in 6.141942742s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:54:52.592: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 19:54:52.696: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f" in namespace "downward-api-1000" to be "success or failure"
Feb 28 19:54:52.703: INFO: Pod "downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.191725ms
Feb 28 19:54:54.708: INFO: Pod "downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012310971s
STEP: Saw pod success
Feb 28 19:54:54.708: INFO: Pod "downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f" satisfied condition "success or failure"
Feb 28 19:54:54.712: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f container client-container: <nil>
STEP: delete the pod
Feb 28 19:54:54.740: INFO: Waiting for pod downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f to disappear
Feb 28 19:54:54.747: INFO: Pod downwardapi-volume-09075ec2-5c3c-4fa8-bd44-abad81fcd52f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:54:54.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1000" for this suite.
Feb 28 19:55:00.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:55:00.852: INFO: namespace downward-api-1000 deletion completed in 6.100353724s

• [SLOW TEST:8.260 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:55:00.853: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4433
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4433
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4433
Feb 28 19:55:00.952: INFO: Found 0 stateful pods, waiting for 1
Feb 28 19:55:10.958: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 28 19:55:10.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:55:11.226: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:55:11.226: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:55:11.227: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 19:55:11.231: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 28 19:55:21.247: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 19:55:21.248: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 19:55:21.293: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998833s
Feb 28 19:55:22.298: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994229689s
Feb 28 19:55:23.305: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988895776s
Feb 28 19:55:24.309: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982629738s
Feb 28 19:55:25.313: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978208868s
Feb 28 19:55:26.317: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97431618s
Feb 28 19:55:27.323: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970117696s
Feb 28 19:55:28.327: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964630011s
Feb 28 19:55:29.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959961777s
Feb 28 19:55:30.336: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.355147ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4433
Feb 28 19:55:31.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:55:31.602: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:55:31.602: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:55:31.602: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:55:31.607: INFO: Found 1 stateful pods, waiting for 3
Feb 28 19:55:41.614: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 19:55:41.614: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 19:55:41.614: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 28 19:55:41.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:55:41.883: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:55:41.883: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:55:41.883: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 19:55:41.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:55:42.195: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:55:42.195: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:55:42.195: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 19:55:42.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 19:55:42.441: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 19:55:42.441: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 19:55:42.441: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 19:55:42.441: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 19:55:42.447: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 28 19:55:52.457: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 19:55:52.457: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 19:55:52.457: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 19:55:52.482: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999039s
Feb 28 19:55:53.487: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991225125s
Feb 28 19:55:54.492: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986527719s
Feb 28 19:55:55.498: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98060979s
Feb 28 19:55:56.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97499032s
Feb 28 19:55:57.515: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965651091s
Feb 28 19:55:58.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958278733s
Feb 28 19:55:59.529: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.952927946s
Feb 28 19:56:00.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944555407s
Feb 28 19:56:01.561: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.865842ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4433
Feb 28 19:56:02.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:56:02.837: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:56:02.837: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:56:02.837: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:56:02.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:56:03.159: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:56:03.159: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:56:03.159: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:56:03.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-4433 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 19:56:03.391: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 19:56:03.391: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 19:56:03.392: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 19:56:03.392: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 28 19:56:13.413: INFO: Deleting all statefulset in ns statefulset-4433
Feb 28 19:56:13.417: INFO: Scaling statefulset ss to 0
Feb 28 19:56:13.426: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 19:56:13.428: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:56:13.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4433" for this suite.
Feb 28 19:56:19.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:56:19.588: INFO: namespace statefulset-4433 deletion completed in 6.134443965s

• [SLOW TEST:78.735 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:56:19.591: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:56:21.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7652" for this suite.
Feb 28 19:57:11.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:57:11.803: INFO: namespace kubelet-test-7652 deletion completed in 50.127841483s

• [SLOW TEST:52.212 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:57:11.806: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-16d8dcb6-98a6-4ec9-8002-ae010ee6704d
STEP: Creating a pod to test consume secrets
Feb 28 19:57:11.873: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb" in namespace "projected-18" to be "success or failure"
Feb 28 19:57:11.877: INFO: Pod "pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.260975ms
Feb 28 19:57:13.885: INFO: Pod "pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01223499s
STEP: Saw pod success
Feb 28 19:57:13.885: INFO: Pod "pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb" satisfied condition "success or failure"
Feb 28 19:57:13.888: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 28 19:57:13.921: INFO: Waiting for pod pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb to disappear
Feb 28 19:57:13.925: INFO: Pod pod-projected-secrets-e9a8168f-4b62-48a1-b456-838805d05ebb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 19:57:13.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-18" for this suite.
Feb 28 19:57:19.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 19:57:20.056: INFO: namespace projected-18 deletion completed in 6.124046348s

• [SLOW TEST:8.250 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 19:57:20.058: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 28 19:57:20.557: INFO: Pod name wrapped-volume-race-e5371f14-1500-4933-ac5b-6322a3550c2f: Found 1 pods out of 5
Feb 28 19:57:25.568: INFO: Pod name wrapped-volume-race-e5371f14-1500-4933-ac5b-6322a3550c2f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e5371f14-1500-4933-ac5b-6322a3550c2f in namespace emptydir-wrapper-7906, will wait for the garbage collector to delete the pods
Feb 28 19:57:39.747: INFO: Deleting ReplicationController wrapped-volume-race-e5371f14-1500-4933-ac5b-6322a3550c2f took: 9.138857ms
Feb 28 19:57:40.249: INFO: Terminating ReplicationController wrapped-volume-race-e5371f14-1500-4933-ac5b-6322a3550c2f pods took: 501.571561ms
STEP: Creating RC which spawns configmap-volume pods
Feb 28 19:58:25.283: INFO: Pod name wrapped-volume-race-70027028-0334-47e6-bcc5-ddcad48a548a: Found 0 pods out of 5
Feb 28 19:58:30.291: INFO: Pod name wrapped-volume-race-70027028-0334-47e6-bcc5-ddcad48a548a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-70027028-0334-47e6-bcc5-ddcad48a548a in namespace emptydir-wrapper-7906, will wait for the garbage collector to delete the pods
Feb 28 19:58:42.414: INFO: Deleting ReplicationController wrapped-volume-race-70027028-0334-47e6-bcc5-ddcad48a548a took: 14.787425ms
Feb 28 19:58:42.914: INFO: Terminating ReplicationController wrapped-volume-race-70027028-0334-47e6-bcc5-ddcad48a548a pods took: 500.366448ms
STEP: Creating RC which spawns configmap-volume pods
Feb 28 19:59:24.346: INFO: Pod name wrapped-volume-race-74fbdb0d-1043-4fdf-b48b-dee7f565b578: Found 0 pods out of 5
Feb 28 19:59:29.370: INFO: Pod name wrapped-volume-race-74fbdb0d-1043-4fdf-b48b-dee7f565b578: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-74fbdb0d-1043-4fdf-b48b-dee7f565b578 in namespace emptydir-wrapper-7906, will wait for the garbage collector to delete the pods
Feb 28 19:59:41.458: INFO: Deleting ReplicationController wrapped-volume-race-74fbdb0d-1043-4fdf-b48b-dee7f565b578 took: 11.536354ms
Feb 28 19:59:41.958: INFO: Terminating ReplicationController wrapped-volume-race-74fbdb0d-1043-4fdf-b48b-dee7f565b578 pods took: 500.463968ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:00:24.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7906" for this suite.
Feb 28 20:00:30.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:00:31.081: INFO: namespace emptydir-wrapper-7906 deletion completed in 6.138784925s

• [SLOW TEST:191.023 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:00:31.085: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-781d7118-70de-4d36-973c-e26212224be1
STEP: Creating a pod to test consume secrets
Feb 28 20:00:31.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0" in namespace "projected-3716" to be "success or failure"
Feb 28 20:00:31.163: INFO: Pod "pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.928375ms
Feb 28 20:00:33.168: INFO: Pod "pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008031049s
STEP: Saw pod success
Feb 28 20:00:33.169: INFO: Pod "pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0" satisfied condition "success or failure"
Feb 28 20:00:33.183: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:00:33.210: INFO: Waiting for pod pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0 to disappear
Feb 28 20:00:33.215: INFO: Pod pod-projected-secrets-db53e9b2-8855-404a-85da-08546d51acf0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:00:33.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3716" for this suite.
Feb 28 20:00:39.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:00:39.343: INFO: namespace projected-3716 deletion completed in 6.123046877s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:00:39.344: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5991
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-5991
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5991
Feb 28 20:00:39.471: INFO: Found 0 stateful pods, waiting for 1
Feb 28 20:00:49.478: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 28 20:00:49.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 20:00:50.058: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 20:00:50.058: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 20:00:50.058: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 20:00:50.067: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 28 20:01:00.083: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 20:01:00.083: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 20:01:00.111: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:00.111: INFO: ss-0  wenjun192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:00.111: INFO: 
Feb 28 20:01:00.111: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 28 20:01:01.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992904143s
Feb 28 20:01:02.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.740380788s
Feb 28 20:01:03.393: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.722338593s
Feb 28 20:01:04.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.711187498s
Feb 28 20:01:05.422: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.703062231s
Feb 28 20:01:06.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.682006285s
Feb 28 20:01:07.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.665574155s
Feb 28 20:01:08.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.661154808s
Feb 28 20:01:09.452: INFO: Verifying statefulset ss doesn't scale past 3 for another 656.627674ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5991
Feb 28 20:01:10.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 20:01:10.698: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 28 20:01:10.698: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 20:01:10.698: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 20:01:10.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 20:01:11.025: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 28 20:01:11.026: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 20:01:11.026: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 20:01:11.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 28 20:01:11.233: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 28 20:01:11.233: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 28 20:01:11.233: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 28 20:01:11.239: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 20:01:11.239: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 28 20:01:11.239: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 28 20:01:11.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 20:01:11.507: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 20:01:11.511: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 20:01:11.511: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 20:01:11.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 20:01:11.797: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 20:01:11.797: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 20:01:11.797: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 20:01:11.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 exec --namespace=statefulset-5991 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 28 20:01:12.009: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 28 20:01:12.009: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 28 20:01:12.009: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 28 20:01:12.009: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 20:01:12.013: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 28 20:01:22.021: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 20:01:22.021: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 20:01:22.021: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 28 20:01:22.046: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:22.046: INFO: ss-0  wenjun192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:22.046: INFO: ss-1  wenjun191  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:22.046: INFO: ss-2  wenjun192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:22.046: INFO: 
Feb 28 20:01:22.046: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 28 20:01:23.055: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:23.055: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:23.055: INFO: ss-1  wenjun191  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:23.055: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:23.055: INFO: 
Feb 28 20:01:23.055: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 28 20:01:24.060: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:24.060: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:24.060: INFO: ss-1  wenjun191  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:24.061: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:24.061: INFO: 
Feb 28 20:01:24.061: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 28 20:01:25.065: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:25.065: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:25.065: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:25.065: INFO: 
Feb 28 20:01:25.065: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 28 20:01:26.070: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:26.070: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:26.070: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:26.071: INFO: 
Feb 28 20:01:26.071: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 28 20:01:27.074: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:27.074: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:27.074: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:27.074: INFO: 
Feb 28 20:01:27.074: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 28 20:01:28.078: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 28 20:01:28.078: INFO: ss-0  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:00:39 +0000 UTC  }]
Feb 28 20:01:28.078: INFO: ss-2  wenjun192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:01:00 +0000 UTC  }]
Feb 28 20:01:28.078: INFO: 
Feb 28 20:01:28.078: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 28 20:01:29.085: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.959034081s
Feb 28 20:01:30.093: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.95198634s
Feb 28 20:01:31.099: INFO: Verifying statefulset ss doesn't scale past 0 for another 944.269882ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5991
Feb 28 20:01:32.105: INFO: Scaling statefulset ss to 0
Feb 28 20:01:32.124: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 28 20:01:32.134: INFO: Deleting all statefulset in ns statefulset-5991
Feb 28 20:01:32.138: INFO: Scaling statefulset ss to 0
Feb 28 20:01:32.164: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 20:01:32.166: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:01:32.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5991" for this suite.
Feb 28 20:01:38.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:01:38.373: INFO: namespace statefulset-5991 deletion completed in 6.158944365s

• [SLOW TEST:59.029 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:01:38.375: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Feb 28 20:01:38.436: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3693" to be "success or failure"
Feb 28 20:01:38.445: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.206329ms
Feb 28 20:01:40.450: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013193769s
STEP: Saw pod success
Feb 28 20:01:40.450: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 28 20:01:40.452: INFO: Trying to get logs from node wenjun192 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 28 20:01:40.491: INFO: Waiting for pod pod-host-path-test to disappear
Feb 28 20:01:40.495: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:01:40.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3693" for this suite.
Feb 28 20:01:46.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:01:46.659: INFO: namespace hostpath-3693 deletion completed in 6.156502804s

• [SLOW TEST:8.285 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:01:46.660: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-76dbff18-d992-4856-85f5-323cb3dd601b
STEP: Creating a pod to test consume configMaps
Feb 28 20:01:46.726: INFO: Waiting up to 5m0s for pod "pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825" in namespace "configmap-1519" to be "success or failure"
Feb 28 20:01:46.735: INFO: Pod "pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825": Phase="Pending", Reason="", readiness=false. Elapsed: 8.485028ms
Feb 28 20:01:48.741: INFO: Pod "pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014758035s
STEP: Saw pod success
Feb 28 20:01:48.741: INFO: Pod "pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825" satisfied condition "success or failure"
Feb 28 20:01:48.744: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:01:48.767: INFO: Waiting for pod pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825 to disappear
Feb 28 20:01:48.769: INFO: Pod pod-configmaps-476dcdb9-fa37-4070-b474-2b0ef4dcd825 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:01:48.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1519" for this suite.
Feb 28 20:01:54.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:01:54.915: INFO: namespace configmap-1519 deletion completed in 6.140506323s

• [SLOW TEST:8.255 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:01:54.915: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 20:01:54.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1880'
Feb 28 20:01:55.109: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 28 20:01:55.110: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Feb 28 20:01:55.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete jobs e2e-test-nginx-job --namespace=kubectl-1880'
Feb 28 20:01:55.245: INFO: stderr: ""
Feb 28 20:01:55.245: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:01:55.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1880" for this suite.
Feb 28 20:02:01.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:01.379: INFO: namespace kubectl-1880 deletion completed in 6.130007388s

• [SLOW TEST:6.464 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:01.381: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 28 20:02:03.961: INFO: Successfully updated pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011"
Feb 28 20:02:03.961: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011" in namespace "pods-5377" to be "terminated due to deadline exceeded"
Feb 28 20:02:03.964: INFO: Pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011": Phase="Running", Reason="", readiness=true. Elapsed: 2.984018ms
Feb 28 20:02:05.974: INFO: Pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011": Phase="Running", Reason="", readiness=true. Elapsed: 2.012936442s
Feb 28 20:02:07.979: INFO: Pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.018214391s
Feb 28 20:02:07.979: INFO: Pod "pod-update-activedeadlineseconds-af949ec1-c2d5-4ac2-8e12-b4c6a3881011" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:02:07.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5377" for this suite.
Feb 28 20:02:13.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:14.213: INFO: namespace pods-5377 deletion completed in 6.230140252s

• [SLOW TEST:12.832 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:14.217: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 28 20:02:14.286: INFO: Waiting up to 5m0s for pod "pod-4fcd2a2a-6a47-44c1-8240-b903db37e034" in namespace "emptydir-1051" to be "success or failure"
Feb 28 20:02:14.292: INFO: Pod "pod-4fcd2a2a-6a47-44c1-8240-b903db37e034": Phase="Pending", Reason="", readiness=false. Elapsed: 5.950075ms
Feb 28 20:02:16.298: INFO: Pod "pod-4fcd2a2a-6a47-44c1-8240-b903db37e034": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011314547s
Feb 28 20:02:18.303: INFO: Pod "pod-4fcd2a2a-6a47-44c1-8240-b903db37e034": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016771538s
STEP: Saw pod success
Feb 28 20:02:18.303: INFO: Pod "pod-4fcd2a2a-6a47-44c1-8240-b903db37e034" satisfied condition "success or failure"
Feb 28 20:02:18.308: INFO: Trying to get logs from node wenjun192 pod pod-4fcd2a2a-6a47-44c1-8240-b903db37e034 container test-container: <nil>
STEP: delete the pod
Feb 28 20:02:18.347: INFO: Waiting for pod pod-4fcd2a2a-6a47-44c1-8240-b903db37e034 to disappear
Feb 28 20:02:18.352: INFO: Pod pod-4fcd2a2a-6a47-44c1-8240-b903db37e034 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:02:18.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1051" for this suite.
Feb 28 20:02:24.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:24.500: INFO: namespace emptydir-1051 deletion completed in 6.142945409s

• [SLOW TEST:10.283 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:24.503: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5064/configmap-test-c3946c2f-fb9e-4faa-bf25-be3f55cb4feb
STEP: Creating a pod to test consume configMaps
Feb 28 20:02:24.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be" in namespace "configmap-5064" to be "success or failure"
Feb 28 20:02:24.589: INFO: Pod "pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253205ms
Feb 28 20:02:26.605: INFO: Pod "pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025309286s
STEP: Saw pod success
Feb 28 20:02:26.605: INFO: Pod "pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be" satisfied condition "success or failure"
Feb 28 20:02:26.610: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be container env-test: <nil>
STEP: delete the pod
Feb 28 20:02:26.644: INFO: Waiting for pod pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be to disappear
Feb 28 20:02:26.650: INFO: Pod pod-configmaps-5f13420d-bf79-495a-afdc-c552ca3b87be no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:02:26.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5064" for this suite.
Feb 28 20:02:32.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:32.791: INFO: namespace configmap-5064 deletion completed in 6.1316007s

• [SLOW TEST:8.288 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:32.792: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 28 20:02:32.858: INFO: Waiting up to 5m0s for pod "pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5" in namespace "emptydir-3706" to be "success or failure"
Feb 28 20:02:32.865: INFO: Pod "pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.709766ms
Feb 28 20:02:34.869: INFO: Pod "pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010473164s
STEP: Saw pod success
Feb 28 20:02:34.869: INFO: Pod "pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5" satisfied condition "success or failure"
Feb 28 20:02:34.881: INFO: Trying to get logs from node wenjun192 pod pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5 container test-container: <nil>
STEP: delete the pod
Feb 28 20:02:34.902: INFO: Waiting for pod pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5 to disappear
Feb 28 20:02:34.905: INFO: Pod pod-bf4cd06c-acfe-4366-8743-be00c6fc3fa5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:02:34.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3706" for this suite.
Feb 28 20:02:40.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:41.047: INFO: namespace emptydir-3706 deletion completed in 6.138050038s

• [SLOW TEST:8.255 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:41.048: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Feb 28 20:02:41.109: INFO: Waiting up to 5m0s for pod "var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149" in namespace "var-expansion-7261" to be "success or failure"
Feb 28 20:02:41.122: INFO: Pod "var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149": Phase="Pending", Reason="", readiness=false. Elapsed: 12.457584ms
Feb 28 20:02:43.126: INFO: Pod "var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016834636s
STEP: Saw pod success
Feb 28 20:02:43.126: INFO: Pod "var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149" satisfied condition "success or failure"
Feb 28 20:02:43.129: INFO: Trying to get logs from node wenjun192 pod var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149 container dapi-container: <nil>
STEP: delete the pod
Feb 28 20:02:43.161: INFO: Waiting for pod var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149 to disappear
Feb 28 20:02:43.164: INFO: Pod var-expansion-30e84d7b-2854-4650-89c0-ac32273d1149 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:02:43.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7261" for this suite.
Feb 28 20:02:49.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:02:49.464: INFO: namespace var-expansion-7261 deletion completed in 6.284440248s

• [SLOW TEST:8.416 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:02:49.467: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-mpmp
STEP: Creating a pod to test atomic-volume-subpath
Feb 28 20:02:49.565: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mpmp" in namespace "subpath-2082" to be "success or failure"
Feb 28 20:02:49.576: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.794729ms
Feb 28 20:02:51.580: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 2.01472905s
Feb 28 20:02:53.585: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 4.020149379s
Feb 28 20:02:55.588: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 6.023630982s
Feb 28 20:02:57.593: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 8.027737237s
Feb 28 20:02:59.597: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 10.031742793s
Feb 28 20:03:01.601: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 12.036367581s
Feb 28 20:03:03.604: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 14.039686018s
Feb 28 20:03:05.609: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 16.043805629s
Feb 28 20:03:07.612: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 18.047287568s
Feb 28 20:03:09.623: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 20.058382663s
Feb 28 20:03:11.628: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Running", Reason="", readiness=true. Elapsed: 22.063563908s
Feb 28 20:03:13.633: INFO: Pod "pod-subpath-test-projected-mpmp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067837158s
STEP: Saw pod success
Feb 28 20:03:13.633: INFO: Pod "pod-subpath-test-projected-mpmp" satisfied condition "success or failure"
Feb 28 20:03:13.638: INFO: Trying to get logs from node wenjun192 pod pod-subpath-test-projected-mpmp container test-container-subpath-projected-mpmp: <nil>
STEP: delete the pod
Feb 28 20:03:13.720: INFO: Waiting for pod pod-subpath-test-projected-mpmp to disappear
Feb 28 20:03:13.723: INFO: Pod pod-subpath-test-projected-mpmp no longer exists
STEP: Deleting pod pod-subpath-test-projected-mpmp
Feb 28 20:03:13.723: INFO: Deleting pod "pod-subpath-test-projected-mpmp" in namespace "subpath-2082"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:03:13.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2082" for this suite.
Feb 28 20:03:19.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:03:19.868: INFO: namespace subpath-2082 deletion completed in 6.1313692s

• [SLOW TEST:30.401 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:03:19.869: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:03:19.917: INFO: Creating deployment "nginx-deployment"
Feb 28 20:03:19.923: INFO: Waiting for observed generation 1
Feb 28 20:03:21.941: INFO: Waiting for all required pods to come up
Feb 28 20:03:21.953: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 28 20:03:26.014: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 28 20:03:26.025: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 28 20:03:26.064: INFO: Updating deployment nginx-deployment
Feb 28 20:03:26.064: INFO: Waiting for observed generation 2
Feb 28 20:03:28.077: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 28 20:03:28.081: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 28 20:03:28.084: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 28 20:03:28.101: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 28 20:03:28.101: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 28 20:03:28.104: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 28 20:03:28.109: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 28 20:03:28.109: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 28 20:03:28.125: INFO: Updating deployment nginx-deployment
Feb 28 20:03:28.125: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 28 20:03:28.140: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 28 20:03:28.168: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 28 20:03:28.262: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3222,SelfLink:/apis/apps/v1/namespaces/deployment-3222/deployments/nginx-deployment,UID:33830f2c-dffc-4cb2-9346-4ef0d2748ba3,ResourceVersion:18963,Generation:3,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2020-02-28 20:03:26 +0000 UTC 2020-02-28 20:03:19 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2020-02-28 20:03:28 +0000 UTC 2020-02-28 20:03:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 28 20:03:28.372: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-3222,SelfLink:/apis/apps/v1/namespaces/deployment-3222/replicasets/nginx-deployment-55fb7cb77f,UID:f58b66ab-4d81-4867-92eb-061607419f40,ResourceVersion:18960,Generation:3,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 33830f2c-dffc-4cb2-9346-4ef0d2748ba3 0xc00305fc17 0xc00305fc18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 20:03:28.372: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 28 20:03:28.372: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-3222,SelfLink:/apis/apps/v1/namespaces/deployment-3222/replicasets/nginx-deployment-7b8c6f4498,UID:8dc30017-9587-4fd9-8e23-ae23b4bc0938,ResourceVersion:18958,Generation:3,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 33830f2c-dffc-4cb2-9346-4ef0d2748ba3 0xc00305fce7 0xc00305fce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 28 20:03:28.442: INFO: Pod "nginx-deployment-55fb7cb77f-49rhs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-49rhs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-49rhs,UID:51b7d359-9114-4234-8035-69d3f4f5a98d,ResourceVersion:18904,Generation:0,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b247 0xc003c3b248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:,StartTime:2020-02-28 20:03:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.442: INFO: Pod "nginx-deployment-55fb7cb77f-8vcvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8vcvp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-8vcvp,UID:bc62b1c8-b4b9-43e1-8a22-7f962924d223,ResourceVersion:18896,Generation:0,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b3b0 0xc003c3b3b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:,StartTime:2020-02-28 20:03:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.443: INFO: Pod "nginx-deployment-55fb7cb77f-b9rqw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b9rqw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-b9rqw,UID:d2e0b631-cf51-4aaa-b0db-7d5752f8fdf1,ResourceVersion:18925,Generation:0,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b520 0xc003c3b521}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:,StartTime:2020-02-28 20:03:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.444: INFO: Pod "nginx-deployment-55fb7cb77f-crn2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-crn2r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-crn2r,UID:9d599a7d-616e-41d1-b5b4-c92bc32e7334,ResourceVersion:18997,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b690 0xc003c3b691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.444: INFO: Pod "nginx-deployment-55fb7cb77f-cvvfk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cvvfk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-cvvfk,UID:5f7be509-3f76-467d-b24e-f2c09c58701f,ResourceVersion:18974,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b787 0xc003c3b788}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.445: INFO: Pod "nginx-deployment-55fb7cb77f-dqktp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dqktp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-dqktp,UID:5ae4adeb-cebf-4645-ab30-54b387cff98c,ResourceVersion:18980,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b8a0 0xc003c3b8a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3b920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3b940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.446: INFO: Pod "nginx-deployment-55fb7cb77f-hnck8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hnck8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-hnck8,UID:ef771d3a-cb71-4b6e-a7d4-c11f166d62a7,ResourceVersion:18914,Generation:0,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3b9c0 0xc003c3b9c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3ba40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3ba60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:,StartTime:2020-02-28 20:03:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.447: INFO: Pod "nginx-deployment-55fb7cb77f-jgshc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jgshc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-jgshc,UID:e3249175-6303-48ee-b181-5a01d3bd8bb1,ResourceVersion:18990,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3bb30 0xc003c3bb31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3bba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3bbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.448: INFO: Pod "nginx-deployment-55fb7cb77f-ql796" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ql796,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-ql796,UID:c9260994-ed1e-4f9c-b57b-cfd6dec26b32,ResourceVersion:18985,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3bc27 0xc003c3bc28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3bca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3bcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.449: INFO: Pod "nginx-deployment-55fb7cb77f-w2kxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w2kxr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-w2kxr,UID:1cc3f56f-a87c-4404-bbf8-2d022ad9e21a,ResourceVersion:18916,Generation:0,CreationTimestamp:2020-02-28 20:03:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3bd40 0xc003c3bd41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3bdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3bde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:,StartTime:2020-02-28 20:03:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.450: INFO: Pod "nginx-deployment-55fb7cb77f-x6bkk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-x6bkk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-x6bkk,UID:f467fc28-48ce-4240-9cd8-aec85726c5a4,ResourceVersion:18988,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3beb0 0xc003c3beb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c3bf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c3bf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.450: INFO: Pod "nginx-deployment-55fb7cb77f-x8h7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-x8h7f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-55fb7cb77f-x8h7f,UID:dfa572fe-3491-48f0-8931-6e049e4fbd76,ResourceVersion:18989,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f f58b66ab-4d81-4867-92eb-061607419f40 0xc003c3bfa7 0xc003c3bfa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.451: INFO: Pod "nginx-deployment-7b8c6f4498-2qcrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2qcrv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-2qcrv,UID:b3fb3d42-ceef-450f-9337-e4215dc0dbca,ResourceVersion:18984,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26387 0xc003c26388}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.451: INFO: Pod "nginx-deployment-7b8c6f4498-2zxxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2zxxb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-2zxxb,UID:35af7834-5ab9-4677-aef9-5b7fd5bacd88,ResourceVersion:18987,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c264a0 0xc003c264a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.452: INFO: Pod "nginx-deployment-7b8c6f4498-4slg6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4slg6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-4slg6,UID:5ed89729-bddd-4c9d-b9c9-f4b100b960dc,ResourceVersion:18991,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c265b0 0xc003c265b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.453: INFO: Pod "nginx-deployment-7b8c6f4498-5526l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5526l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-5526l,UID:1ec7c0bf-cedc-40a3-a966-236283fefcb3,ResourceVersion:18848,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26697 0xc003c26698}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:19 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.14,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4d1bfcebcec8381d6370faabccdfe3ef60eca3c4e02fae97c0508d5dddcc88f4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.453: INFO: Pod "nginx-deployment-7b8c6f4498-6xlpb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6xlpb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-6xlpb,UID:08d29044-f458-4426-951c-ef116fccbd10,ResourceVersion:18995,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26800 0xc003c26801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.454: INFO: Pod "nginx-deployment-7b8c6f4498-78rjd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-78rjd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-78rjd,UID:8b93f9b0-24db-4715-acf0-2eb6831fff73,ResourceVersion:18996,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c268e7 0xc003c268e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:,StartTime:2020-02-28 20:03:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.454: INFO: Pod "nginx-deployment-7b8c6f4498-f99fb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f99fb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-f99fb,UID:db413e86-5201-4c4d-bba2-28ba8588089b,ResourceVersion:18994,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26a40 0xc003c26a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.455: INFO: Pod "nginx-deployment-7b8c6f4498-g44zd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g44zd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-g44zd,UID:890800d7-8249-4179-9e1f-1ce233eac27a,ResourceVersion:18842,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26b27 0xc003c26b28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.15,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7818571f6bc712a635ba2e1c5bc3751845bd2b1a0717be2df01857a3a9d8068d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.455: INFO: Pod "nginx-deployment-7b8c6f4498-gpm5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gpm5g,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-gpm5g,UID:2071ef20-7624-4cb8-98f4-6cf733c3f0f8,ResourceVersion:18806,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26c90 0xc003c26c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:19 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.10,StartTime:2020-02-28 20:03:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://223e192f5a2a9323e93d4d7003a73e9664ece4a32cf043cf2a4ca162dd462bf2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.456: INFO: Pod "nginx-deployment-7b8c6f4498-hkbm4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hkbm4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-hkbm4,UID:bffd5ff1-df81-48be-a75a-cb54a6123237,ResourceVersion:18979,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26df0 0xc003c26df1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.456: INFO: Pod "nginx-deployment-7b8c6f4498-hp7bb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hp7bb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-hp7bb,UID:8dbbe076-eb41-48db-9eb8-7937fe3f3fef,ResourceVersion:18993,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26f00 0xc003c26f01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c26f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c26f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.457: INFO: Pod "nginx-deployment-7b8c6f4498-k94qh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k94qh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-k94qh,UID:329a4f76-7f42-4168-b7e6-83ef981252e8,ResourceVersion:18977,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c26fe7 0xc003c26fe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.457: INFO: Pod "nginx-deployment-7b8c6f4498-p24jk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p24jk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-p24jk,UID:9daf32c4-3d50-47c9-8eb1-a14e72ed29e8,ResourceVersion:18845,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c27100 0xc003c27101}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.16,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://82eb09034be2066017be7fe2cbe863c248a926796d49f18257014285c448ff15}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.458: INFO: Pod "nginx-deployment-7b8c6f4498-pr45f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pr45f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-pr45f,UID:5531fb67-2f07-4454-868f-c639275daf62,ResourceVersion:18851,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c27260 0xc003c27261}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c272d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c272f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.12,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2afceaba82c253a6e2c06df1a7ca7cc9a424c2d27e05a1cacb8ac60321cefe21}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.458: INFO: Pod "nginx-deployment-7b8c6f4498-qcfdw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qcfdw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-qcfdw,UID:97c12fc9-f0bc-44f0-8291-e287f7f5a32c,ResourceVersion:18992,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c273c0 0xc003c273c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.462: INFO: Pod "nginx-deployment-7b8c6f4498-qwgc7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qwgc7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-qwgc7,UID:75b3bdb5-6169-4b80-b726-02d1e263a157,ResourceVersion:18857,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c274a7 0xc003c274a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:19 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:10.35.253.123,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2d413ef44e5c62c4ba249e93fdb1189af37980e0bdf7c5401190569969e9d660}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.462: INFO: Pod "nginx-deployment-7b8c6f4498-sn52p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sn52p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-sn52p,UID:806858bf-2f55-430f-aec2-baeaa5d61023,ResourceVersion:18863,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c27610 0xc003c27611}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c276a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:10.35.253.124,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f2626f774acc3f2894275dcd90650d98861cec7813ebe4cb1dd0e259fe54e545}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.462: INFO: Pod "nginx-deployment-7b8c6f4498-th7c9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-th7c9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-th7c9,UID:25bb29b8-b206-4a27-8df8-187b35538256,ResourceVersion:18865,Generation:0,CreationTimestamp:2020-02-28 20:03:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c27770 0xc003c27771}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun191,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c277e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.191,PodIP:10.35.253.126,StartTime:2020-02-28 20:03:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-28 20:03:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a26970507f0c433306427d85f44f890ac578c7f1f309f9b650b1b9b13083fe5d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.463: INFO: Pod "nginx-deployment-7b8c6f4498-w76ll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w76ll,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-w76ll,UID:a0f87397-2fd2-4c4c-a37a-d58dc5d351df,ResourceVersion:18982,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c278d0 0xc003c278d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 28 20:03:28.463: INFO: Pod "nginx-deployment-7b8c6f4498-xbm5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xbm5r,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3222,SelfLink:/api/v1/namespaces/deployment-3222/pods/nginx-deployment-7b8c6f4498-xbm5r,UID:632bb73e-6368-4220-a1db-029b46bd39a0,ResourceVersion:18970,Generation:0,CreationTimestamp:2020-02-28 20:03:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8dc30017-9587-4fd9-8e23-ae23b4bc0938 0xc003c279e0 0xc003c279e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qj58t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qj58t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qj58t true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003c27a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003c27a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:03:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:03:28.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3222" for this suite.
Feb 28 20:03:39.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:03:39.248: INFO: namespace deployment-3222 deletion completed in 10.170877937s

• [SLOW TEST:19.379 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:03:39.249: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 20:03:39.301: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602" in namespace "projected-3202" to be "success or failure"
Feb 28 20:03:39.304: INFO: Pod "downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602": Phase="Pending", Reason="", readiness=false. Elapsed: 2.767238ms
Feb 28 20:03:41.323: INFO: Pod "downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022173296s
STEP: Saw pod success
Feb 28 20:03:41.323: INFO: Pod "downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602" satisfied condition "success or failure"
Feb 28 20:03:41.340: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602 container client-container: <nil>
STEP: delete the pod
Feb 28 20:03:41.384: INFO: Waiting for pod downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602 to disappear
Feb 28 20:03:41.386: INFO: Pod downwardapi-volume-6bed2b4e-e172-42c2-9a02-e6830c4ee602 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:03:41.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3202" for this suite.
Feb 28 20:03:47.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:03:47.594: INFO: namespace projected-3202 deletion completed in 6.203857154s

• [SLOW TEST:8.346 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:03:47.596: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 28 20:03:50.248: INFO: Successfully updated pod "pod-update-a3e6c153-897b-4207-bbd8-ecef5b6bc814"
STEP: verifying the updated pod is in kubernetes
Feb 28 20:03:50.262: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:03:50.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9137" for this suite.
Feb 28 20:04:12.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:04:12.433: INFO: namespace pods-9137 deletion completed in 22.165339642s

• [SLOW TEST:24.838 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:04:12.434: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9903
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9903
STEP: Creating statefulset with conflicting port in namespace statefulset-9903
STEP: Waiting until pod test-pod will start running in namespace statefulset-9903
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9903
Feb 28 20:04:16.594: INFO: Observed stateful pod in namespace: statefulset-9903, name: ss-0, uid: ee9b2691-ad82-4324-b45c-f12fd6e99cf6, status phase: Pending. Waiting for statefulset controller to delete.
Feb 28 20:04:17.146: INFO: Observed stateful pod in namespace: statefulset-9903, name: ss-0, uid: ee9b2691-ad82-4324-b45c-f12fd6e99cf6, status phase: Failed. Waiting for statefulset controller to delete.
Feb 28 20:04:17.162: INFO: Observed stateful pod in namespace: statefulset-9903, name: ss-0, uid: ee9b2691-ad82-4324-b45c-f12fd6e99cf6, status phase: Failed. Waiting for statefulset controller to delete.
Feb 28 20:04:17.167: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9903
STEP: Removing pod with conflicting port in namespace statefulset-9903
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9903 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 28 20:04:21.216: INFO: Deleting all statefulset in ns statefulset-9903
Feb 28 20:04:21.220: INFO: Scaling statefulset ss to 0
Feb 28 20:04:31.277: INFO: Waiting for statefulset status.replicas updated to 0
Feb 28 20:04:31.281: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:04:31.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9903" for this suite.
Feb 28 20:04:37.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:04:37.435: INFO: namespace statefulset-9903 deletion completed in 6.117299869s

• [SLOW TEST:25.001 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:04:37.435: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:04:37.500: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 28 20:04:42.512: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 28 20:04:42.512: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 28 20:04:44.517: INFO: Creating deployment "test-rollover-deployment"
Feb 28 20:04:44.526: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 28 20:04:46.544: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 28 20:04:46.552: INFO: Ensure that both replica sets have 1 created replica
Feb 28 20:04:46.558: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 28 20:04:46.571: INFO: Updating deployment test-rollover-deployment
Feb 28 20:04:46.571: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 28 20:04:48.586: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 28 20:04:48.593: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 28 20:04:48.600: INFO: all replica sets need to contain the pod-template-hash label
Feb 28 20:04:48.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517088, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:04:50.609: INFO: all replica sets need to contain the pod-template-hash label
Feb 28 20:04:50.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517088, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:04:52.622: INFO: all replica sets need to contain the pod-template-hash label
Feb 28 20:04:52.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517088, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:04:54.613: INFO: all replica sets need to contain the pod-template-hash label
Feb 28 20:04:54.614: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517088, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:04:56.608: INFO: all replica sets need to contain the pod-template-hash label
Feb 28 20:04:56.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517088, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:04:58.653: INFO: 
Feb 28 20:04:58.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517098, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718517084, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 28 20:05:00.609: INFO: 
Feb 28 20:05:00.609: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 28 20:05:00.620: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-4973,SelfLink:/apis/apps/v1/namespaces/deployment-4973/deployments/test-rollover-deployment,UID:a23b8914-543a-4633-b574-aef97cd25fc9,ResourceVersion:19909,Generation:2,CreationTimestamp:2020-02-28 20:04:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-28 20:04:44 +0000 UTC 2020-02-28 20:04:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-28 20:04:58 +0000 UTC 2020-02-28 20:04:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 28 20:05:00.625: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-4973,SelfLink:/apis/apps/v1/namespaces/deployment-4973/replicasets/test-rollover-deployment-854595fc44,UID:843e26eb-cc89-47dd-9927-b7ba62a65fea,ResourceVersion:19898,Generation:2,CreationTimestamp:2020-02-28 20:04:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a23b8914-543a-4633-b574-aef97cd25fc9 0xc003477be7 0xc003477be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 28 20:05:00.625: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 28 20:05:00.625: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-4973,SelfLink:/apis/apps/v1/namespaces/deployment-4973/replicasets/test-rollover-controller,UID:b9f33afa-e15a-4519-bc41-3ed2bffb616b,ResourceVersion:19908,Generation:2,CreationTimestamp:2020-02-28 20:04:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a23b8914-543a-4633-b574-aef97cd25fc9 0xc003477b17 0xc003477b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 20:05:00.626: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-4973,SelfLink:/apis/apps/v1/namespaces/deployment-4973/replicasets/test-rollover-deployment-9b8b997cf,UID:3abb9d00-4b98-43ff-aaee-68e06c9b92df,ResourceVersion:19859,Generation:2,CreationTimestamp:2020-02-28 20:04:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a23b8914-543a-4633-b574-aef97cd25fc9 0xc003477cb0 0xc003477cb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 20:05:00.632: INFO: Pod "test-rollover-deployment-854595fc44-f2k5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-f2k5g,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-4973,SelfLink:/api/v1/namespaces/deployment-4973/pods/test-rollover-deployment-854595fc44-f2k5g,UID:0a2f97e6-66ff-47ff-a68c-4a3c5b7ee47a,ResourceVersion:19874,Generation:0,CreationTimestamp:2020-02-28 20:04:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 843e26eb-cc89-47dd-9927-b7ba62a65fea 0xc0003ff0b7 0xc0003ff0b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9qhrg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qhrg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9qhrg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003ff290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003ff2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:04:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:04:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:04:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:04:46 +0000 UTC  }],Message:,Reason:,HostIP:10.10.1.192,PodIP:10.34.187.34,StartTime:2020-02-28 20:04:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-28 20:04:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3bf70ba8c1e4263ef30ae742f2620bad7d2c17f810ef013553eeb782ee4f4326}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:00.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4973" for this suite.
Feb 28 20:05:06.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:06.792: INFO: namespace deployment-4973 deletion completed in 6.154581978s

• [SLOW TEST:29.357 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:06.793: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 28 20:05:06.849: INFO: Waiting up to 5m0s for pod "pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458" in namespace "emptydir-113" to be "success or failure"
Feb 28 20:05:06.855: INFO: Pod "pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.192599ms
Feb 28 20:05:08.861: INFO: Pod "pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011466915s
Feb 28 20:05:10.878: INFO: Pod "pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029095171s
STEP: Saw pod success
Feb 28 20:05:10.878: INFO: Pod "pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458" satisfied condition "success or failure"
Feb 28 20:05:10.883: INFO: Trying to get logs from node wenjun192 pod pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458 container test-container: <nil>
STEP: delete the pod
Feb 28 20:05:10.919: INFO: Waiting for pod pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458 to disappear
Feb 28 20:05:10.921: INFO: Pod pod-3afcaaf5-8bb3-4681-a1f6-13b548bbf458 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:10.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-113" for this suite.
Feb 28 20:05:16.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:17.052: INFO: namespace emptydir-113 deletion completed in 6.126703769s

• [SLOW TEST:10.259 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:17.053: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-f6044a88-df2c-497d-9acc-b83689722e75
STEP: Creating a pod to test consume secrets
Feb 28 20:05:17.111: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794" in namespace "projected-4508" to be "success or failure"
Feb 28 20:05:17.115: INFO: Pod "pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497716ms
Feb 28 20:05:19.119: INFO: Pod "pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008524104s
STEP: Saw pod success
Feb 28 20:05:19.120: INFO: Pod "pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794" satisfied condition "success or failure"
Feb 28 20:05:19.122: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:05:19.144: INFO: Waiting for pod pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794 to disappear
Feb 28 20:05:19.155: INFO: Pod pod-projected-secrets-8cbcd291-0e48-4171-bc54-ca30161ec794 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:19.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4508" for this suite.
Feb 28 20:05:25.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:25.302: INFO: namespace projected-4508 deletion completed in 6.141516176s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:25.302: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 28 20:05:25.364: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 28 20:05:30.369: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:31.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1087" for this suite.
Feb 28 20:05:37.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:37.550: INFO: namespace replication-controller-1087 deletion completed in 6.131990397s

• [SLOW TEST:12.248 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:37.551: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 28 20:05:37.618: INFO: Waiting up to 5m0s for pod "pod-7482727a-8d79-411e-afab-5b80777b677c" in namespace "emptydir-2916" to be "success or failure"
Feb 28 20:05:37.622: INFO: Pod "pod-7482727a-8d79-411e-afab-5b80777b677c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763377ms
Feb 28 20:05:39.629: INFO: Pod "pod-7482727a-8d79-411e-afab-5b80777b677c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01086942s
STEP: Saw pod success
Feb 28 20:05:39.629: INFO: Pod "pod-7482727a-8d79-411e-afab-5b80777b677c" satisfied condition "success or failure"
Feb 28 20:05:39.632: INFO: Trying to get logs from node wenjun192 pod pod-7482727a-8d79-411e-afab-5b80777b677c container test-container: <nil>
STEP: delete the pod
Feb 28 20:05:39.669: INFO: Waiting for pod pod-7482727a-8d79-411e-afab-5b80777b677c to disappear
Feb 28 20:05:39.674: INFO: Pod pod-7482727a-8d79-411e-afab-5b80777b677c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:39.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2916" for this suite.
Feb 28 20:05:45.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:45.791: INFO: namespace emptydir-2916 deletion completed in 6.112620512s

• [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:45.792: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-d50a9955-d038-4c47-9978-051f44916699
STEP: Creating a pod to test consume configMaps
Feb 28 20:05:45.839: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850" in namespace "projected-458" to be "success or failure"
Feb 28 20:05:45.857: INFO: Pod "pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850": Phase="Pending", Reason="", readiness=false. Elapsed: 17.798092ms
Feb 28 20:05:47.864: INFO: Pod "pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024420877s
STEP: Saw pod success
Feb 28 20:05:47.864: INFO: Pod "pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850" satisfied condition "success or failure"
Feb 28 20:05:47.866: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:05:47.895: INFO: Waiting for pod pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850 to disappear
Feb 28 20:05:47.899: INFO: Pod pod-projected-configmaps-85201a3a-0811-4a4a-81ea-320da01a5850 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:47.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-458" for this suite.
Feb 28 20:05:53.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:05:54.013: INFO: namespace projected-458 deletion completed in 6.107510712s

• [SLOW TEST:8.221 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:05:54.014: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 20:05:54.072: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14" in namespace "downward-api-8046" to be "success or failure"
Feb 28 20:05:54.076: INFO: Pod "downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14": Phase="Pending", Reason="", readiness=false. Elapsed: 3.693414ms
Feb 28 20:05:56.085: INFO: Pod "downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012648133s
STEP: Saw pod success
Feb 28 20:05:56.085: INFO: Pod "downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14" satisfied condition "success or failure"
Feb 28 20:05:56.091: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14 container client-container: <nil>
STEP: delete the pod
Feb 28 20:05:56.148: INFO: Waiting for pod downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14 to disappear
Feb 28 20:05:56.183: INFO: Pod downwardapi-volume-c4cdeef1-46e3-45c3-b81d-6ccaeff57c14 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:05:56.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8046" for this suite.
Feb 28 20:06:02.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:06:02.328: INFO: namespace downward-api-8046 deletion completed in 6.136922694s

• [SLOW TEST:8.314 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:06:02.330: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 28 20:06:02.399: INFO: Waiting up to 5m0s for pod "downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0" in namespace "downward-api-5677" to be "success or failure"
Feb 28 20:06:02.406: INFO: Pod "downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.393921ms
Feb 28 20:06:04.423: INFO: Pod "downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023555341s
STEP: Saw pod success
Feb 28 20:06:04.423: INFO: Pod "downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0" satisfied condition "success or failure"
Feb 28 20:06:04.426: INFO: Trying to get logs from node wenjun192 pod downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0 container dapi-container: <nil>
STEP: delete the pod
Feb 28 20:06:04.461: INFO: Waiting for pod downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0 to disappear
Feb 28 20:06:04.466: INFO: Pod downward-api-26ebd638-9a34-478a-a6a4-7081ed22f2b0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:06:04.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5677" for this suite.
Feb 28 20:06:10.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:06:10.609: INFO: namespace downward-api-5677 deletion completed in 6.138458639s

• [SLOW TEST:8.279 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:06:10.609: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-df46484b-deab-4284-9fb7-60be4f2d8dad
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:06:10.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3923" for this suite.
Feb 28 20:06:16.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:06:16.784: INFO: namespace secrets-3923 deletion completed in 6.11551145s

• [SLOW TEST:6.175 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:06:16.785: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2c8e4df6-666b-4878-9988-0ed6335cb537
STEP: Creating a pod to test consume secrets
Feb 28 20:06:16.856: INFO: Waiting up to 5m0s for pod "pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f" in namespace "secrets-4968" to be "success or failure"
Feb 28 20:06:16.863: INFO: Pod "pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.972685ms
Feb 28 20:06:18.871: INFO: Pod "pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014766459s
STEP: Saw pod success
Feb 28 20:06:18.871: INFO: Pod "pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f" satisfied condition "success or failure"
Feb 28 20:06:18.914: INFO: Trying to get logs from node wenjun192 pod pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:06:18.987: INFO: Waiting for pod pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f to disappear
Feb 28 20:06:18.995: INFO: Pod pod-secrets-38b3af18-d231-4b58-bed4-59f79c34061f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:06:18.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4968" for this suite.
Feb 28 20:06:25.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:06:25.131: INFO: namespace secrets-4968 deletion completed in 6.127379658s

• [SLOW TEST:8.346 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:06:25.132: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 28 20:06:25.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-6174'
Feb 28 20:06:25.431: INFO: stderr: ""
Feb 28 20:06:25.431: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 28 20:06:25.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6174'
Feb 28 20:06:25.552: INFO: stderr: ""
Feb 28 20:06:25.552: INFO: stdout: "update-demo-nautilus-c8fsd update-demo-nautilus-lfkbz "
Feb 28 20:06:25.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-c8fsd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6174'
Feb 28 20:06:25.658: INFO: stderr: ""
Feb 28 20:06:25.658: INFO: stdout: ""
Feb 28 20:06:25.658: INFO: update-demo-nautilus-c8fsd is created but not running
Feb 28 20:06:30.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6174'
Feb 28 20:06:30.765: INFO: stderr: ""
Feb 28 20:06:30.765: INFO: stdout: "update-demo-nautilus-c8fsd update-demo-nautilus-lfkbz "
Feb 28 20:06:30.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-c8fsd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6174'
Feb 28 20:06:30.880: INFO: stderr: ""
Feb 28 20:06:30.880: INFO: stdout: "true"
Feb 28 20:06:30.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-c8fsd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6174'
Feb 28 20:06:30.971: INFO: stderr: ""
Feb 28 20:06:30.971: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 20:06:30.971: INFO: validating pod update-demo-nautilus-c8fsd
Feb 28 20:06:30.979: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 20:06:30.979: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 20:06:30.979: INFO: update-demo-nautilus-c8fsd is verified up and running
Feb 28 20:06:30.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-lfkbz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6174'
Feb 28 20:06:31.083: INFO: stderr: ""
Feb 28 20:06:31.083: INFO: stdout: "true"
Feb 28 20:06:31.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods update-demo-nautilus-lfkbz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6174'
Feb 28 20:06:31.196: INFO: stderr: ""
Feb 28 20:06:31.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 28 20:06:31.196: INFO: validating pod update-demo-nautilus-lfkbz
Feb 28 20:06:31.204: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 28 20:06:31.204: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 28 20:06:31.204: INFO: update-demo-nautilus-lfkbz is verified up and running
STEP: using delete to clean up resources
Feb 28 20:06:31.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-6174'
Feb 28 20:06:31.304: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 20:06:31.304: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 28 20:06:31.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6174'
Feb 28 20:06:31.420: INFO: stderr: "No resources found.\n"
Feb 28 20:06:31.420: INFO: stdout: ""
Feb 28 20:06:31.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=update-demo --namespace=kubectl-6174 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 20:06:31.523: INFO: stderr: ""
Feb 28 20:06:31.523: INFO: stdout: "update-demo-nautilus-c8fsd\nupdate-demo-nautilus-lfkbz\n"
Feb 28 20:06:32.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6174'
Feb 28 20:06:32.198: INFO: stderr: "No resources found.\n"
Feb 28 20:06:32.198: INFO: stdout: ""
Feb 28 20:06:32.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=update-demo --namespace=kubectl-6174 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 20:06:32.317: INFO: stderr: ""
Feb 28 20:06:32.317: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:06:32.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6174" for this suite.
Feb 28 20:06:54.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:06:54.455: INFO: namespace kubectl-6174 deletion completed in 22.120135534s

• [SLOW TEST:29.323 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:06:54.456: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0228 20:07:24.654958      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 28 20:07:24.655: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:07:24.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4749" for this suite.
Feb 28 20:07:30.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:07:30.774: INFO: namespace gc-4749 deletion completed in 6.113948026s

• [SLOW TEST:36.318 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:07:30.776: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-0fd2e5f9-d048-4a01-b6ea-5be057df71cd in namespace container-probe-3768
Feb 28 20:07:34.846: INFO: Started pod busybox-0fd2e5f9-d048-4a01-b6ea-5be057df71cd in namespace container-probe-3768
STEP: checking the pod's current state and verifying that restartCount is present
Feb 28 20:07:34.850: INFO: Initial restart count of pod busybox-0fd2e5f9-d048-4a01-b6ea-5be057df71cd is 0
Feb 28 20:08:28.995: INFO: Restart count of pod container-probe-3768/busybox-0fd2e5f9-d048-4a01-b6ea-5be057df71cd is now 1 (54.145825621s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:08:29.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3768" for this suite.
Feb 28 20:08:35.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:08:35.144: INFO: namespace container-probe-3768 deletion completed in 6.120709119s

• [SLOW TEST:64.368 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:08:35.147: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 28 20:08:35.190: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:08:39.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7547" for this suite.
Feb 28 20:09:01.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:09:01.363: INFO: namespace init-container-7547 deletion completed in 22.126019283s

• [SLOW TEST:26.216 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:09:01.368: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 28 20:09:01.457: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 28 20:09:01.464: INFO: Waiting for terminating namespaces to be deleted...
Feb 28 20:09:01.467: INFO: 
Logging pods the kubelet thinks is on node wenjun191 before test
Feb 28 20:09:01.479: INFO: chiwen-agent-9k95q from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 20:09:01.479: INFO: kube-scheduler-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container kube-scheduler ready: true, restart count 1
Feb 28 20:09:01.479: INFO: kube-apiserver-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container kube-apiserver ready: true, restart count 0
Feb 28 20:09:01.479: INFO: chiwen-k8s-agent-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container chiwen-k8s-agent ready: true, restart count 0
Feb 28 20:09:01.479: INFO: coredns-6879c49cff-wmp8f from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container coredns ready: true, restart count 0
Feb 28 20:09:01.479: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-wsn2d from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 28 20:09:01.479: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 28 20:09:01.479: INFO: chiwen-ingress-controller-9n2n2 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 20:09:01.479: INFO: kube-state-metrics-6b5897fbb8-wfksz from kube-system started at 2020-02-28 18:55:23 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 28 20:09:01.479: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 28 20:09:01.479: INFO: calico-node-xxbcr from kube-system started at 2020-02-28 18:55:09 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 20:09:01.479: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 20:09:01.479: INFO: node-exporter-m7r4n from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 20:09:01.479: INFO: custom-metrics-apiserver-7bf8c988f9-7rz52 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container custom-metrics-apiserver ready: true, restart count 0
Feb 28 20:09:01.479: INFO: chiwen-volume-plugin-2jmh7 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container chiwen-volume-plugin ready: true, restart count 1
Feb 28 20:09:01.479: INFO: prometheus-deployment-55cfdd8597-pw6tt from kube-system started at 2020-02-28 18:55:10 +0000 UTC (4 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container alertmanager ready: true, restart count 0
Feb 28 20:09:01.479: INFO: 	Container prometheus ready: true, restart count 0
Feb 28 20:09:01.479: INFO: 	Container watch-alertmanager ready: true, restart count 0
Feb 28 20:09:01.479: INFO: 	Container watch-prometheus ready: true, restart count 0
Feb 28 20:09:01.479: INFO: etcd-wenjun191 from kube-system started at 2020-02-28 18:54:44 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container etcd ready: true, restart count 0
Feb 28 20:09:01.479: INFO: calico-kube-controllers-5c94f45bd8-jpk5k from kube-system started at 2020-02-28 18:55:09 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 28 20:09:01.479: INFO: kube-controller-manager-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.479: INFO: 	Container kube-controller-manager ready: true, restart count 1
Feb 28 20:09:01.479: INFO: 
Logging pods the kubelet thinks is on node wenjun192 before test
Feb 28 20:09:01.498: INFO: calico-node-8flfd from kube-system started at 2020-02-28 18:56:23 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 20:09:01.498: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 20:09:01.498: INFO: sonobuoy from sonobuoy started at 2020-02-28 18:57:12 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 28 20:09:01.498: INFO: chiwen-volume-plugin-76hr8 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container chiwen-volume-plugin ready: true, restart count 0
Feb 28 20:09:01.498: INFO: chiwen-agent-5fbpv from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 20:09:01.498: INFO: node-exporter-mfl29 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 20:09:01.498: INFO: chiwen-ingress-controller-9ccwn from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 20:09:01.498: INFO: sonobuoy-e2e-job-bb5a8e1744304000 from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container e2e ready: true, restart count 0
Feb 28 20:09:01.498: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 28 20:09:01.498: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-rfdrn from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:09:01.498: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 28 20:09:01.498: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f7a9d88943a299], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:09:02.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5331" for this suite.
Feb 28 20:09:08.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:09:08.663: INFO: namespace sched-pred-5331 deletion completed in 6.12566761s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.295 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:09:08.664: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:09:10.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6944" for this suite.
Feb 28 20:10:00.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:10:00.869: INFO: namespace kubelet-test-6944 deletion completed in 50.108258093s

• [SLOW TEST:52.206 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:10:00.871: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:10:00.974: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 28 20:10:00.996: INFO: Number of nodes with available pods: 0
Feb 28 20:10:00.996: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:10:02.038: INFO: Number of nodes with available pods: 0
Feb 28 20:10:02.040: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:10:03.015: INFO: Number of nodes with available pods: 0
Feb 28 20:10:03.015: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:10:04.003: INFO: Number of nodes with available pods: 2
Feb 28 20:10:04.003: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 28 20:10:04.035: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:04.035: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:05.051: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:05.051: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:06.110: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:06.110: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:07.050: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:07.050: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:07.050: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:08.051: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:08.051: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:08.051: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:09.050: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:09.050: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:09.050: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:10.053: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:10.053: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:10.053: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:11.051: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:11.051: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:11.051: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:12.050: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:12.050: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:12.050: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:13.050: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:13.050: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:13.050: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:14.106: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:14.106: INFO: Wrong image for pod: daemon-set-q6j59. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:14.106: INFO: Pod daemon-set-q6j59 is not available
Feb 28 20:10:15.052: INFO: Pod daemon-set-g2xrv is not available
Feb 28 20:10:15.052: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:16.051: INFO: Pod daemon-set-g2xrv is not available
Feb 28 20:10:16.051: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:17.054: INFO: Pod daemon-set-g2xrv is not available
Feb 28 20:10:17.054: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:18.051: INFO: Pod daemon-set-g2xrv is not available
Feb 28 20:10:18.051: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:19.054: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:20.050: INFO: Wrong image for pod: daemon-set-h75xd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 28 20:10:20.050: INFO: Pod daemon-set-h75xd is not available
Feb 28 20:10:21.085: INFO: Pod daemon-set-nw7gk is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 28 20:10:21.110: INFO: Number of nodes with available pods: 1
Feb 28 20:10:21.110: INFO: Node wenjun192 is running more than one daemon pod
Feb 28 20:10:22.129: INFO: Number of nodes with available pods: 1
Feb 28 20:10:22.129: INFO: Node wenjun192 is running more than one daemon pod
Feb 28 20:10:23.120: INFO: Number of nodes with available pods: 2
Feb 28 20:10:23.120: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3360, will wait for the garbage collector to delete the pods
Feb 28 20:10:23.200: INFO: Deleting DaemonSet.extensions daemon-set took: 6.543125ms
Feb 28 20:10:23.601: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.349322ms
Feb 28 20:10:34.207: INFO: Number of nodes with available pods: 0
Feb 28 20:10:34.207: INFO: Number of running nodes: 0, number of available pods: 0
Feb 28 20:10:34.211: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3360/daemonsets","resourceVersion":"21343"},"items":null}

Feb 28 20:10:34.214: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3360/pods","resourceVersion":"21343"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:10:34.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3360" for this suite.
Feb 28 20:10:40.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:10:40.341: INFO: namespace daemonsets-3360 deletion completed in 6.10513086s

• [SLOW TEST:39.471 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:10:40.342: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 28 20:10:40.407: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21395,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 28 20:10:40.408: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21395,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 28 20:10:50.419: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21417,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 28 20:10:50.419: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21417,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 28 20:11:00.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21440,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 28 20:11:00.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21440,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 28 20:11:10.447: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21462,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 28 20:11:10.447: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-a,UID:5c85dbdc-9429-47fa-a49a-65e0edcb6e0c,ResourceVersion:21462,Generation:0,CreationTimestamp:2020-02-28 20:10:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 28 20:11:20.474: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-b,UID:3bc3f04a-ad99-4ac6-9da3-8aeaf2128e3b,ResourceVersion:21484,Generation:0,CreationTimestamp:2020-02-28 20:11:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 28 20:11:20.475: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-b,UID:3bc3f04a-ad99-4ac6-9da3-8aeaf2128e3b,ResourceVersion:21484,Generation:0,CreationTimestamp:2020-02-28 20:11:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 28 20:11:30.485: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-b,UID:3bc3f04a-ad99-4ac6-9da3-8aeaf2128e3b,ResourceVersion:21507,Generation:0,CreationTimestamp:2020-02-28 20:11:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 28 20:11:30.485: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3193,SelfLink:/api/v1/namespaces/watch-3193/configmaps/e2e-watch-test-configmap-b,UID:3bc3f04a-ad99-4ac6-9da3-8aeaf2128e3b,ResourceVersion:21507,Generation:0,CreationTimestamp:2020-02-28 20:11:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:11:40.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3193" for this suite.
Feb 28 20:11:46.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:11:46.612: INFO: namespace watch-3193 deletion completed in 6.119598683s

• [SLOW TEST:66.270 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:11:46.614: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 28 20:11:51.717: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:11:51.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8331" for this suite.
Feb 28 20:12:13.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:12:13.947: INFO: namespace replicaset-8331 deletion completed in 22.180665685s

• [SLOW TEST:27.333 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:12:13.948: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a in namespace container-probe-7623
Feb 28 20:12:16.066: INFO: Started pod liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a in namespace container-probe-7623
STEP: checking the pod's current state and verifying that restartCount is present
Feb 28 20:12:16.072: INFO: Initial restart count of pod liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is 0
Feb 28 20:12:36.279: INFO: Restart count of pod container-probe-7623/liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is now 1 (20.207664988s elapsed)
Feb 28 20:12:54.325: INFO: Restart count of pod container-probe-7623/liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is now 2 (38.25336291s elapsed)
Feb 28 20:13:14.383: INFO: Restart count of pod container-probe-7623/liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is now 3 (58.311422808s elapsed)
Feb 28 20:13:34.436: INFO: Restart count of pod container-probe-7623/liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is now 4 (1m18.363990661s elapsed)
Feb 28 20:14:36.613: INFO: Restart count of pod container-probe-7623/liveness-8fdf6366-e4d0-4e6b-b604-70fbf764831a is now 5 (2m20.541178577s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:14:36.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7623" for this suite.
Feb 28 20:14:42.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:14:42.748: INFO: namespace container-probe-7623 deletion completed in 6.113880355s

• [SLOW TEST:148.800 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:14:42.749: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:14:42.806: INFO: (0) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.852781ms)
Feb 28 20:14:42.811: INFO: (1) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.060264ms)
Feb 28 20:14:42.815: INFO: (2) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.976587ms)
Feb 28 20:14:42.818: INFO: (3) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.63478ms)
Feb 28 20:14:42.822: INFO: (4) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.895643ms)
Feb 28 20:14:42.826: INFO: (5) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.371778ms)
Feb 28 20:14:42.829: INFO: (6) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.191338ms)
Feb 28 20:14:42.833: INFO: (7) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.44084ms)
Feb 28 20:14:42.851: INFO: (8) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 17.936271ms)
Feb 28 20:14:42.857: INFO: (9) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 5.118603ms)
Feb 28 20:14:42.861: INFO: (10) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.440231ms)
Feb 28 20:14:42.866: INFO: (11) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.380933ms)
Feb 28 20:14:42.869: INFO: (12) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.93117ms)
Feb 28 20:14:42.873: INFO: (13) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.556046ms)
Feb 28 20:14:42.877: INFO: (14) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.598334ms)
Feb 28 20:14:42.881: INFO: (15) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.414354ms)
Feb 28 20:14:42.885: INFO: (16) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.80257ms)
Feb 28 20:14:42.889: INFO: (17) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 3.40851ms)
Feb 28 20:14:42.893: INFO: (18) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 4.54598ms)
Feb 28 20:14:42.904: INFO: (19) /api/v1/nodes/wenjun191/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="alternatives.log.1">alternatives.l... (200; 11.302504ms)
[AfterEach] version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:14:42.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8792" for this suite.
Feb 28 20:14:48.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:14:49.013: INFO: namespace proxy-8792 deletion completed in 6.103621112s

• [SLOW TEST:6.265 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:14:49.016: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-305
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-305
STEP: Deleting pre-stop pod
Feb 28 20:15:04.110: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:15:04.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-305" for this suite.
Feb 28 20:15:42.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:15:42.357: INFO: namespace prestop-305 deletion completed in 38.223895415s

• [SLOW TEST:53.341 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:15:42.360: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 28 20:15:42.418: INFO: Waiting up to 5m0s for pod "pod-4b948b2b-1a58-4135-8fce-0be460737d24" in namespace "emptydir-9255" to be "success or failure"
Feb 28 20:15:42.422: INFO: Pod "pod-4b948b2b-1a58-4135-8fce-0be460737d24": Phase="Pending", Reason="", readiness=false. Elapsed: 4.289709ms
Feb 28 20:15:44.426: INFO: Pod "pod-4b948b2b-1a58-4135-8fce-0be460737d24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008518518s
STEP: Saw pod success
Feb 28 20:15:44.426: INFO: Pod "pod-4b948b2b-1a58-4135-8fce-0be460737d24" satisfied condition "success or failure"
Feb 28 20:15:44.430: INFO: Trying to get logs from node wenjun192 pod pod-4b948b2b-1a58-4135-8fce-0be460737d24 container test-container: <nil>
STEP: delete the pod
Feb 28 20:15:44.452: INFO: Waiting for pod pod-4b948b2b-1a58-4135-8fce-0be460737d24 to disappear
Feb 28 20:15:44.456: INFO: Pod pod-4b948b2b-1a58-4135-8fce-0be460737d24 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:15:44.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9255" for this suite.
Feb 28 20:15:50.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:15:50.620: INFO: namespace emptydir-9255 deletion completed in 6.159010806s

• [SLOW TEST:8.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:15:50.621: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 28 20:15:52.747: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:15:52.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4736" for this suite.
Feb 28 20:15:58.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:15:58.914: INFO: namespace container-runtime-4736 deletion completed in 6.136683349s

• [SLOW TEST:8.293 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:15:58.916: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-66adb68d-30bd-470a-b533-4adc3737ae65 in namespace container-probe-9052
Feb 28 20:16:01.006: INFO: Started pod test-webserver-66adb68d-30bd-470a-b533-4adc3737ae65 in namespace container-probe-9052
STEP: checking the pod's current state and verifying that restartCount is present
Feb 28 20:16:01.009: INFO: Initial restart count of pod test-webserver-66adb68d-30bd-470a-b533-4adc3737ae65 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:20:01.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9052" for this suite.
Feb 28 20:20:07.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:20:07.983: INFO: namespace container-probe-9052 deletion completed in 6.141518667s

• [SLOW TEST:249.067 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:20:07.983: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:21:08.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9007" for this suite.
Feb 28 20:21:30.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:21:30.240: INFO: namespace container-probe-9007 deletion completed in 22.191182971s

• [SLOW TEST:82.257 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:21:30.241: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 28 20:21:30.329: INFO: Number of nodes with available pods: 0
Feb 28 20:21:30.329: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:21:31.342: INFO: Number of nodes with available pods: 0
Feb 28 20:21:31.342: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:21:32.337: INFO: Number of nodes with available pods: 1
Feb 28 20:21:32.337: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:21:33.337: INFO: Number of nodes with available pods: 2
Feb 28 20:21:33.337: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 28 20:21:33.377: INFO: Number of nodes with available pods: 2
Feb 28 20:21:33.377: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1159, will wait for the garbage collector to delete the pods
Feb 28 20:21:34.492: INFO: Deleting DaemonSet.extensions daemon-set took: 50.620265ms
Feb 28 20:21:34.892: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.333788ms
Feb 28 20:21:48.196: INFO: Number of nodes with available pods: 0
Feb 28 20:21:48.197: INFO: Number of running nodes: 0, number of available pods: 0
Feb 28 20:21:48.202: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1159/daemonsets","resourceVersion":"23245"},"items":null}

Feb 28 20:21:48.205: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1159/pods","resourceVersion":"23245"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:21:48.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1159" for this suite.
Feb 28 20:21:54.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:21:54.333: INFO: namespace daemonsets-1159 deletion completed in 6.111295009s

• [SLOW TEST:24.093 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:21:54.335: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:21:54.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3007" for this suite.
Feb 28 20:22:16.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:22:16.553: INFO: namespace pods-3007 deletion completed in 22.14158225s

• [SLOW TEST:22.217 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:22:16.555: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Feb 28 20:22:16.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 create -f - --namespace=kubectl-9936'
Feb 28 20:22:17.017: INFO: stderr: ""
Feb 28 20:22:17.017: INFO: stdout: "pod/pause created\n"
Feb 28 20:22:17.017: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 28 20:22:17.017: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9936" to be "running and ready"
Feb 28 20:22:17.035: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.610308ms
Feb 28 20:22:19.041: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.024196629s
Feb 28 20:22:19.041: INFO: Pod "pause" satisfied condition "running and ready"
Feb 28 20:22:19.041: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 28 20:22:19.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 label pods pause testing-label=testing-label-value --namespace=kubectl-9936'
Feb 28 20:22:19.158: INFO: stderr: ""
Feb 28 20:22:19.158: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 28 20:22:19.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pod pause -L testing-label --namespace=kubectl-9936'
Feb 28 20:22:19.261: INFO: stderr: ""
Feb 28 20:22:19.261: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 28 20:22:19.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 label pods pause testing-label- --namespace=kubectl-9936'
Feb 28 20:22:19.373: INFO: stderr: ""
Feb 28 20:22:19.373: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 28 20:22:19.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pod pause -L testing-label --namespace=kubectl-9936'
Feb 28 20:22:19.464: INFO: stderr: ""
Feb 28 20:22:19.464: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Feb 28 20:22:19.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete --grace-period=0 --force -f - --namespace=kubectl-9936'
Feb 28 20:22:19.570: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 28 20:22:19.570: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 28 20:22:19.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get rc,svc -l name=pause --no-headers --namespace=kubectl-9936'
Feb 28 20:22:19.705: INFO: stderr: "No resources found.\n"
Feb 28 20:22:19.705: INFO: stdout: ""
Feb 28 20:22:19.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 get pods -l name=pause --namespace=kubectl-9936 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 28 20:22:19.843: INFO: stderr: ""
Feb 28 20:22:19.843: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:22:19.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9936" for this suite.
Feb 28 20:22:25.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:22:25.965: INFO: namespace kubectl-9936 deletion completed in 6.115713248s

• [SLOW TEST:9.411 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:22:25.967: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:22:26.077: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"52eb27cc-75f4-43f6-8a4d-182dc06dbfec", Controller:(*bool)(0xc0023b7096), BlockOwnerDeletion:(*bool)(0xc0023b7097)}}
Feb 28 20:22:26.087: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"622fc102-b313-449d-9dc7-dd505d0c8577", Controller:(*bool)(0xc000836cde), BlockOwnerDeletion:(*bool)(0xc000836cdf)}}
Feb 28 20:22:26.097: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0eee238d-8017-4589-9499-c4b1550415b3", Controller:(*bool)(0xc002a7d07e), BlockOwnerDeletion:(*bool)(0xc002a7d07f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:22:31.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6900" for this suite.
Feb 28 20:22:37.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:22:37.259: INFO: namespace gc-6900 deletion completed in 6.138468969s

• [SLOW TEST:11.293 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:22:37.260: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-38ea360b-acb4-45c1-bf6a-cd42141a0fe6
STEP: Creating a pod to test consume secrets
Feb 28 20:22:37.326: INFO: Waiting up to 5m0s for pod "pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f" in namespace "secrets-7687" to be "success or failure"
Feb 28 20:22:37.329: INFO: Pod "pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.426255ms
Feb 28 20:22:39.333: INFO: Pod "pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007523926s
STEP: Saw pod success
Feb 28 20:22:39.333: INFO: Pod "pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f" satisfied condition "success or failure"
Feb 28 20:22:39.336: INFO: Trying to get logs from node wenjun192 pod pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:22:39.361: INFO: Waiting for pod pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f to disappear
Feb 28 20:22:39.368: INFO: Pod pod-secrets-91a6003e-7c3c-4b26-b1a1-d5793f14be1f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:22:39.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7687" for this suite.
Feb 28 20:22:45.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:22:45.512: INFO: namespace secrets-7687 deletion completed in 6.138803077s

• [SLOW TEST:8.252 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:22:45.523: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 28 20:22:45.580: INFO: Waiting up to 5m0s for pod "downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4" in namespace "downward-api-282" to be "success or failure"
Feb 28 20:22:45.602: INFO: Pod "downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.859759ms
Feb 28 20:22:47.606: INFO: Pod "downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02492075s
STEP: Saw pod success
Feb 28 20:22:47.606: INFO: Pod "downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4" satisfied condition "success or failure"
Feb 28 20:22:47.608: INFO: Trying to get logs from node wenjun192 pod downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4 container dapi-container: <nil>
STEP: delete the pod
Feb 28 20:22:47.633: INFO: Waiting for pod downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4 to disappear
Feb 28 20:22:47.638: INFO: Pod downward-api-76ac5bfd-67d6-4b47-9fdc-a5197a6f1ee4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:22:47.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-282" for this suite.
Feb 28 20:22:53.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:22:53.759: INFO: namespace downward-api-282 deletion completed in 6.112277305s

• [SLOW TEST:8.236 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:22:53.760: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:22:53.820: INFO: Create a RollingUpdate DaemonSet
Feb 28 20:22:53.829: INFO: Check that daemon pods launch on every node of the cluster
Feb 28 20:22:53.837: INFO: Number of nodes with available pods: 0
Feb 28 20:22:53.837: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:22:54.847: INFO: Number of nodes with available pods: 0
Feb 28 20:22:54.847: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:22:55.863: INFO: Number of nodes with available pods: 1
Feb 28 20:22:55.863: INFO: Node wenjun191 is running more than one daemon pod
Feb 28 20:22:56.845: INFO: Number of nodes with available pods: 2
Feb 28 20:22:56.846: INFO: Number of running nodes: 2, number of available pods: 2
Feb 28 20:22:56.846: INFO: Update the DaemonSet to trigger a rollout
Feb 28 20:22:56.858: INFO: Updating DaemonSet daemon-set
Feb 28 20:23:00.878: INFO: Roll back the DaemonSet before rollout is complete
Feb 28 20:23:00.891: INFO: Updating DaemonSet daemon-set
Feb 28 20:23:00.891: INFO: Make sure DaemonSet rollback is complete
Feb 28 20:23:00.933: INFO: Wrong image for pod: daemon-set-sxwmx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 28 20:23:00.933: INFO: Pod daemon-set-sxwmx is not available
Feb 28 20:23:01.988: INFO: Wrong image for pod: daemon-set-sxwmx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 28 20:23:01.988: INFO: Pod daemon-set-sxwmx is not available
Feb 28 20:23:02.988: INFO: Wrong image for pod: daemon-set-sxwmx. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 28 20:23:02.988: INFO: Pod daemon-set-sxwmx is not available
Feb 28 20:23:03.987: INFO: Pod daemon-set-dg6hq is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4864, will wait for the garbage collector to delete the pods
Feb 28 20:23:04.066: INFO: Deleting DaemonSet.extensions daemon-set took: 11.294241ms
Feb 28 20:23:04.466: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.375048ms
Feb 28 20:23:07.670: INFO: Number of nodes with available pods: 0
Feb 28 20:23:07.670: INFO: Number of running nodes: 0, number of available pods: 0
Feb 28 20:23:07.678: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4864/daemonsets","resourceVersion":"23721"},"items":null}

Feb 28 20:23:07.680: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4864/pods","resourceVersion":"23722"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:23:07.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4864" for this suite.
Feb 28 20:23:13.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:23:13.889: INFO: namespace daemonsets-4864 deletion completed in 6.190049643s

• [SLOW TEST:20.129 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:23:13.890: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 28 20:23:13.934: INFO: Waiting up to 5m0s for pod "pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2" in namespace "emptydir-2403" to be "success or failure"
Feb 28 20:23:13.938: INFO: Pod "pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.266184ms
Feb 28 20:23:15.945: INFO: Pod "pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010612032s
Feb 28 20:23:17.955: INFO: Pod "pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021079035s
STEP: Saw pod success
Feb 28 20:23:17.955: INFO: Pod "pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2" satisfied condition "success or failure"
Feb 28 20:23:17.968: INFO: Trying to get logs from node wenjun192 pod pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2 container test-container: <nil>
STEP: delete the pod
Feb 28 20:23:17.997: INFO: Waiting for pod pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2 to disappear
Feb 28 20:23:18.008: INFO: Pod pod-c4568cce-2e93-458e-aff4-c5c14ac7a8c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:23:18.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2403" for this suite.
Feb 28 20:23:24.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:23:24.141: INFO: namespace emptydir-2403 deletion completed in 6.127522028s

• [SLOW TEST:10.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:23:24.142: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Feb 28 20:23:24.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 --namespace=kubectl-8654 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 28 20:23:26.384: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 28 20:23:26.384: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:23:28.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8654" for this suite.
Feb 28 20:23:34.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:23:34.544: INFO: namespace kubectl-8654 deletion completed in 6.144027932s

• [SLOW TEST:10.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:23:34.546: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 28 20:23:34.622: INFO: Waiting up to 5m0s for pod "pod-6e426d64-5a74-4df3-865d-00901fc09936" in namespace "emptydir-494" to be "success or failure"
Feb 28 20:23:34.629: INFO: Pod "pod-6e426d64-5a74-4df3-865d-00901fc09936": Phase="Pending", Reason="", readiness=false. Elapsed: 6.416734ms
Feb 28 20:23:36.633: INFO: Pod "pod-6e426d64-5a74-4df3-865d-00901fc09936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010732618s
STEP: Saw pod success
Feb 28 20:23:36.633: INFO: Pod "pod-6e426d64-5a74-4df3-865d-00901fc09936" satisfied condition "success or failure"
Feb 28 20:23:36.647: INFO: Trying to get logs from node wenjun192 pod pod-6e426d64-5a74-4df3-865d-00901fc09936 container test-container: <nil>
STEP: delete the pod
Feb 28 20:23:36.680: INFO: Waiting for pod pod-6e426d64-5a74-4df3-865d-00901fc09936 to disappear
Feb 28 20:23:36.683: INFO: Pod pod-6e426d64-5a74-4df3-865d-00901fc09936 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:23:36.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-494" for this suite.
Feb 28 20:23:42.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:23:42.800: INFO: namespace emptydir-494 deletion completed in 6.111497712s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:23:42.802: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 28 20:23:42.864: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361" in namespace "downward-api-258" to be "success or failure"
Feb 28 20:23:42.872: INFO: Pod "downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361": Phase="Pending", Reason="", readiness=false. Elapsed: 8.39772ms
Feb 28 20:23:44.876: INFO: Pod "downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012300989s
STEP: Saw pod success
Feb 28 20:23:44.876: INFO: Pod "downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361" satisfied condition "success or failure"
Feb 28 20:23:44.879: INFO: Trying to get logs from node wenjun192 pod downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361 container client-container: <nil>
STEP: delete the pod
Feb 28 20:23:44.915: INFO: Waiting for pod downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361 to disappear
Feb 28 20:23:44.919: INFO: Pod downwardapi-volume-5364a470-0b82-4d46-8170-6ab98bc76361 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:23:44.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-258" for this suite.
Feb 28 20:23:50.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:23:51.114: INFO: namespace downward-api-258 deletion completed in 6.190747988s

• [SLOW TEST:8.312 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:23:51.116: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4622
I0228 20:23:51.186258      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4622, replica count: 1
I0228 20:23:52.237813      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0228 20:23:53.238319      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 28 20:23:53.374: INFO: Created: latency-svc-fhp2x
Feb 28 20:23:53.424: INFO: Got endpoints: latency-svc-fhp2x [85.892262ms]
Feb 28 20:23:53.503: INFO: Created: latency-svc-fw7kt
Feb 28 20:23:53.530: INFO: Got endpoints: latency-svc-fw7kt [104.800854ms]
Feb 28 20:23:53.564: INFO: Created: latency-svc-twfzh
Feb 28 20:23:53.613: INFO: Got endpoints: latency-svc-twfzh [188.119175ms]
Feb 28 20:23:53.622: INFO: Created: latency-svc-kq7d4
Feb 28 20:23:53.628: INFO: Got endpoints: latency-svc-kq7d4 [203.167294ms]
Feb 28 20:23:53.664: INFO: Created: latency-svc-9skxn
Feb 28 20:23:53.681: INFO: Got endpoints: latency-svc-9skxn [256.094985ms]
Feb 28 20:23:53.749: INFO: Created: latency-svc-grg92
Feb 28 20:23:53.759: INFO: Got endpoints: latency-svc-grg92 [334.120028ms]
Feb 28 20:23:53.783: INFO: Created: latency-svc-82ktl
Feb 28 20:23:53.791: INFO: Got endpoints: latency-svc-82ktl [366.128694ms]
Feb 28 20:23:53.830: INFO: Created: latency-svc-f7t2s
Feb 28 20:23:53.840: INFO: Got endpoints: latency-svc-f7t2s [415.453848ms]
Feb 28 20:23:53.860: INFO: Created: latency-svc-xrjxm
Feb 28 20:23:53.875: INFO: Got endpoints: latency-svc-xrjxm [449.823028ms]
Feb 28 20:23:53.882: INFO: Created: latency-svc-mc7s7
Feb 28 20:23:53.887: INFO: Got endpoints: latency-svc-mc7s7 [462.014226ms]
Feb 28 20:23:53.915: INFO: Created: latency-svc-8wj6d
Feb 28 20:23:53.932: INFO: Got endpoints: latency-svc-8wj6d [507.036ms]
Feb 28 20:23:53.961: INFO: Created: latency-svc-rbcpn
Feb 28 20:23:53.965: INFO: Got endpoints: latency-svc-rbcpn [539.774797ms]
Feb 28 20:23:53.998: INFO: Created: latency-svc-5hmhf
Feb 28 20:23:54.004: INFO: Got endpoints: latency-svc-5hmhf [578.753977ms]
Feb 28 20:23:54.014: INFO: Created: latency-svc-4gj5s
Feb 28 20:23:54.025: INFO: Got endpoints: latency-svc-4gj5s [599.724891ms]
Feb 28 20:23:54.045: INFO: Created: latency-svc-4h2mg
Feb 28 20:23:54.061: INFO: Got endpoints: latency-svc-4h2mg [636.390578ms]
Feb 28 20:23:54.103: INFO: Created: latency-svc-kf2xf
Feb 28 20:23:54.147: INFO: Got endpoints: latency-svc-kf2xf [722.136126ms]
Feb 28 20:23:54.182: INFO: Created: latency-svc-28l4v
Feb 28 20:23:54.199: INFO: Got endpoints: latency-svc-28l4v [668.622298ms]
Feb 28 20:23:54.200: INFO: Created: latency-svc-pjg7q
Feb 28 20:23:54.211: INFO: Got endpoints: latency-svc-pjg7q [597.933912ms]
Feb 28 20:23:54.252: INFO: Created: latency-svc-pl95j
Feb 28 20:23:54.328: INFO: Got endpoints: latency-svc-pl95j [699.122267ms]
Feb 28 20:23:54.363: INFO: Created: latency-svc-4756l
Feb 28 20:23:54.378: INFO: Got endpoints: latency-svc-4756l [696.690555ms]
Feb 28 20:23:54.440: INFO: Created: latency-svc-tmkff
Feb 28 20:23:54.452: INFO: Got endpoints: latency-svc-tmkff [123.934173ms]
Feb 28 20:23:54.492: INFO: Created: latency-svc-tr7b5
Feb 28 20:23:54.505: INFO: Got endpoints: latency-svc-tr7b5 [746.386868ms]
Feb 28 20:23:54.541: INFO: Created: latency-svc-8rhf6
Feb 28 20:23:54.569: INFO: Got endpoints: latency-svc-8rhf6 [777.056916ms]
Feb 28 20:23:54.612: INFO: Created: latency-svc-nhp95
Feb 28 20:23:54.624: INFO: Got endpoints: latency-svc-nhp95 [783.673623ms]
Feb 28 20:23:54.680: INFO: Created: latency-svc-q4k9l
Feb 28 20:23:54.686: INFO: Got endpoints: latency-svc-q4k9l [810.654669ms]
Feb 28 20:23:54.699: INFO: Created: latency-svc-9drdg
Feb 28 20:23:54.703: INFO: Got endpoints: latency-svc-9drdg [815.197373ms]
Feb 28 20:23:54.726: INFO: Created: latency-svc-7qxb4
Feb 28 20:23:54.734: INFO: Got endpoints: latency-svc-7qxb4 [801.019668ms]
Feb 28 20:23:54.742: INFO: Created: latency-svc-7tcwz
Feb 28 20:23:54.749: INFO: Got endpoints: latency-svc-7tcwz [784.430092ms]
Feb 28 20:23:54.762: INFO: Created: latency-svc-8xvh2
Feb 28 20:23:54.809: INFO: Got endpoints: latency-svc-8xvh2 [805.311282ms]
Feb 28 20:23:54.823: INFO: Created: latency-svc-lhb66
Feb 28 20:23:54.831: INFO: Got endpoints: latency-svc-lhb66 [806.171847ms]
Feb 28 20:23:54.836: INFO: Created: latency-svc-m5tww
Feb 28 20:23:54.846: INFO: Got endpoints: latency-svc-m5tww [784.14228ms]
Feb 28 20:23:54.853: INFO: Created: latency-svc-dhkwz
Feb 28 20:23:54.861: INFO: Got endpoints: latency-svc-dhkwz [713.842979ms]
Feb 28 20:23:54.870: INFO: Created: latency-svc-clt5k
Feb 28 20:23:54.878: INFO: Got endpoints: latency-svc-clt5k [679.390442ms]
Feb 28 20:23:54.890: INFO: Created: latency-svc-dx6lp
Feb 28 20:23:54.896: INFO: Got endpoints: latency-svc-dx6lp [685.129857ms]
Feb 28 20:23:54.942: INFO: Created: latency-svc-fmr4p
Feb 28 20:23:54.950: INFO: Created: latency-svc-h2gb6
Feb 28 20:23:54.950: INFO: Got endpoints: latency-svc-h2gb6 [497.874642ms]
Feb 28 20:23:54.959: INFO: Got endpoints: latency-svc-fmr4p [580.965893ms]
Feb 28 20:23:54.979: INFO: Created: latency-svc-s9xhw
Feb 28 20:23:54.998: INFO: Got endpoints: latency-svc-s9xhw [492.473971ms]
Feb 28 20:23:55.018: INFO: Created: latency-svc-vv2g5
Feb 28 20:23:55.032: INFO: Got endpoints: latency-svc-vv2g5 [463.525531ms]
Feb 28 20:23:55.036: INFO: Created: latency-svc-fjcdb
Feb 28 20:23:55.049: INFO: Got endpoints: latency-svc-fjcdb [424.98494ms]
Feb 28 20:23:55.056: INFO: Created: latency-svc-wfnbw
Feb 28 20:23:55.066: INFO: Got endpoints: latency-svc-wfnbw [380.056256ms]
Feb 28 20:23:55.070: INFO: Created: latency-svc-t6q7t
Feb 28 20:23:55.073: INFO: Got endpoints: latency-svc-t6q7t [369.994685ms]
Feb 28 20:23:55.098: INFO: Created: latency-svc-6bqst
Feb 28 20:23:55.101: INFO: Got endpoints: latency-svc-6bqst [367.702188ms]
Feb 28 20:23:55.113: INFO: Created: latency-svc-9slwm
Feb 28 20:23:55.124: INFO: Got endpoints: latency-svc-9slwm [374.397661ms]
Feb 28 20:23:55.126: INFO: Created: latency-svc-4s2wt
Feb 28 20:23:55.132: INFO: Got endpoints: latency-svc-4s2wt [322.724159ms]
Feb 28 20:23:55.143: INFO: Created: latency-svc-rb92r
Feb 28 20:23:55.161: INFO: Created: latency-svc-ksszr
Feb 28 20:23:55.161: INFO: Got endpoints: latency-svc-rb92r [329.705223ms]
Feb 28 20:23:55.177: INFO: Created: latency-svc-qx6h9
Feb 28 20:23:55.181: INFO: Got endpoints: latency-svc-ksszr [334.876354ms]
Feb 28 20:23:55.184: INFO: Got endpoints: latency-svc-qx6h9 [322.709409ms]
Feb 28 20:23:55.204: INFO: Created: latency-svc-zrwhn
Feb 28 20:23:55.204: INFO: Got endpoints: latency-svc-zrwhn [326.014228ms]
Feb 28 20:23:55.216: INFO: Created: latency-svc-l66h8
Feb 28 20:23:55.222: INFO: Got endpoints: latency-svc-l66h8 [325.599407ms]
Feb 28 20:23:55.229: INFO: Created: latency-svc-nlm5t
Feb 28 20:23:55.238: INFO: Got endpoints: latency-svc-nlm5t [288.192109ms]
Feb 28 20:23:55.251: INFO: Created: latency-svc-xggxx
Feb 28 20:23:55.252: INFO: Got endpoints: latency-svc-xggxx [293.203295ms]
Feb 28 20:23:55.275: INFO: Created: latency-svc-nf4kv
Feb 28 20:23:55.283: INFO: Got endpoints: latency-svc-nf4kv [285.202891ms]
Feb 28 20:23:55.294: INFO: Created: latency-svc-5zfcz
Feb 28 20:23:55.312: INFO: Got endpoints: latency-svc-5zfcz [280.162512ms]
Feb 28 20:23:55.326: INFO: Created: latency-svc-mrzsz
Feb 28 20:23:55.340: INFO: Created: latency-svc-l77zd
Feb 28 20:23:55.347: INFO: Got endpoints: latency-svc-mrzsz [298.072624ms]
Feb 28 20:23:55.359: INFO: Got endpoints: latency-svc-l77zd [292.602725ms]
Feb 28 20:23:55.365: INFO: Created: latency-svc-mvrll
Feb 28 20:23:55.382: INFO: Got endpoints: latency-svc-mvrll [308.64712ms]
Feb 28 20:23:55.394: INFO: Created: latency-svc-qgnxb
Feb 28 20:23:55.402: INFO: Got endpoints: latency-svc-qgnxb [300.934897ms]
Feb 28 20:23:55.413: INFO: Created: latency-svc-7zwst
Feb 28 20:23:55.429: INFO: Got endpoints: latency-svc-7zwst [297.183793ms]
Feb 28 20:23:55.440: INFO: Created: latency-svc-xnnz8
Feb 28 20:23:55.445: INFO: Got endpoints: latency-svc-xnnz8 [321.285204ms]
Feb 28 20:23:55.460: INFO: Created: latency-svc-vd29x
Feb 28 20:23:55.505: INFO: Got endpoints: latency-svc-vd29x [343.56121ms]
Feb 28 20:23:55.521: INFO: Created: latency-svc-n9b24
Feb 28 20:23:55.538: INFO: Got endpoints: latency-svc-n9b24 [357.583587ms]
Feb 28 20:23:55.552: INFO: Created: latency-svc-7vwxc
Feb 28 20:23:55.557: INFO: Got endpoints: latency-svc-7vwxc [372.522139ms]
Feb 28 20:23:55.572: INFO: Created: latency-svc-h8hxc
Feb 28 20:23:55.579: INFO: Got endpoints: latency-svc-h8hxc [374.617471ms]
Feb 28 20:23:55.586: INFO: Created: latency-svc-qtzgm
Feb 28 20:23:55.597: INFO: Got endpoints: latency-svc-qtzgm [375.074451ms]
Feb 28 20:23:55.606: INFO: Created: latency-svc-mcq9r
Feb 28 20:23:55.619: INFO: Got endpoints: latency-svc-mcq9r [380.722539ms]
Feb 28 20:23:55.626: INFO: Created: latency-svc-678jf
Feb 28 20:23:55.656: INFO: Got endpoints: latency-svc-678jf [403.697723ms]
Feb 28 20:23:55.657: INFO: Created: latency-svc-2s8zd
Feb 28 20:23:55.675: INFO: Created: latency-svc-c9dxb
Feb 28 20:23:55.676: INFO: Got endpoints: latency-svc-2s8zd [392.695339ms]
Feb 28 20:23:55.687: INFO: Got endpoints: latency-svc-c9dxb [374.050109ms]
Feb 28 20:23:55.705: INFO: Created: latency-svc-k8fm6
Feb 28 20:23:55.726: INFO: Got endpoints: latency-svc-k8fm6 [378.41857ms]
Feb 28 20:23:55.736: INFO: Created: latency-svc-szhm7
Feb 28 20:23:55.742: INFO: Got endpoints: latency-svc-szhm7 [383.131952ms]
Feb 28 20:23:55.763: INFO: Created: latency-svc-zktnm
Feb 28 20:23:55.769: INFO: Got endpoints: latency-svc-zktnm [387.574855ms]
Feb 28 20:23:55.794: INFO: Created: latency-svc-9ccr9
Feb 28 20:23:55.808: INFO: Created: latency-svc-c4pjg
Feb 28 20:23:55.809: INFO: Got endpoints: latency-svc-9ccr9 [406.717387ms]
Feb 28 20:23:55.842: INFO: Got endpoints: latency-svc-c4pjg [412.743631ms]
Feb 28 20:23:55.847: INFO: Created: latency-svc-ntbgp
Feb 28 20:23:55.890: INFO: Created: latency-svc-hmhsk
Feb 28 20:23:55.890: INFO: Created: latency-svc-bwgp5
Feb 28 20:23:55.897: INFO: Got endpoints: latency-svc-ntbgp [452.031366ms]
Feb 28 20:23:55.897: INFO: Got endpoints: latency-svc-bwgp5 [392.705001ms]
Feb 28 20:23:55.916: INFO: Got endpoints: latency-svc-hmhsk [377.644932ms]
Feb 28 20:23:55.927: INFO: Created: latency-svc-n2g6f
Feb 28 20:23:55.931: INFO: Got endpoints: latency-svc-n2g6f [374.817595ms]
Feb 28 20:23:55.949: INFO: Created: latency-svc-jqld6
Feb 28 20:23:55.961: INFO: Got endpoints: latency-svc-jqld6 [382.396149ms]
Feb 28 20:23:55.980: INFO: Created: latency-svc-d2fr6
Feb 28 20:23:55.986: INFO: Got endpoints: latency-svc-d2fr6 [388.388963ms]
Feb 28 20:23:56.003: INFO: Created: latency-svc-sxs2z
Feb 28 20:23:56.013: INFO: Got endpoints: latency-svc-sxs2z [393.809998ms]
Feb 28 20:23:56.051: INFO: Created: latency-svc-twhps
Feb 28 20:23:56.064: INFO: Got endpoints: latency-svc-twhps [407.52109ms]
Feb 28 20:23:56.073: INFO: Created: latency-svc-xsm8c
Feb 28 20:23:56.104: INFO: Created: latency-svc-kpgpt
Feb 28 20:23:56.128: INFO: Got endpoints: latency-svc-xsm8c [452.253847ms]
Feb 28 20:23:56.134: INFO: Created: latency-svc-vdktt
Feb 28 20:23:56.154: INFO: Created: latency-svc-28rks
Feb 28 20:23:56.164: INFO: Got endpoints: latency-svc-kpgpt [477.415688ms]
Feb 28 20:23:56.204: INFO: Created: latency-svc-4lj6c
Feb 28 20:23:56.215: INFO: Got endpoints: latency-svc-vdktt [489.35912ms]
Feb 28 20:23:56.226: INFO: Created: latency-svc-55zmt
Feb 28 20:23:56.242: INFO: Created: latency-svc-q2n5z
Feb 28 20:23:56.251: INFO: Got endpoints: latency-svc-28rks [508.884817ms]
Feb 28 20:23:56.263: INFO: Created: latency-svc-wgt7z
Feb 28 20:23:56.281: INFO: Created: latency-svc-2nzjg
Feb 28 20:23:56.304: INFO: Got endpoints: latency-svc-4lj6c [534.485533ms]
Feb 28 20:23:56.311: INFO: Created: latency-svc-w5zfj
Feb 28 20:23:56.353: INFO: Got endpoints: latency-svc-55zmt [543.479914ms]
Feb 28 20:23:56.356: INFO: Created: latency-svc-t57cs
Feb 28 20:23:56.391: INFO: Created: latency-svc-4x526
Feb 28 20:23:56.409: INFO: Got endpoints: latency-svc-q2n5z [567.312966ms]
Feb 28 20:23:56.412: INFO: Created: latency-svc-6lpvp
Feb 28 20:23:56.446: INFO: Created: latency-svc-gqcm6
Feb 28 20:23:56.460: INFO: Got endpoints: latency-svc-wgt7z [562.606873ms]
Feb 28 20:23:56.470: INFO: Created: latency-svc-xff2d
Feb 28 20:23:56.480: INFO: Created: latency-svc-f55gf
Feb 28 20:23:56.505: INFO: Created: latency-svc-cp26v
Feb 28 20:23:56.509: INFO: Got endpoints: latency-svc-2nzjg [611.063323ms]
Feb 28 20:23:56.540: INFO: Created: latency-svc-zrppj
Feb 28 20:23:56.557: INFO: Got endpoints: latency-svc-w5zfj [641.152096ms]
Feb 28 20:23:56.560: INFO: Created: latency-svc-pnbqx
Feb 28 20:23:56.585: INFO: Created: latency-svc-s6qpl
Feb 28 20:23:56.614: INFO: Got endpoints: latency-svc-t57cs [682.787447ms]
Feb 28 20:23:56.644: INFO: Created: latency-svc-g87kh
Feb 28 20:23:56.663: INFO: Got endpoints: latency-svc-4x526 [701.314998ms]
Feb 28 20:23:56.687: INFO: Created: latency-svc-xczfn
Feb 28 20:23:56.703: INFO: Created: latency-svc-4cd2c
Feb 28 20:23:56.704: INFO: Got endpoints: latency-svc-6lpvp [718.098098ms]
Feb 28 20:23:56.722: INFO: Created: latency-svc-98wz8
Feb 28 20:23:56.752: INFO: Created: latency-svc-kpbmq
Feb 28 20:23:56.759: INFO: Got endpoints: latency-svc-gqcm6 [745.840512ms]
Feb 28 20:23:56.768: INFO: Created: latency-svc-s97jl
Feb 28 20:23:56.786: INFO: Created: latency-svc-2vdhm
Feb 28 20:23:56.803: INFO: Created: latency-svc-9lfc2
Feb 28 20:23:56.806: INFO: Got endpoints: latency-svc-xff2d [742.4228ms]
Feb 28 20:23:56.830: INFO: Created: latency-svc-kmbmn
Feb 28 20:23:56.866: INFO: Got endpoints: latency-svc-f55gf [737.418485ms]
Feb 28 20:23:56.901: INFO: Got endpoints: latency-svc-cp26v [737.356848ms]
Feb 28 20:23:56.952: INFO: Got endpoints: latency-svc-zrppj [736.523443ms]
Feb 28 20:23:57.007: INFO: Got endpoints: latency-svc-pnbqx [756.105081ms]
Feb 28 20:23:57.051: INFO: Got endpoints: latency-svc-s6qpl [746.687899ms]
Feb 28 20:23:57.081: INFO: Created: latency-svc-259b6
Feb 28 20:23:57.096: INFO: Created: latency-svc-g2s6c
Feb 28 20:23:57.140: INFO: Created: latency-svc-tzhsp
Feb 28 20:23:57.153: INFO: Got endpoints: latency-svc-g87kh [800.353953ms]
Feb 28 20:23:57.171: INFO: Got endpoints: latency-svc-xczfn [761.461405ms]
Feb 28 20:23:57.215: INFO: Got endpoints: latency-svc-4cd2c [754.839417ms]
Feb 28 20:23:57.221: INFO: Created: latency-svc-smjvf
Feb 28 20:23:57.242: INFO: Created: latency-svc-vnxg7
Feb 28 20:23:57.271: INFO: Created: latency-svc-vjjd4
Feb 28 20:23:57.277: INFO: Got endpoints: latency-svc-98wz8 [768.49348ms]
Feb 28 20:23:57.303: INFO: Created: latency-svc-hhwf8
Feb 28 20:23:57.307: INFO: Got endpoints: latency-svc-kpbmq [749.596692ms]
Feb 28 20:23:57.329: INFO: Created: latency-svc-vcp8l
Feb 28 20:23:57.360: INFO: Created: latency-svc-mxlfh
Feb 28 20:23:57.367: INFO: Got endpoints: latency-svc-s97jl [752.493716ms]
Feb 28 20:23:57.386: INFO: Created: latency-svc-mdh87
Feb 28 20:23:57.464: INFO: Got endpoints: latency-svc-2vdhm [801.225855ms]
Feb 28 20:23:57.470: INFO: Created: latency-svc-7q52s
Feb 28 20:23:57.476: INFO: Got endpoints: latency-svc-9lfc2 [772.33911ms]
Feb 28 20:23:57.502: INFO: Created: latency-svc-smslt
Feb 28 20:23:57.504: INFO: Got endpoints: latency-svc-kmbmn [745.88776ms]
Feb 28 20:23:57.534: INFO: Created: latency-svc-s87d6
Feb 28 20:23:57.583: INFO: Got endpoints: latency-svc-259b6 [776.464333ms]
Feb 28 20:23:57.592: INFO: Created: latency-svc-kg25n
Feb 28 20:23:57.619: INFO: Got endpoints: latency-svc-g2s6c [753.558433ms]
Feb 28 20:23:57.632: INFO: Created: latency-svc-z47lz
Feb 28 20:23:57.656: INFO: Got endpoints: latency-svc-tzhsp [754.576022ms]
Feb 28 20:23:57.669: INFO: Created: latency-svc-qg9r7
Feb 28 20:23:57.706: INFO: Got endpoints: latency-svc-smjvf [754.272199ms]
Feb 28 20:23:57.753: INFO: Created: latency-svc-bx5bq
Feb 28 20:23:57.759: INFO: Got endpoints: latency-svc-vnxg7 [752.11701ms]
Feb 28 20:23:57.782: INFO: Created: latency-svc-nph52
Feb 28 20:23:57.804: INFO: Got endpoints: latency-svc-vjjd4 [753.611999ms]
Feb 28 20:23:57.807: INFO: Created: latency-svc-zh2dz
Feb 28 20:23:57.824: INFO: Created: latency-svc-h2xz6
Feb 28 20:23:57.840: INFO: Created: latency-svc-d9kz5
Feb 28 20:23:57.855: INFO: Got endpoints: latency-svc-hhwf8 [702.426446ms]
Feb 28 20:23:57.880: INFO: Created: latency-svc-bgr4k
Feb 28 20:23:57.901: INFO: Got endpoints: latency-svc-vcp8l [730.156052ms]
Feb 28 20:23:57.928: INFO: Created: latency-svc-gc77t
Feb 28 20:23:57.953: INFO: Got endpoints: latency-svc-mxlfh [738.75735ms]
Feb 28 20:23:57.972: INFO: Created: latency-svc-kmzmp
Feb 28 20:23:58.003: INFO: Got endpoints: latency-svc-mdh87 [725.603449ms]
Feb 28 20:23:58.028: INFO: Created: latency-svc-dvbq8
Feb 28 20:23:58.058: INFO: Got endpoints: latency-svc-7q52s [751.241156ms]
Feb 28 20:23:58.082: INFO: Created: latency-svc-4dbbv
Feb 28 20:23:58.103: INFO: Got endpoints: latency-svc-smslt [735.869208ms]
Feb 28 20:23:58.142: INFO: Created: latency-svc-9zgwr
Feb 28 20:23:58.151: INFO: Got endpoints: latency-svc-s87d6 [687.062175ms]
Feb 28 20:23:58.173: INFO: Created: latency-svc-pjmqf
Feb 28 20:23:58.201: INFO: Got endpoints: latency-svc-kg25n [724.424936ms]
Feb 28 20:23:58.216: INFO: Created: latency-svc-qws84
Feb 28 20:23:58.252: INFO: Got endpoints: latency-svc-z47lz [747.81836ms]
Feb 28 20:23:58.275: INFO: Created: latency-svc-mskbz
Feb 28 20:23:58.300: INFO: Got endpoints: latency-svc-qg9r7 [717.065757ms]
Feb 28 20:23:58.317: INFO: Created: latency-svc-f6zgj
Feb 28 20:23:58.351: INFO: Got endpoints: latency-svc-bx5bq [694.954236ms]
Feb 28 20:23:58.372: INFO: Created: latency-svc-vmc8g
Feb 28 20:23:58.400: INFO: Got endpoints: latency-svc-nph52 [780.770716ms]
Feb 28 20:23:58.443: INFO: Created: latency-svc-dkgq8
Feb 28 20:23:58.452: INFO: Got endpoints: latency-svc-zh2dz [745.159648ms]
Feb 28 20:23:58.478: INFO: Created: latency-svc-5zzwq
Feb 28 20:23:58.501: INFO: Got endpoints: latency-svc-h2xz6 [741.561217ms]
Feb 28 20:23:58.569: INFO: Created: latency-svc-g7vh8
Feb 28 20:23:58.581: INFO: Got endpoints: latency-svc-d9kz5 [777.079713ms]
Feb 28 20:23:58.622: INFO: Got endpoints: latency-svc-bgr4k [766.900247ms]
Feb 28 20:23:58.623: INFO: Created: latency-svc-w59ls
Feb 28 20:23:58.643: INFO: Created: latency-svc-5tsqs
Feb 28 20:23:58.655: INFO: Got endpoints: latency-svc-gc77t [753.496773ms]
Feb 28 20:23:58.677: INFO: Created: latency-svc-f8q9j
Feb 28 20:23:58.712: INFO: Got endpoints: latency-svc-kmzmp [758.442136ms]
Feb 28 20:23:58.736: INFO: Created: latency-svc-wwh9l
Feb 28 20:23:58.752: INFO: Got endpoints: latency-svc-dvbq8 [748.957614ms]
Feb 28 20:23:58.778: INFO: Created: latency-svc-k7kdb
Feb 28 20:23:58.803: INFO: Got endpoints: latency-svc-4dbbv [744.478167ms]
Feb 28 20:23:58.819: INFO: Created: latency-svc-4cj82
Feb 28 20:23:58.859: INFO: Got endpoints: latency-svc-9zgwr [755.635164ms]
Feb 28 20:23:58.894: INFO: Created: latency-svc-2qhtk
Feb 28 20:23:58.908: INFO: Got endpoints: latency-svc-pjmqf [756.8041ms]
Feb 28 20:23:58.972: INFO: Created: latency-svc-vt9px
Feb 28 20:23:58.978: INFO: Got endpoints: latency-svc-qws84 [776.684928ms]
Feb 28 20:23:59.000: INFO: Created: latency-svc-fpvw8
Feb 28 20:23:59.006: INFO: Got endpoints: latency-svc-mskbz [753.257078ms]
Feb 28 20:23:59.029: INFO: Created: latency-svc-ltn2c
Feb 28 20:23:59.057: INFO: Got endpoints: latency-svc-f6zgj [757.265701ms]
Feb 28 20:23:59.078: INFO: Created: latency-svc-vcb5q
Feb 28 20:23:59.104: INFO: Got endpoints: latency-svc-vmc8g [752.737925ms]
Feb 28 20:23:59.139: INFO: Created: latency-svc-bsbrf
Feb 28 20:23:59.153: INFO: Got endpoints: latency-svc-dkgq8 [752.909547ms]
Feb 28 20:23:59.176: INFO: Created: latency-svc-nxlbn
Feb 28 20:23:59.208: INFO: Got endpoints: latency-svc-5zzwq [756.126748ms]
Feb 28 20:23:59.242: INFO: Created: latency-svc-c8ptl
Feb 28 20:23:59.252: INFO: Got endpoints: latency-svc-g7vh8 [751.004585ms]
Feb 28 20:23:59.269: INFO: Created: latency-svc-frnt8
Feb 28 20:23:59.320: INFO: Got endpoints: latency-svc-w59ls [738.10095ms]
Feb 28 20:23:59.345: INFO: Created: latency-svc-tvqxj
Feb 28 20:23:59.353: INFO: Got endpoints: latency-svc-5tsqs [730.182787ms]
Feb 28 20:23:59.375: INFO: Created: latency-svc-dcs29
Feb 28 20:23:59.402: INFO: Got endpoints: latency-svc-f8q9j [746.929524ms]
Feb 28 20:23:59.435: INFO: Created: latency-svc-b2jw9
Feb 28 20:23:59.479: INFO: Got endpoints: latency-svc-wwh9l [767.362166ms]
Feb 28 20:23:59.624: INFO: Got endpoints: latency-svc-4cj82 [820.913638ms]
Feb 28 20:23:59.624: INFO: Got endpoints: latency-svc-k7kdb [872.398873ms]
Feb 28 20:23:59.638: INFO: Created: latency-svc-qzj7m
Feb 28 20:23:59.645: INFO: Got endpoints: latency-svc-2qhtk [786.297604ms]
Feb 28 20:23:59.665: INFO: Got endpoints: latency-svc-vt9px [756.454217ms]
Feb 28 20:23:59.679: INFO: Created: latency-svc-dxdgl
Feb 28 20:23:59.707: INFO: Got endpoints: latency-svc-fpvw8 [729.722867ms]
Feb 28 20:23:59.709: INFO: Created: latency-svc-k6dsf
Feb 28 20:23:59.774: INFO: Got endpoints: latency-svc-ltn2c [768.461069ms]
Feb 28 20:23:59.795: INFO: Created: latency-svc-dpspn
Feb 28 20:23:59.847: INFO: Got endpoints: latency-svc-vcb5q [789.382231ms]
Feb 28 20:23:59.857: INFO: Got endpoints: latency-svc-bsbrf [752.805837ms]
Feb 28 20:23:59.869: INFO: Created: latency-svc-4dp4h
Feb 28 20:23:59.913: INFO: Created: latency-svc-dqhkt
Feb 28 20:23:59.936: INFO: Created: latency-svc-474gm
Feb 28 20:23:59.938: INFO: Got endpoints: latency-svc-nxlbn [784.153914ms]
Feb 28 20:23:59.966: INFO: Got endpoints: latency-svc-c8ptl [758.180823ms]
Feb 28 20:23:59.972: INFO: Created: latency-svc-j9mnq
Feb 28 20:24:00.012: INFO: Got endpoints: latency-svc-frnt8 [758.905383ms]
Feb 28 20:24:00.015: INFO: Created: latency-svc-7ftqm
Feb 28 20:24:00.046: INFO: Created: latency-svc-xxmp5
Feb 28 20:24:00.053: INFO: Got endpoints: latency-svc-tvqxj [733.654922ms]
Feb 28 20:24:00.075: INFO: Created: latency-svc-dzhb4
Feb 28 20:24:00.084: INFO: Created: latency-svc-kq54p
Feb 28 20:24:00.104: INFO: Got endpoints: latency-svc-dcs29 [751.115223ms]
Feb 28 20:24:00.107: INFO: Created: latency-svc-zqgxm
Feb 28 20:24:00.145: INFO: Created: latency-svc-m5lvx
Feb 28 20:24:00.153: INFO: Got endpoints: latency-svc-b2jw9 [751.153451ms]
Feb 28 20:24:00.180: INFO: Created: latency-svc-cmvp5
Feb 28 20:24:00.217: INFO: Got endpoints: latency-svc-qzj7m [737.711526ms]
Feb 28 20:24:00.241: INFO: Created: latency-svc-fmq2g
Feb 28 20:24:00.251: INFO: Got endpoints: latency-svc-dxdgl [627.639929ms]
Feb 28 20:24:00.283: INFO: Created: latency-svc-kqnrz
Feb 28 20:24:00.304: INFO: Got endpoints: latency-svc-k6dsf [679.856336ms]
Feb 28 20:24:00.351: INFO: Got endpoints: latency-svc-dpspn [706.536933ms]
Feb 28 20:24:00.355: INFO: Created: latency-svc-pjjkp
Feb 28 20:24:00.381: INFO: Created: latency-svc-dfb9b
Feb 28 20:24:00.408: INFO: Got endpoints: latency-svc-4dp4h [743.485573ms]
Feb 28 20:24:00.431: INFO: Created: latency-svc-n4h6t
Feb 28 20:24:00.460: INFO: Got endpoints: latency-svc-dqhkt [752.798659ms]
Feb 28 20:24:00.492: INFO: Created: latency-svc-bt2cm
Feb 28 20:24:00.531: INFO: Got endpoints: latency-svc-474gm [757.251674ms]
Feb 28 20:24:00.561: INFO: Got endpoints: latency-svc-j9mnq [713.984446ms]
Feb 28 20:24:00.593: INFO: Created: latency-svc-qzhgv
Feb 28 20:24:00.607: INFO: Got endpoints: latency-svc-7ftqm [749.712754ms]
Feb 28 20:24:00.661: INFO: Created: latency-svc-2tvjp
Feb 28 20:24:00.666: INFO: Got endpoints: latency-svc-xxmp5 [728.029252ms]
Feb 28 20:24:00.684: INFO: Created: latency-svc-hbwn9
Feb 28 20:24:00.698: INFO: Created: latency-svc-s9cpl
Feb 28 20:24:00.703: INFO: Got endpoints: latency-svc-dzhb4 [736.957176ms]
Feb 28 20:24:00.730: INFO: Created: latency-svc-vbvhf
Feb 28 20:24:00.768: INFO: Got endpoints: latency-svc-kq54p [756.470718ms]
Feb 28 20:24:00.791: INFO: Created: latency-svc-c9t2r
Feb 28 20:24:00.800: INFO: Got endpoints: latency-svc-zqgxm [746.802225ms]
Feb 28 20:24:00.823: INFO: Created: latency-svc-lvn5t
Feb 28 20:24:00.859: INFO: Got endpoints: latency-svc-m5lvx [755.292466ms]
Feb 28 20:24:00.907: INFO: Created: latency-svc-pb2q2
Feb 28 20:24:00.924: INFO: Got endpoints: latency-svc-cmvp5 [770.844179ms]
Feb 28 20:24:00.951: INFO: Created: latency-svc-m2kvf
Feb 28 20:24:00.961: INFO: Got endpoints: latency-svc-fmq2g [743.518358ms]
Feb 28 20:24:01.004: INFO: Created: latency-svc-fzbt6
Feb 28 20:24:01.010: INFO: Got endpoints: latency-svc-kqnrz [757.998709ms]
Feb 28 20:24:01.045: INFO: Created: latency-svc-hxnvl
Feb 28 20:24:01.051: INFO: Got endpoints: latency-svc-pjjkp [746.719632ms]
Feb 28 20:24:01.078: INFO: Created: latency-svc-sppm7
Feb 28 20:24:01.116: INFO: Got endpoints: latency-svc-dfb9b [764.315259ms]
Feb 28 20:24:01.204: INFO: Got endpoints: latency-svc-n4h6t [795.158024ms]
Feb 28 20:24:01.221: INFO: Got endpoints: latency-svc-bt2cm [760.867823ms]
Feb 28 20:24:01.227: INFO: Created: latency-svc-zkpl6
Feb 28 20:24:01.246: INFO: Created: latency-svc-z8949
Feb 28 20:24:01.252: INFO: Got endpoints: latency-svc-qzhgv [720.307186ms]
Feb 28 20:24:01.264: INFO: Created: latency-svc-hqqqr
Feb 28 20:24:01.277: INFO: Created: latency-svc-m4rz5
Feb 28 20:24:01.301: INFO: Got endpoints: latency-svc-2tvjp [740.605881ms]
Feb 28 20:24:01.333: INFO: Created: latency-svc-p9kk5
Feb 28 20:24:01.353: INFO: Got endpoints: latency-svc-hbwn9 [746.115133ms]
Feb 28 20:24:01.401: INFO: Got endpoints: latency-svc-s9cpl [735.188061ms]
Feb 28 20:24:01.451: INFO: Got endpoints: latency-svc-vbvhf [747.900779ms]
Feb 28 20:24:01.501: INFO: Got endpoints: latency-svc-c9t2r [732.318794ms]
Feb 28 20:24:01.550: INFO: Got endpoints: latency-svc-lvn5t [749.396243ms]
Feb 28 20:24:01.602: INFO: Got endpoints: latency-svc-pb2q2 [742.524708ms]
Feb 28 20:24:01.650: INFO: Got endpoints: latency-svc-m2kvf [726.017766ms]
Feb 28 20:24:01.701: INFO: Got endpoints: latency-svc-fzbt6 [740.380124ms]
Feb 28 20:24:01.750: INFO: Got endpoints: latency-svc-hxnvl [740.012824ms]
Feb 28 20:24:01.800: INFO: Got endpoints: latency-svc-sppm7 [749.326682ms]
Feb 28 20:24:01.864: INFO: Got endpoints: latency-svc-zkpl6 [748.099202ms]
Feb 28 20:24:01.906: INFO: Got endpoints: latency-svc-z8949 [702.164278ms]
Feb 28 20:24:01.950: INFO: Got endpoints: latency-svc-hqqqr [728.910785ms]
Feb 28 20:24:02.001: INFO: Got endpoints: latency-svc-m4rz5 [749.532355ms]
Feb 28 20:24:02.051: INFO: Got endpoints: latency-svc-p9kk5 [749.113656ms]
Feb 28 20:24:02.051: INFO: Latencies: [104.800854ms 123.934173ms 188.119175ms 203.167294ms 256.094985ms 280.162512ms 285.202891ms 288.192109ms 292.602725ms 293.203295ms 297.183793ms 298.072624ms 300.934897ms 308.64712ms 321.285204ms 322.709409ms 322.724159ms 325.599407ms 326.014228ms 329.705223ms 334.120028ms 334.876354ms 343.56121ms 357.583587ms 366.128694ms 367.702188ms 369.994685ms 372.522139ms 374.050109ms 374.397661ms 374.617471ms 374.817595ms 375.074451ms 377.644932ms 378.41857ms 380.056256ms 380.722539ms 382.396149ms 383.131952ms 387.574855ms 388.388963ms 392.695339ms 392.705001ms 393.809998ms 403.697723ms 406.717387ms 407.52109ms 412.743631ms 415.453848ms 424.98494ms 449.823028ms 452.031366ms 452.253847ms 462.014226ms 463.525531ms 477.415688ms 489.35912ms 492.473971ms 497.874642ms 507.036ms 508.884817ms 534.485533ms 539.774797ms 543.479914ms 562.606873ms 567.312966ms 578.753977ms 580.965893ms 597.933912ms 599.724891ms 611.063323ms 627.639929ms 636.390578ms 641.152096ms 668.622298ms 679.390442ms 679.856336ms 682.787447ms 685.129857ms 687.062175ms 694.954236ms 696.690555ms 699.122267ms 701.314998ms 702.164278ms 702.426446ms 706.536933ms 713.842979ms 713.984446ms 717.065757ms 718.098098ms 720.307186ms 722.136126ms 724.424936ms 725.603449ms 726.017766ms 728.029252ms 728.910785ms 729.722867ms 730.156052ms 730.182787ms 732.318794ms 733.654922ms 735.188061ms 735.869208ms 736.523443ms 736.957176ms 737.356848ms 737.418485ms 737.711526ms 738.10095ms 738.75735ms 740.012824ms 740.380124ms 740.605881ms 741.561217ms 742.4228ms 742.524708ms 743.485573ms 743.518358ms 744.478167ms 745.159648ms 745.840512ms 745.88776ms 746.115133ms 746.386868ms 746.687899ms 746.719632ms 746.802225ms 746.929524ms 747.81836ms 747.900779ms 748.099202ms 748.957614ms 749.113656ms 749.326682ms 749.396243ms 749.532355ms 749.596692ms 749.712754ms 751.004585ms 751.115223ms 751.153451ms 751.241156ms 752.11701ms 752.493716ms 752.737925ms 752.798659ms 752.805837ms 752.909547ms 753.257078ms 753.496773ms 753.558433ms 753.611999ms 754.272199ms 754.576022ms 754.839417ms 755.292466ms 755.635164ms 756.105081ms 756.126748ms 756.454217ms 756.470718ms 756.8041ms 757.251674ms 757.265701ms 757.998709ms 758.180823ms 758.442136ms 758.905383ms 760.867823ms 761.461405ms 764.315259ms 766.900247ms 767.362166ms 768.461069ms 768.49348ms 770.844179ms 772.33911ms 776.464333ms 776.684928ms 777.056916ms 777.079713ms 780.770716ms 783.673623ms 784.14228ms 784.153914ms 784.430092ms 786.297604ms 789.382231ms 795.158024ms 800.353953ms 801.019668ms 801.225855ms 805.311282ms 806.171847ms 810.654669ms 815.197373ms 820.913638ms 872.398873ms]
Feb 28 20:24:02.051: INFO: 50 %ile: 730.182787ms
Feb 28 20:24:02.051: INFO: 90 %ile: 776.684928ms
Feb 28 20:24:02.051: INFO: 99 %ile: 820.913638ms
Feb 28 20:24:02.051: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:24:02.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4622" for this suite.
Feb 28 20:24:18.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:24:18.237: INFO: namespace svc-latency-4622 deletion completed in 16.178762682s

• [SLOW TEST:27.121 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:24:18.238: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-1d9d5257-e60b-4bde-b6ca-53eb5c9851c6
STEP: Creating secret with name secret-projected-all-test-volume-5fabb0db-f11e-41bd-b607-a4795f3f8184
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 28 20:24:18.352: INFO: Waiting up to 5m0s for pod "projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2" in namespace "projected-8493" to be "success or failure"
Feb 28 20:24:18.360: INFO: Pod "projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.16968ms
Feb 28 20:24:20.372: INFO: Pod "projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020505797s
STEP: Saw pod success
Feb 28 20:24:20.373: INFO: Pod "projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2" satisfied condition "success or failure"
Feb 28 20:24:20.376: INFO: Trying to get logs from node wenjun192 pod projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 28 20:24:20.628: INFO: Waiting for pod projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2 to disappear
Feb 28 20:24:20.633: INFO: Pod projected-volume-0ce3ad23-4444-4915-b0bb-a9eac9ac3db2 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:24:20.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8493" for this suite.
Feb 28 20:24:26.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:24:26.755: INFO: namespace projected-8493 deletion completed in 6.118424196s

• [SLOW TEST:8.517 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:24:26.755: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:24:39.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2440" for this suite.
Feb 28 20:24:45.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:24:46.095: INFO: namespace namespaces-2440 deletion completed in 6.141160367s
STEP: Destroying namespace "nsdeletetest-4619" for this suite.
Feb 28 20:24:46.101: INFO: Namespace nsdeletetest-4619 was already deleted
STEP: Destroying namespace "nsdeletetest-9136" for this suite.
Feb 28 20:24:52.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:24:52.288: INFO: namespace nsdeletetest-9136 deletion completed in 6.186582518s

• [SLOW TEST:25.533 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:24:52.291: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5770.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5770.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 28 20:24:56.505: INFO: DNS probes using dns-5770/dns-test-4e3a333b-4fff-489b-b14e-5460448995d8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:24:56.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5770" for this suite.
Feb 28 20:25:02.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:25:02.662: INFO: namespace dns-5770 deletion completed in 6.1277386s

• [SLOW TEST:10.371 seconds]
[sig-network] DNS
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:25:02.663: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-511cb553-9e16-4f6a-8dcf-7b0a92c33f36
STEP: Creating a pod to test consume secrets
Feb 28 20:25:02.724: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d" in namespace "projected-2386" to be "success or failure"
Feb 28 20:25:02.732: INFO: Pod "pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.532881ms
Feb 28 20:25:04.742: INFO: Pod "pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018086484s
STEP: Saw pod success
Feb 28 20:25:04.742: INFO: Pod "pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d" satisfied condition "success or failure"
Feb 28 20:25:04.746: INFO: Trying to get logs from node wenjun192 pod pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:25:04.782: INFO: Waiting for pod pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d to disappear
Feb 28 20:25:04.785: INFO: Pod pod-projected-secrets-4a778369-794c-41ec-afe7-2b1c39910b1d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:25:04.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2386" for this suite.
Feb 28 20:25:10.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:25:11.036: INFO: namespace projected-2386 deletion completed in 6.245020896s

• [SLOW TEST:8.373 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:25:11.041: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-bf19ea16-dcc4-46a9-9a1e-f68f97954073
STEP: Creating a pod to test consume configMaps
Feb 28 20:25:11.138: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd" in namespace "projected-9361" to be "success or failure"
Feb 28 20:25:11.156: INFO: Pod "pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.084008ms
Feb 28 20:25:13.177: INFO: Pod "pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039016494s
Feb 28 20:25:15.182: INFO: Pod "pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043421875s
STEP: Saw pod success
Feb 28 20:25:15.182: INFO: Pod "pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd" satisfied condition "success or failure"
Feb 28 20:25:15.185: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:25:15.209: INFO: Waiting for pod pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd to disappear
Feb 28 20:25:15.218: INFO: Pod pod-projected-configmaps-ff954dfa-bb21-4190-9e30-2bc93ac0d7dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:25:15.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9361" for this suite.
Feb 28 20:25:21.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:25:21.365: INFO: namespace projected-9361 deletion completed in 6.140588059s

• [SLOW TEST:10.325 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:25:21.368: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-14f9e825-0717-4054-983c-42138f203655
STEP: Creating a pod to test consume secrets
Feb 28 20:25:21.443: INFO: Waiting up to 5m0s for pod "pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63" in namespace "secrets-7879" to be "success or failure"
Feb 28 20:25:21.460: INFO: Pod "pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63": Phase="Pending", Reason="", readiness=false. Elapsed: 17.227139ms
Feb 28 20:25:23.463: INFO: Pod "pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02054903s
STEP: Saw pod success
Feb 28 20:25:23.463: INFO: Pod "pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63" satisfied condition "success or failure"
Feb 28 20:25:23.465: INFO: Trying to get logs from node wenjun192 pod pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63 container secret-volume-test: <nil>
STEP: delete the pod
Feb 28 20:25:23.494: INFO: Waiting for pod pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63 to disappear
Feb 28 20:25:23.498: INFO: Pod pod-secrets-c3d7c02f-f4a8-4766-8683-4a01b7597b63 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:25:23.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7879" for this suite.
Feb 28 20:25:29.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:25:29.645: INFO: namespace secrets-7879 deletion completed in 6.140851893s

• [SLOW TEST:8.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:25:29.646: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:25:32.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3031" for this suite.
Feb 28 20:25:54.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:25:54.885: INFO: namespace replication-controller-3031 deletion completed in 22.133038174s

• [SLOW TEST:25.239 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:25:54.885: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-f375854b-8284-4c40-b934-d8e750bcc865 in namespace container-probe-9715
Feb 28 20:25:56.972: INFO: Started pod busybox-f375854b-8284-4c40-b934-d8e750bcc865 in namespace container-probe-9715
STEP: checking the pod's current state and verifying that restartCount is present
Feb 28 20:25:56.975: INFO: Initial restart count of pod busybox-f375854b-8284-4c40-b934-d8e750bcc865 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:29:57.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9715" for this suite.
Feb 28 20:30:03.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:30:03.917: INFO: namespace container-probe-9715 deletion completed in 6.203281911s

• [SLOW TEST:249.032 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:30:03.920: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 28 20:30:03.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-6428'
Feb 28 20:30:04.102: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 28 20:30:04.102: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Feb 28 20:30:06.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-779692974 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6428'
Feb 28 20:30:06.341: INFO: stderr: ""
Feb 28 20:30:06.341: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:30:06.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6428" for this suite.
Feb 28 20:30:28.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:30:28.495: INFO: namespace kubectl-6428 deletion completed in 22.144321795s

• [SLOW TEST:24.575 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:30:28.496: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-e1d676d9-3106-4e7c-b110-2ee19c0a0730
STEP: Creating a pod to test consume configMaps
Feb 28 20:30:28.695: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347" in namespace "configmap-4891" to be "success or failure"
Feb 28 20:30:28.701: INFO: Pod "pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347": Phase="Pending", Reason="", readiness=false. Elapsed: 5.680924ms
Feb 28 20:30:30.706: INFO: Pod "pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010404713s
STEP: Saw pod success
Feb 28 20:30:30.706: INFO: Pod "pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347" satisfied condition "success or failure"
Feb 28 20:30:30.709: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:30:30.740: INFO: Waiting for pod pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347 to disappear
Feb 28 20:30:30.744: INFO: Pod pod-configmaps-3ef3631d-bab4-4982-a80f-341146d7d347 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:30:30.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4891" for this suite.
Feb 28 20:30:36.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:30:36.876: INFO: namespace configmap-4891 deletion completed in 6.122842364s

• [SLOW TEST:8.380 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:30:36.877: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Feb 28 20:30:37.471: INFO: created pod pod-service-account-defaultsa
Feb 28 20:30:37.471: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 28 20:30:37.486: INFO: created pod pod-service-account-mountsa
Feb 28 20:30:37.486: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 28 20:30:37.499: INFO: created pod pod-service-account-nomountsa
Feb 28 20:30:37.499: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 28 20:30:37.510: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 28 20:30:37.511: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 28 20:30:37.519: INFO: created pod pod-service-account-mountsa-mountspec
Feb 28 20:30:37.519: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 28 20:30:37.535: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 28 20:30:37.535: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 28 20:30:37.541: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 28 20:30:37.541: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 28 20:30:37.553: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 28 20:30:37.553: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 28 20:30:37.567: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 28 20:30:37.567: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:30:37.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-590" for this suite.
Feb 28 20:30:59.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:30:59.781: INFO: namespace svcaccounts-590 deletion completed in 22.199323993s

• [SLOW TEST:22.904 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:30:59.782: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 28 20:30:59.845: INFO: Waiting up to 5m0s for pod "pod-82980e77-534b-4a49-bfdd-61028fc40004" in namespace "emptydir-6308" to be "success or failure"
Feb 28 20:30:59.855: INFO: Pod "pod-82980e77-534b-4a49-bfdd-61028fc40004": Phase="Pending", Reason="", readiness=false. Elapsed: 9.233908ms
Feb 28 20:31:01.859: INFO: Pod "pod-82980e77-534b-4a49-bfdd-61028fc40004": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013946739s
STEP: Saw pod success
Feb 28 20:31:01.859: INFO: Pod "pod-82980e77-534b-4a49-bfdd-61028fc40004" satisfied condition "success or failure"
Feb 28 20:31:01.862: INFO: Trying to get logs from node wenjun192 pod pod-82980e77-534b-4a49-bfdd-61028fc40004 container test-container: <nil>
STEP: delete the pod
Feb 28 20:31:01.896: INFO: Waiting for pod pod-82980e77-534b-4a49-bfdd-61028fc40004 to disappear
Feb 28 20:31:01.900: INFO: Pod pod-82980e77-534b-4a49-bfdd-61028fc40004 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:01.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6308" for this suite.
Feb 28 20:31:07.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:08.013: INFO: namespace emptydir-6308 deletion completed in 6.108860794s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:08.013: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-d147d628-8881-41ba-9d83-1b506b822699
STEP: Creating a pod to test consume configMaps
Feb 28 20:31:08.115: INFO: Waiting up to 5m0s for pod "pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e" in namespace "configmap-728" to be "success or failure"
Feb 28 20:31:08.119: INFO: Pod "pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123726ms
Feb 28 20:31:10.124: INFO: Pod "pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009014839s
Feb 28 20:31:12.129: INFO: Pod "pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014123998s
STEP: Saw pod success
Feb 28 20:31:12.129: INFO: Pod "pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e" satisfied condition "success or failure"
Feb 28 20:31:12.133: INFO: Trying to get logs from node wenjun192 pod pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e container configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:31:12.171: INFO: Waiting for pod pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e to disappear
Feb 28 20:31:12.177: INFO: Pod pod-configmaps-79ab1899-ff09-4982-8241-aa48ce633a2e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:12.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-728" for this suite.
Feb 28 20:31:18.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:18.289: INFO: namespace configmap-728 deletion completed in 6.107003878s

• [SLOW TEST:10.276 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:18.290: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:20.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3260" for this suite.
Feb 28 20:31:26.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:26.538: INFO: namespace emptydir-wrapper-3260 deletion completed in 6.115185242s

• [SLOW TEST:8.248 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:26.540: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-ad9c8709-8e37-46ca-aa2a-f3ff67a5198e
STEP: Creating a pod to test consume configMaps
Feb 28 20:31:26.607: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a" in namespace "projected-9872" to be "success or failure"
Feb 28 20:31:26.613: INFO: Pod "pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.582967ms
Feb 28 20:31:28.623: INFO: Pod "pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015521122s
STEP: Saw pod success
Feb 28 20:31:28.623: INFO: Pod "pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a" satisfied condition "success or failure"
Feb 28 20:31:28.625: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:31:28.741: INFO: Waiting for pod pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a to disappear
Feb 28 20:31:28.747: INFO: Pod pod-projected-configmaps-e78118a3-beb4-4ee3-952c-4fd7be27e52a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:28.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9872" for this suite.
Feb 28 20:31:34.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:34.861: INFO: namespace projected-9872 deletion completed in 6.103795498s

• [SLOW TEST:8.327 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:34.868: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-9a66632a-5f0e-4080-989b-5499e39a72de
STEP: Creating a pod to test consume configMaps
Feb 28 20:31:34.921: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155" in namespace "projected-1573" to be "success or failure"
Feb 28 20:31:34.924: INFO: Pod "pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155": Phase="Pending", Reason="", readiness=false. Elapsed: 3.404222ms
Feb 28 20:31:36.931: INFO: Pod "pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01051647s
STEP: Saw pod success
Feb 28 20:31:36.931: INFO: Pod "pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155" satisfied condition "success or failure"
Feb 28 20:31:36.935: INFO: Trying to get logs from node wenjun192 pod pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 28 20:31:36.973: INFO: Waiting for pod pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155 to disappear
Feb 28 20:31:36.977: INFO: Pod pod-projected-configmaps-98d4c865-ddad-4a87-bad4-98dd48db3155 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:36.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1573" for this suite.
Feb 28 20:31:42.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:43.083: INFO: namespace projected-1573 deletion completed in 6.101681953s

• [SLOW TEST:8.215 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:43.084: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 28 20:31:43.132: INFO: Creating deployment "test-recreate-deployment"
Feb 28 20:31:43.140: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 28 20:31:43.159: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 28 20:31:45.168: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 28 20:31:45.171: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 28 20:31:45.191: INFO: Updating deployment test-recreate-deployment
Feb 28 20:31:45.191: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 28 20:31:45.297: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1007,SelfLink:/apis/apps/v1/namespaces/deployment-1007/deployments/test-recreate-deployment,UID:b40f7f7d-6069-4eab-8d4a-660f3cfb65d0,ResourceVersion:27098,Generation:2,CreationTimestamp:2020-02-28 20:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-02-28 20:31:45 +0000 UTC 2020-02-28 20:31:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-02-28 20:31:45 +0000 UTC 2020-02-28 20:31:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 28 20:31:45.300: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1007,SelfLink:/apis/apps/v1/namespaces/deployment-1007/replicasets/test-recreate-deployment-5c8c9cc69d,UID:f3d2957e-6fae-48ce-9152-36499acab640,ResourceVersion:27096,Generation:1,CreationTimestamp:2020-02-28 20:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b40f7f7d-6069-4eab-8d4a-660f3cfb65d0 0xc002736097 0xc002736098}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 20:31:45.300: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 28 20:31:45.300: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1007,SelfLink:/apis/apps/v1/namespaces/deployment-1007/replicasets/test-recreate-deployment-6df85df6b9,UID:e922f756-ae95-42fa-ad8f-fdb1db05949a,ResourceVersion:27088,Generation:2,CreationTimestamp:2020-02-28 20:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b40f7f7d-6069-4eab-8d4a-660f3cfb65d0 0xc002736227 0xc002736228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 28 20:31:45.304: INFO: Pod "test-recreate-deployment-5c8c9cc69d-nmdrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-nmdrv,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1007,SelfLink:/api/v1/namespaces/deployment-1007/pods/test-recreate-deployment-5c8c9cc69d-nmdrv,UID:7ba6818d-6040-4fd6-bb14-b49259c82b40,ResourceVersion:27095,Generation:0,CreationTimestamp:2020-02-28 20:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d f3d2957e-6fae-48ce-9152-36499acab640 0xc002737177 0xc002737178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2ntfw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2ntfw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2ntfw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wenjun192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002737280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027372a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-28 20:31:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:45.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1007" for this suite.
Feb 28 20:31:51.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:31:51.475: INFO: namespace deployment-1007 deletion completed in 6.166395017s

• [SLOW TEST:8.391 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 28 20:31:51.480: INFO: >>> kubeConfig: /tmp/kubeconfig-779692974
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 28 20:31:51.523: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 28 20:31:51.531: INFO: Waiting for terminating namespaces to be deleted...
Feb 28 20:31:51.537: INFO: 
Logging pods the kubelet thinks is on node wenjun191 before test
Feb 28 20:31:51.549: INFO: chiwen-k8s-agent-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container chiwen-k8s-agent ready: true, restart count 0
Feb 28 20:31:51.549: INFO: coredns-6879c49cff-wmp8f from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container coredns ready: true, restart count 0
Feb 28 20:31:51.549: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-wsn2d from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 28 20:31:51.549: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 28 20:31:51.549: INFO: kube-scheduler-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container kube-scheduler ready: true, restart count 1
Feb 28 20:31:51.549: INFO: kube-apiserver-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container kube-apiserver ready: true, restart count 0
Feb 28 20:31:51.549: INFO: chiwen-ingress-controller-9n2n2 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 20:31:51.549: INFO: kube-state-metrics-6b5897fbb8-wfksz from kube-system started at 2020-02-28 18:55:23 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 28 20:31:51.549: INFO: custom-metrics-apiserver-7bf8c988f9-7rz52 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container custom-metrics-apiserver ready: true, restart count 0
Feb 28 20:31:51.549: INFO: chiwen-volume-plugin-2jmh7 from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container chiwen-volume-plugin ready: true, restart count 1
Feb 28 20:31:51.549: INFO: prometheus-deployment-55cfdd8597-pw6tt from kube-system started at 2020-02-28 18:55:10 +0000 UTC (4 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container alertmanager ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 	Container prometheus ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 	Container watch-alertmanager ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 	Container watch-prometheus ready: true, restart count 0
Feb 28 20:31:51.549: INFO: calico-node-xxbcr from kube-system started at 2020-02-28 18:55:09 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 20:31:51.549: INFO: node-exporter-m7r4n from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 20:31:51.549: INFO: etcd-wenjun191 from kube-system started at 2020-02-28 18:54:44 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container etcd ready: true, restart count 0
Feb 28 20:31:51.549: INFO: calico-kube-controllers-5c94f45bd8-jpk5k from kube-system started at 2020-02-28 18:55:09 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 28 20:31:51.549: INFO: kube-controller-manager-wenjun191 from kube-system started at 2020-02-28 18:54:49 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container kube-controller-manager ready: true, restart count 1
Feb 28 20:31:51.549: INFO: chiwen-agent-9k95q from kube-system started at 2020-02-28 18:55:10 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.549: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 20:31:51.549: INFO: 
Logging pods the kubelet thinks is on node wenjun192 before test
Feb 28 20:31:51.559: INFO: chiwen-volume-plugin-76hr8 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container chiwen-volume-plugin ready: true, restart count 0
Feb 28 20:31:51.559: INFO: chiwen-agent-5fbpv from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container chiwen-agent ready: true, restart count 0
Feb 28 20:31:51.559: INFO: node-exporter-mfl29 from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container node-exporter ready: true, restart count 0
Feb 28 20:31:51.559: INFO: chiwen-ingress-controller-9ccwn from kube-system started at 2020-02-28 18:56:23 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container chiwen-ingress-controller ready: true, restart count 0
Feb 28 20:31:51.559: INFO: sonobuoy-e2e-job-bb5a8e1744304000 from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container e2e ready: true, restart count 0
Feb 28 20:31:51.559: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 28 20:31:51.559: INFO: sonobuoy-systemd-logs-daemon-set-59ba6e1a8507461f-rfdrn from sonobuoy started at 2020-02-28 18:57:14 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 28 20:31:51.559: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 28 20:31:51.559: INFO: calico-node-8flfd from kube-system started at 2020-02-28 18:56:23 +0000 UTC (2 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container calico-node ready: true, restart count 0
Feb 28 20:31:51.559: INFO: 	Container install-cni ready: true, restart count 0
Feb 28 20:31:51.559: INFO: sonobuoy from sonobuoy started at 2020-02-28 18:57:12 +0000 UTC (1 container statuses recorded)
Feb 28 20:31:51.559: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4d82caaf-ea81-4dd6-8af4-2f6b15b3c0fb 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4d82caaf-ea81-4dd6-8af4-2f6b15b3c0fb off the node wenjun192
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4d82caaf-ea81-4dd6-8af4-2f6b15b3c0fb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 28 20:31:55.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3275" for this suite.
Feb 28 20:32:03.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 28 20:32:03.796: INFO: namespace sched-pred-3275 deletion completed in 8.101824368s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.316 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.9-beta.0.3+2e808b7cb054ee/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSFeb 28 20:32:03.797: INFO: Running AfterSuite actions on all nodes
Feb 28 20:32:03.797: INFO: Running AfterSuite actions on node 1
Feb 28 20:32:03.797: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 5678.351 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h34m39.856529849s
Test Suite Passed
