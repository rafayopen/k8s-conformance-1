I0219 03:36:37.111173      19 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-152545945
I0219 03:36:37.111301      19 e2e.go:243] Starting e2e run "1623298a-ce86-4c8f-a92b-53c0ddc6b615" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582083395 - Will randomize all specs
Will run 215 of 4412 specs

Feb 19 03:36:37.212: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:36:37.214: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 19 03:36:37.234: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 19 03:36:37.286: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 19 03:36:37.286: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb 19 03:36:37.286: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 19 03:36:37.298: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-oci-node' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin-1-8' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'proxymux-client' (0 seconds elapsed)
Feb 19 03:36:37.298: INFO: e2e test version: v1.15.7
Feb 19 03:36:37.302: INFO: kube-apiserver version: v1.15.7
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:36:37.303: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename prestop
Feb 19 03:36:37.356: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3122
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3122
STEP: Deleting pre-stop pod
Feb 19 03:36:50.946: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:36:50.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3122" for this suite.
Feb 19 03:37:31.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:37:31.207: INFO: namespace prestop-3122 deletion completed in 40.244224767s

• [SLOW TEST:53.905 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:37:31.207: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 19 03:37:31.356: INFO: Waiting up to 5m0s for pod "downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38" in namespace "downward-api-1627" to be "success or failure"
Feb 19 03:37:31.362: INFO: Pod "downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38": Phase="Pending", Reason="", readiness=false. Elapsed: 6.623909ms
Feb 19 03:37:33.371: INFO: Pod "downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014925642s
Feb 19 03:37:35.479: INFO: Pod "downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122892365s
STEP: Saw pod success
Feb 19 03:37:35.479: INFO: Pod "downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38" satisfied condition "success or failure"
Feb 19 03:37:35.484: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:37:35.687: INFO: Waiting for pod downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38 to disappear
Feb 19 03:37:35.695: INFO: Pod downward-api-5d8f0858-5fff-46ab-b044-35c1ca720f38 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:37:35.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1627" for this suite.
Feb 19 03:37:41.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:37:41.934: INFO: namespace downward-api-1627 deletion completed in 6.234065046s

• [SLOW TEST:10.727 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:37:41.934: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 03:37:46.737: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ed9b9b9e-c23c-4485-b77c-36785db97f40"
Feb 19 03:37:46.737: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-ed9b9b9e-c23c-4485-b77c-36785db97f40" in namespace "pods-7718" to be "terminated due to deadline exceeded"
Feb 19 03:37:46.744: INFO: Pod "pod-update-activedeadlineseconds-ed9b9b9e-c23c-4485-b77c-36785db97f40": Phase="Running", Reason="", readiness=true. Elapsed: 7.188893ms
Feb 19 03:37:48.911: INFO: Pod "pod-update-activedeadlineseconds-ed9b9b9e-c23c-4485-b77c-36785db97f40": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.173992044s
Feb 19 03:37:48.911: INFO: Pod "pod-update-activedeadlineseconds-ed9b9b9e-c23c-4485-b77c-36785db97f40" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:37:48.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7718" for this suite.
Feb 19 03:37:54.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:37:55.128: INFO: namespace pods-7718 deletion completed in 6.210988913s

• [SLOW TEST:13.194 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:37:55.129: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Feb 19 03:37:55.203: INFO: Waiting up to 5m0s for pod "client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6" in namespace "containers-3240" to be "success or failure"
Feb 19 03:37:55.209: INFO: Pod "client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.279808ms
Feb 19 03:37:57.216: INFO: Pod "client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012524573s
Feb 19 03:37:59.222: INFO: Pod "client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019411752s
STEP: Saw pod success
Feb 19 03:37:59.222: INFO: Pod "client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6" satisfied condition "success or failure"
Feb 19 03:37:59.228: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6 container test-container: <nil>
STEP: delete the pod
Feb 19 03:37:59.265: INFO: Waiting for pod client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6 to disappear
Feb 19 03:37:59.271: INFO: Pod client-containers-63b8af45-18cc-47c7-90af-0efe1f04b4b6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:37:59.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3240" for this suite.
Feb 19 03:38:05.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:38:05.972: INFO: namespace containers-3240 deletion completed in 6.695246172s

• [SLOW TEST:10.844 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:38:05.973: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-a070d8f8-e2a8-479d-9354-19c668531f55
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:38:06.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4160" for this suite.
Feb 19 03:38:12.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:38:12.655: INFO: namespace secrets-4160 deletion completed in 6.622293441s

• [SLOW TEST:6.682 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:38:12.655: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-5ca5db9d-e983-4b61-b2ef-ff5e64e41031
STEP: Creating a pod to test consume secrets
Feb 19 03:38:12.729: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013" in namespace "projected-5983" to be "success or failure"
Feb 19 03:38:12.736: INFO: Pod "pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013": Phase="Pending", Reason="", readiness=false. Elapsed: 6.784404ms
Feb 19 03:38:14.745: INFO: Pod "pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015803713s
Feb 19 03:38:16.806: INFO: Pod "pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077241722s
STEP: Saw pod success
Feb 19 03:38:16.806: INFO: Pod "pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013" satisfied condition "success or failure"
Feb 19 03:38:17.012: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:38:17.063: INFO: Waiting for pod pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013 to disappear
Feb 19 03:38:17.071: INFO: Pod pod-projected-secrets-9a053bab-bba7-4847-a16b-0a4ba1aa3013 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:38:17.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5983" for this suite.
Feb 19 03:38:23.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:38:23.839: INFO: namespace projected-5983 deletion completed in 6.760551217s

• [SLOW TEST:11.185 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:38:23.840: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Feb 19 03:38:23.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-1283'
Feb 19 03:38:24.264: INFO: stderr: ""
Feb 19 03:38:24.264: INFO: stdout: "pod/pause created\n"
Feb 19 03:38:24.264: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 19 03:38:24.264: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1283" to be "running and ready"
Feb 19 03:38:24.271: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.036473ms
Feb 19 03:38:26.278: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013490091s
Feb 19 03:38:28.285: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.020220428s
Feb 19 03:38:28.285: INFO: Pod "pause" satisfied condition "running and ready"
Feb 19 03:38:28.285: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 19 03:38:28.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 label pods pause testing-label=testing-label-value --namespace=kubectl-1283'
Feb 19 03:38:28.368: INFO: stderr: ""
Feb 19 03:38:28.368: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 19 03:38:28.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pod pause -L testing-label --namespace=kubectl-1283'
Feb 19 03:38:28.442: INFO: stderr: ""
Feb 19 03:38:28.442: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 19 03:38:28.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 label pods pause testing-label- --namespace=kubectl-1283'
Feb 19 03:38:28.518: INFO: stderr: ""
Feb 19 03:38:28.518: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 19 03:38:28.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pod pause -L testing-label --namespace=kubectl-1283'
Feb 19 03:38:28.593: INFO: stderr: ""
Feb 19 03:38:28.593: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Feb 19 03:38:28.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-1283'
Feb 19 03:38:28.679: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:38:28.679: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 19 03:38:28.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=pause --no-headers --namespace=kubectl-1283'
Feb 19 03:38:28.762: INFO: stderr: "No resources found.\n"
Feb 19 03:38:28.762: INFO: stdout: ""
Feb 19 03:38:28.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=pause --namespace=kubectl-1283 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 03:38:28.835: INFO: stderr: ""
Feb 19 03:38:28.835: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:38:28.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1283" for this suite.
Feb 19 03:38:34.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:38:35.113: INFO: namespace kubectl-1283 deletion completed in 6.271699536s

• [SLOW TEST:11.273 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:38:35.113: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dd40d0df-41bc-4628-a1d7-69caba1d9ee1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-dd40d0df-41bc-4628-a1d7-69caba1d9ee1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:38:39.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8982" for this suite.
Feb 19 03:39:03.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:39:04.187: INFO: namespace projected-8982 deletion completed in 24.781291011s

• [SLOW TEST:29.074 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:39:04.188: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 03:39:04.239: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:39:05.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1212" for this suite.
Feb 19 03:39:11.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:39:11.538: INFO: namespace custom-resource-definition-1212 deletion completed in 6.219468678s

• [SLOW TEST:7.350 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:39:11.539: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 03:39:14.070: INFO: Waiting up to 5m0s for pod "client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71" in namespace "pods-7063" to be "success or failure"
Feb 19 03:39:14.077: INFO: Pod "client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71": Phase="Pending", Reason="", readiness=false. Elapsed: 6.708464ms
Feb 19 03:39:16.275: INFO: Pod "client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204742403s
Feb 19 03:39:18.282: INFO: Pod "client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211311895s
STEP: Saw pod success
Feb 19 03:39:18.282: INFO: Pod "client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71" satisfied condition "success or failure"
Feb 19 03:39:18.288: INFO: Trying to get logs from node 10.0.10.4 pod client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71 container env3cont: <nil>
STEP: delete the pod
Feb 19 03:39:18.711: INFO: Waiting for pod client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71 to disappear
Feb 19 03:39:18.717: INFO: Pod client-envvars-dc9dca3e-650a-457b-b9c0-f3f6f0848b71 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:39:18.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7063" for this suite.
Feb 19 03:40:12.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:40:12.952: INFO: namespace pods-7063 deletion completed in 54.220076224s

• [SLOW TEST:61.413 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:40:12.952: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 03:40:13.002: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 19 03:40:13.446: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 03:40:15.671: INFO: Creating deployment "test-rolling-update-deployment"
Feb 19 03:40:15.684: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 19 03:40:15.699: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 19 03:40:17.921: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 19 03:40:17.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717680415, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717680415, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717680415, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717680415, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 03:40:20.016: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 19 03:40:20.153: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5883,SelfLink:/apis/apps/v1/namespaces/deployment-5883/deployments/test-rolling-update-deployment,UID:df1a6f83-ef08-4b64-9f60-dce79bbf3d6d,ResourceVersion:3871,Generation:1,CreationTimestamp:2020-02-19 03:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-19 03:40:15 +0000 UTC 2020-02-19 03:40:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-19 03:40:18 +0000 UTC 2020-02-19 03:40:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 03:40:20.184: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-5883,SelfLink:/apis/apps/v1/namespaces/deployment-5883/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:5a442041-e8d1-4617-ab15-e5bfb720f413,ResourceVersion:3860,Generation:1,CreationTimestamp:2020-02-19 03:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df1a6f83-ef08-4b64-9f60-dce79bbf3d6d 0xc0026ace67 0xc0026ace68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 03:40:20.184: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 19 03:40:20.184: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5883,SelfLink:/apis/apps/v1/namespaces/deployment-5883/replicasets/test-rolling-update-controller,UID:edc82cc1-564d-4d8f-9a0c-fe243f9cecc2,ResourceVersion:3869,Generation:2,CreationTimestamp:2020-02-19 03:40:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment df1a6f83-ef08-4b64-9f60-dce79bbf3d6d 0xc0026acd8f 0xc0026acda0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 03:40:20.206: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-zp6mg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-zp6mg,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-5883,SelfLink:/api/v1/namespaces/deployment-5883/pods/test-rolling-update-deployment-79f6b9d75c-zp6mg,UID:f89df9f8-49aa-4f69-848d-2f447f86edb4,ResourceVersion:3859,Generation:0,CreationTimestamp:2020-02-19 03:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 5a442041-e8d1-4617-ab15-e5bfb720f413 0xc001052ec7 0xc001052ec8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-647qh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-647qh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-647qh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001052f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001052f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 03:40:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 03:40:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 03:40:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 03:40:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.13,StartTime:2020-02-19 03:40:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-19 03:40:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://02900d0665488070df04a2bc1ab716afc2231a167b9cb4f53cc1ec45eb274b6b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:40:20.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5883" for this suite.
Feb 19 03:40:26.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:40:26.697: INFO: namespace deployment-5883 deletion completed in 6.475724376s

• [SLOW TEST:13.745 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:40:26.698: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 03:40:26.883: INFO: Waiting up to 5m0s for pod "pod-8d03b59f-1e97-4f96-8186-c425036e6b2e" in namespace "emptydir-9414" to be "success or failure"
Feb 19 03:40:26.898: INFO: Pod "pod-8d03b59f-1e97-4f96-8186-c425036e6b2e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.269442ms
Feb 19 03:40:29.141: INFO: Pod "pod-8d03b59f-1e97-4f96-8186-c425036e6b2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.258685601s
STEP: Saw pod success
Feb 19 03:40:29.141: INFO: Pod "pod-8d03b59f-1e97-4f96-8186-c425036e6b2e" satisfied condition "success or failure"
Feb 19 03:40:29.148: INFO: Trying to get logs from node 10.0.10.2 pod pod-8d03b59f-1e97-4f96-8186-c425036e6b2e container test-container: <nil>
STEP: delete the pod
Feb 19 03:40:29.185: INFO: Waiting for pod pod-8d03b59f-1e97-4f96-8186-c425036e6b2e to disappear
Feb 19 03:40:29.193: INFO: Pod pod-8d03b59f-1e97-4f96-8186-c425036e6b2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:40:29.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9414" for this suite.
Feb 19 03:40:35.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:40:35.636: INFO: namespace emptydir-9414 deletion completed in 6.435958615s

• [SLOW TEST:8.939 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:40:35.637: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:40:36.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a" in namespace "downward-api-280" to be "success or failure"
Feb 19 03:40:36.404: INFO: Pod "downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.687263ms
Feb 19 03:40:38.628: INFO: Pod "downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.231573129s
STEP: Saw pod success
Feb 19 03:40:38.628: INFO: Pod "downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a" satisfied condition "success or failure"
Feb 19 03:40:38.635: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a container client-container: <nil>
STEP: delete the pod
Feb 19 03:40:38.669: INFO: Waiting for pod downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a to disappear
Feb 19 03:40:38.676: INFO: Pod downwardapi-volume-aaab75c2-cbfc-417b-8b47-4d312af9ee5a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:40:38.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-280" for this suite.
Feb 19 03:40:44.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:40:45.382: INFO: namespace downward-api-280 deletion completed in 6.699040903s

• [SLOW TEST:9.745 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:40:45.382: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7315
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 03:40:45.434: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 03:41:11.733: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.17:8080/dial?request=hostName&protocol=http&host=10.244.2.5&port=8080&tries=1'] Namespace:pod-network-test-7315 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:41:11.733: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:41:11.929: INFO: Waiting for endpoints: map[]
Feb 19 03:41:11.935: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.17:8080/dial?request=hostName&protocol=http&host=10.244.1.16&port=8080&tries=1'] Namespace:pod-network-test-7315 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:41:11.935: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:41:12.136: INFO: Waiting for endpoints: map[]
Feb 19 03:41:12.143: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.17:8080/dial?request=hostName&protocol=http&host=10.244.0.6&port=8080&tries=1'] Namespace:pod-network-test-7315 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:41:12.143: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:41:12.335: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:41:12.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7315" for this suite.
Feb 19 03:41:36.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:41:37.083: INFO: namespace pod-network-test-7315 deletion completed in 24.651311465s

• [SLOW TEST:51.700 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:41:37.083: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 19 03:41:39.837: INFO: Successfully updated pod "annotationupdate3f1079d2-0ccd-40ea-83c3-f69defad18ab"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:41:42.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8173" for this suite.
Feb 19 03:42:04.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:04.584: INFO: namespace downward-api-8173 deletion completed in 22.436313492s

• [SLOW TEST:27.501 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:42:04.584: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:42:04.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7089" for this suite.
Feb 19 03:42:26.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:42:27.019: INFO: namespace pods-7089 deletion completed in 22.351048483s

• [SLOW TEST:22.434 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:42:27.019: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8757, will wait for the garbage collector to delete the pods
Feb 19 03:42:29.161: INFO: Deleting Job.batch foo took: 12.449319ms
Feb 19 03:42:29.661: INFO: Terminating Job.batch foo pods took: 500.270697ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:43:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8757" for this suite.
Feb 19 03:43:16.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:43:16.278: INFO: namespace job-8757 deletion completed in 6.304090263s

• [SLOW TEST:49.258 seconds]
[sig-apps] Job
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:43:16.278: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 19 03:43:24.710: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:24.710: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:24.915: INFO: Exec stderr: ""
Feb 19 03:43:24.915: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:24.915: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:25.289: INFO: Exec stderr: ""
Feb 19 03:43:25.289: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:25.289: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:25.717: INFO: Exec stderr: ""
Feb 19 03:43:25.717: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:25.717: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:25.893: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 19 03:43:25.893: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:25.893: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:26.253: INFO: Exec stderr: ""
Feb 19 03:43:26.253: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:26.253: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:26.731: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 19 03:43:26.731: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:26.731: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:26.896: INFO: Exec stderr: ""
Feb 19 03:43:26.896: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:26.896: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:28.218: INFO: Exec stderr: ""
Feb 19 03:43:28.218: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:28.218: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:28.421: INFO: Exec stderr: ""
Feb 19 03:43:28.421: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9573 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 03:43:28.421: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 03:43:28.595: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:43:28.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9573" for this suite.
Feb 19 03:44:08.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:44:09.221: INFO: namespace e2e-kubelet-etc-hosts-9573 deletion completed in 40.594348193s

• [SLOW TEST:52.943 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:44:09.222: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-3fa635c1-85e8-408e-824c-482606600138 in namespace container-probe-4574
Feb 19 03:44:13.340: INFO: Started pod liveness-3fa635c1-85e8-408e-824c-482606600138 in namespace container-probe-4574
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 03:44:13.381: INFO: Initial restart count of pod liveness-3fa635c1-85e8-408e-824c-482606600138 is 0
Feb 19 03:44:26.261: INFO: Restart count of pod container-probe-4574/liveness-3fa635c1-85e8-408e-824c-482606600138 is now 1 (12.879912008s elapsed)
Feb 19 03:44:45.444: INFO: Restart count of pod container-probe-4574/liveness-3fa635c1-85e8-408e-824c-482606600138 is now 2 (32.063107672s elapsed)
Feb 19 03:45:04.883: INFO: Restart count of pod container-probe-4574/liveness-3fa635c1-85e8-408e-824c-482606600138 is now 3 (51.502240117s elapsed)
Feb 19 03:45:26.179: INFO: Restart count of pod container-probe-4574/liveness-3fa635c1-85e8-408e-824c-482606600138 is now 4 (1m12.79805564s elapsed)
Feb 19 03:46:26.838: INFO: Restart count of pod container-probe-4574/liveness-3fa635c1-85e8-408e-824c-482606600138 is now 5 (2m13.457118384s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:46:26.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4574" for this suite.
Feb 19 03:46:32.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:46:33.337: INFO: namespace container-probe-4574 deletion completed in 6.473544632s

• [SLOW TEST:144.114 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:46:33.337: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-3c43348e-a4d3-4b83-adb7-4b7a58ea8f10
STEP: Creating secret with name s-test-opt-upd-ecd8a738-2d09-4ebc-bd1e-d2ec8480f2d6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3c43348e-a4d3-4b83-adb7-4b7a58ea8f10
STEP: Updating secret s-test-opt-upd-ecd8a738-2d09-4ebc-bd1e-d2ec8480f2d6
STEP: Creating secret with name s-test-opt-create-527857e3-152a-493a-9d0f-b178a6bdafcd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:47:55.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5814" for this suite.
Feb 19 03:48:19.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:48:20.327: INFO: namespace secrets-5814 deletion completed in 24.681874735s

• [SLOW TEST:106.990 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:48:20.327: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-n2ph
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 03:48:20.413: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-n2ph" in namespace "subpath-3862" to be "success or failure"
Feb 19 03:48:20.419: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106455ms
Feb 19 03:48:22.425: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 2.01222582s
Feb 19 03:48:24.452: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 4.038636073s
Feb 19 03:48:26.717: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 6.303972442s
Feb 19 03:48:28.845: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 8.432313913s
Feb 19 03:48:31.044: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 10.631081179s
Feb 19 03:48:33.370: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 12.957227194s
Feb 19 03:48:35.536: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 15.123337237s
Feb 19 03:48:37.866: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 17.452633667s
Feb 19 03:48:40.025: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Running", Reason="", readiness=true. Elapsed: 19.612028103s
Feb 19 03:48:42.224: INFO: Pod "pod-subpath-test-configmap-n2ph": Phase="Succeeded", Reason="", readiness=false. Elapsed: 21.811019033s
STEP: Saw pod success
Feb 19 03:48:42.224: INFO: Pod "pod-subpath-test-configmap-n2ph" satisfied condition "success or failure"
Feb 19 03:48:42.242: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-n2ph container test-container-subpath-configmap-n2ph: <nil>
STEP: delete the pod
Feb 19 03:48:42.294: INFO: Waiting for pod pod-subpath-test-configmap-n2ph to disappear
Feb 19 03:48:42.302: INFO: Pod pod-subpath-test-configmap-n2ph no longer exists
STEP: Deleting pod pod-subpath-test-configmap-n2ph
Feb 19 03:48:42.302: INFO: Deleting pod "pod-subpath-test-configmap-n2ph" in namespace "subpath-3862"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:48:42.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3862" for this suite.
Feb 19 03:48:48.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:48:48.536: INFO: namespace subpath-3862 deletion completed in 6.22275813s

• [SLOW TEST:28.209 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:48:48.538: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0
Feb 19 03:48:48.611: INFO: Pod name my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0: Found 0 pods out of 1
Feb 19 03:48:53.619: INFO: Pod name my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0: Found 1 pods out of 1
Feb 19 03:48:53.619: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0" are running
Feb 19 03:48:53.626: INFO: Pod "my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0-pr2b2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-19 03:48:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-19 03:48:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-19 03:48:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-19 03:48:48 +0000 UTC Reason: Message:}])
Feb 19 03:48:53.626: INFO: Trying to dial the pod
Feb 19 03:48:58.731: INFO: Controller my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0: Got expected result from replica 1 [my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0-pr2b2]: "my-hostname-basic-683a8254-550c-45e3-9679-7a9af0e8e5d0-pr2b2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:48:58.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-428" for this suite.
Feb 19 03:49:05.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:49:05.258: INFO: namespace replication-controller-428 deletion completed in 6.212963183s

• [SLOW TEST:16.720 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:49:05.259: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0200a522-977b-4988-aec6-4d7aafa76e2b
STEP: Creating a pod to test consume configMaps
Feb 19 03:49:05.336: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a" in namespace "configmap-2296" to be "success or failure"
Feb 19 03:49:05.343: INFO: Pod "pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.859734ms
Feb 19 03:49:07.349: INFO: Pod "pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013229595s
STEP: Saw pod success
Feb 19 03:49:07.349: INFO: Pod "pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a" satisfied condition "success or failure"
Feb 19 03:49:07.355: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:49:07.392: INFO: Waiting for pod pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a to disappear
Feb 19 03:49:07.400: INFO: Pod pod-configmaps-6c7cc5d2-f788-46e4-ac9b-bec503d16d1a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:49:07.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2296" for this suite.
Feb 19 03:49:13.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:49:14.014: INFO: namespace configmap-2296 deletion completed in 6.608046554s

• [SLOW TEST:8.755 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:49:14.015: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 03:49:14.104: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 19 03:49:14.120: INFO: Number of nodes with available pods: 0
Feb 19 03:49:14.120: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 19 03:49:14.146: INFO: Number of nodes with available pods: 0
Feb 19 03:49:14.146: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:15.153: INFO: Number of nodes with available pods: 0
Feb 19 03:49:15.153: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:16.152: INFO: Number of nodes with available pods: 1
Feb 19 03:49:16.152: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 19 03:49:16.178: INFO: Number of nodes with available pods: 1
Feb 19 03:49:16.178: INFO: Number of running nodes: 0, number of available pods: 1
Feb 19 03:49:17.186: INFO: Number of nodes with available pods: 0
Feb 19 03:49:17.186: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 19 03:49:17.203: INFO: Number of nodes with available pods: 0
Feb 19 03:49:17.203: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:18.228: INFO: Number of nodes with available pods: 0
Feb 19 03:49:18.228: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:19.213: INFO: Number of nodes with available pods: 0
Feb 19 03:49:19.213: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:20.341: INFO: Number of nodes with available pods: 0
Feb 19 03:49:20.341: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:21.436: INFO: Number of nodes with available pods: 0
Feb 19 03:49:21.436: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:22.211: INFO: Number of nodes with available pods: 0
Feb 19 03:49:22.211: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:23.212: INFO: Number of nodes with available pods: 0
Feb 19 03:49:23.212: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:24.210: INFO: Number of nodes with available pods: 0
Feb 19 03:49:24.210: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:25.210: INFO: Number of nodes with available pods: 0
Feb 19 03:49:25.210: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:26.210: INFO: Number of nodes with available pods: 0
Feb 19 03:49:26.210: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:27.469: INFO: Number of nodes with available pods: 0
Feb 19 03:49:27.469: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:28.210: INFO: Number of nodes with available pods: 0
Feb 19 03:49:28.210: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:49:29.322: INFO: Number of nodes with available pods: 1
Feb 19 03:49:29.322: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1603, will wait for the garbage collector to delete the pods
Feb 19 03:49:29.586: INFO: Deleting DaemonSet.extensions daemon-set took: 39.945083ms
Feb 19 03:49:29.886: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.268944ms
Feb 19 03:49:33.192: INFO: Number of nodes with available pods: 0
Feb 19 03:49:33.192: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 03:49:33.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1603/daemonsets","resourceVersion":"6100"},"items":null}

Feb 19 03:49:33.205: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1603/pods","resourceVersion":"6101"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:49:33.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1603" for this suite.
Feb 19 03:49:39.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:49:39.647: INFO: namespace daemonsets-1603 deletion completed in 6.408947883s

• [SLOW TEST:25.633 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:49:39.648: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 19 03:49:39.724: INFO: Waiting up to 5m0s for pod "downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e" in namespace "downward-api-9463" to be "success or failure"
Feb 19 03:49:39.730: INFO: Pod "downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319906ms
Feb 19 03:49:41.737: INFO: Pod "downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012615577s
STEP: Saw pod success
Feb 19 03:49:41.737: INFO: Pod "downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e" satisfied condition "success or failure"
Feb 19 03:49:41.742: INFO: Trying to get logs from node 10.0.10.4 pod downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:49:41.778: INFO: Waiting for pod downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e to disappear
Feb 19 03:49:41.784: INFO: Pod downward-api-fc9ad4dc-d067-4f8d-abff-c8b7190e772e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:49:41.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9463" for this suite.
Feb 19 03:49:47.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:49:48.380: INFO: namespace downward-api-9463 deletion completed in 6.589288853s

• [SLOW TEST:8.733 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:49:48.381: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:49:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9264" for this suite.
Feb 19 03:49:54.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:49:55.246: INFO: namespace services-9264 deletion completed in 6.586949535s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.865 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:49:55.247: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-3d3887e0-fe91-49bd-ba18-c8b91c810c81
STEP: Creating a pod to test consume configMaps
Feb 19 03:49:55.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4" in namespace "configmap-2821" to be "success or failure"
Feb 19 03:49:55.399: INFO: Pod "pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.700059ms
Feb 19 03:49:57.409: INFO: Pod "pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01819944s
STEP: Saw pod success
Feb 19 03:49:57.409: INFO: Pod "pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4" satisfied condition "success or failure"
Feb 19 03:49:57.414: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:49:57.897: INFO: Waiting for pod pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4 to disappear
Feb 19 03:49:57.904: INFO: Pod pod-configmaps-43b284db-e49b-4e92-85d7-3138bfd5d1c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:49:57.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2821" for this suite.
Feb 19 03:50:04.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:04.254: INFO: namespace configmap-2821 deletion completed in 6.342653138s

• [SLOW TEST:9.008 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:50:04.255: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-187eba43-e8db-47f1-befa-ef3d03cb996f
STEP: Creating a pod to test consume secrets
Feb 19 03:50:04.369: INFO: Waiting up to 5m0s for pod "pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e" in namespace "secrets-745" to be "success or failure"
Feb 19 03:50:04.378: INFO: Pod "pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.968908ms
Feb 19 03:50:06.386: INFO: Pod "pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016159821s
Feb 19 03:50:08.551: INFO: Pod "pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.181545274s
STEP: Saw pod success
Feb 19 03:50:08.551: INFO: Pod "pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e" satisfied condition "success or failure"
Feb 19 03:50:08.557: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:50:08.993: INFO: Waiting for pod pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e to disappear
Feb 19 03:50:09.001: INFO: Pod pod-secrets-eb052e5a-9988-4dc9-b3d1-65e58ed5ce8e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:50:09.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-745" for this suite.
Feb 19 03:50:15.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:15.548: INFO: namespace secrets-745 deletion completed in 6.540986874s

• [SLOW TEST:11.293 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:50:15.548: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5775/configmap-test-01a9f85b-3d40-48a4-856b-066663960e26
STEP: Creating a pod to test consume configMaps
Feb 19 03:50:15.624: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31" in namespace "configmap-5775" to be "success or failure"
Feb 19 03:50:15.631: INFO: Pod "pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31": Phase="Pending", Reason="", readiness=false. Elapsed: 7.36637ms
Feb 19 03:50:17.640: INFO: Pod "pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016471362s
STEP: Saw pod success
Feb 19 03:50:17.640: INFO: Pod "pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31" satisfied condition "success or failure"
Feb 19 03:50:17.646: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31 container env-test: <nil>
STEP: delete the pod
Feb 19 03:50:18.041: INFO: Waiting for pod pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31 to disappear
Feb 19 03:50:18.048: INFO: Pod pod-configmaps-a0da770f-03e5-46c9-b7b7-5987e3a86f31 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:50:18.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5775" for this suite.
Feb 19 03:50:24.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:24.439: INFO: namespace configmap-5775 deletion completed in 6.385049894s

• [SLOW TEST:8.891 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:50:24.440: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 03:50:24.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8019'
Feb 19 03:50:24.899: INFO: stderr: ""
Feb 19 03:50:24.899: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Feb 19 03:50:24.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete pods e2e-test-nginx-pod --namespace=kubectl-8019'
Feb 19 03:50:36.835: INFO: stderr: ""
Feb 19 03:50:36.836: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:50:36.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8019" for this suite.
Feb 19 03:50:42.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:43.427: INFO: namespace kubectl-8019 deletion completed in 6.550433392s

• [SLOW TEST:18.987 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:50:43.427: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-8a9ada45-8530-47ef-9c1a-6132b87a76df
STEP: Creating secret with name secret-projected-all-test-volume-3fd60787-113b-4a98-a6ea-2c6891a7cc35
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 19 03:50:43.514: INFO: Waiting up to 5m0s for pod "projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6" in namespace "projected-8982" to be "success or failure"
Feb 19 03:50:43.521: INFO: Pod "projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.49229ms
Feb 19 03:50:45.745: INFO: Pod "projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.230840159s
STEP: Saw pod success
Feb 19 03:50:45.745: INFO: Pod "projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6" satisfied condition "success or failure"
Feb 19 03:50:45.752: INFO: Trying to get logs from node 10.0.10.2 pod projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 19 03:50:45.793: INFO: Waiting for pod projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6 to disappear
Feb 19 03:50:45.801: INFO: Pod projected-volume-074dd5eb-307c-4bda-b188-4908b5f3eaa6 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:50:45.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8982" for this suite.
Feb 19 03:50:51.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:50:52.017: INFO: namespace projected-8982 deletion completed in 6.208516796s

• [SLOW TEST:8.590 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:50:52.017: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 19 03:50:54.598: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:50:54.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-980" for this suite.
Feb 19 03:51:00.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:51:00.918: INFO: namespace container-runtime-980 deletion completed in 6.217168797s

• [SLOW TEST:8.901 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:51:00.919: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-325925bd-6a08-4dcc-9daa-e03ad67360a3
STEP: Creating a pod to test consume secrets
Feb 19 03:51:00.996: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187" in namespace "projected-9502" to be "success or failure"
Feb 19 03:51:01.003: INFO: Pod "pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187": Phase="Pending", Reason="", readiness=false. Elapsed: 6.15604ms
Feb 19 03:51:03.010: INFO: Pod "pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013742299s
STEP: Saw pod success
Feb 19 03:51:03.010: INFO: Pod "pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187" satisfied condition "success or failure"
Feb 19 03:51:03.016: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:51:03.068: INFO: Waiting for pod pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187 to disappear
Feb 19 03:51:03.075: INFO: Pod pod-projected-secrets-9f024da8-bb02-4c99-8546-714ff3e3b187 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:51:03.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9502" for this suite.
Feb 19 03:51:09.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:51:09.527: INFO: namespace projected-9502 deletion completed in 6.44441947s

• [SLOW TEST:8.609 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:51:09.528: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Feb 19 03:51:09.578: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 19 03:51:09.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:09.865: INFO: stderr: ""
Feb 19 03:51:09.865: INFO: stdout: "service/redis-slave created\n"
Feb 19 03:51:09.865: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 19 03:51:09.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:10.412: INFO: stderr: ""
Feb 19 03:51:10.412: INFO: stdout: "service/redis-master created\n"
Feb 19 03:51:10.412: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 19 03:51:10.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:10.680: INFO: stderr: ""
Feb 19 03:51:10.680: INFO: stdout: "service/frontend created\n"
Feb 19 03:51:10.680: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 19 03:51:10.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:10.941: INFO: stderr: ""
Feb 19 03:51:10.941: INFO: stdout: "deployment.apps/frontend created\n"
Feb 19 03:51:10.941: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 19 03:51:10.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:11.190: INFO: stderr: ""
Feb 19 03:51:11.190: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 19 03:51:11.190: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 19 03:51:11.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4364'
Feb 19 03:51:11.617: INFO: stderr: ""
Feb 19 03:51:11.617: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 19 03:51:11.617: INFO: Waiting for all frontend pods to be Running.
Feb 19 03:51:56.869: INFO: Waiting for frontend to serve content.
Feb 19 03:51:56.952: INFO: Trying to add a new entry to the guestbook.
Feb 19 03:51:57.240: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 19 03:51:57.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.354: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.354: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:51:57.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.473: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.473: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:51:57.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.591: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.591: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:51:57.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.689: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.689: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:51:57.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.793: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.793: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 03:51:57.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4364'
Feb 19 03:51:57.874: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:51:57.874: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:51:57.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4364" for this suite.
Feb 19 03:52:37.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:52:38.224: INFO: namespace kubectl-4364 deletion completed in 40.343075471s

• [SLOW TEST:88.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:52:38.224: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-bce6647a-0a6b-4f9b-a4e9-2317db3e9309
STEP: Creating a pod to test consume configMaps
Feb 19 03:52:38.310: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc" in namespace "projected-4525" to be "success or failure"
Feb 19 03:52:38.317: INFO: Pod "pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.606303ms
Feb 19 03:52:40.324: INFO: Pod "pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014208149s
Feb 19 03:52:42.544: INFO: Pod "pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.233884271s
STEP: Saw pod success
Feb 19 03:52:42.544: INFO: Pod "pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc" satisfied condition "success or failure"
Feb 19 03:52:42.550: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 03:52:42.629: INFO: Waiting for pod pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc to disappear
Feb 19 03:52:42.634: INFO: Pod pod-projected-configmaps-11e2b937-ed92-4055-a571-b2a6b941f4cc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:52:42.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4525" for this suite.
Feb 19 03:52:48.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:52:49.119: INFO: namespace projected-4525 deletion completed in 6.478139656s

• [SLOW TEST:10.895 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:52:49.120: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:52:49.498: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f" in namespace "projected-7987" to be "success or failure"
Feb 19 03:52:49.504: INFO: Pod "downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.693909ms
Feb 19 03:52:51.530: INFO: Pod "downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032321762s
Feb 19 03:52:53.678: INFO: Pod "downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.180690785s
STEP: Saw pod success
Feb 19 03:52:53.678: INFO: Pod "downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f" satisfied condition "success or failure"
Feb 19 03:52:53.736: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f container client-container: <nil>
STEP: delete the pod
Feb 19 03:52:53.833: INFO: Waiting for pod downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f to disappear
Feb 19 03:52:53.844: INFO: Pod downwardapi-volume-e5629bcc-61fd-47d9-967d-e69d9d55730f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:52:53.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7987" for this suite.
Feb 19 03:52:59.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:00.087: INFO: namespace projected-7987 deletion completed in 6.227093557s

• [SLOW TEST:10.968 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:53:00.087: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 19 03:53:05.018: INFO: Successfully updated pod "labelsupdate360cc0b4-d740-433b-ad0e-9716c95ac7e2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:53:07.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-18" for this suite.
Feb 19 03:53:29.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:29.860: INFO: namespace projected-18 deletion completed in 22.51106307s

• [SLOW TEST:29.773 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:53:29.861: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:53:36.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6666" for this suite.
Feb 19 03:53:42.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:42.570: INFO: namespace namespaces-6666 deletion completed in 6.219611995s
STEP: Destroying namespace "nsdeletetest-7808" for this suite.
Feb 19 03:53:42.575: INFO: Namespace nsdeletetest-7808 was already deleted
STEP: Destroying namespace "nsdeletetest-6187" for this suite.
Feb 19 03:53:48.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:53:48.939: INFO: namespace nsdeletetest-6187 deletion completed in 6.363768899s

• [SLOW TEST:19.079 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:53:48.939: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-pzfh
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 03:53:49.021: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pzfh" in namespace "subpath-133" to be "success or failure"
Feb 19 03:53:49.028: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052496ms
Feb 19 03:53:51.034: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012240357s
Feb 19 03:53:53.276: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 4.254041736s
Feb 19 03:53:55.523: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 6.501024765s
Feb 19 03:53:57.745: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 8.723743448s
Feb 19 03:53:59.974: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 10.952608062s
Feb 19 03:54:01.990: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 12.968672946s
Feb 19 03:54:03.997: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 14.975643278s
Feb 19 03:54:06.013: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 16.991036813s
Feb 19 03:54:08.021: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 18.999149554s
Feb 19 03:54:10.037: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Running", Reason="", readiness=true. Elapsed: 21.015649574s
Feb 19 03:54:12.343: INFO: Pod "pod-subpath-test-projected-pzfh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.321502688s
STEP: Saw pod success
Feb 19 03:54:12.343: INFO: Pod "pod-subpath-test-projected-pzfh" satisfied condition "success or failure"
Feb 19 03:54:12.350: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-projected-pzfh container test-container-subpath-projected-pzfh: <nil>
STEP: delete the pod
Feb 19 03:54:12.417: INFO: Waiting for pod pod-subpath-test-projected-pzfh to disappear
Feb 19 03:54:12.423: INFO: Pod pod-subpath-test-projected-pzfh no longer exists
STEP: Deleting pod pod-subpath-test-projected-pzfh
Feb 19 03:54:12.423: INFO: Deleting pod "pod-subpath-test-projected-pzfh" in namespace "subpath-133"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:54:12.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-133" for this suite.
Feb 19 03:54:18.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:54:18.994: INFO: namespace subpath-133 deletion completed in 6.559900207s

• [SLOW TEST:30.055 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:54:18.995: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Feb 19 03:54:19.064: INFO: Waiting up to 5m0s for pod "var-expansion-40592d72-2fcd-468d-99af-0ef866402224" in namespace "var-expansion-4740" to be "success or failure"
Feb 19 03:54:19.070: INFO: Pod "var-expansion-40592d72-2fcd-468d-99af-0ef866402224": Phase="Pending", Reason="", readiness=false. Elapsed: 6.557017ms
Feb 19 03:54:21.107: INFO: Pod "var-expansion-40592d72-2fcd-468d-99af-0ef866402224": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043677943s
STEP: Saw pod success
Feb 19 03:54:21.107: INFO: Pod "var-expansion-40592d72-2fcd-468d-99af-0ef866402224" satisfied condition "success or failure"
Feb 19 03:54:21.149: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-40592d72-2fcd-468d-99af-0ef866402224 container dapi-container: <nil>
STEP: delete the pod
Feb 19 03:54:21.199: INFO: Waiting for pod var-expansion-40592d72-2fcd-468d-99af-0ef866402224 to disappear
Feb 19 03:54:21.207: INFO: Pod var-expansion-40592d72-2fcd-468d-99af-0ef866402224 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:54:21.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4740" for this suite.
Feb 19 03:54:27.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:54:27.435: INFO: namespace var-expansion-4740 deletion completed in 6.221755018s

• [SLOW TEST:8.439 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:54:27.435: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 19 03:54:27.532: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7559,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 03:54:27.532: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7560,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 03:54:27.532: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7561,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 19 03:54:37.807: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7594,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 03:54:37.807: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7595,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 19 03:54:37.807: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-9117,SelfLink:/api/v1/namespaces/watch-9117/configmaps/e2e-watch-test-label-changed,UID:0f5a472b-3f94-46cc-b9f6-a5adb7164cfd,ResourceVersion:7596,Generation:0,CreationTimestamp:2020-02-19 03:54:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:54:37.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9117" for this suite.
Feb 19 03:54:43.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:54:44.230: INFO: namespace watch-9117 deletion completed in 6.416697076s

• [SLOW TEST:16.795 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:54:44.231: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5884/configmap-test-0983fae5-8ca4-4fee-b691-a32417383928
STEP: Creating a pod to test consume configMaps
Feb 19 03:54:44.518: INFO: Waiting up to 5m0s for pod "pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9" in namespace "configmap-5884" to be "success or failure"
Feb 19 03:54:44.525: INFO: Pod "pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79203ms
Feb 19 03:54:46.531: INFO: Pod "pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012805515s
STEP: Saw pod success
Feb 19 03:54:46.531: INFO: Pod "pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9" satisfied condition "success or failure"
Feb 19 03:54:46.536: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9 container env-test: <nil>
STEP: delete the pod
Feb 19 03:54:47.162: INFO: Waiting for pod pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9 to disappear
Feb 19 03:54:47.168: INFO: Pod pod-configmaps-3506dc54-2363-408b-9e6f-ed104ecba9e9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:54:47.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5884" for this suite.
Feb 19 03:54:53.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:54:53.392: INFO: namespace configmap-5884 deletion completed in 6.217975712s

• [SLOW TEST:9.161 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:54:53.393: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 03:54:53.478: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514" in namespace "projected-5139" to be "success or failure"
Feb 19 03:54:53.486: INFO: Pod "downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514": Phase="Pending", Reason="", readiness=false. Elapsed: 7.808991ms
Feb 19 03:54:55.493: INFO: Pod "downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014553753s
Feb 19 03:54:57.522: INFO: Pod "downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043748606s
STEP: Saw pod success
Feb 19 03:54:57.522: INFO: Pod "downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514" satisfied condition "success or failure"
Feb 19 03:54:57.527: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514 container client-container: <nil>
STEP: delete the pod
Feb 19 03:54:57.691: INFO: Waiting for pod downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514 to disappear
Feb 19 03:54:57.698: INFO: Pod downwardapi-volume-3eef42cf-2bf0-4ccd-ae66-a4784f0bb514 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:54:57.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5139" for this suite.
Feb 19 03:55:03.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:04.267: INFO: namespace projected-5139 deletion completed in 6.563652994s

• [SLOW TEST:10.875 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:55:04.268: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 19 03:55:07.035: INFO: Successfully updated pod "labelsupdate0cc010ba-1e86-4e8a-94d0-7427c0ed1b86"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:55:09.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2077" for this suite.
Feb 19 03:55:33.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:33.784: INFO: namespace downward-api-2077 deletion completed in 24.220161691s

• [SLOW TEST:29.517 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:55:33.785: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Feb 19 03:55:33.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 api-versions'
Feb 19 03:55:33.913: INFO: stderr: ""
Feb 19 03:55:33.913: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:55:33.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8889" for this suite.
Feb 19 03:55:40.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:40.269: INFO: namespace kubectl-8889 deletion completed in 6.348281209s

• [SLOW TEST:6.484 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:55:40.269: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 19 03:55:42.793: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:55:42.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2589" for this suite.
Feb 19 03:55:49.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:55:49.248: INFO: namespace container-runtime-2589 deletion completed in 6.418739321s

• [SLOW TEST:8.979 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:55:49.248: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 19 03:55:49.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-8036'
Feb 19 03:55:49.686: INFO: stderr: ""
Feb 19 03:55:49.686: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 03:55:49.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8036'
Feb 19 03:55:50.883: INFO: stderr: ""
Feb 19 03:55:50.883: INFO: stdout: "update-demo-nautilus-v8b7z update-demo-nautilus-vknvx "
Feb 19 03:55:50.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v8b7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8036'
Feb 19 03:55:50.952: INFO: stderr: ""
Feb 19 03:55:50.952: INFO: stdout: ""
Feb 19 03:55:50.952: INFO: update-demo-nautilus-v8b7z is created but not running
Feb 19 03:55:55.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8036'
Feb 19 03:55:56.057: INFO: stderr: ""
Feb 19 03:55:56.057: INFO: stdout: "update-demo-nautilus-v8b7z update-demo-nautilus-vknvx "
Feb 19 03:55:56.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v8b7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8036'
Feb 19 03:55:56.140: INFO: stderr: ""
Feb 19 03:55:56.140: INFO: stdout: "true"
Feb 19 03:55:56.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v8b7z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8036'
Feb 19 03:55:56.214: INFO: stderr: ""
Feb 19 03:55:56.214: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:55:56.214: INFO: validating pod update-demo-nautilus-v8b7z
Feb 19 03:55:56.289: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:55:56.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:55:56.289: INFO: update-demo-nautilus-v8b7z is verified up and running
Feb 19 03:55:56.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-vknvx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8036'
Feb 19 03:55:56.362: INFO: stderr: ""
Feb 19 03:55:56.362: INFO: stdout: "true"
Feb 19 03:55:56.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-vknvx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8036'
Feb 19 03:55:56.433: INFO: stderr: ""
Feb 19 03:55:56.433: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 03:55:56.433: INFO: validating pod update-demo-nautilus-vknvx
Feb 19 03:55:56.719: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 03:55:56.719: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 03:55:56.719: INFO: update-demo-nautilus-vknvx is verified up and running
STEP: using delete to clean up resources
Feb 19 03:55:56.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-8036'
Feb 19 03:55:56.803: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 03:55:56.803: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 03:55:56.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8036'
Feb 19 03:55:56.883: INFO: stderr: "No resources found.\n"
Feb 19 03:55:56.883: INFO: stdout: ""
Feb 19 03:55:56.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=update-demo --namespace=kubectl-8036 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 03:55:56.959: INFO: stderr: ""
Feb 19 03:55:56.959: INFO: stdout: "update-demo-nautilus-v8b7z\nupdate-demo-nautilus-vknvx\n"
Feb 19 03:55:57.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8036'
Feb 19 03:55:57.540: INFO: stderr: "No resources found.\n"
Feb 19 03:55:57.540: INFO: stdout: ""
Feb 19 03:55:57.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=update-demo --namespace=kubectl-8036 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 03:55:57.615: INFO: stderr: ""
Feb 19 03:55:57.615: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:55:57.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8036" for this suite.
Feb 19 03:56:03.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:56:03.852: INFO: namespace kubectl-8036 deletion completed in 6.224775827s

• [SLOW TEST:14.604 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:56:03.853: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-b0916f8b-d9bc-4bc8-94df-8d7c1227e060
STEP: Creating a pod to test consume secrets
Feb 19 03:56:03.930: INFO: Waiting up to 5m0s for pod "pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125" in namespace "secrets-3636" to be "success or failure"
Feb 19 03:56:03.937: INFO: Pod "pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125": Phase="Pending", Reason="", readiness=false. Elapsed: 6.895425ms
Feb 19 03:56:05.943: INFO: Pod "pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012785795s
STEP: Saw pod success
Feb 19 03:56:05.943: INFO: Pod "pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125" satisfied condition "success or failure"
Feb 19 03:56:05.948: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 03:56:05.985: INFO: Waiting for pod pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125 to disappear
Feb 19 03:56:05.992: INFO: Pod pod-secrets-17ff0780-14be-44bb-9941-f950e31ed125 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:56:05.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3636" for this suite.
Feb 19 03:56:12.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:56:12.208: INFO: namespace secrets-3636 deletion completed in 6.210447529s

• [SLOW TEST:8.355 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:56:12.208: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 19 03:56:12.450: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:56:17.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7552" for this suite.
Feb 19 03:56:41.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:56:41.395: INFO: namespace init-container-7552 deletion completed in 24.217596474s

• [SLOW TEST:29.186 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:56:41.395: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 03:56:41.713: INFO: Create a RollingUpdate DaemonSet
Feb 19 03:56:41.725: INFO: Check that daemon pods launch on every node of the cluster
Feb 19 03:56:41.737: INFO: Number of nodes with available pods: 0
Feb 19 03:56:41.737: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:56:42.962: INFO: Number of nodes with available pods: 0
Feb 19 03:56:42.962: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 03:56:43.940: INFO: Number of nodes with available pods: 2
Feb 19 03:56:43.940: INFO: Node 10.0.10.3 is running more than one daemon pod
Feb 19 03:56:44.855: INFO: Number of nodes with available pods: 2
Feb 19 03:56:44.855: INFO: Node 10.0.10.3 is running more than one daemon pod
Feb 19 03:56:45.751: INFO: Number of nodes with available pods: 3
Feb 19 03:56:45.751: INFO: Number of running nodes: 3, number of available pods: 3
Feb 19 03:56:45.751: INFO: Update the DaemonSet to trigger a rollout
Feb 19 03:56:45.765: INFO: Updating DaemonSet daemon-set
Feb 19 03:56:54.793: INFO: Roll back the DaemonSet before rollout is complete
Feb 19 03:56:54.808: INFO: Updating DaemonSet daemon-set
Feb 19 03:56:54.808: INFO: Make sure DaemonSet rollback is complete
Feb 19 03:56:54.814: INFO: Wrong image for pod: daemon-set-w85wc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 19 03:56:54.814: INFO: Pod daemon-set-w85wc is not available
Feb 19 03:56:56.008: INFO: Wrong image for pod: daemon-set-w85wc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 19 03:56:56.008: INFO: Pod daemon-set-w85wc is not available
Feb 19 03:56:56.827: INFO: Pod daemon-set-xfgzw is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1263, will wait for the garbage collector to delete the pods
Feb 19 03:56:56.912: INFO: Deleting DaemonSet.extensions daemon-set took: 12.547338ms
Feb 19 03:56:57.213: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.247914ms
Feb 19 03:57:09.819: INFO: Number of nodes with available pods: 0
Feb 19 03:57:09.819: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 03:57:09.824: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1263/daemonsets","resourceVersion":"8382"},"items":null}

Feb 19 03:57:09.830: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1263/pods","resourceVersion":"8382"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 03:57:09.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1263" for this suite.
Feb 19 03:57:15.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 03:57:16.536: INFO: namespace daemonsets-1263 deletion completed in 6.676412523s

• [SLOW TEST:35.141 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 03:57:16.536: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-598e5b7d-2af9-4083-a174-a5ee478dcb46 in namespace container-probe-8670
Feb 19 03:57:20.915: INFO: Started pod test-webserver-598e5b7d-2af9-4083-a174-a5ee478dcb46 in namespace container-probe-8670
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 03:57:20.944: INFO: Initial restart count of pod test-webserver-598e5b7d-2af9-4083-a174-a5ee478dcb46 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:01:22.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8670" for this suite.
Feb 19 04:01:28.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:01:28.515: INFO: namespace container-probe-8670 deletion completed in 6.215380866s

• [SLOW TEST:251.979 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:01:28.516: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-89f20bbd-f07e-44ef-a152-4543b1a4307a in namespace container-probe-5306
Feb 19 04:01:30.592: INFO: Started pod busybox-89f20bbd-f07e-44ef-a152-4543b1a4307a in namespace container-probe-5306
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 04:01:30.597: INFO: Initial restart count of pod busybox-89f20bbd-f07e-44ef-a152-4543b1a4307a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:05:32.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5306" for this suite.
Feb 19 04:05:38.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:05:38.375: INFO: namespace container-probe-5306 deletion completed in 6.216254954s

• [SLOW TEST:249.859 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:05:38.375: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-5469
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5469 to expose endpoints map[]
Feb 19 04:05:38.993: INFO: successfully validated that service multi-endpoint-test in namespace services-5469 exposes endpoints map[] (13.027919ms elapsed)
STEP: Creating pod pod1 in namespace services-5469
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5469 to expose endpoints map[pod1:[100]]
Feb 19 04:05:41.074: INFO: successfully validated that service multi-endpoint-test in namespace services-5469 exposes endpoints map[pod1:[100]] (2.062936825s elapsed)
STEP: Creating pod pod2 in namespace services-5469
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5469 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 19 04:05:43.354: INFO: successfully validated that service multi-endpoint-test in namespace services-5469 exposes endpoints map[pod1:[100] pod2:[101]] (2.269274725s elapsed)
STEP: Deleting pod pod1 in namespace services-5469
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5469 to expose endpoints map[pod2:[101]]
Feb 19 04:05:43.377: INFO: successfully validated that service multi-endpoint-test in namespace services-5469 exposes endpoints map[pod2:[101]] (12.154581ms elapsed)
STEP: Deleting pod pod2 in namespace services-5469
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5469 to expose endpoints map[]
Feb 19 04:05:44.400: INFO: successfully validated that service multi-endpoint-test in namespace services-5469 exposes endpoints map[] (1.012346982s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:05:44.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5469" for this suite.
Feb 19 04:05:50.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:05:50.649: INFO: namespace services-5469 deletion completed in 6.212599459s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:12.274 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:05:50.649: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5015
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5015
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5015
Feb 19 04:05:50.738: INFO: Found 0 stateful pods, waiting for 1
Feb 19 04:06:00.745: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 19 04:06:00.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:06:01.400: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:06:01.400: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:06:01.400: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:06:01.406: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 04:06:11.413: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:06:11.413: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:06:11.446: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999769s
Feb 19 04:06:12.493: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988348788s
Feb 19 04:06:13.500: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.941614542s
Feb 19 04:06:14.724: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.93450548s
Feb 19 04:06:15.731: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.710105615s
Feb 19 04:06:16.952: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.703421315s
Feb 19 04:06:17.958: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.482893615s
Feb 19 04:06:19.222: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.476352963s
Feb 19 04:06:20.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.212119341s
Feb 19 04:06:21.474: INFO: Verifying statefulset ss doesn't scale past 1 for another 205.446867ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5015
Feb 19 04:06:22.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:06:22.865: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:06:22.865: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:06:22.865: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:06:22.871: INFO: Found 1 stateful pods, waiting for 3
Feb 19 04:06:32.879: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:06:32.879: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:06:32.879: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 19 04:06:32.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:06:33.184: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:06:33.184: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:06:33.184: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:06:33.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:06:33.506: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:06:33.506: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:06:33.506: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:06:33.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:06:35.823: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:06:35.823: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:06:35.823: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:06:35.823: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:06:35.829: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 19 04:06:46.091: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:06:46.091: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:06:46.091: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:06:46.117: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999692s
Feb 19 04:06:47.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992221377s
Feb 19 04:06:48.357: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984308051s
Feb 19 04:06:49.365: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.752037029s
Feb 19 04:06:50.626: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.744598793s
Feb 19 04:06:51.634: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.483395534s
Feb 19 04:06:52.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.475860826s
Feb 19 04:06:53.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.347348348s
Feb 19 04:06:54.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.340136919s
Feb 19 04:06:56.004: INFO: Verifying statefulset ss doesn't scale past 3 for another 112.841267ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5015
Feb 19 04:06:57.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:06:57.580: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:06:57.580: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:06:57.580: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:06:57.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:06:57.849: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:06:57.849: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:06:57.849: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:06:57.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:06:58.060: INFO: rc: 1
Feb 19 04:06:58.060: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0030267b0 exit status 1 <nil> <nil> true [0xc0030f2070 0xc0030f20a8 0xc0030f20e0] [0xc0030f2070 0xc0030f20a8 0xc0030f20e0] [0xc0030f20a0 0xc0030f20c0] [0xba6c10 0xba6c10] 0xc0028794a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Feb 19 04:07:08.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:08.529: INFO: rc: 1
Feb 19 04:07:08.529: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001966480 exit status 1 <nil> <nil> true [0xc0001893b0 0xc000189570 0xc0001897a0] [0xc0001893b0 0xc000189570 0xc0001897a0] [0xc000189548 0xc000189788] [0xba6c10 0xba6c10] 0xc002566fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:07:18.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:18.606: INFO: rc: 1
Feb 19 04:07:18.607: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003026b10 exit status 1 <nil> <nil> true [0xc0030f20e8 0xc0030f2118 0xc0030f2148] [0xc0030f20e8 0xc0030f2118 0xc0030f2148] [0xc0030f2108 0xc0030f2140] [0xba6c10 0xba6c10] 0xc002879e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:07:28.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:28.681: INFO: rc: 1
Feb 19 04:07:28.681: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019667b0 exit status 1 <nil> <nil> true [0xc0001897f0 0xc000189a68 0xc000189c68] [0xc0001897f0 0xc000189a68 0xc000189c68] [0xc0001899e0 0xc000189c10] [0xba6c10 0xba6c10] 0xc002567680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:07:38.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:38.758: INFO: rc: 1
Feb 19 04:07:38.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003026e40 exit status 1 <nil> <nil> true [0xc0030f2170 0xc0030f21c0 0xc0030f21f8] [0xc0030f2170 0xc0030f21c0 0xc0030f21f8] [0xc0030f21a0 0xc0030f21e0] [0xba6c10 0xba6c10] 0xc002abe2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:07:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:48.833: INFO: rc: 1
Feb 19 04:07:48.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001966b10 exit status 1 <nil> <nil> true [0xc000189c88 0xc000189cb0 0xc000189d10] [0xc000189c88 0xc000189cb0 0xc000189d10] [0xc000189ca0 0xc000189cf8] [0xba6c10 0xba6c10] 0xc0025679e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:07:58.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:07:58.909: INFO: rc: 1
Feb 19 04:07:58.909: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab9ef0 exit status 1 <nil> <nil> true [0xc0013d5028 0xc0013d5060 0xc0013d5118] [0xc0013d5028 0xc0013d5060 0xc0013d5118] [0xc0013d5048 0xc0013d50b8] [0xba6c10 0xba6c10] 0xc002f1d4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:08.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:08.986: INFO: rc: 1
Feb 19 04:08:08.986: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001966e70 exit status 1 <nil> <nil> true [0xc000189d40 0xc000189db8 0xc000189de8] [0xc000189d40 0xc000189db8 0xc000189de8] [0xc000189da0 0xc000189dd8] [0xba6c10 0xba6c10] 0xc002567d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:18.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:19.064: INFO: rc: 1
Feb 19 04:08:19.064: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d21350 exit status 1 <nil> <nil> true [0xc0003b0e30 0xc0003b0e58 0xc0003b0ea0] [0xc0003b0e30 0xc0003b0e58 0xc0003b0ea0] [0xc0003b0e50 0xc0003b0e88] [0xba6c10 0xba6c10] 0xc002267080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:29.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:29.243: INFO: rc: 1
Feb 19 04:08:29.243: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019671d0 exit status 1 <nil> <nil> true [0xc000189df8 0xc000189ea0 0xc000189f00] [0xc000189df8 0xc000189ea0 0xc000189f00] [0xc000189e50 0xc000189ed8] [0xba6c10 0xba6c10] 0xc002c44120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:39.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:39.630: INFO: rc: 1
Feb 19 04:08:39.630: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003027200 exit status 1 <nil> <nil> true [0xc0030f2200 0xc0030f2240 0xc0030f2290] [0xc0030f2200 0xc0030f2240 0xc0030f2290] [0xc0030f2228 0xc0030f2278] [0xba6c10 0xba6c10] 0xc002abe840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:49.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:49.706: INFO: rc: 1
Feb 19 04:08:49.707: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b50300 exit status 1 <nil> <nil> true [0xc0000cd830 0xc0000cda20 0xc0000cde20] [0xc0000cd830 0xc0000cda20 0xc0000cde20] [0xc0000cd9c8 0xc0000cdd10] [0xba6c10 0xba6c10] 0xc002878a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:08:59.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:08:59.789: INFO: rc: 1
Feb 19 04:08:59.789: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b50660 exit status 1 <nil> <nil> true [0xc0000cdf18 0xc0000cdfa0 0xc0030f2008] [0xc0000cdf18 0xc0000cdfa0 0xc0030f2008] [0xc0000cdf80 0xc0030f2000] [0xba6c10 0xba6c10] 0xc0028794a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:09:09.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:09.871: INFO: rc: 1
Feb 19 04:09:09.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b509f0 exit status 1 <nil> <nil> true [0xc0030f2030 0xc0030f2060 0xc0030f2088] [0xc0030f2030 0xc0030f2060 0xc0030f2088] [0xc0030f2048 0xc0030f2070] [0xba6c10 0xba6c10] 0xc002879e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:09:19.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:19.966: INFO: rc: 1
Feb 19 04:09:19.966: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b50d20 exit status 1 <nil> <nil> true [0xc0030f20a0 0xc0030f20c0 0xc0030f2100] [0xc0030f20a0 0xc0030f20c0 0xc0030f2100] [0xc0030f20b0 0xc0030f20e8] [0xba6c10 0xba6c10] 0xc002566420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:09:29.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:30.044: INFO: rc: 1
Feb 19 04:09:30.044: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003026330 exit status 1 <nil> <nil> true [0xc0013d4078 0xc0013d4468 0xc0013d4900] [0xc0013d4078 0xc0013d4468 0xc0013d4900] [0xc0013d4390 0xc0013d4860] [0xba6c10 0xba6c10] 0xc002f1c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:09:40.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:40.353: INFO: rc: 1
Feb 19 04:09:40.353: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b51050 exit status 1 <nil> <nil> true [0xc0030f2108 0xc0030f2140 0xc0030f2188] [0xc0030f2108 0xc0030f2140 0xc0030f2188] [0xc0030f2130 0xc0030f2170] [0xba6c10 0xba6c10] 0xc002566780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:09:50.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:09:50.432: INFO: rc: 1
Feb 19 04:09:50.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0030266f0 exit status 1 <nil> <nil> true [0xc0013d4a40 0xc0013d4d20 0xc0013d4e30] [0xc0013d4a40 0xc0013d4d20 0xc0013d4e30] [0xc0013d4ce8 0xc0013d4d70] [0xba6c10 0xba6c10] 0xc002f1cc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:00.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:00.505: INFO: rc: 1
Feb 19 04:10:00.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab8360 exit status 1 <nil> <nil> true [0xc000188000 0xc0001886f0 0xc0001889b0] [0xc000188000 0xc0001886f0 0xc0001889b0] [0xc000188650 0xc0001888f0] [0xba6c10 0xba6c10] 0xc002abe300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:10.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:10.584: INFO: rc: 1
Feb 19 04:10:10.584: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab8690 exit status 1 <nil> <nil> true [0xc000188a80 0xc000188fd0 0xc000189508] [0xc000188a80 0xc000188fd0 0xc000189508] [0xc000188f90 0xc0001893b0] [0xba6c10 0xba6c10] 0xc002abe8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:20.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:20.660: INFO: rc: 1
Feb 19 04:10:20.660: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab89f0 exit status 1 <nil> <nil> true [0xc000189548 0xc000189788 0xc000189978] [0xc000189548 0xc000189788 0xc000189978] [0xc0001895f8 0xc0001897f0] [0xba6c10 0xba6c10] 0xc002abec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:30.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:30.742: INFO: rc: 1
Feb 19 04:10:30.742: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab8d20 exit status 1 <nil> <nil> true [0xc0001899e0 0xc000189c10 0xc000189c90] [0xc0001899e0 0xc000189c10 0xc000189c90] [0xc000189b10 0xc000189c88] [0xba6c10 0xba6c10] 0xc002abf080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:40.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:41.143: INFO: rc: 1
Feb 19 04:10:41.143: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bb03c0 exit status 1 <nil> <nil> true [0xc0003b00a0 0xc0003b0490 0xc0003b0510] [0xc0003b00a0 0xc0003b0490 0xc0003b0510] [0xc0003b0470 0xc0003b04c0] [0xba6c10 0xba6c10] 0xc002c442a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:10:51.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:10:51.217: INFO: rc: 1
Feb 19 04:10:51.217: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab8330 exit status 1 <nil> <nil> true [0xc0000cd5a8 0xc0000cd9c8 0xc0000cdd10] [0xc0000cd5a8 0xc0000cd9c8 0xc0000cdd10] [0xc0000cd8f0 0xc0000cdb88] [0xba6c10 0xba6c10] 0xc002878a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:01.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:01.505: INFO: rc: 1
Feb 19 04:11:01.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bb0300 exit status 1 <nil> <nil> true [0xc000188000 0xc0001886f0 0xc0001889b0] [0xc000188000 0xc0001886f0 0xc0001889b0] [0xc000188650 0xc0001888f0] [0xba6c10 0xba6c10] 0xc002abe300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:11.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:11.580: INFO: rc: 1
Feb 19 04:11:11.581: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b50330 exit status 1 <nil> <nil> true [0xc0013d4078 0xc0013d4468 0xc0013d4900] [0xc0013d4078 0xc0013d4468 0xc0013d4900] [0xc0013d4390 0xc0013d4860] [0xba6c10 0xba6c10] 0xc002f1c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:21.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:21.659: INFO: rc: 1
Feb 19 04:11:21.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bb06c0 exit status 1 <nil> <nil> true [0xc000188a80 0xc000188fd0 0xc000189508] [0xc000188a80 0xc000188fd0 0xc000189508] [0xc000188f90 0xc0001893b0] [0xba6c10 0xba6c10] 0xc002abe8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:31.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:32.803: INFO: rc: 1
Feb 19 04:11:32.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ab86c0 exit status 1 <nil> <nil> true [0xc0000cde20 0xc0000cdf80 0xc0003b0278] [0xc0000cde20 0xc0000cdf80 0xc0003b0278] [0xc0000cdf30 0xc0003b00a0] [0xba6c10 0xba6c10] 0xc0028794a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:42.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:42.875: INFO: rc: 1
Feb 19 04:11:42.876: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b506f0 exit status 1 <nil> <nil> true [0xc0013d4a40 0xc0013d4d20 0xc0013d4e30] [0xc0013d4a40 0xc0013d4d20 0xc0013d4e30] [0xc0013d4ce8 0xc0013d4d70] [0xba6c10 0xba6c10] 0xc002f1cc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:11:52.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:11:52.963: INFO: rc: 1
Feb 19 04:11:52.964: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002bb0a20 exit status 1 <nil> <nil> true [0xc000189548 0xc000189788 0xc000189978] [0xc000189548 0xc000189788 0xc000189978] [0xc0001895f8 0xc0001897f0] [0xba6c10 0xba6c10] 0xc002abec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 19 04:12:02.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-5015 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:12:03.039: INFO: rc: 1
Feb 19 04:12:03.039: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 19 04:12:03.039: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 19 04:12:03.071: INFO: Deleting all statefulset in ns statefulset-5015
Feb 19 04:12:03.083: INFO: Scaling statefulset ss to 0
Feb 19 04:12:03.101: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:12:03.107: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:12:03.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5015" for this suite.
Feb 19 04:12:09.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:09.777: INFO: namespace statefulset-5015 deletion completed in 6.636540252s

• [SLOW TEST:379.127 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:12:09.777: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 04:12:09.889: INFO: Number of nodes with available pods: 0
Feb 19 04:12:09.889: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:10.902: INFO: Number of nodes with available pods: 0
Feb 19 04:12:10.902: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:11.914: INFO: Number of nodes with available pods: 3
Feb 19 04:12:11.914: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 19 04:12:11.950: INFO: Number of nodes with available pods: 2
Feb 19 04:12:11.950: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:13.112: INFO: Number of nodes with available pods: 2
Feb 19 04:12:13.112: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:13.998: INFO: Number of nodes with available pods: 2
Feb 19 04:12:13.998: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:14.964: INFO: Number of nodes with available pods: 2
Feb 19 04:12:14.964: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:16.193: INFO: Number of nodes with available pods: 2
Feb 19 04:12:16.193: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:16.964: INFO: Number of nodes with available pods: 2
Feb 19 04:12:16.964: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:12:17.964: INFO: Number of nodes with available pods: 3
Feb 19 04:12:17.964: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1815, will wait for the garbage collector to delete the pods
Feb 19 04:12:18.037: INFO: Deleting DaemonSet.extensions daemon-set took: 13.163702ms
Feb 19 04:12:18.637: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.242037ms
Feb 19 04:12:21.244: INFO: Number of nodes with available pods: 0
Feb 19 04:12:21.244: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 04:12:21.249: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1815/daemonsets","resourceVersion":"11506"},"items":null}

Feb 19 04:12:21.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1815/pods","resourceVersion":"11506"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:12:21.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1815" for this suite.
Feb 19 04:12:27.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:27.742: INFO: namespace daemonsets-1815 deletion completed in 6.458614359s

• [SLOW TEST:17.966 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:12:27.743: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 19 04:12:29.840: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-152545945 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 19 04:12:35.574: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:12:35.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2418" for this suite.
Feb 19 04:12:41.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:41.800: INFO: namespace pods-2418 deletion completed in 6.214461789s

• [SLOW TEST:14.057 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:12:41.801: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:12:41.865: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393" in namespace "downward-api-6982" to be "success or failure"
Feb 19 04:12:41.873: INFO: Pod "downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393": Phase="Pending", Reason="", readiness=false. Elapsed: 7.713139ms
Feb 19 04:12:43.880: INFO: Pod "downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015048356s
STEP: Saw pod success
Feb 19 04:12:43.880: INFO: Pod "downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393" satisfied condition "success or failure"
Feb 19 04:12:43.888: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393 container client-container: <nil>
STEP: delete the pod
Feb 19 04:12:44.558: INFO: Waiting for pod downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393 to disappear
Feb 19 04:12:44.564: INFO: Pod downwardapi-volume-7d75a2e7-96f9-40f7-99b2-ac70bbd8f393 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:12:44.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6982" for this suite.
Feb 19 04:12:50.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:12:50.779: INFO: namespace downward-api-6982 deletion completed in 6.209745426s

• [SLOW TEST:8.978 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:12:50.779: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 19 04:12:50.830: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:12:53.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7031" for this suite.
Feb 19 04:13:00.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:13:00.465: INFO: namespace init-container-7031 deletion completed in 6.513659756s

• [SLOW TEST:9.686 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:13:00.466: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:13:00.530: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9" in namespace "downward-api-5575" to be "success or failure"
Feb 19 04:13:00.537: INFO: Pod "downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994844ms
Feb 19 04:13:02.546: INFO: Pod "downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015543924s
Feb 19 04:13:04.732: INFO: Pod "downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.202284556s
STEP: Saw pod success
Feb 19 04:13:04.732: INFO: Pod "downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9" satisfied condition "success or failure"
Feb 19 04:13:04.742: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9 container client-container: <nil>
STEP: delete the pod
Feb 19 04:13:04.775: INFO: Waiting for pod downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9 to disappear
Feb 19 04:13:04.781: INFO: Pod downwardapi-volume-fd69db10-5959-4018-82c0-b78d4e1f46c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:13:04.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5575" for this suite.
Feb 19 04:13:10.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:13:10.999: INFO: namespace downward-api-5575 deletion completed in 6.211954468s

• [SLOW TEST:10.534 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:13:11.000: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 04:13:17.739: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:17.747: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:13:19.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:19.753: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:13:21.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:21.753: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:13:23.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:23.831: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:13:25.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:25.774: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 04:13:27.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 04:13:27.977: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:13:27.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9941" for this suite.
Feb 19 04:13:52.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:13:52.674: INFO: namespace container-lifecycle-hook-9941 deletion completed in 24.668093497s

• [SLOW TEST:41.674 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:13:52.674: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:13:52.741: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:13:55.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8300" for this suite.
Feb 19 04:14:37.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:14:37.946: INFO: namespace pods-8300 deletion completed in 42.674686656s

• [SLOW TEST:45.272 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:14:37.947: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1675.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1675.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1675.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1675.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 11.253.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.253.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.253.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.253.11_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1675.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1675.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1675.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1675.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1675.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1675.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 11.253.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.253.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.253.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.253.11_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:14:52.139: INFO: Unable to read wheezy_udp@dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.350: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.430: INFO: Unable to read jessie_udp@dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.439: INFO: Unable to read jessie_tcp@dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.448: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.459: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local from pod dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28: the server could not find the requested resource (get pods dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28)
Feb 19 04:14:52.513: INFO: Lookups using dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28 failed for: [wheezy_udp@dns-test-service.dns-1675.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local jessie_udp@dns-test-service.dns-1675.svc.cluster.local jessie_tcp@dns-test-service.dns-1675.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1675.svc.cluster.local]

Feb 19 04:14:58.257: INFO: DNS probes using dns-1675/dns-test-f3ac4086-8e49-4a96-9a14-916ac5212a28 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:14:58.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1675" for this suite.
Feb 19 04:15:04.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:15:05.028: INFO: namespace dns-1675 deletion completed in 6.688205058s

• [SLOW TEST:27.081 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:15:05.029: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:16:05.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-271" for this suite.
Feb 19 04:16:21.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:16:21.543: INFO: namespace container-probe-271 deletion completed in 16.422358154s

• [SLOW TEST:76.514 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:16:21.543: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:16:21.712: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 04:16:21.741: INFO: Number of nodes with available pods: 0
Feb 19 04:16:21.741: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:16:22.941: INFO: Number of nodes with available pods: 0
Feb 19 04:16:22.941: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:16:23.754: INFO: Number of nodes with available pods: 2
Feb 19 04:16:23.754: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:16:24.755: INFO: Number of nodes with available pods: 3
Feb 19 04:16:24.755: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 19 04:16:24.799: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:24.799: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:24.799: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.028: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.028: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.028: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.813: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:26.813: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:27.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:27.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:27.813: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:27.813: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:28.816: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:28.816: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:28.816: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:28.816: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:29.817: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:29.817: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:29.817: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:29.817: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:30.814: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:30.814: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:30.814: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:30.814: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:31.853: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:31.853: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:31.853: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:31.853: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:32.815: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:32.815: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:32.815: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:32.815: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:34.034: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:34.034: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:34.034: INFO: Wrong image for pod: daemon-set-sgqxz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:34.034: INFO: Pod daemon-set-sgqxz is not available
Feb 19 04:16:34.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:34.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:34.813: INFO: Pod daemon-set-t55f4 is not available
Feb 19 04:16:35.814: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:35.814: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:35.814: INFO: Pod daemon-set-t55f4 is not available
Feb 19 04:16:37.024: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:37.025: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:37.025: INFO: Pod daemon-set-t55f4 is not available
Feb 19 04:16:37.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:37.812: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:38.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:38.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:38.813: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:39.983: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:39.983: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:39.983: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:40.861: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:40.862: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:40.862: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:41.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:41.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:41.813: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:43.005: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:43.005: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:43.005: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:43.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:43.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:43.813: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:44.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:44.813: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:44.813: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:46.000: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:46.000: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:46.000: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:46.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:46.812: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:46.812: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:47.815: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:47.815: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:47.815: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:48.942: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:48.942: INFO: Wrong image for pod: daemon-set-prdsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:48.942: INFO: Pod daemon-set-prdsh is not available
Feb 19 04:16:49.849: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:49.849: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:50.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:50.813: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:51.975: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:51.975: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:52.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:52.814: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:53.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:53.813: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:54.957: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:54.957: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:55.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:55.812: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:56.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:56.813: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:57.906: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:57.906: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:58.840: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:58.840: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:16:59.813: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:16:59.813: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:17:00.979: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:00.980: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:17:01.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:01.812: INFO: Pod daemon-set-ph4v6 is not available
Feb 19 04:17:02.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:03.916: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:03.917: INFO: Pod daemon-set-gkvpw is not available
Feb 19 04:17:04.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:04.812: INFO: Pod daemon-set-gkvpw is not available
Feb 19 04:17:05.812: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:05.813: INFO: Pod daemon-set-gkvpw is not available
Feb 19 04:17:06.870: INFO: Wrong image for pod: daemon-set-gkvpw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 19 04:17:06.870: INFO: Pod daemon-set-gkvpw is not available
Feb 19 04:17:07.845: INFO: Pod daemon-set-gtnvq is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 19 04:17:07.939: INFO: Number of nodes with available pods: 2
Feb 19 04:17:07.939: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:17:09.111: INFO: Number of nodes with available pods: 3
Feb 19 04:17:09.111: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7806, will wait for the garbage collector to delete the pods
Feb 19 04:17:09.206: INFO: Deleting DaemonSet.extensions daemon-set took: 12.154728ms
Feb 19 04:17:09.506: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.18445ms
Feb 19 04:17:19.913: INFO: Number of nodes with available pods: 0
Feb 19 04:17:19.913: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 04:17:19.918: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7806/daemonsets","resourceVersion":"12810"},"items":null}

Feb 19 04:17:19.923: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7806/pods","resourceVersion":"12810"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:17:19.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7806" for this suite.
Feb 19 04:17:25.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:17:26.387: INFO: namespace daemonsets-7806 deletion completed in 6.432322432s

• [SLOW TEST:64.843 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:17:26.387: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:17:26.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9570" for this suite.
Feb 19 04:17:48.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:17:48.989: INFO: namespace kubelet-test-9570 deletion completed in 22.317531316s

• [SLOW TEST:22.602 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:17:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Feb 19 04:17:51.764: INFO: Successfully updated pod "annotationupdatecc46e703-1e98-4d49-8d75-ddbb04c24ed1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:17:53.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3629" for this suite.
Feb 19 04:18:15.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:18:16.373: INFO: namespace projected-3629 deletion completed in 22.436267764s

• [SLOW TEST:27.384 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:18:16.373: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:18:16.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c" in namespace "projected-1797" to be "success or failure"
Feb 19 04:18:16.449: INFO: Pod "downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.586169ms
Feb 19 04:18:18.547: INFO: Pod "downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104720183s
Feb 19 04:18:20.554: INFO: Pod "downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111811777s
STEP: Saw pod success
Feb 19 04:18:20.554: INFO: Pod "downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c" satisfied condition "success or failure"
Feb 19 04:18:20.560: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c container client-container: <nil>
STEP: delete the pod
Feb 19 04:18:20.806: INFO: Waiting for pod downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c to disappear
Feb 19 04:18:20.813: INFO: Pod downwardapi-volume-f8fa7917-03cf-4b81-9cdb-82bff89b1e7c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:18:20.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1797" for this suite.
Feb 19 04:18:26.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:18:27.070: INFO: namespace projected-1797 deletion completed in 6.251898073s

• [SLOW TEST:10.697 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:18:27.071: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2802.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2802.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:18:41.569: INFO: DNS probes using dns-2802/dns-test-c3928a87-d637-418f-ad76-4bbf849ef9cc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:18:41.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2802" for this suite.
Feb 19 04:18:47.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:18:47.922: INFO: namespace dns-2802 deletion completed in 6.32589591s

• [SLOW TEST:20.851 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:18:47.923: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-qsvj
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 04:18:48.005: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qsvj" in namespace "subpath-5212" to be "success or failure"
Feb 19 04:18:48.012: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.333552ms
Feb 19 04:18:50.018: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 2.01271297s
Feb 19 04:18:52.222: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 4.217235391s
Feb 19 04:18:54.231: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 6.226100362s
Feb 19 04:18:56.422: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 8.416772516s
Feb 19 04:18:58.428: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 10.422978066s
Feb 19 04:19:00.436: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 12.430363298s
Feb 19 04:19:02.482: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 14.477305859s
Feb 19 04:19:04.655: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 16.649381315s
Feb 19 04:19:06.901: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 18.895962267s
Feb 19 04:19:09.245: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Running", Reason="", readiness=true. Elapsed: 21.239531413s
Feb 19 04:19:11.383: INFO: Pod "pod-subpath-test-configmap-qsvj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.378106726s
STEP: Saw pod success
Feb 19 04:19:11.383: INFO: Pod "pod-subpath-test-configmap-qsvj" satisfied condition "success or failure"
Feb 19 04:19:11.426: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-qsvj container test-container-subpath-configmap-qsvj: <nil>
STEP: delete the pod
Feb 19 04:19:11.477: INFO: Waiting for pod pod-subpath-test-configmap-qsvj to disappear
Feb 19 04:19:11.486: INFO: Pod pod-subpath-test-configmap-qsvj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qsvj
Feb 19 04:19:11.486: INFO: Deleting pod "pod-subpath-test-configmap-qsvj" in namespace "subpath-5212"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:19:11.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5212" for this suite.
Feb 19 04:19:17.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:17.715: INFO: namespace subpath-5212 deletion completed in 6.217461972s

• [SLOW TEST:29.792 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:19:17.715: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:19:17.787: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6" in namespace "projected-4879" to be "success or failure"
Feb 19 04:19:17.793: INFO: Pod "downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.67145ms
Feb 19 04:19:19.800: INFO: Pod "downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013659845s
Feb 19 04:19:21.807: INFO: Pod "downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020439255s
STEP: Saw pod success
Feb 19 04:19:21.807: INFO: Pod "downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6" satisfied condition "success or failure"
Feb 19 04:19:21.812: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6 container client-container: <nil>
STEP: delete the pod
Feb 19 04:19:21.860: INFO: Waiting for pod downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6 to disappear
Feb 19 04:19:21.866: INFO: Pod downwardapi-volume-5667c3ac-1f50-4a0e-b0a8-35a721fd71e6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:19:21.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4879" for this suite.
Feb 19 04:19:28.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:28.430: INFO: namespace projected-4879 deletion completed in 6.557579805s

• [SLOW TEST:10.715 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:19:28.431: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 19 04:19:30.526: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:19:30.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6365" for this suite.
Feb 19 04:19:36.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:36.794: INFO: namespace container-runtime-6365 deletion completed in 6.235927151s

• [SLOW TEST:8.364 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:19:36.796: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Feb 19 04:19:37.229: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-152545945 proxy --unix-socket=/tmp/kubectl-proxy-unix129500964/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:19:37.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-877" for this suite.
Feb 19 04:19:43.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:43.510: INFO: namespace kubectl-877 deletion completed in 6.221740722s

• [SLOW TEST:6.714 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:19:43.510: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-da26ab7f-d5d4-4851-95b8-88f484b3d24e
STEP: Creating a pod to test consume configMaps
Feb 19 04:19:44.019: INFO: Waiting up to 5m0s for pod "pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4" in namespace "configmap-2783" to be "success or failure"
Feb 19 04:19:44.026: INFO: Pod "pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.021718ms
Feb 19 04:19:46.227: INFO: Pod "pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.207758539s
Feb 19 04:19:48.460: INFO: Pod "pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.440472085s
STEP: Saw pod success
Feb 19 04:19:48.460: INFO: Pod "pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4" satisfied condition "success or failure"
Feb 19 04:19:48.466: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:19:48.502: INFO: Waiting for pod pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4 to disappear
Feb 19 04:19:48.508: INFO: Pod pod-configmaps-20ad0465-7967-45a2-bc53-7342a81fe4e4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:19:48.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2783" for this suite.
Feb 19 04:19:54.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:19:54.929: INFO: namespace configmap-2783 deletion completed in 6.414508516s

• [SLOW TEST:11.419 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:19:54.930: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:19:55.196: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 19 04:20:00.203: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 04:20:00.203: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 19 04:20:02.211: INFO: Creating deployment "test-rollover-deployment"
Feb 19 04:20:02.228: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 19 04:20:04.239: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 19 04:20:04.260: INFO: Ensure that both replica sets have 1 created replica
Feb 19 04:20:04.272: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 19 04:20:04.285: INFO: Updating deployment test-rollover-deployment
Feb 19 04:20:04.285: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 19 04:20:06.379: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 19 04:20:06.390: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 19 04:20:06.400: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:06.400: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682805, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:08.635: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:08.635: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682805, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:10.612: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:10.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682805, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:12.413: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:12.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682805, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:14.416: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 04:20:14.416: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682805, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717682802, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:20:16.626: INFO: 
Feb 19 04:20:16.626: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 19 04:20:16.648: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7387,SelfLink:/apis/apps/v1/namespaces/deployment-7387/deployments/test-rollover-deployment,UID:cc2b3afd-2804-468b-b3bb-ebdfa26834e1,ResourceVersion:13681,Generation:2,CreationTimestamp:2020-02-19 04:20:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-19 04:20:02 +0000 UTC 2020-02-19 04:20:02 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-19 04:20:15 +0000 UTC 2020-02-19 04:20:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 04:20:16.657: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-7387,SelfLink:/apis/apps/v1/namespaces/deployment-7387/replicasets/test-rollover-deployment-854595fc44,UID:41550028-10a8-41ee-ba35-d5a8ae119a45,ResourceVersion:13670,Generation:2,CreationTimestamp:2020-02-19 04:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc2b3afd-2804-468b-b3bb-ebdfa26834e1 0xc002d335f7 0xc002d335f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 04:20:16.657: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 19 04:20:16.657: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7387,SelfLink:/apis/apps/v1/namespaces/deployment-7387/replicasets/test-rollover-controller,UID:e744f181-96bd-48ab-beb5-ed92df6d1fcb,ResourceVersion:13680,Generation:2,CreationTimestamp:2020-02-19 04:19:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc2b3afd-2804-468b-b3bb-ebdfa26834e1 0xc002d33527 0xc002d33528}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:20:16.657: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-7387,SelfLink:/apis/apps/v1/namespaces/deployment-7387/replicasets/test-rollover-deployment-9b8b997cf,UID:359cf3f5-1bf2-48df-a238-349506fba828,ResourceVersion:13618,Generation:2,CreationTimestamp:2020-02-19 04:20:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment cc2b3afd-2804-468b-b3bb-ebdfa26834e1 0xc002d336c0 0xc002d336c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:20:16.664: INFO: Pod "test-rollover-deployment-854595fc44-jn7tf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-jn7tf,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-7387,SelfLink:/api/v1/namespaces/deployment-7387/pods/test-rollover-deployment-854595fc44-jn7tf,UID:709a9d55-36f0-4c16-ac70-1a701fc86f6f,ResourceVersion:13634,Generation:0,CreationTimestamp:2020-02-19 04:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 41550028-10a8-41ee-ba35-d5a8ae119a45 0xc002942737 0xc002942738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4xjbg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4xjbg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4xjbg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029428f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002942910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.70,StartTime:2020-02-19 04:20:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-19 04:20:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5619e0310399cf40f52e71e1e6aefa9cd94e3221a18a1910185585b2ca2ca7f0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:20:16.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7387" for this suite.
Feb 19 04:20:22.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:20:22.883: INFO: namespace deployment-7387 deletion completed in 6.213484383s

• [SLOW TEST:27.953 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:20:22.883: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-473
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-473
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-473
Feb 19 04:20:23.275: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 04:20:33.326: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 19 04:20:33.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:20:33.779: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:20:33.779: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:20:33.779: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:20:33.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 04:20:43.794: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:20:43.794: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:20:43.823: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:20:43.823: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:20:43.823: INFO: ss-1             Pending         []
Feb 19 04:20:43.823: INFO: 
Feb 19 04:20:43.823: INFO: StatefulSet ss has not reached scale 3, at 2
Feb 19 04:20:44.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991447905s
Feb 19 04:20:45.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984745073s
Feb 19 04:20:46.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977766922s
Feb 19 04:20:47.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.968296005s
Feb 19 04:20:49.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.898431816s
Feb 19 04:20:50.171: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.667458017s
Feb 19 04:20:51.258: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.643565309s
Feb 19 04:20:52.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.556658394s
Feb 19 04:20:53.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 315.385008ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-473
Feb 19 04:20:54.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:20:55.033: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:20:55.033: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:20:55.033: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:20:55.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:20:55.888: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 19 04:20:55.888: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:20:55.888: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:20:55.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:20:56.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 19 04:20:56.399: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:20:56.399: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:20:56.406: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:20:56.406: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:20:56.406: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 19 04:20:56.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:20:56.716: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:20:56.716: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:20:56.716: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:20:56.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:20:58.200: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:20:58.200: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:20:58.200: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:20:58.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-473 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:20:58.508: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:20:58.508: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:20:58.508: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:20:58.508: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:20:58.513: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 19 04:21:08.861: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:21:08.861: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:21:08.861: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 04:21:08.891: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:08.891: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:08.891: INFO: ss-1  10.0.10.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:08.891: INFO: ss-2  10.0.10.4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:08.891: INFO: 
Feb 19 04:21:08.891: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 04:21:09.900: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:09.900: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:09.900: INFO: ss-1  10.0.10.3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:09.900: INFO: ss-2  10.0.10.4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:09.900: INFO: 
Feb 19 04:21:09.900: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 04:21:11.086: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:11.086: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:11.086: INFO: ss-2  10.0.10.4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:11.087: INFO: 
Feb 19 04:21:11.087: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 04:21:12.093: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:12.093: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:12.094: INFO: ss-2  10.0.10.4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:12.094: INFO: 
Feb 19 04:21:12.094: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 04:21:13.353: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:13.353: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:13.353: INFO: ss-2  10.0.10.4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:43 +0000 UTC  }]
Feb 19 04:21:13.353: INFO: 
Feb 19 04:21:13.353: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 04:21:14.360: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:14.360: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:14.360: INFO: 
Feb 19 04:21:14.360: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 04:21:15.596: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Feb 19 04:21:15.596: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:20:23 +0000 UTC  }]
Feb 19 04:21:15.596: INFO: 
Feb 19 04:21:15.596: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 04:21:16.602: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.285665686s
Feb 19 04:21:17.821: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.278954137s
Feb 19 04:21:18.828: INFO: Verifying statefulset ss doesn't scale past 0 for another 60.17051ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-473
Feb 19 04:21:20.089: INFO: Scaling statefulset ss to 0
Feb 19 04:21:20.355: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 19 04:21:20.363: INFO: Deleting all statefulset in ns statefulset-473
Feb 19 04:21:20.370: INFO: Scaling statefulset ss to 0
Feb 19 04:21:20.387: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:21:20.391: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:21:20.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-473" for this suite.
Feb 19 04:21:26.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:21:27.238: INFO: namespace statefulset-473 deletion completed in 6.816807454s

• [SLOW TEST:64.354 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:21:27.238: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 19 04:21:27.309: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14099,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 04:21:27.309: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14099,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 19 04:21:37.324: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14130,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 04:21:37.324: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14130,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 19 04:21:47.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14161,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 04:21:47.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14161,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 19 04:21:57.353: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14189,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 04:21:57.353: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-a,UID:28932f03-cff8-4d60-bea4-1e4114b19f28,ResourceVersion:14189,Generation:0,CreationTimestamp:2020-02-19 04:21:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 19 04:22:07.416: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-b,UID:05fefa1d-e126-4b41-876a-452f0cd581af,ResourceVersion:14221,Generation:0,CreationTimestamp:2020-02-19 04:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 04:22:07.416: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-b,UID:05fefa1d-e126-4b41-876a-452f0cd581af,ResourceVersion:14221,Generation:0,CreationTimestamp:2020-02-19 04:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 19 04:22:17.434: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-b,UID:05fefa1d-e126-4b41-876a-452f0cd581af,ResourceVersion:14253,Generation:0,CreationTimestamp:2020-02-19 04:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 04:22:17.434: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2348,SelfLink:/api/v1/namespaces/watch-2348/configmaps/e2e-watch-test-configmap-b,UID:05fefa1d-e126-4b41-876a-452f0cd581af,ResourceVersion:14253,Generation:0,CreationTimestamp:2020-02-19 04:22:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:22:27.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2348" for this suite.
Feb 19 04:22:33.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:22:34.382: INFO: namespace watch-2348 deletion completed in 6.824166959s

• [SLOW TEST:67.144 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:22:34.382: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Feb 19 04:22:34.453: INFO: Waiting up to 5m0s for pod "var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e" in namespace "var-expansion-3981" to be "success or failure"
Feb 19 04:22:34.461: INFO: Pod "var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.86746ms
Feb 19 04:22:36.521: INFO: Pod "var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06859977s
Feb 19 04:22:38.757: INFO: Pod "var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.304097583s
STEP: Saw pod success
Feb 19 04:22:38.757: INFO: Pod "var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e" satisfied condition "success or failure"
Feb 19 04:22:38.766: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:22:38.802: INFO: Waiting for pod var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e to disappear
Feb 19 04:22:38.809: INFO: Pod var-expansion-5ffaf15e-7c8f-4008-819b-0a9c7d944f9e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:22:38.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3981" for this suite.
Feb 19 04:22:44.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:22:45.630: INFO: namespace var-expansion-3981 deletion completed in 6.815185122s

• [SLOW TEST:11.248 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:22:45.631: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 19 04:22:45.689: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:22:56.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3879" for this suite.
Feb 19 04:23:02.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:03.479: INFO: namespace pods-3879 deletion completed in 6.771225221s

• [SLOW TEST:17.848 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:23:03.480: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Feb 19 04:23:04.618: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0219 04:23:04.618742      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:23:04.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6246" for this suite.
Feb 19 04:23:10.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:10.848: INFO: namespace gc-6246 deletion completed in 6.224511576s

• [SLOW TEST:7.369 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:23:10.849: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-d7cbbc09-dd6c-40c0-a3fe-f1f70250211b
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:23:10.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2461" for this suite.
Feb 19 04:23:16.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:17.130: INFO: namespace configmap-2461 deletion completed in 6.222464838s

• [SLOW TEST:6.281 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:23:17.131: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-767c7b0d-2219-46b6-a30d-59195fef2370
STEP: Creating a pod to test consume configMaps
Feb 19 04:23:17.208: INFO: Waiting up to 5m0s for pod "pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f" in namespace "configmap-5440" to be "success or failure"
Feb 19 04:23:17.215: INFO: Pod "pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.272969ms
Feb 19 04:23:19.221: INFO: Pod "pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012992614s
STEP: Saw pod success
Feb 19 04:23:19.221: INFO: Pod "pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f" satisfied condition "success or failure"
Feb 19 04:23:19.226: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:23:19.267: INFO: Waiting for pod pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f to disappear
Feb 19 04:23:19.275: INFO: Pod pod-configmaps-2da908a3-bcd8-4470-8805-678b4d2fae0f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:23:19.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5440" for this suite.
Feb 19 04:23:25.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:23:25.982: INFO: namespace configmap-5440 deletion completed in 6.701182465s

• [SLOW TEST:8.851 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:23:25.982: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb 19 04:24:06.120: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0219 04:24:06.120662      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:24:06.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2024" for this suite.
Feb 19 04:24:14.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:14.337: INFO: namespace gc-2024 deletion completed in 8.209606245s

• [SLOW TEST:48.355 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:24:14.338: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-e3def568-77b1-46a6-bf51-4926d7d6504d
STEP: Creating a pod to test consume secrets
Feb 19 04:24:14.482: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57" in namespace "projected-4207" to be "success or failure"
Feb 19 04:24:14.489: INFO: Pod "pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.777278ms
Feb 19 04:24:16.496: INFO: Pod "pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013335755s
Feb 19 04:24:18.502: INFO: Pod "pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020223418s
STEP: Saw pod success
Feb 19 04:24:18.503: INFO: Pod "pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57" satisfied condition "success or failure"
Feb 19 04:24:18.508: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:24:18.543: INFO: Waiting for pod pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57 to disappear
Feb 19 04:24:18.549: INFO: Pod pod-projected-secrets-95e860ad-38bf-4ca0-9cbb-a13286100f57 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:24:18.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4207" for this suite.
Feb 19 04:24:24.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:24.771: INFO: namespace projected-4207 deletion completed in 6.211434064s

• [SLOW TEST:10.433 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:24:24.771: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8057.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8057.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8057.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8057.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8057.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8057.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:24:29.056: INFO: DNS probes using dns-8057/dns-test-7b46c24a-6ea8-4180-9f7c-92e76e7a6934 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:24:29.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8057" for this suite.
Feb 19 04:24:35.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:35.436: INFO: namespace dns-8057 deletion completed in 6.353381914s

• [SLOW TEST:10.664 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:24:35.436: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:24:35.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66" in namespace "downward-api-5193" to be "success or failure"
Feb 19 04:24:35.513: INFO: Pod "downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66": Phase="Pending", Reason="", readiness=false. Elapsed: 6.556945ms
Feb 19 04:24:37.520: INFO: Pod "downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01351418s
Feb 19 04:24:39.718: INFO: Pod "downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211623906s
STEP: Saw pod success
Feb 19 04:24:39.718: INFO: Pod "downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66" satisfied condition "success or failure"
Feb 19 04:24:39.724: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66 container client-container: <nil>
STEP: delete the pod
Feb 19 04:24:40.063: INFO: Waiting for pod downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66 to disappear
Feb 19 04:24:40.069: INFO: Pod downwardapi-volume-3ad61791-1f82-406f-a328-1bfb5669cb66 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:24:40.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5193" for this suite.
Feb 19 04:24:46.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:46.652: INFO: namespace downward-api-5193 deletion completed in 6.575591706s

• [SLOW TEST:11.216 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:24:46.652: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 19 04:24:49.248: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8079 pod-service-account-ebcdd238-8977-45d2-9dbb-bac1407f4496 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 19 04:24:49.602: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8079 pod-service-account-ebcdd238-8977-45d2-9dbb-bac1407f4496 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 19 04:24:49.869: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8079 pod-service-account-ebcdd238-8977-45d2-9dbb-bac1407f4496 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:24:50.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8079" for this suite.
Feb 19 04:24:56.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:24:56.597: INFO: namespace svcaccounts-8079 deletion completed in 6.208483183s

• [SLOW TEST:9.945 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:24:56.598: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:24:56.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5" in namespace "downward-api-1980" to be "success or failure"
Feb 19 04:24:56.678: INFO: Pod "downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.427264ms
Feb 19 04:24:58.684: INFO: Pod "downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014110624s
Feb 19 04:25:00.691: INFO: Pod "downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020769816s
STEP: Saw pod success
Feb 19 04:25:00.691: INFO: Pod "downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5" satisfied condition "success or failure"
Feb 19 04:25:00.697: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5 container client-container: <nil>
STEP: delete the pod
Feb 19 04:25:00.730: INFO: Waiting for pod downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5 to disappear
Feb 19 04:25:00.736: INFO: Pod downwardapi-volume-349d3f4c-aac7-48c3-9d36-bf3d03f062a5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:25:00.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1980" for this suite.
Feb 19 04:25:06.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:06.956: INFO: namespace downward-api-1980 deletion completed in 6.211989304s

• [SLOW TEST:10.358 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:25:06.956: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-4bba9182-6f35-47f8-94ce-d25144860592 in namespace container-probe-6377
Feb 19 04:25:09.037: INFO: Started pod liveness-4bba9182-6f35-47f8-94ce-d25144860592 in namespace container-probe-6377
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 04:25:09.043: INFO: Initial restart count of pod liveness-4bba9182-6f35-47f8-94ce-d25144860592 is 0
Feb 19 04:25:26.878: INFO: Restart count of pod container-probe-6377/liveness-4bba9182-6f35-47f8-94ce-d25144860592 is now 1 (17.835376131s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:25:26.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6377" for this suite.
Feb 19 04:25:32.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:33.756: INFO: namespace container-probe-6377 deletion completed in 6.849213564s

• [SLOW TEST:26.800 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:25:33.757: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Feb 19 04:25:34.357: INFO: created pod pod-service-account-defaultsa
Feb 19 04:25:34.357: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 19 04:25:34.364: INFO: created pod pod-service-account-mountsa
Feb 19 04:25:34.364: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 19 04:25:34.370: INFO: created pod pod-service-account-nomountsa
Feb 19 04:25:34.370: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 19 04:25:34.376: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 19 04:25:34.376: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 19 04:25:34.382: INFO: created pod pod-service-account-mountsa-mountspec
Feb 19 04:25:34.382: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 19 04:25:34.389: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 19 04:25:34.389: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 19 04:25:34.395: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 19 04:25:34.395: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 19 04:25:34.401: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 19 04:25:34.401: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 19 04:25:34.407: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 19 04:25:34.407: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:25:34.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9056" for this suite.
Feb 19 04:25:58.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:25:58.626: INFO: namespace svcaccounts-9056 deletion completed in 24.212860344s

• [SLOW TEST:24.870 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:25:58.627: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 04:25:58.696: INFO: Waiting up to 5m0s for pod "pod-11f4fb3f-084a-457e-bd18-745e15657a67" in namespace "emptydir-7833" to be "success or failure"
Feb 19 04:25:58.703: INFO: Pod "pod-11f4fb3f-084a-457e-bd18-745e15657a67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.483703ms
Feb 19 04:26:00.709: INFO: Pod "pod-11f4fb3f-084a-457e-bd18-745e15657a67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01309304s
Feb 19 04:26:02.797: INFO: Pod "pod-11f4fb3f-084a-457e-bd18-745e15657a67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100478977s
STEP: Saw pod success
Feb 19 04:26:02.797: INFO: Pod "pod-11f4fb3f-084a-457e-bd18-745e15657a67" satisfied condition "success or failure"
Feb 19 04:26:02.803: INFO: Trying to get logs from node 10.0.10.2 pod pod-11f4fb3f-084a-457e-bd18-745e15657a67 container test-container: <nil>
STEP: delete the pod
Feb 19 04:26:02.980: INFO: Waiting for pod pod-11f4fb3f-084a-457e-bd18-745e15657a67 to disappear
Feb 19 04:26:02.987: INFO: Pod pod-11f4fb3f-084a-457e-bd18-745e15657a67 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:26:02.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7833" for this suite.
Feb 19 04:26:09.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:26:09.709: INFO: namespace emptydir-7833 deletion completed in 6.716322847s

• [SLOW TEST:11.083 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:26:09.710: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:26:33.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8177" for this suite.
Feb 19 04:26:39.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:26:39.268: INFO: namespace container-runtime-8177 deletion completed in 6.21965321s

• [SLOW TEST:29.558 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:26:39.268: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3405
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 19 04:26:39.352: INFO: Found 0 stateful pods, waiting for 3
Feb 19 04:26:49.623: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:26:49.623: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:26:49.623: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:26:49.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-3405 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:26:50.217: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:26:50.217: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:26:50.217: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 04:27:00.267: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 19 04:27:10.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-3405 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:27:10.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:27:10.794: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:27:10.794: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:27:21.269: INFO: Waiting for StatefulSet statefulset-3405/ss2 to complete update
Feb 19 04:27:21.269: INFO: Waiting for Pod statefulset-3405/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:27:21.269: INFO: Waiting for Pod statefulset-3405/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:27:21.269: INFO: Waiting for Pod statefulset-3405/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:27:31.282: INFO: Waiting for StatefulSet statefulset-3405/ss2 to complete update
Feb 19 04:27:31.282: INFO: Waiting for Pod statefulset-3405/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:27:31.282: INFO: Waiting for Pod statefulset-3405/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:27:41.415: INFO: Waiting for StatefulSet statefulset-3405/ss2 to complete update
Feb 19 04:27:41.415: INFO: Waiting for Pod statefulset-3405/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Feb 19 04:27:51.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-3405 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 04:27:51.890: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 19 04:27:51.890: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 04:27:51.890: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 04:28:01.939: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 19 04:28:11.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec --namespace=statefulset-3405 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 04:28:12.747: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 19 04:28:12.747: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 04:28:12.748: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 04:28:33.007: INFO: Waiting for StatefulSet statefulset-3405/ss2 to complete update
Feb 19 04:28:33.007: INFO: Waiting for Pod statefulset-3405/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 19 04:28:43.020: INFO: Deleting all statefulset in ns statefulset-3405
Feb 19 04:28:43.026: INFO: Scaling statefulset ss2 to 0
Feb 19 04:29:13.092: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:29:13.137: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:29:13.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3405" for this suite.
Feb 19 04:29:21.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:29:21.605: INFO: namespace statefulset-3405 deletion completed in 8.205418336s

• [SLOW TEST:162.337 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:29:21.605: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 19 04:29:21.679: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 19 04:29:26.890: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:29:27.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7311" for this suite.
Feb 19 04:29:33.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:29:34.137: INFO: namespace replication-controller-7311 deletion completed in 6.212174925s

• [SLOW TEST:12.531 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:29:34.137: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:29:34.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-996'
Feb 19 04:29:34.271: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 19 04:29:34.271: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Feb 19 04:29:36.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete deployment e2e-test-nginx-deployment --namespace=kubectl-996'
Feb 19 04:29:36.370: INFO: stderr: ""
Feb 19 04:29:36.370: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:29:36.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-996" for this suite.
Feb 19 04:29:58.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:29:58.853: INFO: namespace kubectl-996 deletion completed in 22.475895375s

• [SLOW TEST:24.716 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:29:58.854: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 04:29:58.966: INFO: Number of nodes with available pods: 0
Feb 19 04:29:58.966: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:30:00.196: INFO: Number of nodes with available pods: 0
Feb 19 04:30:00.196: INFO: Node 10.0.10.2 is running more than one daemon pod
Feb 19 04:30:00.981: INFO: Number of nodes with available pods: 3
Feb 19 04:30:00.981: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 19 04:30:01.018: INFO: Number of nodes with available pods: 2
Feb 19 04:30:01.018: INFO: Node 10.0.10.3 is running more than one daemon pod
Feb 19 04:30:02.031: INFO: Number of nodes with available pods: 2
Feb 19 04:30:02.031: INFO: Node 10.0.10.3 is running more than one daemon pod
Feb 19 04:30:03.182: INFO: Number of nodes with available pods: 3
Feb 19 04:30:03.182: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3405, will wait for the garbage collector to delete the pods
Feb 19 04:30:03.264: INFO: Deleting DaemonSet.extensions daemon-set took: 13.063861ms
Feb 19 04:30:03.564: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.253501ms
Feb 19 04:30:16.671: INFO: Number of nodes with available pods: 0
Feb 19 04:30:16.671: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 04:30:16.676: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3405/daemonsets","resourceVersion":"16851"},"items":null}

Feb 19 04:30:16.681: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3405/pods","resourceVersion":"16851"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:30:16.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3405" for this suite.
Feb 19 04:30:22.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:30:23.040: INFO: namespace daemonsets-3405 deletion completed in 6.334171361s

• [SLOW TEST:24.187 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:30:23.041: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb 19 04:30:53.388: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0219 04:30:53.388822      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:30:53.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-692" for this suite.
Feb 19 04:30:59.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:30:59.612: INFO: namespace gc-692 deletion completed in 6.217621835s

• [SLOW TEST:36.572 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:30:59.613: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Feb 19 04:30:59.880: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-152545945 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:30:59.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5057" for this suite.
Feb 19 04:31:05.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:31:06.188: INFO: namespace kubectl-5057 deletion completed in 6.232942276s

• [SLOW TEST:6.575 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:31:06.189: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1408
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1408
STEP: Creating statefulset with conflicting port in namespace statefulset-1408
STEP: Waiting until pod test-pod will start running in namespace statefulset-1408
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1408
Feb 19 04:31:10.430: INFO: Observed stateful pod in namespace: statefulset-1408, name: ss-0, uid: 850af898-95d0-4093-8949-bcb08fe06fd9, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 04:31:10.434: INFO: Observed stateful pod in namespace: statefulset-1408, name: ss-0, uid: 850af898-95d0-4093-8949-bcb08fe06fd9, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 04:31:10.438: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1408
STEP: Removing pod with conflicting port in namespace statefulset-1408
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1408 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 19 04:31:14.677: INFO: Deleting all statefulset in ns statefulset-1408
Feb 19 04:31:14.684: INFO: Scaling statefulset ss to 0
Feb 19 04:31:24.930: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:31:24.936: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:31:25.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1408" for this suite.
Feb 19 04:31:31.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:31:31.548: INFO: namespace statefulset-1408 deletion completed in 6.341080884s

• [SLOW TEST:25.359 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:31:31.549: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 19 04:31:31.609: INFO: namespace kubectl-9122
Feb 19 04:31:31.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-9122'
Feb 19 04:31:31.986: INFO: stderr: ""
Feb 19 04:31:31.986: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:31:32.995: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:31:32.995: INFO: Found 1 / 1
Feb 19 04:31:32.995: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:31:33.001: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:31:33.001: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:31:33.001: INFO: wait on redis-master startup in kubectl-9122 
Feb 19 04:31:33.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-h2rqr redis-master --namespace=kubectl-9122'
Feb 19 04:31:33.205: INFO: stderr: ""
Feb 19 04:31:33.205: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:31:32.850 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:31:32.850 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:31:32.850 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:31:32.850 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 19 04:31:33.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9122'
Feb 19 04:31:33.310: INFO: stderr: ""
Feb 19 04:31:33.310: INFO: stdout: "service/rm2 exposed\n"
Feb 19 04:31:33.319: INFO: Service rm2 in namespace kubectl-9122 found.
STEP: exposing service
Feb 19 04:31:35.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9122'
Feb 19 04:31:35.431: INFO: stderr: ""
Feb 19 04:31:35.431: INFO: stdout: "service/rm3 exposed\n"
Feb 19 04:31:35.438: INFO: Service rm3 in namespace kubectl-9122 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:31:37.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9122" for this suite.
Feb 19 04:32:01.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:32:02.158: INFO: namespace kubectl-9122 deletion completed in 24.70016698s

• [SLOW TEST:30.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:32:02.159: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:32:02.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8857'
Feb 19 04:32:02.313: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 19 04:32:02.313: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Feb 19 04:32:04.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8857'
Feb 19 04:32:04.409: INFO: stderr: ""
Feb 19 04:32:04.409: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:32:04.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8857" for this suite.
Feb 19 04:32:10.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:32:11.007: INFO: namespace kubectl-8857 deletion completed in 6.591125223s

• [SLOW TEST:8.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:32:11.008: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Feb 19 04:32:11.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4639'
Feb 19 04:32:11.231: INFO: stderr: ""
Feb 19 04:32:11.231: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 04:32:11.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:11.311: INFO: stderr: ""
Feb 19 04:32:11.311: INFO: stdout: "update-demo-nautilus-mfcrb update-demo-nautilus-v2nrd "
Feb 19 04:32:11.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:11.604: INFO: stderr: ""
Feb 19 04:32:11.604: INFO: stdout: ""
Feb 19 04:32:11.604: INFO: update-demo-nautilus-mfcrb is created but not running
Feb 19 04:32:16.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:16.754: INFO: stderr: ""
Feb 19 04:32:16.754: INFO: stdout: "update-demo-nautilus-mfcrb update-demo-nautilus-v2nrd "
Feb 19 04:32:16.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:16.824: INFO: stderr: ""
Feb 19 04:32:16.824: INFO: stdout: "true"
Feb 19 04:32:16.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:16.897: INFO: stderr: ""
Feb 19 04:32:16.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:16.897: INFO: validating pod update-demo-nautilus-mfcrb
Feb 19 04:32:17.246: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:17.246: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:17.246: INFO: update-demo-nautilus-mfcrb is verified up and running
Feb 19 04:32:17.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v2nrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:17.333: INFO: stderr: ""
Feb 19 04:32:17.333: INFO: stdout: ""
Feb 19 04:32:17.333: INFO: update-demo-nautilus-v2nrd is created but not running
Feb 19 04:32:22.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:22.411: INFO: stderr: ""
Feb 19 04:32:22.411: INFO: stdout: "update-demo-nautilus-mfcrb update-demo-nautilus-v2nrd "
Feb 19 04:32:22.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:22.492: INFO: stderr: ""
Feb 19 04:32:22.492: INFO: stdout: "true"
Feb 19 04:32:22.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:22.790: INFO: stderr: ""
Feb 19 04:32:22.790: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:22.790: INFO: validating pod update-demo-nautilus-mfcrb
Feb 19 04:32:22.802: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:22.803: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:22.803: INFO: update-demo-nautilus-mfcrb is verified up and running
Feb 19 04:32:22.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v2nrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:22.875: INFO: stderr: ""
Feb 19 04:32:22.875: INFO: stdout: "true"
Feb 19 04:32:22.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-v2nrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:22.952: INFO: stderr: ""
Feb 19 04:32:22.952: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:22.952: INFO: validating pod update-demo-nautilus-v2nrd
Feb 19 04:32:23.020: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:23.020: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:23.020: INFO: update-demo-nautilus-v2nrd is verified up and running
STEP: scaling down the replication controller
Feb 19 04:32:23.022: INFO: scanned /root for discovery docs: <nil>
Feb 19 04:32:23.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4639'
Feb 19 04:32:24.131: INFO: stderr: ""
Feb 19 04:32:24.131: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 04:32:24.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:25.213: INFO: stderr: ""
Feb 19 04:32:25.213: INFO: stdout: "update-demo-nautilus-mfcrb update-demo-nautilus-v2nrd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 19 04:32:30.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:30.288: INFO: stderr: ""
Feb 19 04:32:30.288: INFO: stdout: "update-demo-nautilus-mfcrb "
Feb 19 04:32:30.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:30.359: INFO: stderr: ""
Feb 19 04:32:30.359: INFO: stdout: "true"
Feb 19 04:32:30.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:30.429: INFO: stderr: ""
Feb 19 04:32:30.429: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:30.429: INFO: validating pod update-demo-nautilus-mfcrb
Feb 19 04:32:30.709: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:30.709: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:30.709: INFO: update-demo-nautilus-mfcrb is verified up and running
STEP: scaling up the replication controller
Feb 19 04:32:30.711: INFO: scanned /root for discovery docs: <nil>
Feb 19 04:32:30.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4639'
Feb 19 04:32:31.852: INFO: stderr: ""
Feb 19 04:32:31.852: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 04:32:31.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:31.926: INFO: stderr: ""
Feb 19 04:32:31.926: INFO: stdout: "update-demo-nautilus-2szcx update-demo-nautilus-mfcrb "
Feb 19 04:32:31.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-2szcx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:32.229: INFO: stderr: ""
Feb 19 04:32:32.229: INFO: stdout: ""
Feb 19 04:32:32.229: INFO: update-demo-nautilus-2szcx is created but not running
Feb 19 04:32:37.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4639'
Feb 19 04:32:37.304: INFO: stderr: ""
Feb 19 04:32:37.304: INFO: stdout: "update-demo-nautilus-2szcx update-demo-nautilus-mfcrb "
Feb 19 04:32:37.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-2szcx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:37.379: INFO: stderr: ""
Feb 19 04:32:37.379: INFO: stdout: "true"
Feb 19 04:32:37.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-2szcx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:37.452: INFO: stderr: ""
Feb 19 04:32:37.452: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:37.452: INFO: validating pod update-demo-nautilus-2szcx
Feb 19 04:32:37.528: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:37.528: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:37.528: INFO: update-demo-nautilus-2szcx is verified up and running
Feb 19 04:32:37.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:37.600: INFO: stderr: ""
Feb 19 04:32:37.600: INFO: stdout: "true"
Feb 19 04:32:37.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-mfcrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4639'
Feb 19 04:32:37.679: INFO: stderr: ""
Feb 19 04:32:37.679: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 04:32:37.679: INFO: validating pod update-demo-nautilus-mfcrb
Feb 19 04:32:37.690: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 04:32:37.690: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 04:32:37.690: INFO: update-demo-nautilus-mfcrb is verified up and running
STEP: using delete to clean up resources
Feb 19 04:32:37.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-4639'
Feb 19 04:32:37.785: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 04:32:37.785: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 04:32:37.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4639'
Feb 19 04:32:37.864: INFO: stderr: "No resources found.\n"
Feb 19 04:32:37.864: INFO: stdout: ""
Feb 19 04:32:37.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=update-demo --namespace=kubectl-4639 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 04:32:37.939: INFO: stderr: ""
Feb 19 04:32:37.939: INFO: stdout: "update-demo-nautilus-2szcx\nupdate-demo-nautilus-mfcrb\n"
Feb 19 04:32:38.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4639'
Feb 19 04:32:38.520: INFO: stderr: "No resources found.\n"
Feb 19 04:32:38.520: INFO: stdout: ""
Feb 19 04:32:38.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=update-demo --namespace=kubectl-4639 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 04:32:38.595: INFO: stderr: ""
Feb 19 04:32:38.595: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:32:38.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4639" for this suite.
Feb 19 04:33:00.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:00.816: INFO: namespace kubectl-4639 deletion completed in 22.215217209s

• [SLOW TEST:49.809 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:33:00.817: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-90a8c1ad-0d1b-4d0f-8746-82525a468395
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-90a8c1ad-0d1b-4d0f-8746-82525a468395
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:33:07.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7439" for this suite.
Feb 19 04:33:29.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:29.808: INFO: namespace configmap-7439 deletion completed in 22.22193549s

• [SLOW TEST:28.992 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:33:29.808: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 19 04:33:40.392: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0219 04:33:40.392807      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:33:40.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4929" for this suite.
Feb 19 04:33:48.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:33:48.856: INFO: namespace gc-4929 deletion completed in 8.43997234s

• [SLOW TEST:19.047 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:33:48.856: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Feb 19 04:33:48.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-7086'
Feb 19 04:33:49.157: INFO: stderr: ""
Feb 19 04:33:49.157: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:33:50.164: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:33:50.165: INFO: Found 0 / 1
Feb 19 04:33:51.164: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:33:51.165: INFO: Found 1 / 1
Feb 19 04:33:51.165: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 19 04:33:51.170: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:33:51.170: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:33:51.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 patch pod redis-master-scn7h --namespace=kubectl-7086 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 19 04:33:51.249: INFO: stderr: ""
Feb 19 04:33:51.249: INFO: stdout: "pod/redis-master-scn7h patched\n"
STEP: checking annotations
Feb 19 04:33:51.501: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:33:51.501: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:33:51.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7086" for this suite.
Feb 19 04:34:15.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:34:15.785: INFO: namespace kubectl-7086 deletion completed in 24.238696237s

• [SLOW TEST:26.929 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:34:15.785: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:34:41.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1356" for this suite.
Feb 19 04:34:47.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:34:48.159: INFO: namespace namespaces-1356 deletion completed in 6.685954843s
STEP: Destroying namespace "nsdeletetest-2280" for this suite.
Feb 19 04:34:48.164: INFO: Namespace nsdeletetest-2280 was already deleted
STEP: Destroying namespace "nsdeletetest-5941" for this suite.
Feb 19 04:34:54.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:34:54.885: INFO: namespace nsdeletetest-5941 deletion completed in 6.720702202s

• [SLOW TEST:39.100 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:34:54.885: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:34:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-5282'
Feb 19 04:34:55.108: INFO: stderr: ""
Feb 19 04:34:55.108: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 19 04:34:55.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-5282'
Feb 19 04:34:55.281: INFO: stderr: ""
Feb 19 04:34:55.281: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 04:34:56.470: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:34:56.470: INFO: Found 0 / 1
Feb 19 04:34:57.288: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:34:57.288: INFO: Found 1 / 1
Feb 19 04:34:57.288: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:34:57.295: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:34:57.295: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 04:34:57.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 describe pod redis-master-ff8v6 --namespace=kubectl-5282'
Feb 19 04:34:57.391: INFO: stderr: ""
Feb 19 04:34:57.391: INFO: stdout: "Name:           redis-master-ff8v6\nNamespace:      kubectl-5282\nPriority:       0\nNode:           10.0.10.2/10.0.10.2\nStart Time:     Wed, 19 Feb 2020 04:34:55 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.1.107\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a3b0409da9457d85dbd6962cc39d5bd658203b97c3ae351a3bbc038fbd1c44dc\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 19 Feb 2020 04:34:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-zwxsv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-zwxsv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-zwxsv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  2s    default-scheduler   Successfully assigned kubectl-5282/redis-master-ff8v6 to 10.0.10.2\n  Normal  Pulled     2s    kubelet, 10.0.10.2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.0.10.2  Created container redis-master\n  Normal  Started    1s    kubelet, 10.0.10.2  Started container redis-master\n"
Feb 19 04:34:57.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 describe rc redis-master --namespace=kubectl-5282'
Feb 19 04:34:57.495: INFO: stderr: ""
Feb 19 04:34:57.495: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5282\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-ff8v6\n"
Feb 19 04:34:57.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 describe service redis-master --namespace=kubectl-5282'
Feb 19 04:34:57.584: INFO: stderr: ""
Feb 19 04:34:57.584: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5282\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.39.210\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.107:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 19 04:34:57.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 describe node 10.0.10.2'
Feb 19 04:34:57.699: INFO: stderr: ""
Feb 19 04:34:57.699: INFO: stdout: "Name:               10.0.10.2\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=VM.Standard1.2\n                    beta.kubernetes.io/os=linux\n                    displayName=oke-csdiobumu4g-n3denzthe3d-sk7p4cz5pqq-0\n                    failure-domain.beta.kubernetes.io/region=iad\n                    failure-domain.beta.kubernetes.io/zone=US-ASHBURN-AD-3\n                    hostname=oke-csdiobumu4g-n3denzthe3d-sk7p4cz5pqq-0\n                    internal_addr=10.0.10.2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.0.10.2\n                    kubernetes.io/os=linux\n                    name=pool1\n                    node-role.kubernetes.io/node=\n                    node.info.ds_proxymux_client=true\n                    node.info/compartment.id_prefix=ocid1.compartment.oc1\n                    node.info/compartment.id_suffix=aaaaaaaaztlikxtfte2mcdtyeyzvrcbjm6x3yfo2uhfh2kfemgvnmnqvc56q\n                    node.info/compartment.name=knn\n                    node.info/kubeletVersion=v1.15\n                    oke.oraclecloud.com/node.info.private_subnet=false\n                    oke.oraclecloud.com/node.info.private_worker=true\n                    oke.oraclecloud.com/tenant_agent.version=1.20.0-80eac4e-90\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.0.10.2\n                    csi.volume.kubernetes.io/nodeid: {\"blockvolume.csi.oraclecloud.com\":\"10.0.10.2\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ae:5e:55:e6:66:19\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.10.2\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 19 Feb 2020 03:30:46 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 19 Feb 2020 04:34:51 +0000   Wed, 19 Feb 2020 03:30:46 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 19 Feb 2020 04:34:51 +0000   Wed, 19 Feb 2020 03:30:46 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 19 Feb 2020 04:34:51 +0000   Wed, 19 Feb 2020 03:30:46 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 19 Feb 2020 04:34:51 +0000   Wed, 19 Feb 2020 03:31:06 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.10.2\n  ExternalIP:  129.213.157.101\nCapacity:\n attachable-volumes-csi-blockvolume.csi.oraclecloud.com:  32\n cpu:                                                     4\n ephemeral-storage:                                       40223552Ki\n hugepages-1Gi:                                           0\n hugepages-2Mi:                                           0\n memory:                                                  14083436Ki\n pods:                                                    110\nAllocatable:\n attachable-volumes-csi-blockvolume.csi.oraclecloud.com:  32\n cpu:                                                     4\n ephemeral-storage:                                       37070025462\n hugepages-1Gi:                                           0\n hugepages-2Mi:                                           0\n memory:                                                  13981036Ki\n pods:                                                    110\nSystem Info:\n Machine ID:                 c08f95ce89b64194bb05e5db16c92408\n System UUID:                3B2B3954-42F0-4186-9CA4-FE61739E0BB4\n Boot ID:                    6dcabc80-440a-4170-8353-094f3e8f2ddd\n Kernel Version:             4.14.35-1902.10.4.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.7\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.8\n Kubelet Version:            v1.15.7\n Kube-Proxy Version:         v1.15.7\nPodCIDR:                     10.244.1.0/24\nProviderID:                  ocid1.instance.oc1.iad.anuwcljsh4gjgpycasimxzazfiifpiqcc73454gwyelwalgc7fwjwhlzxieq\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-547fdd776c-rcf7n                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     63m\n  kube-system                csi-oci-node-jgr72                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         63m\n  kube-system                kube-flannel-ds-dd7gd                                      100m (2%)     1 (25%)     50Mi (0%)        500Mi (3%)     64m\n  kube-system                kube-proxy-8l2fs                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         64m\n  kube-system                proxymux-client-l94j2                                      50m (1%)      500m (12%)  64Mi (0%)        256Mi (1%)     63m\n  kubectl-5282               redis-master-ff8v6                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-wsrnl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                                Requests    Limits\n  --------                                                --------    ------\n  cpu                                                     250m (6%)   1500m (37%)\n  memory                                                  184Mi (1%)  926Mi (6%)\n  ephemeral-storage                                       0 (0%)      0 (0%)\n  attachable-volumes-csi-blockvolume.csi.oraclecloud.com  0           0\nEvents:                                                   <none>\n"
Feb 19 04:34:57.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 describe namespace kubectl-5282'
Feb 19 04:34:57.800: INFO: stderr: ""
Feb 19 04:34:57.800: INFO: stdout: "Name:         kubectl-5282\nLabels:       e2e-framework=kubectl\n              e2e-run=1623298a-ce86-4c8f-a92b-53c0ddc6b615\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:34:57.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5282" for this suite.
Feb 19 04:35:19.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:35:20.020: INFO: namespace kubectl-5282 deletion completed in 22.213194309s

• [SLOW TEST:25.135 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:35:20.020: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0219 04:35:30.224311      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 04:35:30.224: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:35:30.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-558" for this suite.
Feb 19 04:35:36.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:35:36.487: INFO: namespace gc-558 deletion completed in 6.236029437s

• [SLOW TEST:16.467 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:35:36.487: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 19 04:35:37.032: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7559,SelfLink:/api/v1/namespaces/watch-7559/configmaps/e2e-watch-test-resource-version,UID:2d8655f8-8037-4b0d-8504-70a71ca3d148,ResourceVersion:18642,Generation:0,CreationTimestamp:2020-02-19 04:35:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 04:35:37.032: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7559,SelfLink:/api/v1/namespaces/watch-7559/configmaps/e2e-watch-test-resource-version,UID:2d8655f8-8037-4b0d-8504-70a71ca3d148,ResourceVersion:18643,Generation:0,CreationTimestamp:2020-02-19 04:35:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:35:37.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7559" for this suite.
Feb 19 04:35:43.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:35:43.485: INFO: namespace watch-7559 deletion completed in 6.442887564s

• [SLOW TEST:6.997 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:35:43.485: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:35:43.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb" in namespace "downward-api-8150" to be "success or failure"
Feb 19 04:35:43.820: INFO: Pod "downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb": Phase="Pending", Reason="", readiness=false. Elapsed: 41.048091ms
Feb 19 04:35:45.844: INFO: Pod "downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.064214448s
STEP: Saw pod success
Feb 19 04:35:45.844: INFO: Pod "downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb" satisfied condition "success or failure"
Feb 19 04:35:45.855: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb container client-container: <nil>
STEP: delete the pod
Feb 19 04:35:45.925: INFO: Waiting for pod downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb to disappear
Feb 19 04:35:45.948: INFO: Pod downwardapi-volume-718e4521-983a-4467-aa3d-e839248b48eb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:35:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8150" for this suite.
Feb 19 04:35:52.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:35:52.201: INFO: namespace downward-api-8150 deletion completed in 6.222738129s

• [SLOW TEST:8.716 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:35:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 04:35:55.465: INFO: Successfully updated pod "pod-update-ef38971c-2608-4664-b6cf-bd858c9c77e5"
STEP: verifying the updated pod is in kubernetes
Feb 19 04:35:55.476: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:35:55.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5945" for this suite.
Feb 19 04:36:17.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:36:17.931: INFO: namespace pods-5945 deletion completed in 22.447897718s

• [SLOW TEST:25.729 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:36:17.931: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:36:40.234: INFO: Container started at 2020-02-19 04:36:18 +0000 UTC, pod became ready at 2020-02-19 04:36:39 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:36:40.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2190" for this suite.
Feb 19 04:37:04.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:37:04.569: INFO: namespace container-probe-2190 deletion completed in 24.327231183s

• [SLOW TEST:46.638 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:37:04.569: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Feb 19 04:37:04.857: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7716" to be "success or failure"
Feb 19 04:37:04.867: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.264384ms
Feb 19 04:37:06.875: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017443578s
Feb 19 04:37:08.882: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024456643s
STEP: Saw pod success
Feb 19 04:37:08.882: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 19 04:37:08.888: INFO: Trying to get logs from node 10.0.10.2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 19 04:37:08.979: INFO: Waiting for pod pod-host-path-test to disappear
Feb 19 04:37:08.986: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:37:08.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7716" for this suite.
Feb 19 04:37:15.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:37:15.717: INFO: namespace hostpath-7716 deletion completed in 6.723789996s

• [SLOW TEST:11.148 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:37:15.718: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-d5ab0210-33e8-422a-8542-eac8039643e7
STEP: Creating a pod to test consume configMaps
Feb 19 04:37:15.793: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79" in namespace "projected-4316" to be "success or failure"
Feb 19 04:37:15.800: INFO: Pod "pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79": Phase="Pending", Reason="", readiness=false. Elapsed: 6.377708ms
Feb 19 04:37:17.806: INFO: Pod "pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013095727s
STEP: Saw pod success
Feb 19 04:37:17.807: INFO: Pod "pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79" satisfied condition "success or failure"
Feb 19 04:37:17.813: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:37:17.850: INFO: Waiting for pod pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79 to disappear
Feb 19 04:37:17.857: INFO: Pod pod-projected-configmaps-b36f0807-466a-4978-8dec-a0f8988a9c79 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:37:17.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4316" for this suite.
Feb 19 04:37:23.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:37:24.072: INFO: namespace projected-4316 deletion completed in 6.20803017s

• [SLOW TEST:8.354 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:37:24.072: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:37:27.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-388" for this suite.
Feb 19 04:37:51.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:37:51.964: INFO: namespace replication-controller-388 deletion completed in 24.691999708s

• [SLOW TEST:27.892 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:37:51.964: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-3aefe3e4-e640-49f9-85d3-efc9cfaf2fea
STEP: Creating a pod to test consume configMaps
Feb 19 04:37:52.037: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7" in namespace "projected-5290" to be "success or failure"
Feb 19 04:37:52.043: INFO: Pod "pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.625845ms
Feb 19 04:37:54.157: INFO: Pod "pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.120467457s
STEP: Saw pod success
Feb 19 04:37:54.157: INFO: Pod "pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7" satisfied condition "success or failure"
Feb 19 04:37:54.163: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:37:54.314: INFO: Waiting for pod pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7 to disappear
Feb 19 04:37:54.320: INFO: Pod pod-projected-configmaps-72a93347-ea7d-49d5-a20d-e9c16ec4d7e7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:37:54.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5290" for this suite.
Feb 19 04:38:00.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:01.068: INFO: namespace projected-5290 deletion completed in 6.742684295s

• [SLOW TEST:9.104 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:01.068: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a5409578-c451-4b6d-8bf5-76b0d5be61a8
STEP: Creating a pod to test consume secrets
Feb 19 04:38:01.341: INFO: Waiting up to 5m0s for pod "pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285" in namespace "secrets-1184" to be "success or failure"
Feb 19 04:38:01.347: INFO: Pod "pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285": Phase="Pending", Reason="", readiness=false. Elapsed: 5.931553ms
Feb 19 04:38:03.354: INFO: Pod "pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01236955s
STEP: Saw pod success
Feb 19 04:38:03.354: INFO: Pod "pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285" satisfied condition "success or failure"
Feb 19 04:38:03.360: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:38:03.561: INFO: Waiting for pod pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285 to disappear
Feb 19 04:38:03.568: INFO: Pod pod-secrets-8d23c88e-eb70-4c99-bbdb-6611cf66b285 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:03.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1184" for this suite.
Feb 19 04:38:09.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:10.023: INFO: namespace secrets-1184 deletion completed in 6.44845757s

• [SLOW TEST:8.954 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:10.023: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:38:10.333: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47" in namespace "projected-2612" to be "success or failure"
Feb 19 04:38:10.340: INFO: Pod "downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47": Phase="Pending", Reason="", readiness=false. Elapsed: 6.488569ms
Feb 19 04:38:12.348: INFO: Pod "downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014200395s
STEP: Saw pod success
Feb 19 04:38:12.348: INFO: Pod "downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47" satisfied condition "success or failure"
Feb 19 04:38:12.354: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47 container client-container: <nil>
STEP: delete the pod
Feb 19 04:38:12.499: INFO: Waiting for pod downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47 to disappear
Feb 19 04:38:12.506: INFO: Pod downwardapi-volume-d62002d3-9140-4164-8c24-6637ab8f3e47 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:12.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2612" for this suite.
Feb 19 04:38:18.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:18.958: INFO: namespace projected-2612 deletion completed in 6.446687832s

• [SLOW TEST:8.935 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:18.959: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-1b1beaca-acb1-4abe-a2a2-5b5054cf8910
STEP: Creating a pod to test consume configMaps
Feb 19 04:38:19.249: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577" in namespace "projected-7103" to be "success or failure"
Feb 19 04:38:19.255: INFO: Pod "pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577": Phase="Pending", Reason="", readiness=false. Elapsed: 5.742587ms
Feb 19 04:38:21.262: INFO: Pod "pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01276197s
STEP: Saw pod success
Feb 19 04:38:21.262: INFO: Pod "pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577" satisfied condition "success or failure"
Feb 19 04:38:21.268: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:38:21.450: INFO: Waiting for pod pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577 to disappear
Feb 19 04:38:21.456: INFO: Pod pod-projected-configmaps-ca65beae-3b86-4d19-a876-1218eb979577 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:21.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7103" for this suite.
Feb 19 04:38:27.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:27.957: INFO: namespace projected-7103 deletion completed in 6.496015161s

• [SLOW TEST:8.999 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:27.958: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 19 04:38:28.198: INFO: Waiting up to 5m0s for pod "pod-6a194c23-79c7-47a1-9af9-31a7457193b6" in namespace "emptydir-5750" to be "success or failure"
Feb 19 04:38:28.205: INFO: Pod "pod-6a194c23-79c7-47a1-9af9-31a7457193b6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.075458ms
Feb 19 04:38:30.211: INFO: Pod "pod-6a194c23-79c7-47a1-9af9-31a7457193b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012984411s
Feb 19 04:38:32.343: INFO: Pod "pod-6a194c23-79c7-47a1-9af9-31a7457193b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.14400829s
STEP: Saw pod success
Feb 19 04:38:32.343: INFO: Pod "pod-6a194c23-79c7-47a1-9af9-31a7457193b6" satisfied condition "success or failure"
Feb 19 04:38:32.348: INFO: Trying to get logs from node 10.0.10.2 pod pod-6a194c23-79c7-47a1-9af9-31a7457193b6 container test-container: <nil>
STEP: delete the pod
Feb 19 04:38:32.434: INFO: Waiting for pod pod-6a194c23-79c7-47a1-9af9-31a7457193b6 to disappear
Feb 19 04:38:32.440: INFO: Pod pod-6a194c23-79c7-47a1-9af9-31a7457193b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:32.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5750" for this suite.
Feb 19 04:38:38.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:39.225: INFO: namespace emptydir-5750 deletion completed in 6.777222081s

• [SLOW TEST:11.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:39.225: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1b54b576-f19c-4769-993a-b4bb77c78b98
STEP: Creating a pod to test consume configMaps
Feb 19 04:38:39.419: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81" in namespace "projected-4992" to be "success or failure"
Feb 19 04:38:39.426: INFO: Pod "pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81": Phase="Pending", Reason="", readiness=false. Elapsed: 7.607511ms
Feb 19 04:38:41.433: INFO: Pod "pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014213595s
Feb 19 04:38:43.612: INFO: Pod "pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.193344357s
STEP: Saw pod success
Feb 19 04:38:43.612: INFO: Pod "pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81" satisfied condition "success or failure"
Feb 19 04:38:43.618: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:38:43.865: INFO: Waiting for pod pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81 to disappear
Feb 19 04:38:43.871: INFO: Pod pod-projected-configmaps-4f7da996-42ca-4e3a-a3d3-0463ea715f81 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:43.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4992" for this suite.
Feb 19 04:38:49.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:38:50.423: INFO: namespace projected-4992 deletion completed in 6.545139223s

• [SLOW TEST:11.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:38:50.423: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-5796/secret-test-24fa8a3b-6c6a-42dc-bdce-d1adcd4a083b
STEP: Creating a pod to test consume secrets
Feb 19 04:38:50.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24" in namespace "secrets-5796" to be "success or failure"
Feb 19 04:38:50.625: INFO: Pod "pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24": Phase="Pending", Reason="", readiness=false. Elapsed: 8.548342ms
Feb 19 04:38:52.655: INFO: Pod "pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038501195s
Feb 19 04:38:54.871: INFO: Pod "pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.254441737s
STEP: Saw pod success
Feb 19 04:38:54.871: INFO: Pod "pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24" satisfied condition "success or failure"
Feb 19 04:38:54.878: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24 container env-test: <nil>
STEP: delete the pod
Feb 19 04:38:55.090: INFO: Waiting for pod pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24 to disappear
Feb 19 04:38:55.096: INFO: Pod pod-configmaps-ba14af49-5a66-4a01-83c0-0f1b05b5be24 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:38:55.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5796" for this suite.
Feb 19 04:39:01.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:39:01.330: INFO: namespace secrets-5796 deletion completed in 6.227590316s

• [SLOW TEST:10.907 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:39:01.330: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-168f3080-03b8-4334-8c39-c75aef4684df
STEP: Creating secret with name s-test-opt-upd-fb7259dd-ba15-4d31-9b11-e9cbd635cbcf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-168f3080-03b8-4334-8c39-c75aef4684df
STEP: Updating secret s-test-opt-upd-fb7259dd-ba15-4d31-9b11-e9cbd635cbcf
STEP: Creating secret with name s-test-opt-create-dd6f7dfe-acac-40fc-b827-a8eed8a46ba7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:39:06.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5651" for this suite.
Feb 19 04:39:30.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:39:30.981: INFO: namespace projected-5651 deletion completed in 24.460956064s

• [SLOW TEST:29.651 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:39:30.981: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 04:39:31.045: INFO: Waiting up to 5m0s for pod "pod-60b66416-36ea-4d21-a94b-630560992041" in namespace "emptydir-6377" to be "success or failure"
Feb 19 04:39:31.051: INFO: Pod "pod-60b66416-36ea-4d21-a94b-630560992041": Phase="Pending", Reason="", readiness=false. Elapsed: 6.203297ms
Feb 19 04:39:33.057: INFO: Pod "pod-60b66416-36ea-4d21-a94b-630560992041": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012024295s
Feb 19 04:39:35.260: INFO: Pod "pod-60b66416-36ea-4d21-a94b-630560992041": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.215102087s
STEP: Saw pod success
Feb 19 04:39:35.260: INFO: Pod "pod-60b66416-36ea-4d21-a94b-630560992041" satisfied condition "success or failure"
Feb 19 04:39:35.265: INFO: Trying to get logs from node 10.0.10.2 pod pod-60b66416-36ea-4d21-a94b-630560992041 container test-container: <nil>
STEP: delete the pod
Feb 19 04:39:35.375: INFO: Waiting for pod pod-60b66416-36ea-4d21-a94b-630560992041 to disappear
Feb 19 04:39:35.381: INFO: Pod pod-60b66416-36ea-4d21-a94b-630560992041 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:39:35.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6377" for this suite.
Feb 19 04:39:41.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:39:41.729: INFO: namespace emptydir-6377 deletion completed in 6.34265914s

• [SLOW TEST:10.748 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:39:41.730: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:39:44.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1951" for this suite.
Feb 19 04:39:50.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:39:50.782: INFO: namespace emptydir-wrapper-1951 deletion completed in 6.477555357s

• [SLOW TEST:9.052 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:39:50.782: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-0ec75a77-5097-46df-a24e-3a1838be1eb4
STEP: Creating a pod to test consume configMaps
Feb 19 04:39:51.097: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e" in namespace "configmap-1143" to be "success or failure"
Feb 19 04:39:51.105: INFO: Pod "pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.133723ms
Feb 19 04:39:53.266: INFO: Pod "pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.169521895s
STEP: Saw pod success
Feb 19 04:39:53.266: INFO: Pod "pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e" satisfied condition "success or failure"
Feb 19 04:39:53.274: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:39:53.308: INFO: Waiting for pod pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e to disappear
Feb 19 04:39:53.314: INFO: Pod pod-configmaps-1e08c819-4318-43bf-a6ac-c8ce758c6a7e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:39:53.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1143" for this suite.
Feb 19 04:39:59.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:39:59.665: INFO: namespace configmap-1143 deletion completed in 6.345449446s

• [SLOW TEST:8.883 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:39:59.665: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 19 04:40:00.564: INFO: Pod name wrapped-volume-race-985d4529-a4a8-4bd3-82d0-2211af09c252: Found 0 pods out of 5
Feb 19 04:40:05.573: INFO: Pod name wrapped-volume-race-985d4529-a4a8-4bd3-82d0-2211af09c252: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-985d4529-a4a8-4bd3-82d0-2211af09c252 in namespace emptydir-wrapper-9666, will wait for the garbage collector to delete the pods
Feb 19 04:40:17.684: INFO: Deleting ReplicationController wrapped-volume-race-985d4529-a4a8-4bd3-82d0-2211af09c252 took: 12.630271ms
Feb 19 04:40:18.084: INFO: Terminating ReplicationController wrapped-volume-race-985d4529-a4a8-4bd3-82d0-2211af09c252 pods took: 400.331508ms
STEP: Creating RC which spawns configmap-volume pods
Feb 19 04:40:57.811: INFO: Pod name wrapped-volume-race-bdb95284-96df-499c-b121-e55ddd69a1a3: Found 0 pods out of 5
Feb 19 04:41:02.887: INFO: Pod name wrapped-volume-race-bdb95284-96df-499c-b121-e55ddd69a1a3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bdb95284-96df-499c-b121-e55ddd69a1a3 in namespace emptydir-wrapper-9666, will wait for the garbage collector to delete the pods
Feb 19 04:41:16.998: INFO: Deleting ReplicationController wrapped-volume-race-bdb95284-96df-499c-b121-e55ddd69a1a3 took: 13.089828ms
Feb 19 04:41:17.298: INFO: Terminating ReplicationController wrapped-volume-race-bdb95284-96df-499c-b121-e55ddd69a1a3 pods took: 300.270328ms
STEP: Creating RC which spawns configmap-volume pods
Feb 19 04:41:57.623: INFO: Pod name wrapped-volume-race-2c8c111a-f045-4671-8869-7fa1bb23d468: Found 0 pods out of 5
Feb 19 04:42:02.642: INFO: Pod name wrapped-volume-race-2c8c111a-f045-4671-8869-7fa1bb23d468: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2c8c111a-f045-4671-8869-7fa1bb23d468 in namespace emptydir-wrapper-9666, will wait for the garbage collector to delete the pods
Feb 19 04:42:20.769: INFO: Deleting ReplicationController wrapped-volume-race-2c8c111a-f045-4671-8869-7fa1bb23d468 took: 15.087354ms
Feb 19 04:42:21.169: INFO: Terminating ReplicationController wrapped-volume-race-2c8c111a-f045-4671-8869-7fa1bb23d468 pods took: 400.336169ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:07.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9666" for this suite.
Feb 19 04:43:15.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:16.021: INFO: namespace emptydir-wrapper-9666 deletion completed in 8.220266794s

• [SLOW TEST:196.355 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:43:16.022: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Feb 19 04:43:16.090: INFO: Waiting up to 5m0s for pod "client-containers-63df81ed-78ca-4156-b223-ab1047127a79" in namespace "containers-8231" to be "success or failure"
Feb 19 04:43:16.096: INFO: Pod "client-containers-63df81ed-78ca-4156-b223-ab1047127a79": Phase="Pending", Reason="", readiness=false. Elapsed: 6.625743ms
Feb 19 04:43:18.103: INFO: Pod "client-containers-63df81ed-78ca-4156-b223-ab1047127a79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013142943s
STEP: Saw pod success
Feb 19 04:43:18.103: INFO: Pod "client-containers-63df81ed-78ca-4156-b223-ab1047127a79" satisfied condition "success or failure"
Feb 19 04:43:18.108: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-63df81ed-78ca-4156-b223-ab1047127a79 container test-container: <nil>
STEP: delete the pod
Feb 19 04:43:18.148: INFO: Waiting for pod client-containers-63df81ed-78ca-4156-b223-ab1047127a79 to disappear
Feb 19 04:43:18.154: INFO: Pod client-containers-63df81ed-78ca-4156-b223-ab1047127a79 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:18.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8231" for this suite.
Feb 19 04:43:24.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:24.613: INFO: namespace containers-8231 deletion completed in 6.453662289s

• [SLOW TEST:8.592 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:43:24.614: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Feb 19 04:43:24.686: INFO: Waiting up to 5m0s for pod "client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d" in namespace "containers-3080" to be "success or failure"
Feb 19 04:43:24.692: INFO: Pod "client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.443028ms
Feb 19 04:43:26.704: INFO: Pod "client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018014262s
STEP: Saw pod success
Feb 19 04:43:26.704: INFO: Pod "client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d" satisfied condition "success or failure"
Feb 19 04:43:26.711: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d container test-container: <nil>
STEP: delete the pod
Feb 19 04:43:26.812: INFO: Waiting for pod client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d to disappear
Feb 19 04:43:26.818: INFO: Pod client-containers-0e08eda6-4bc7-4f39-b26f-61999b8d4d7d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:26.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3080" for this suite.
Feb 19 04:43:32.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:33.487: INFO: namespace containers-3080 deletion completed in 6.66276315s

• [SLOW TEST:8.873 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:43:33.487: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-6ad7ed46-9395-4cd7-a333-1bf63f3e515b
STEP: Creating a pod to test consume configMaps
Feb 19 04:43:33.578: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54" in namespace "projected-4947" to be "success or failure"
Feb 19 04:43:33.585: INFO: Pod "pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54": Phase="Pending", Reason="", readiness=false. Elapsed: 7.052619ms
Feb 19 04:43:35.660: INFO: Pod "pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082129712s
Feb 19 04:43:37.667: INFO: Pod "pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.089115398s
STEP: Saw pod success
Feb 19 04:43:37.667: INFO: Pod "pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54" satisfied condition "success or failure"
Feb 19 04:43:37.673: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:43:37.913: INFO: Waiting for pod pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54 to disappear
Feb 19 04:43:37.920: INFO: Pod pod-projected-configmaps-ada8bb9c-8503-4ab3-8df5-ac576c667d54 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:37.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4947" for this suite.
Feb 19 04:43:44.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:44.821: INFO: namespace projected-4947 deletion completed in 6.894716386s

• [SLOW TEST:11.333 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:43:44.821: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-f4d089f0-478f-4c1c-a539-c61309fa87bd
STEP: Creating a pod to test consume configMaps
Feb 19 04:43:44.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d" in namespace "projected-9215" to be "success or failure"
Feb 19 04:43:44.904: INFO: Pod "pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.813563ms
Feb 19 04:43:46.910: INFO: Pod "pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013050369s
STEP: Saw pod success
Feb 19 04:43:46.910: INFO: Pod "pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d" satisfied condition "success or failure"
Feb 19 04:43:46.916: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:43:46.950: INFO: Waiting for pod pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d to disappear
Feb 19 04:43:46.956: INFO: Pod pod-projected-configmaps-24056974-7325-4bcf-85f4-d342ba58342d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:46.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9215" for this suite.
Feb 19 04:43:52.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:43:53.606: INFO: namespace projected-9215 deletion completed in 6.64469689s

• [SLOW TEST:8.785 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:43:53.607: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 04:43:53.684: INFO: Waiting up to 5m0s for pod "pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607" in namespace "emptydir-5241" to be "success or failure"
Feb 19 04:43:53.691: INFO: Pod "pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607": Phase="Pending", Reason="", readiness=false. Elapsed: 7.036169ms
Feb 19 04:43:55.810: INFO: Pod "pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.126369611s
STEP: Saw pod success
Feb 19 04:43:55.810: INFO: Pod "pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607" satisfied condition "success or failure"
Feb 19 04:43:55.816: INFO: Trying to get logs from node 10.0.10.2 pod pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607 container test-container: <nil>
STEP: delete the pod
Feb 19 04:43:55.861: INFO: Waiting for pod pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607 to disappear
Feb 19 04:43:55.867: INFO: Pod pod-3dd01f1f-cb74-40d1-b4ae-c18eccf57607 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:43:55.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5241" for this suite.
Feb 19 04:44:01.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:44:02.088: INFO: namespace emptydir-5241 deletion completed in 6.215291532s

• [SLOW TEST:8.481 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:44:02.088: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:44:04.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1103" for this suite.
Feb 19 04:44:48.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:44:49.040: INFO: namespace kubelet-test-1103 deletion completed in 44.222998304s

• [SLOW TEST:46.951 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:44:49.040: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Feb 19 04:44:49.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-6890'
Feb 19 04:44:49.659: INFO: stderr: ""
Feb 19 04:44:49.659: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Feb 19 04:44:50.730: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:50.730: INFO: Found 0 / 1
Feb 19 04:44:51.667: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:51.667: INFO: Found 1 / 1
Feb 19 04:44:51.667: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 04:44:51.672: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 04:44:51.672: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 19 04:44:51.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890'
Feb 19 04:44:51.963: INFO: stderr: ""
Feb 19 04:44:51.963: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:44:50.498 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:44:50.498 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:44:50.499 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:44:50.499 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 19 04:44:51.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890 --tail=1'
Feb 19 04:44:52.054: INFO: stderr: ""
Feb 19 04:44:52.054: INFO: stdout: "1:M 19 Feb 04:44:50.499 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 19 04:44:52.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890 --limit-bytes=1'
Feb 19 04:44:52.141: INFO: stderr: ""
Feb 19 04:44:52.141: INFO: stdout: " "
STEP: exposing timestamps
Feb 19 04:44:52.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890 --tail=1 --timestamps'
Feb 19 04:44:52.233: INFO: stderr: ""
Feb 19 04:44:52.233: INFO: stdout: "2020-02-19T04:44:50.499173925Z 1:M 19 Feb 04:44:50.499 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 19 04:44:54.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890 --since=1s'
Feb 19 04:44:55.005: INFO: stderr: ""
Feb 19 04:44:55.006: INFO: stdout: ""
Feb 19 04:44:55.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs redis-master-ssrb2 redis-master --namespace=kubectl-6890 --since=24h'
Feb 19 04:44:55.096: INFO: stderr: ""
Feb 19 04:44:55.096: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 04:44:50.498 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 04:44:50.498 # Server started, Redis version 3.2.12\n1:M 19 Feb 04:44:50.499 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 04:44:50.499 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Feb 19 04:44:55.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete --grace-period=0 --force -f - --namespace=kubectl-6890'
Feb 19 04:44:55.179: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 04:44:55.179: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 19 04:44:55.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6890'
Feb 19 04:44:55.259: INFO: stderr: "No resources found.\n"
Feb 19 04:44:55.259: INFO: stdout: ""
Feb 19 04:44:55.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -l name=nginx --namespace=kubectl-6890 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 04:44:55.331: INFO: stderr: ""
Feb 19 04:44:55.331: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:44:55.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6890" for this suite.
Feb 19 04:45:17.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:45:17.901: INFO: namespace kubectl-6890 deletion completed in 22.561543797s

• [SLOW TEST:28.860 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:45:17.901: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:45:18.122: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:45:20.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2013" for this suite.
Feb 19 04:46:00.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:00.739: INFO: namespace pods-2013 deletion completed in 40.39372699s

• [SLOW TEST:42.838 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:00.739: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:46:00.813: INFO: Creating deployment "test-recreate-deployment"
Feb 19 04:46:00.827: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 19 04:46:00.851: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 19 04:46:02.878: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 19 04:46:02.891: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717684360, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717684360, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717684360, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717684360, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 04:46:04.901: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 19 04:46:04.934: INFO: Updating deployment test-recreate-deployment
Feb 19 04:46:04.935: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 19 04:46:05.347: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-4527,SelfLink:/apis/apps/v1/namespaces/deployment-4527/deployments/test-recreate-deployment,UID:2e0839a1-974a-40be-b18e-0c77bbbdb719,ResourceVersion:21840,Generation:2,CreationTimestamp:2020-02-19 04:46:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-02-19 04:46:05 +0000 UTC 2020-02-19 04:46:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-02-19 04:46:05 +0000 UTC 2020-02-19 04:46:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 04:46:05.361: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-4527,SelfLink:/apis/apps/v1/namespaces/deployment-4527/replicasets/test-recreate-deployment-5c8c9cc69d,UID:d90775ba-f305-4a86-9be3-c6fd69416171,ResourceVersion:21837,Generation:1,CreationTimestamp:2020-02-19 04:46:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2e0839a1-974a-40be-b18e-0c77bbbdb719 0xc00288d597 0xc00288d598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:46:05.361: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 19 04:46:05.361: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-4527,SelfLink:/apis/apps/v1/namespaces/deployment-4527/replicasets/test-recreate-deployment-6df85df6b9,UID:ca85e10a-3bc6-430b-a255-8e3d63dc7cfa,ResourceVersion:21828,Generation:2,CreationTimestamp:2020-02-19 04:46:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2e0839a1-974a-40be-b18e-0c77bbbdb719 0xc00288d667 0xc00288d668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:46:05.372: INFO: Pod "test-recreate-deployment-5c8c9cc69d-5996z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-5996z,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-4527,SelfLink:/api/v1/namespaces/deployment-4527/pods/test-recreate-deployment-5c8c9cc69d-5996z,UID:9c982297-77cb-446c-bf98-39f26b466eb4,ResourceVersion:21839,Generation:0,CreationTimestamp:2020-02-19 04:46:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d d90775ba-f305-4a86-9be3-c6fd69416171 0xc00288df77 0xc00288df78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5s76x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5s76x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5s76x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00288dff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029580a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:46:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:46:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:46:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:46:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:46:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:05.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4527" for this suite.
Feb 19 04:46:11.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:11.824: INFO: namespace deployment-4527 deletion completed in 6.435424038s

• [SLOW TEST:11.084 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:11.824: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d65955ca-d26d-437c-8037-e0f9b77a286a
STEP: Creating a pod to test consume secrets
Feb 19 04:46:11.957: INFO: Waiting up to 5m0s for pod "pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161" in namespace "secrets-9471" to be "success or failure"
Feb 19 04:46:11.968: INFO: Pod "pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161": Phase="Pending", Reason="", readiness=false. Elapsed: 10.987827ms
Feb 19 04:46:13.976: INFO: Pod "pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019595841s
STEP: Saw pod success
Feb 19 04:46:13.976: INFO: Pod "pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161" satisfied condition "success or failure"
Feb 19 04:46:13.985: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:46:14.285: INFO: Waiting for pod pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161 to disappear
Feb 19 04:46:14.298: INFO: Pod pod-secrets-21209f0c-b3d5-4864-965f-d6b535945161 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:14.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9471" for this suite.
Feb 19 04:46:20.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:20.687: INFO: namespace secrets-9471 deletion completed in 6.377540581s

• [SLOW TEST:8.863 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:20.687: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-7d601491-cebb-493c-9011-8fc99e3cc6d0
STEP: Creating a pod to test consume secrets
Feb 19 04:46:20.853: INFO: Waiting up to 5m0s for pod "pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28" in namespace "secrets-8042" to be "success or failure"
Feb 19 04:46:20.863: INFO: Pod "pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28": Phase="Pending", Reason="", readiness=false. Elapsed: 9.371762ms
Feb 19 04:46:22.870: INFO: Pod "pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016337404s
Feb 19 04:46:24.884: INFO: Pod "pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030639237s
STEP: Saw pod success
Feb 19 04:46:24.884: INFO: Pod "pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28" satisfied condition "success or failure"
Feb 19 04:46:24.890: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:46:24.930: INFO: Waiting for pod pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28 to disappear
Feb 19 04:46:24.936: INFO: Pod pod-secrets-e4f21097-bf02-46e1-be72-6330c4971a28 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:24.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8042" for this suite.
Feb 19 04:46:30.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:31.159: INFO: namespace secrets-8042 deletion completed in 6.215384012s

• [SLOW TEST:10.471 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:31.159: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 19 04:46:31.634: INFO: Waiting up to 5m0s for pod "downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6" in namespace "downward-api-9870" to be "success or failure"
Feb 19 04:46:31.642: INFO: Pod "downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.497516ms
Feb 19 04:46:33.865: INFO: Pod "downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.231628104s
Feb 19 04:46:35.935: INFO: Pod "downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.301408017s
STEP: Saw pod success
Feb 19 04:46:35.935: INFO: Pod "downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6" satisfied condition "success or failure"
Feb 19 04:46:36.005: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6 container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:46:36.078: INFO: Waiting for pod downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6 to disappear
Feb 19 04:46:36.087: INFO: Pod downward-api-0c156da7-3154-4d8e-8ce4-743dae20a5d6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:36.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9870" for this suite.
Feb 19 04:46:42.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:42.343: INFO: namespace downward-api-9870 deletion completed in 6.248648828s

• [SLOW TEST:11.184 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:42.343: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-m87pp in namespace proxy-1350
I0219 04:46:42.741522      19 runners.go:180] Created replication controller with name: proxy-service-m87pp, namespace: proxy-1350, replica count: 1
I0219 04:46:43.791956      19 runners.go:180] proxy-service-m87pp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:44.792187      19 runners.go:180] proxy-service-m87pp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:46:45.792429      19 runners.go:180] proxy-service-m87pp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:46.792657      19 runners.go:180] proxy-service-m87pp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 04:46:47.792879      19 runners.go:180] proxy-service-m87pp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 04:46:47.802: INFO: setup took 5.148815917s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 19 04:46:48.017: INFO: (0) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 214.124774ms)
Feb 19 04:46:48.019: INFO: (0) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 216.060189ms)
Feb 19 04:46:48.021: INFO: (0) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 218.670352ms)
Feb 19 04:46:48.021: INFO: (0) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 218.765764ms)
Feb 19 04:46:48.024: INFO: (0) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 221.405823ms)
Feb 19 04:46:48.024: INFO: (0) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 221.70393ms)
Feb 19 04:46:48.026: INFO: (0) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 223.948522ms)
Feb 19 04:46:48.027: INFO: (0) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 224.325248ms)
Feb 19 04:46:48.029: INFO: (0) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 225.989948ms)
Feb 19 04:46:48.030: INFO: (0) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 227.685119ms)
Feb 19 04:46:48.032: INFO: (0) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 229.161945ms)
Feb 19 04:46:48.038: INFO: (0) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 235.744095ms)
Feb 19 04:46:48.042: INFO: (0) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 238.903145ms)
Feb 19 04:46:48.046: INFO: (0) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 243.371789ms)
Feb 19 04:46:48.371: INFO: (0) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 568.60697ms)
Feb 19 04:46:48.371: INFO: (0) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 568.469043ms)
Feb 19 04:46:48.439: INFO: (1) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 67.5105ms)
Feb 19 04:46:48.439: INFO: (1) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 67.613458ms)
Feb 19 04:46:48.439: INFO: (1) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 67.945531ms)
Feb 19 04:46:48.439: INFO: (1) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 68.074326ms)
Feb 19 04:46:48.440: INFO: (1) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 68.117628ms)
Feb 19 04:46:48.440: INFO: (1) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 68.288181ms)
Feb 19 04:46:48.440: INFO: (1) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 68.427233ms)
Feb 19 04:46:48.441: INFO: (1) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 69.175485ms)
Feb 19 04:46:48.441: INFO: (1) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 69.396816ms)
Feb 19 04:46:48.449: INFO: (1) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 77.215612ms)
Feb 19 04:46:48.449: INFO: (1) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 77.11613ms)
Feb 19 04:46:48.503: INFO: (1) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 131.333148ms)
Feb 19 04:46:48.503: INFO: (1) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 131.407079ms)
Feb 19 04:46:48.503: INFO: (1) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 131.45459ms)
Feb 19 04:46:48.503: INFO: (1) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 131.779411ms)
Feb 19 04:46:48.503: INFO: (1) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 131.657074ms)
Feb 19 04:46:48.517: INFO: (2) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 13.336593ms)
Feb 19 04:46:48.517: INFO: (2) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 13.597648ms)
Feb 19 04:46:48.518: INFO: (2) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 14.03707ms)
Feb 19 04:46:48.518: INFO: (2) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 14.750368ms)
Feb 19 04:46:48.518: INFO: (2) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.669701ms)
Feb 19 04:46:48.518: INFO: (2) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.994598ms)
Feb 19 04:46:48.518: INFO: (2) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 14.629252ms)
Feb 19 04:46:48.519: INFO: (2) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 15.820911ms)
Feb 19 04:46:48.519: INFO: (2) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 15.519017ms)
Feb 19 04:46:48.519: INFO: (2) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 15.76362ms)
Feb 19 04:46:48.520: INFO: (2) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 16.680755ms)
Feb 19 04:46:48.520: INFO: (2) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 16.994136ms)
Feb 19 04:46:48.522: INFO: (2) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 18.299894ms)
Feb 19 04:46:48.522: INFO: (2) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 18.442135ms)
Feb 19 04:46:48.522: INFO: (2) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 18.147056ms)
Feb 19 04:46:48.523: INFO: (2) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 19.339082ms)
Feb 19 04:46:48.533: INFO: (3) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 9.452312ms)
Feb 19 04:46:48.533: INFO: (3) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 9.53199ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 22.459076ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 21.783052ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 22.974007ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 22.733909ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 22.458968ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 22.681413ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 22.6803ms)
Feb 19 04:46:48.546: INFO: (3) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 22.978769ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 25.956123ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 26.312235ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 26.070027ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 26.07759ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 26.013642ms)
Feb 19 04:46:48.550: INFO: (3) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 26.070324ms)
Feb 19 04:46:48.562: INFO: (4) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 11.780427ms)
Feb 19 04:46:48.563: INFO: (4) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 12.759241ms)
Feb 19 04:46:48.564: INFO: (4) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 13.981322ms)
Feb 19 04:46:48.565: INFO: (4) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 14.953705ms)
Feb 19 04:46:48.565: INFO: (4) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 15.098013ms)
Feb 19 04:46:48.565: INFO: (4) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 15.386613ms)
Feb 19 04:46:48.568: INFO: (4) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 17.834826ms)
Feb 19 04:46:48.568: INFO: (4) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 18.016496ms)
Feb 19 04:46:48.568: INFO: (4) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 17.769146ms)
Feb 19 04:46:48.568: INFO: (4) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 17.948427ms)
Feb 19 04:46:48.569: INFO: (4) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 18.80907ms)
Feb 19 04:46:48.571: INFO: (4) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 21.13445ms)
Feb 19 04:46:48.571: INFO: (4) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 21.039256ms)
Feb 19 04:46:48.573: INFO: (4) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 22.646738ms)
Feb 19 04:46:48.573: INFO: (4) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 22.835785ms)
Feb 19 04:46:48.573: INFO: (4) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 22.683758ms)
Feb 19 04:46:48.583: INFO: (5) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 10.180358ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 12.1566ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 12.442095ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 12.534559ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 12.267545ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 12.689277ms)
Feb 19 04:46:48.586: INFO: (5) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 12.945733ms)
Feb 19 04:46:48.590: INFO: (5) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 16.07679ms)
Feb 19 04:46:48.590: INFO: (5) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 17.10056ms)
Feb 19 04:46:48.592: INFO: (5) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 18.881329ms)
Feb 19 04:46:48.592: INFO: (5) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 18.871413ms)
Feb 19 04:46:48.593: INFO: (5) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 19.031645ms)
Feb 19 04:46:48.593: INFO: (5) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 19.160398ms)
Feb 19 04:46:48.593: INFO: (5) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 19.672834ms)
Feb 19 04:46:48.594: INFO: (5) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 20.921391ms)
Feb 19 04:46:48.596: INFO: (5) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 22.605078ms)
Feb 19 04:46:48.610: INFO: (6) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 13.599211ms)
Feb 19 04:46:48.610: INFO: (6) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 13.435757ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 16.812335ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 16.546706ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 16.558433ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 16.435266ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 16.649555ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 16.58117ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 16.52402ms)
Feb 19 04:46:48.613: INFO: (6) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 16.834203ms)
Feb 19 04:46:48.618: INFO: (6) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 21.747897ms)
Feb 19 04:46:48.618: INFO: (6) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 22.194439ms)
Feb 19 04:46:48.623: INFO: (6) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 27.095526ms)
Feb 19 04:46:48.623: INFO: (6) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 27.055645ms)
Feb 19 04:46:48.623: INFO: (6) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 27.165508ms)
Feb 19 04:46:48.623: INFO: (6) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 27.101522ms)
Feb 19 04:46:48.634: INFO: (7) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 9.935031ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 10.761281ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 10.656086ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 10.123099ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 10.947422ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 10.53334ms)
Feb 19 04:46:48.635: INFO: (7) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 10.298463ms)
Feb 19 04:46:48.636: INFO: (7) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 10.632224ms)
Feb 19 04:46:48.636: INFO: (7) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 12.296823ms)
Feb 19 04:46:48.636: INFO: (7) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 11.264594ms)
Feb 19 04:46:48.636: INFO: (7) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 12.552214ms)
Feb 19 04:46:48.638: INFO: (7) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 13.565368ms)
Feb 19 04:46:48.640: INFO: (7) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 15.446828ms)
Feb 19 04:46:48.641: INFO: (7) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 16.908487ms)
Feb 19 04:46:48.641: INFO: (7) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 17.414504ms)
Feb 19 04:46:48.641: INFO: (7) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 17.150039ms)
Feb 19 04:46:48.655: INFO: (8) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 13.093441ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 14.440393ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.153767ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 14.049483ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 14.286669ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 13.937825ms)
Feb 19 04:46:48.656: INFO: (8) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 14.208146ms)
Feb 19 04:46:48.657: INFO: (8) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.665993ms)
Feb 19 04:46:48.657: INFO: (8) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 15.472058ms)
Feb 19 04:46:48.659: INFO: (8) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 17.859355ms)
Feb 19 04:46:48.659: INFO: (8) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 17.666817ms)
Feb 19 04:46:48.662: INFO: (8) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 20.596112ms)
Feb 19 04:46:48.662: INFO: (8) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 20.230865ms)
Feb 19 04:46:48.662: INFO: (8) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 20.182522ms)
Feb 19 04:46:48.662: INFO: (8) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 20.631669ms)
Feb 19 04:46:48.664: INFO: (8) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 22.753755ms)
Feb 19 04:46:48.682: INFO: (9) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 17.599629ms)
Feb 19 04:46:48.682: INFO: (9) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 17.701953ms)
Feb 19 04:46:48.682: INFO: (9) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 17.895435ms)
Feb 19 04:46:48.682: INFO: (9) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 17.58606ms)
Feb 19 04:46:48.682: INFO: (9) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 17.978505ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 20.08005ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 19.792082ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 19.738607ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 19.927357ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 20.174014ms)
Feb 19 04:46:48.684: INFO: (9) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 20.254654ms)
Feb 19 04:46:48.685: INFO: (9) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 20.877756ms)
Feb 19 04:46:48.686: INFO: (9) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 21.94968ms)
Feb 19 04:46:48.687: INFO: (9) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 21.889331ms)
Feb 19 04:46:48.688: INFO: (9) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 23.527064ms)
Feb 19 04:46:48.688: INFO: (9) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 23.662654ms)
Feb 19 04:46:48.699: INFO: (10) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 10.898039ms)
Feb 19 04:46:48.699: INFO: (10) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 10.878456ms)
Feb 19 04:46:48.701: INFO: (10) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 12.646042ms)
Feb 19 04:46:48.703: INFO: (10) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 14.684114ms)
Feb 19 04:46:48.704: INFO: (10) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 15.569651ms)
Feb 19 04:46:48.707: INFO: (10) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 18.34164ms)
Feb 19 04:46:48.708: INFO: (10) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 19.176308ms)
Feb 19 04:46:48.710: INFO: (10) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 21.803136ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 26.460259ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 26.732345ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 26.655533ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 26.604396ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 26.702839ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 26.639577ms)
Feb 19 04:46:48.715: INFO: (10) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 26.918028ms)
Feb 19 04:46:48.716: INFO: (10) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 26.991848ms)
Feb 19 04:46:48.730: INFO: (11) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 13.567913ms)
Feb 19 04:46:48.730: INFO: (11) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 13.605193ms)
Feb 19 04:46:48.730: INFO: (11) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 13.852486ms)
Feb 19 04:46:48.730: INFO: (11) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 14.033742ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 15.528167ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 15.302018ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 15.594278ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 15.518518ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 15.414065ms)
Feb 19 04:46:48.731: INFO: (11) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 15.545872ms)
Feb 19 04:46:48.732: INFO: (11) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 16.461764ms)
Feb 19 04:46:48.733: INFO: (11) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 17.171675ms)
Feb 19 04:46:48.734: INFO: (11) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 18.413453ms)
Feb 19 04:46:48.735: INFO: (11) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 19.372737ms)
Feb 19 04:46:48.735: INFO: (11) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 19.439948ms)
Feb 19 04:46:48.736: INFO: (11) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 20.291582ms)
Feb 19 04:46:48.746: INFO: (12) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 9.497537ms)
Feb 19 04:46:48.754: INFO: (12) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 17.358269ms)
Feb 19 04:46:48.754: INFO: (12) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 17.500686ms)
Feb 19 04:46:48.755: INFO: (12) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 18.217613ms)
Feb 19 04:46:48.755: INFO: (12) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 18.227513ms)
Feb 19 04:46:48.755: INFO: (12) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 18.08318ms)
Feb 19 04:46:48.755: INFO: (12) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 18.464527ms)
Feb 19 04:46:48.755: INFO: (12) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 18.434441ms)
Feb 19 04:46:48.756: INFO: (12) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 19.137948ms)
Feb 19 04:46:48.756: INFO: (12) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 19.01953ms)
Feb 19 04:46:48.757: INFO: (12) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 20.542546ms)
Feb 19 04:46:48.758: INFO: (12) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 21.390862ms)
Feb 19 04:46:48.760: INFO: (12) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 23.163705ms)
Feb 19 04:46:48.760: INFO: (12) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 23.32205ms)
Feb 19 04:46:48.760: INFO: (12) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 23.16608ms)
Feb 19 04:46:48.760: INFO: (12) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 23.483742ms)
Feb 19 04:46:48.774: INFO: (13) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 12.200733ms)
Feb 19 04:46:48.774: INFO: (13) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 12.351998ms)
Feb 19 04:46:48.774: INFO: (13) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 12.345902ms)
Feb 19 04:46:48.775: INFO: (13) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 14.205552ms)
Feb 19 04:46:48.775: INFO: (13) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 13.586963ms)
Feb 19 04:46:48.775: INFO: (13) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 13.120625ms)
Feb 19 04:46:48.776: INFO: (13) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 16.138713ms)
Feb 19 04:46:48.777: INFO: (13) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 16.904367ms)
Feb 19 04:46:48.777: INFO: (13) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 16.733047ms)
Feb 19 04:46:48.779: INFO: (13) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 17.876573ms)
Feb 19 04:46:48.779: INFO: (13) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 16.785438ms)
Feb 19 04:46:48.779: INFO: (13) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 17.594916ms)
Feb 19 04:46:48.781: INFO: (13) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 18.84117ms)
Feb 19 04:46:48.781: INFO: (13) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 19.677693ms)
Feb 19 04:46:48.785: INFO: (13) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 23.844636ms)
Feb 19 04:46:48.785: INFO: (13) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 22.919705ms)
Feb 19 04:46:48.799: INFO: (14) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 14.147307ms)
Feb 19 04:46:48.801: INFO: (14) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 15.716146ms)
Feb 19 04:46:48.801: INFO: (14) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.546071ms)
Feb 19 04:46:48.801: INFO: (14) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 15.286153ms)
Feb 19 04:46:48.801: INFO: (14) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 14.691821ms)
Feb 19 04:46:48.801: INFO: (14) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 15.017911ms)
Feb 19 04:46:48.802: INFO: (14) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 16.251598ms)
Feb 19 04:46:48.802: INFO: (14) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 16.630173ms)
Feb 19 04:46:48.802: INFO: (14) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 16.441064ms)
Feb 19 04:46:48.802: INFO: (14) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 16.108236ms)
Feb 19 04:46:48.804: INFO: (14) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 19.185131ms)
Feb 19 04:46:48.804: INFO: (14) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 17.765234ms)
Feb 19 04:46:48.804: INFO: (14) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 17.807031ms)
Feb 19 04:46:48.804: INFO: (14) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 19.133988ms)
Feb 19 04:46:48.804: INFO: (14) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 18.256327ms)
Feb 19 04:46:48.808: INFO: (14) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 21.704251ms)
Feb 19 04:46:48.821: INFO: (15) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 12.858563ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 15.456688ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 15.632193ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 15.728877ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 16.015237ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 15.99595ms)
Feb 19 04:46:48.824: INFO: (15) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 15.984454ms)
Feb 19 04:46:48.826: INFO: (15) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 17.368993ms)
Feb 19 04:46:48.826: INFO: (15) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 17.620521ms)
Feb 19 04:46:48.826: INFO: (15) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 17.379785ms)
Feb 19 04:46:48.826: INFO: (15) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 17.629444ms)
Feb 19 04:46:48.828: INFO: (15) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 19.835957ms)
Feb 19 04:46:48.828: INFO: (15) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 19.997764ms)
Feb 19 04:46:48.842: INFO: (15) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 33.880761ms)
Feb 19 04:46:48.842: INFO: (15) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 33.914072ms)
Feb 19 04:46:48.842: INFO: (15) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 33.717698ms)
Feb 19 04:46:48.854: INFO: (16) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 11.143862ms)
Feb 19 04:46:48.854: INFO: (16) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 11.663696ms)
Feb 19 04:46:48.854: INFO: (16) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 11.098209ms)
Feb 19 04:46:48.856: INFO: (16) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 12.961673ms)
Feb 19 04:46:48.858: INFO: (16) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 14.934999ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 18.236507ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 18.394683ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 18.232433ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 18.389015ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 18.258245ms)
Feb 19 04:46:48.861: INFO: (16) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 18.285655ms)
Feb 19 04:46:48.872: INFO: (16) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 29.339564ms)
Feb 19 04:46:48.872: INFO: (16) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 29.116283ms)
Feb 19 04:46:48.872: INFO: (16) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 29.188374ms)
Feb 19 04:46:48.872: INFO: (16) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 29.382858ms)
Feb 19 04:46:48.872: INFO: (16) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 29.240796ms)
Feb 19 04:46:48.886: INFO: (17) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 13.381263ms)
Feb 19 04:46:48.886: INFO: (17) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 13.488954ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 14.672564ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 14.485153ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 14.426403ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 14.615165ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 14.548093ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 14.540438ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 14.477654ms)
Feb 19 04:46:48.887: INFO: (17) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 14.699735ms)
Feb 19 04:46:48.891: INFO: (17) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 18.126536ms)
Feb 19 04:46:48.892: INFO: (17) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 18.695638ms)
Feb 19 04:46:48.894: INFO: (17) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 21.090555ms)
Feb 19 04:46:48.894: INFO: (17) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 20.982594ms)
Feb 19 04:46:48.896: INFO: (17) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 22.913168ms)
Feb 19 04:46:48.896: INFO: (17) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 22.735312ms)
Feb 19 04:46:48.913: INFO: (18) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 17.302079ms)
Feb 19 04:46:48.913: INFO: (18) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 17.041111ms)
Feb 19 04:46:48.913: INFO: (18) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 17.109197ms)
Feb 19 04:46:48.917: INFO: (18) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 20.463434ms)
Feb 19 04:46:48.917: INFO: (18) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 20.363906ms)
Feb 19 04:46:48.919: INFO: (18) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 22.813074ms)
Feb 19 04:46:48.919: INFO: (18) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 22.894336ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 29.255647ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 28.851151ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 28.794191ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 29.352963ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 28.859153ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 29.15609ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 29.059917ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 28.937231ms)
Feb 19 04:46:48.925: INFO: (18) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 28.857041ms)
Feb 19 04:46:48.936: INFO: (19) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:460/proxy/: tls baz (200; 10.881446ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 11.615679ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">... (200; 11.518266ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:443/proxy/tlsrewritem... (200; 11.428797ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr/proxy/rewriteme">test</a> (200; 11.392609ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 11.548511ms)
Feb 19 04:46:48.937: INFO: (19) /api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/: <a href="/api/v1/namespaces/proxy-1350/pods/proxy-service-m87pp-g5wjr:1080/proxy/rewriteme">test<... (200; 11.584494ms)
Feb 19 04:46:48.938: INFO: (19) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:160/proxy/: foo (200; 11.974808ms)
Feb 19 04:46:48.938: INFO: (19) /api/v1/namespaces/proxy-1350/pods/https:proxy-service-m87pp-g5wjr:462/proxy/: tls qux (200; 11.903946ms)
Feb 19 04:46:48.938: INFO: (19) /api/v1/namespaces/proxy-1350/pods/http:proxy-service-m87pp-g5wjr:162/proxy/: bar (200; 11.956579ms)
Feb 19 04:46:48.940: INFO: (19) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname2/proxy/: tls qux (200; 14.676188ms)
Feb 19 04:46:48.942: INFO: (19) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname1/proxy/: foo (200; 15.864428ms)
Feb 19 04:46:48.942: INFO: (19) /api/v1/namespaces/proxy-1350/services/http:proxy-service-m87pp:portname2/proxy/: bar (200; 16.38633ms)
Feb 19 04:46:48.942: INFO: (19) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname2/proxy/: bar (200; 16.380906ms)
Feb 19 04:46:48.942: INFO: (19) /api/v1/namespaces/proxy-1350/services/https:proxy-service-m87pp:tlsportname1/proxy/: tls baz (200; 16.758142ms)
Feb 19 04:46:48.942: INFO: (19) /api/v1/namespaces/proxy-1350/services/proxy-service-m87pp:portname1/proxy/: foo (200; 16.741625ms)
STEP: deleting ReplicationController proxy-service-m87pp in namespace proxy-1350, will wait for the garbage collector to delete the pods
Feb 19 04:46:49.012: INFO: Deleting ReplicationController proxy-service-m87pp took: 12.999164ms
Feb 19 04:46:49.512: INFO: Terminating ReplicationController proxy-service-m87pp pods took: 500.274447ms
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:51.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1350" for this suite.
Feb 19 04:46:57.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:46:57.586: INFO: namespace proxy-1350 deletion completed in 6.364221268s

• [SLOW TEST:15.243 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:46:57.587: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 04:46:57.655: INFO: Waiting up to 5m0s for pod "pod-b1797725-561c-4ef9-bc59-b10efc38fc21" in namespace "emptydir-9422" to be "success or failure"
Feb 19 04:46:57.662: INFO: Pod "pod-b1797725-561c-4ef9-bc59-b10efc38fc21": Phase="Pending", Reason="", readiness=false. Elapsed: 6.826385ms
Feb 19 04:46:59.669: INFO: Pod "pod-b1797725-561c-4ef9-bc59-b10efc38fc21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013878659s
STEP: Saw pod success
Feb 19 04:46:59.669: INFO: Pod "pod-b1797725-561c-4ef9-bc59-b10efc38fc21" satisfied condition "success or failure"
Feb 19 04:46:59.675: INFO: Trying to get logs from node 10.0.10.2 pod pod-b1797725-561c-4ef9-bc59-b10efc38fc21 container test-container: <nil>
STEP: delete the pod
Feb 19 04:46:59.713: INFO: Waiting for pod pod-b1797725-561c-4ef9-bc59-b10efc38fc21 to disappear
Feb 19 04:46:59.719: INFO: Pod pod-b1797725-561c-4ef9-bc59-b10efc38fc21 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:46:59.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9422" for this suite.
Feb 19 04:47:05.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:47:06.042: INFO: namespace emptydir-9422 deletion completed in 6.316019108s

• [SLOW TEST:8.455 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:47:06.042: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:47:06.401: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6cb19f49-da8f-443e-a809-b8fb019d15c1", Controller:(*bool)(0xc00249293e), BlockOwnerDeletion:(*bool)(0xc00249293f)}}
Feb 19 04:47:06.413: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d9c77140-fa63-4e7b-859f-4f0eff3dab7f", Controller:(*bool)(0xc002f0a73e), BlockOwnerDeletion:(*bool)(0xc002f0a73f)}}
Feb 19 04:47:06.424: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d73bfaaf-337c-48f1-b0ff-a02bd3765cc4", Controller:(*bool)(0xc002ec1e96), BlockOwnerDeletion:(*bool)(0xc002ec1e97)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:47:11.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4029" for this suite.
Feb 19 04:47:17.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:47:17.774: INFO: namespace gc-4029 deletion completed in 6.314543098s

• [SLOW TEST:11.732 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:47:17.775: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d02a34b0-8bc2-44a9-8011-cd290a2e35ff
STEP: Creating a pod to test consume secrets
Feb 19 04:47:17.864: INFO: Waiting up to 5m0s for pod "pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793" in namespace "secrets-830" to be "success or failure"
Feb 19 04:47:17.870: INFO: Pod "pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793": Phase="Pending", Reason="", readiness=false. Elapsed: 6.552124ms
Feb 19 04:47:19.876: INFO: Pod "pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012589558s
STEP: Saw pod success
Feb 19 04:47:19.876: INFO: Pod "pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793" satisfied condition "success or failure"
Feb 19 04:47:19.882: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793 container secret-env-test: <nil>
STEP: delete the pod
Feb 19 04:47:20.013: INFO: Waiting for pod pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793 to disappear
Feb 19 04:47:20.021: INFO: Pod pod-secrets-604a572b-e1d9-4a77-9fdb-9065cbc1c793 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:47:20.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-830" for this suite.
Feb 19 04:47:26.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:47:26.240: INFO: namespace secrets-830 deletion completed in 6.212512899s

• [SLOW TEST:8.465 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:47:26.240: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-09e5c568-18c1-4470-b395-8df34e1627c6
STEP: Creating configMap with name cm-test-opt-upd-4592d255-069e-4b17-b14a-751fd482e1ae
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-09e5c568-18c1-4470-b395-8df34e1627c6
STEP: Updating configmap cm-test-opt-upd-4592d255-069e-4b17-b14a-751fd482e1ae
STEP: Creating configMap with name cm-test-opt-create-995e214b-2471-4566-9cda-e80a1351e1f5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:48:40.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9771" for this suite.
Feb 19 04:49:02.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:49:03.218: INFO: namespace configmap-9771 deletion completed in 22.518683524s

• [SLOW TEST:96.977 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:49:03.218: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 19 04:49:06.330: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:49:07.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6015" for this suite.
Feb 19 04:49:29.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:49:30.075: INFO: namespace replicaset-6015 deletion completed in 22.566350859s

• [SLOW TEST:26.858 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:49:30.076: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:49:35.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9228" for this suite.
Feb 19 04:49:42.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:49:42.213: INFO: namespace watch-9228 deletion completed in 6.528249927s

• [SLOW TEST:12.137 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:49:42.214: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:49:42.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0" in namespace "projected-552" to be "success or failure"
Feb 19 04:49:42.501: INFO: Pod "downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.641239ms
Feb 19 04:49:44.507: INFO: Pod "downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01421064s
Feb 19 04:49:46.516: INFO: Pod "downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022551124s
STEP: Saw pod success
Feb 19 04:49:46.516: INFO: Pod "downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0" satisfied condition "success or failure"
Feb 19 04:49:46.522: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0 container client-container: <nil>
STEP: delete the pod
Feb 19 04:49:46.556: INFO: Waiting for pod downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0 to disappear
Feb 19 04:49:46.562: INFO: Pod downwardapi-volume-392f5d61-a372-468b-bb20-a6333add1fb0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:49:46.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-552" for this suite.
Feb 19 04:49:52.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:49:53.015: INFO: namespace projected-552 deletion completed in 6.446492296s

• [SLOW TEST:10.802 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:49:53.016: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:49:53.184: INFO: Waiting up to 5m0s for pod "downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df" in namespace "downward-api-172" to be "success or failure"
Feb 19 04:49:53.192: INFO: Pod "downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.762355ms
Feb 19 04:49:55.303: INFO: Pod "downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.118913342s
STEP: Saw pod success
Feb 19 04:49:55.303: INFO: Pod "downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df" satisfied condition "success or failure"
Feb 19 04:49:55.350: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df container client-container: <nil>
STEP: delete the pod
Feb 19 04:49:55.428: INFO: Waiting for pod downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df to disappear
Feb 19 04:49:55.443: INFO: Pod downwardapi-volume-76b94efd-69ea-4032-b5cf-376a4c1ac4df no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:49:55.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-172" for this suite.
Feb 19 04:50:01.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:50:01.691: INFO: namespace downward-api-172 deletion completed in 6.238197317s

• [SLOW TEST:8.676 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:50:01.692: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:50:02.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692" in namespace "downward-api-4361" to be "success or failure"
Feb 19 04:50:02.074: INFO: Pod "downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692": Phase="Pending", Reason="", readiness=false. Elapsed: 50.345167ms
Feb 19 04:50:04.312: INFO: Pod "downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.288336638s
STEP: Saw pod success
Feb 19 04:50:04.312: INFO: Pod "downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692" satisfied condition "success or failure"
Feb 19 04:50:04.332: INFO: Trying to get logs from node 10.0.10.4 pod downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692 container client-container: <nil>
STEP: delete the pod
Feb 19 04:50:04.374: INFO: Waiting for pod downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692 to disappear
Feb 19 04:50:04.382: INFO: Pod downwardapi-volume-4d647366-e07d-4a93-a3f3-404664fb3692 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:50:04.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4361" for this suite.
Feb 19 04:50:10.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:50:10.604: INFO: namespace downward-api-4361 deletion completed in 6.215826957s

• [SLOW TEST:8.912 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:50:10.604: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Feb 19 04:50:10.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 --namespace=kubectl-2158 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 19 04:50:12.480: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 19 04:50:12.480: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:50:14.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2158" for this suite.
Feb 19 04:50:20.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:50:21.135: INFO: namespace kubectl-2158 deletion completed in 6.222425548s

• [SLOW TEST:10.531 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:50:21.136: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-2895
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2895 to expose endpoints map[]
Feb 19 04:50:21.451: INFO: successfully validated that service endpoint-test2 in namespace services-2895 exposes endpoints map[] (7.116309ms elapsed)
STEP: Creating pod pod1 in namespace services-2895
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2895 to expose endpoints map[pod1:[80]]
Feb 19 04:50:23.670: INFO: successfully validated that service endpoint-test2 in namespace services-2895 exposes endpoints map[pod1:[80]] (2.206741079s elapsed)
STEP: Creating pod pod2 in namespace services-2895
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2895 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 19 04:50:28.179: INFO: Unexpected endpoints: found map[3e9294d4-10c2-4018-8d04-f50f5036d268:[80]], expected map[pod1:[80] pod2:[80]] (4.500757075s elapsed, will retry)
Feb 19 04:50:32.681: INFO: successfully validated that service endpoint-test2 in namespace services-2895 exposes endpoints map[pod1:[80] pod2:[80]] (9.002238813s elapsed)
STEP: Deleting pod pod1 in namespace services-2895
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2895 to expose endpoints map[pod2:[80]]
Feb 19 04:50:32.704: INFO: successfully validated that service endpoint-test2 in namespace services-2895 exposes endpoints map[pod2:[80]] (11.193761ms elapsed)
STEP: Deleting pod pod2 in namespace services-2895
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2895 to expose endpoints map[]
Feb 19 04:50:32.722: INFO: successfully validated that service endpoint-test2 in namespace services-2895 exposes endpoints map[] (6.086203ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:50:32.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2895" for this suite.
Feb 19 04:50:56.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:50:56.981: INFO: namespace services-2895 deletion completed in 24.217037636s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:35.845 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:50:56.981: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:50:57.278: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 19 04:50:59.579: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:51:00.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2109" for this suite.
Feb 19 04:51:06.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:51:07.233: INFO: namespace replication-controller-2109 deletion completed in 6.60216539s

• [SLOW TEST:10.252 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:51:07.233: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Feb 19 04:51:07.311: INFO: Waiting up to 5m0s for pod "var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75" in namespace "var-expansion-4817" to be "success or failure"
Feb 19 04:51:07.320: INFO: Pod "var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75": Phase="Pending", Reason="", readiness=false. Elapsed: 9.200752ms
Feb 19 04:51:09.356: INFO: Pod "var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044618923s
STEP: Saw pod success
Feb 19 04:51:09.356: INFO: Pod "var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75" satisfied condition "success or failure"
Feb 19 04:51:09.385: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75 container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:51:09.516: INFO: Waiting for pod var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75 to disappear
Feb 19 04:51:09.525: INFO: Pod var-expansion-dddc5f64-e1ea-4395-a88e-a417cf16cc75 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:51:09.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4817" for this suite.
Feb 19 04:51:15.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:51:15.756: INFO: namespace var-expansion-4817 deletion completed in 6.222307569s

• [SLOW TEST:8.523 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:51:15.757: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 04:51:16.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c" in namespace "projected-8134" to be "success or failure"
Feb 19 04:51:16.099: INFO: Pod "downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.709988ms
Feb 19 04:51:18.293: INFO: Pod "downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.207873145s
STEP: Saw pod success
Feb 19 04:51:18.293: INFO: Pod "downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c" satisfied condition "success or failure"
Feb 19 04:51:18.336: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c container client-container: <nil>
STEP: delete the pod
Feb 19 04:51:18.403: INFO: Waiting for pod downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c to disappear
Feb 19 04:51:18.415: INFO: Pod downwardapi-volume-b68c6f0d-f9ab-48ec-a4c4-335348ecc51c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:51:18.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8134" for this suite.
Feb 19 04:51:24.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:51:24.651: INFO: namespace projected-8134 deletion completed in 6.22848557s

• [SLOW TEST:8.894 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:51:24.652: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:51:24.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4275'
Feb 19 04:51:24.805: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 19 04:51:24.805: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Feb 19 04:51:24.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete jobs e2e-test-nginx-job --namespace=kubectl-4275'
Feb 19 04:51:25.086: INFO: stderr: ""
Feb 19 04:51:25.086: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:51:25.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4275" for this suite.
Feb 19 04:51:49.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:51:50.024: INFO: namespace kubectl-4275 deletion completed in 24.907767782s

• [SLOW TEST:25.373 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:51:50.025: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6415
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 04:51:50.253: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 04:52:20.596: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.168 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6415 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:52:20.596: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:52:22.277: INFO: Found all expected endpoints: [netserver-0]
Feb 19 04:52:22.555: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.41 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6415 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:52:22.555: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:52:23.916: INFO: Found all expected endpoints: [netserver-1]
Feb 19 04:52:23.929: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.37 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6415 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:52:23.929: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:52:26.268: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:52:26.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6415" for this suite.
Feb 19 04:52:50.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:52:50.719: INFO: namespace pod-network-test-6415 deletion completed in 24.440411353s

• [SLOW TEST:60.695 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:52:50.720: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 19 04:52:50.823: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:52:54.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1297" for this suite.
Feb 19 04:53:02.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:53:03.092: INFO: namespace init-container-1297 deletion completed in 8.919453932s

• [SLOW TEST:12.372 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:53:03.092: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 04:53:03.198: INFO: Waiting up to 5m0s for pod "pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a" in namespace "emptydir-4497" to be "success or failure"
Feb 19 04:53:03.213: INFO: Pod "pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.86644ms
Feb 19 04:53:05.330: INFO: Pod "pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.132067235s
Feb 19 04:53:07.554: INFO: Pod "pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.35614751s
STEP: Saw pod success
Feb 19 04:53:07.554: INFO: Pod "pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a" satisfied condition "success or failure"
Feb 19 04:53:07.565: INFO: Trying to get logs from node 10.0.10.2 pod pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a container test-container: <nil>
STEP: delete the pod
Feb 19 04:53:07.654: INFO: Waiting for pod pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a to disappear
Feb 19 04:53:07.664: INFO: Pod pod-2c4c060c-42e1-4d8d-a939-5c4c8903882a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:53:07.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4497" for this suite.
Feb 19 04:53:13.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:53:14.502: INFO: namespace emptydir-4497 deletion completed in 6.826128698s

• [SLOW TEST:11.410 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:53:14.503: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f9cd9380-7753-4f22-8015-935bfc94d4de
STEP: Creating a pod to test consume configMaps
Feb 19 04:53:14.920: INFO: Waiting up to 5m0s for pod "pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a" in namespace "configmap-6420" to be "success or failure"
Feb 19 04:53:14.936: INFO: Pod "pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.114183ms
Feb 19 04:53:17.194: INFO: Pod "pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.273520853s
STEP: Saw pod success
Feb 19 04:53:17.194: INFO: Pod "pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a" satisfied condition "success or failure"
Feb 19 04:53:17.207: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:53:17.254: INFO: Waiting for pod pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a to disappear
Feb 19 04:53:17.266: INFO: Pod pod-configmaps-139349e6-026f-4754-b8a1-0a08351e487a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:53:17.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6420" for this suite.
Feb 19 04:53:23.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:53:24.041: INFO: namespace configmap-6420 deletion completed in 6.76399604s

• [SLOW TEST:9.538 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:53:24.042: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 04:53:24.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9496'
Feb 19 04:53:24.339: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 19 04:53:24.339: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 19 04:53:24.349: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 19 04:53:24.354: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 19 04:53:24.363: INFO: scanned /root for discovery docs: <nil>
Feb 19 04:53:24.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9496'
Feb 19 04:53:40.405: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 04:53:40.405: INFO: stdout: "Created e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02\nScaling up e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 19 04:53:40.405: INFO: stdout: "Created e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02\nScaling up e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 19 04:53:40.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9496'
Feb 19 04:53:40.485: INFO: stderr: ""
Feb 19 04:53:40.485: INFO: stdout: "e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02-hxdlr "
Feb 19 04:53:40.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02-hxdlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9496'
Feb 19 04:53:41.562: INFO: stderr: ""
Feb 19 04:53:41.562: INFO: stdout: "true"
Feb 19 04:53:41.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02-hxdlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9496'
Feb 19 04:53:41.639: INFO: stderr: ""
Feb 19 04:53:41.639: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 19 04:53:41.639: INFO: e2e-test-nginx-rc-f57699c1d7b27ff3692fa682f89c6d02-hxdlr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Feb 19 04:53:41.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete rc e2e-test-nginx-rc --namespace=kubectl-9496'
Feb 19 04:53:41.727: INFO: stderr: ""
Feb 19 04:53:41.727: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:53:41.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9496" for this suite.
Feb 19 04:54:06.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:54:06.218: INFO: namespace kubectl-9496 deletion completed in 24.261854842s

• [SLOW TEST:42.177 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:54:06.219: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 04:54:06.639: INFO: Waiting up to 5m0s for pod "pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46" in namespace "emptydir-7076" to be "success or failure"
Feb 19 04:54:06.650: INFO: Pod "pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46": Phase="Pending", Reason="", readiness=false. Elapsed: 10.525292ms
Feb 19 04:54:08.733: INFO: Pod "pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093006692s
STEP: Saw pod success
Feb 19 04:54:08.733: INFO: Pod "pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46" satisfied condition "success or failure"
Feb 19 04:54:08.797: INFO: Trying to get logs from node 10.0.10.2 pod pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46 container test-container: <nil>
STEP: delete the pod
Feb 19 04:54:09.033: INFO: Waiting for pod pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46 to disappear
Feb 19 04:54:09.039: INFO: Pod pod-0ca4ddcb-f67b-48ec-bfec-f65d5bf05a46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:54:09.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7076" for this suite.
Feb 19 04:54:15.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:54:15.660: INFO: namespace emptydir-7076 deletion completed in 6.61507838s

• [SLOW TEST:9.441 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:54:15.660: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-8d7dfda2-af6e-4c5b-ad0a-67fa9e7f770f
STEP: Creating a pod to test consume configMaps
Feb 19 04:54:15.818: INFO: Waiting up to 5m0s for pod "pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871" in namespace "configmap-774" to be "success or failure"
Feb 19 04:54:15.825: INFO: Pod "pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871": Phase="Pending", Reason="", readiness=false. Elapsed: 6.936983ms
Feb 19 04:54:17.857: INFO: Pod "pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039216209s
STEP: Saw pod success
Feb 19 04:54:17.857: INFO: Pod "pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871" satisfied condition "success or failure"
Feb 19 04:54:17.887: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 04:54:18.000: INFO: Waiting for pod pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871 to disappear
Feb 19 04:54:18.007: INFO: Pod pod-configmaps-9be38d42-1d7a-420b-b7a1-8d6559216871 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:54:18.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-774" for this suite.
Feb 19 04:54:24.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:54:24.714: INFO: namespace configmap-774 deletion completed in 6.700517199s

• [SLOW TEST:9.053 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:54:24.714: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3008
I0219 04:54:24.778368      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3008, replica count: 1
I0219 04:54:25.828811      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 04:54:26.829079      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 04:54:26.944: INFO: Created: latency-svc-hlqd4
Feb 19 04:54:26.951: INFO: Got endpoints: latency-svc-hlqd4 [22.101133ms]
Feb 19 04:54:26.965: INFO: Created: latency-svc-s8ccf
Feb 19 04:54:26.970: INFO: Got endpoints: latency-svc-s8ccf [18.899442ms]
Feb 19 04:54:26.973: INFO: Created: latency-svc-gr92g
Feb 19 04:54:26.978: INFO: Got endpoints: latency-svc-gr92g [26.876967ms]
Feb 19 04:54:26.981: INFO: Created: latency-svc-lndh7
Feb 19 04:54:26.986: INFO: Created: latency-svc-s9tnv
Feb 19 04:54:26.988: INFO: Got endpoints: latency-svc-lndh7 [35.940017ms]
Feb 19 04:54:26.990: INFO: Got endpoints: latency-svc-s9tnv [37.913419ms]
Feb 19 04:54:26.993: INFO: Created: latency-svc-l2cpn
Feb 19 04:54:26.998: INFO: Got endpoints: latency-svc-l2cpn [45.816492ms]
Feb 19 04:54:26.999: INFO: Created: latency-svc-dk8l5
Feb 19 04:54:27.004: INFO: Got endpoints: latency-svc-dk8l5 [51.461584ms]
Feb 19 04:54:27.006: INFO: Created: latency-svc-zhwl6
Feb 19 04:54:27.012: INFO: Got endpoints: latency-svc-zhwl6 [58.794638ms]
Feb 19 04:54:27.016: INFO: Created: latency-svc-hgtxp
Feb 19 04:54:27.020: INFO: Got endpoints: latency-svc-hgtxp [66.935638ms]
Feb 19 04:54:27.023: INFO: Created: latency-svc-7kmhf
Feb 19 04:54:27.028: INFO: Got endpoints: latency-svc-7kmhf [74.904216ms]
Feb 19 04:54:27.032: INFO: Created: latency-svc-8pnzn
Feb 19 04:54:27.037: INFO: Got endpoints: latency-svc-8pnzn [83.726813ms]
Feb 19 04:54:27.041: INFO: Created: latency-svc-f5pjq
Feb 19 04:54:27.047: INFO: Got endpoints: latency-svc-f5pjq [92.258979ms]
Feb 19 04:54:27.051: INFO: Created: latency-svc-t7bwc
Feb 19 04:54:27.055: INFO: Got endpoints: latency-svc-t7bwc [100.896606ms]
Feb 19 04:54:27.056: INFO: Created: latency-svc-dll6f
Feb 19 04:54:27.062: INFO: Got endpoints: latency-svc-dll6f [107.727326ms]
Feb 19 04:54:27.064: INFO: Created: latency-svc-9bwjw
Feb 19 04:54:27.069: INFO: Got endpoints: latency-svc-9bwjw [114.648819ms]
Feb 19 04:54:27.071: INFO: Created: latency-svc-nzs5z
Feb 19 04:54:27.076: INFO: Got endpoints: latency-svc-nzs5z [121.182011ms]
Feb 19 04:54:27.078: INFO: Created: latency-svc-tvpxq
Feb 19 04:54:27.083: INFO: Got endpoints: latency-svc-tvpxq [112.742308ms]
Feb 19 04:54:27.086: INFO: Created: latency-svc-zjpcm
Feb 19 04:54:27.093: INFO: Got endpoints: latency-svc-zjpcm [114.420821ms]
Feb 19 04:54:27.093: INFO: Created: latency-svc-9wz8s
Feb 19 04:54:27.098: INFO: Got endpoints: latency-svc-9wz8s [110.737526ms]
Feb 19 04:54:27.103: INFO: Created: latency-svc-4kcnf
Feb 19 04:54:27.108: INFO: Got endpoints: latency-svc-4kcnf [118.399186ms]
Feb 19 04:54:27.109: INFO: Created: latency-svc-r4vrf
Feb 19 04:54:27.114: INFO: Got endpoints: latency-svc-r4vrf [115.820767ms]
Feb 19 04:54:27.122: INFO: Created: latency-svc-q9rqw
Feb 19 04:54:27.125: INFO: Got endpoints: latency-svc-q9rqw [121.250951ms]
Feb 19 04:54:27.131: INFO: Created: latency-svc-7wqx5
Feb 19 04:54:27.136: INFO: Got endpoints: latency-svc-7wqx5 [123.866636ms]
Feb 19 04:54:27.138: INFO: Created: latency-svc-ssnxl
Feb 19 04:54:27.144: INFO: Got endpoints: latency-svc-ssnxl [124.010252ms]
Feb 19 04:54:27.144: INFO: Created: latency-svc-hz7n8
Feb 19 04:54:27.153: INFO: Created: latency-svc-gcmfr
Feb 19 04:54:27.153: INFO: Got endpoints: latency-svc-hz7n8 [124.920698ms]
Feb 19 04:54:27.158: INFO: Got endpoints: latency-svc-gcmfr [121.001419ms]
Feb 19 04:54:27.162: INFO: Created: latency-svc-h9pch
Feb 19 04:54:27.166: INFO: Got endpoints: latency-svc-h9pch [119.841767ms]
Feb 19 04:54:27.170: INFO: Created: latency-svc-qpg29
Feb 19 04:54:27.174: INFO: Got endpoints: latency-svc-qpg29 [118.67556ms]
Feb 19 04:54:27.175: INFO: Created: latency-svc-2qfw7
Feb 19 04:54:27.180: INFO: Got endpoints: latency-svc-2qfw7 [118.448765ms]
Feb 19 04:54:27.184: INFO: Created: latency-svc-bhnw9
Feb 19 04:54:27.188: INFO: Got endpoints: latency-svc-bhnw9 [119.585554ms]
Feb 19 04:54:27.191: INFO: Created: latency-svc-65v2b
Feb 19 04:54:27.195: INFO: Got endpoints: latency-svc-65v2b [119.370668ms]
Feb 19 04:54:27.198: INFO: Created: latency-svc-j4pt7
Feb 19 04:54:27.204: INFO: Got endpoints: latency-svc-j4pt7 [121.151211ms]
Feb 19 04:54:27.205: INFO: Created: latency-svc-gp49m
Feb 19 04:54:27.210: INFO: Got endpoints: latency-svc-gp49m [116.815515ms]
Feb 19 04:54:27.213: INFO: Created: latency-svc-477jq
Feb 19 04:54:27.222: INFO: Got endpoints: latency-svc-477jq [123.273446ms]
Feb 19 04:54:27.224: INFO: Created: latency-svc-hbm5g
Feb 19 04:54:27.230: INFO: Got endpoints: latency-svc-hbm5g [121.298523ms]
Feb 19 04:54:27.233: INFO: Created: latency-svc-fdslg
Feb 19 04:54:27.240: INFO: Created: latency-svc-6wwrr
Feb 19 04:54:27.247: INFO: Created: latency-svc-ff286
Feb 19 04:54:27.251: INFO: Got endpoints: latency-svc-fdslg [136.872876ms]
Feb 19 04:54:27.254: INFO: Created: latency-svc-zg8xx
Feb 19 04:54:27.267: INFO: Created: latency-svc-fqfg9
Feb 19 04:54:27.267: INFO: Created: latency-svc-v8vn9
Feb 19 04:54:27.274: INFO: Created: latency-svc-m6tfv
Feb 19 04:54:27.281: INFO: Created: latency-svc-tqxph
Feb 19 04:54:27.287: INFO: Created: latency-svc-wbrx8
Feb 19 04:54:27.296: INFO: Created: latency-svc-qsh5m
Feb 19 04:54:27.300: INFO: Got endpoints: latency-svc-6wwrr [174.531021ms]
Feb 19 04:54:27.303: INFO: Created: latency-svc-2c684
Feb 19 04:54:27.310: INFO: Created: latency-svc-jr8rt
Feb 19 04:54:27.317: INFO: Created: latency-svc-lcntg
Feb 19 04:54:27.325: INFO: Created: latency-svc-wddrg
Feb 19 04:54:27.332: INFO: Created: latency-svc-mrt2t
Feb 19 04:54:27.338: INFO: Created: latency-svc-4jmjd
Feb 19 04:54:27.350: INFO: Created: latency-svc-4nmfj
Feb 19 04:54:27.351: INFO: Got endpoints: latency-svc-ff286 [215.460338ms]
Feb 19 04:54:27.366: INFO: Created: latency-svc-hkww4
Feb 19 04:54:27.401: INFO: Got endpoints: latency-svc-zg8xx [256.951299ms]
Feb 19 04:54:27.419: INFO: Created: latency-svc-x4f7f
Feb 19 04:54:27.451: INFO: Got endpoints: latency-svc-v8vn9 [297.451479ms]
Feb 19 04:54:27.466: INFO: Created: latency-svc-t8j2d
Feb 19 04:54:27.502: INFO: Got endpoints: latency-svc-fqfg9 [343.708372ms]
Feb 19 04:54:27.518: INFO: Created: latency-svc-xlr6c
Feb 19 04:54:27.552: INFO: Got endpoints: latency-svc-m6tfv [385.66894ms]
Feb 19 04:54:27.567: INFO: Created: latency-svc-rtpjp
Feb 19 04:54:27.603: INFO: Got endpoints: latency-svc-tqxph [429.056527ms]
Feb 19 04:54:27.622: INFO: Created: latency-svc-gq2w9
Feb 19 04:54:27.651: INFO: Got endpoints: latency-svc-wbrx8 [470.487408ms]
Feb 19 04:54:27.665: INFO: Created: latency-svc-rhrvx
Feb 19 04:54:27.880: INFO: Got endpoints: latency-svc-jr8rt [676.254576ms]
Feb 19 04:54:27.881: INFO: Got endpoints: latency-svc-qsh5m [692.511019ms]
Feb 19 04:54:27.881: INFO: Got endpoints: latency-svc-lcntg [671.27045ms]
Feb 19 04:54:27.882: INFO: Got endpoints: latency-svc-2c684 [686.674551ms]
Feb 19 04:54:27.902: INFO: Got endpoints: latency-svc-wddrg [680.633697ms]
Feb 19 04:54:27.903: INFO: Created: latency-svc-hbtq7
Feb 19 04:54:27.912: INFO: Created: latency-svc-hwnwp
Feb 19 04:54:27.920: INFO: Created: latency-svc-cntgg
Feb 19 04:54:27.929: INFO: Created: latency-svc-k4w68
Feb 19 04:54:27.941: INFO: Created: latency-svc-7ww5c
Feb 19 04:54:27.950: INFO: Got endpoints: latency-svc-mrt2t [720.342923ms]
Feb 19 04:54:27.965: INFO: Created: latency-svc-8ss28
Feb 19 04:54:28.001: INFO: Got endpoints: latency-svc-4jmjd [749.651233ms]
Feb 19 04:54:28.016: INFO: Created: latency-svc-rp5pk
Feb 19 04:54:28.051: INFO: Got endpoints: latency-svc-4nmfj [751.189568ms]
Feb 19 04:54:28.067: INFO: Created: latency-svc-wvdwr
Feb 19 04:54:28.103: INFO: Got endpoints: latency-svc-hkww4 [752.079994ms]
Feb 19 04:54:28.119: INFO: Created: latency-svc-k242j
Feb 19 04:54:28.150: INFO: Got endpoints: latency-svc-x4f7f [748.912466ms]
Feb 19 04:54:28.165: INFO: Created: latency-svc-g27gz
Feb 19 04:54:28.201: INFO: Got endpoints: latency-svc-t8j2d [750.403595ms]
Feb 19 04:54:28.215: INFO: Created: latency-svc-hgd2r
Feb 19 04:54:28.443: INFO: Got endpoints: latency-svc-xlr6c [940.527506ms]
Feb 19 04:54:28.445: INFO: Got endpoints: latency-svc-rtpjp [892.992315ms]
Feb 19 04:54:28.446: INFO: Got endpoints: latency-svc-gq2w9 [842.753962ms]
Feb 19 04:54:28.449: INFO: Got endpoints: latency-svc-rhrvx [798.405119ms]
Feb 19 04:54:28.452: INFO: Got endpoints: latency-svc-hbtq7 [571.230843ms]
Feb 19 04:54:28.463: INFO: Created: latency-svc-p8cxv
Feb 19 04:54:28.469: INFO: Created: latency-svc-mjkl2
Feb 19 04:54:28.476: INFO: Created: latency-svc-lmp4c
Feb 19 04:54:28.485: INFO: Created: latency-svc-zqb46
Feb 19 04:54:28.492: INFO: Created: latency-svc-5ss4m
Feb 19 04:54:28.501: INFO: Got endpoints: latency-svc-hwnwp [620.986891ms]
Feb 19 04:54:28.515: INFO: Created: latency-svc-xl66r
Feb 19 04:54:28.551: INFO: Got endpoints: latency-svc-cntgg [669.498226ms]
Feb 19 04:54:28.566: INFO: Created: latency-svc-8t5kn
Feb 19 04:54:28.601: INFO: Got endpoints: latency-svc-k4w68 [719.004781ms]
Feb 19 04:54:28.615: INFO: Created: latency-svc-l68ml
Feb 19 04:54:28.860: INFO: Got endpoints: latency-svc-7ww5c [957.496088ms]
Feb 19 04:54:28.866: INFO: Got endpoints: latency-svc-rp5pk [865.664029ms]
Feb 19 04:54:28.867: INFO: Got endpoints: latency-svc-8ss28 [916.730874ms]
Feb 19 04:54:28.870: INFO: Got endpoints: latency-svc-k242j [766.868278ms]
Feb 19 04:54:28.870: INFO: Got endpoints: latency-svc-wvdwr [818.734657ms]
Feb 19 04:54:28.959: INFO: Created: latency-svc-ncmdg
Feb 19 04:54:28.959: INFO: Created: latency-svc-r2rch
Feb 19 04:54:28.959: INFO: Created: latency-svc-s7c88
Feb 19 04:54:28.959: INFO: Created: latency-svc-x8c9t
Feb 19 04:54:28.959: INFO: Got endpoints: latency-svc-g27gz [809.06433ms]
Feb 19 04:54:28.960: INFO: Created: latency-svc-m2gnz
Feb 19 04:54:28.985: INFO: Got endpoints: latency-svc-hgd2r [783.49609ms]
Feb 19 04:54:28.995: INFO: Created: latency-svc-d9wk5
Feb 19 04:54:29.008: INFO: Created: latency-svc-grnd7
Feb 19 04:54:29.182: INFO: Got endpoints: latency-svc-p8cxv [738.929867ms]
Feb 19 04:54:29.187: INFO: Got endpoints: latency-svc-lmp4c [740.540129ms]
Feb 19 04:54:29.187: INFO: Got endpoints: latency-svc-mjkl2 [741.404729ms]
Feb 19 04:54:29.187: INFO: Got endpoints: latency-svc-zqb46 [737.887931ms]
Feb 19 04:54:29.196: INFO: Created: latency-svc-b5zvf
Feb 19 04:54:29.199: INFO: Got endpoints: latency-svc-5ss4m [747.262761ms]
Feb 19 04:54:29.203: INFO: Created: latency-svc-6tgjq
Feb 19 04:54:29.209: INFO: Created: latency-svc-5jdhm
Feb 19 04:54:29.216: INFO: Created: latency-svc-xqmkk
Feb 19 04:54:29.222: INFO: Created: latency-svc-md7jg
Feb 19 04:54:29.251: INFO: Got endpoints: latency-svc-xl66r [749.419268ms]
Feb 19 04:54:29.266: INFO: Created: latency-svc-p8v78
Feb 19 04:54:29.301: INFO: Got endpoints: latency-svc-8t5kn [750.502157ms]
Feb 19 04:54:29.319: INFO: Created: latency-svc-97d5q
Feb 19 04:54:29.352: INFO: Got endpoints: latency-svc-l68ml [751.230588ms]
Feb 19 04:54:29.368: INFO: Created: latency-svc-njck7
Feb 19 04:54:29.402: INFO: Got endpoints: latency-svc-m2gnz [542.205626ms]
Feb 19 04:54:29.417: INFO: Created: latency-svc-2b7kr
Feb 19 04:54:29.452: INFO: Got endpoints: latency-svc-ncmdg [585.178882ms]
Feb 19 04:54:29.466: INFO: Created: latency-svc-dlnn5
Feb 19 04:54:29.502: INFO: Got endpoints: latency-svc-s7c88 [635.202026ms]
Feb 19 04:54:29.517: INFO: Created: latency-svc-pdmfv
Feb 19 04:54:29.552: INFO: Got endpoints: latency-svc-x8c9t [682.171418ms]
Feb 19 04:54:29.570: INFO: Created: latency-svc-5fsj6
Feb 19 04:54:29.602: INFO: Got endpoints: latency-svc-r2rch [731.833223ms]
Feb 19 04:54:29.626: INFO: Created: latency-svc-86vhx
Feb 19 04:54:29.653: INFO: Got endpoints: latency-svc-d9wk5 [693.286034ms]
Feb 19 04:54:29.668: INFO: Created: latency-svc-pzpk7
Feb 19 04:54:29.701: INFO: Got endpoints: latency-svc-grnd7 [716.316918ms]
Feb 19 04:54:29.716: INFO: Created: latency-svc-tzrqx
Feb 19 04:54:29.750: INFO: Got endpoints: latency-svc-b5zvf [568.552432ms]
Feb 19 04:54:29.765: INFO: Created: latency-svc-fjnhw
Feb 19 04:54:29.800: INFO: Got endpoints: latency-svc-6tgjq [613.484809ms]
Feb 19 04:54:29.815: INFO: Created: latency-svc-rltcp
Feb 19 04:54:29.851: INFO: Got endpoints: latency-svc-5jdhm [664.539933ms]
Feb 19 04:54:29.866: INFO: Created: latency-svc-v2tgl
Feb 19 04:54:29.900: INFO: Got endpoints: latency-svc-xqmkk [713.117203ms]
Feb 19 04:54:29.915: INFO: Created: latency-svc-kl4mm
Feb 19 04:54:30.141: INFO: Got endpoints: latency-svc-97d5q [839.167991ms]
Feb 19 04:54:30.141: INFO: Got endpoints: latency-svc-md7jg [941.201282ms]
Feb 19 04:54:30.141: INFO: Got endpoints: latency-svc-p8v78 [890.046308ms]
Feb 19 04:54:30.142: INFO: Got endpoints: latency-svc-njck7 [789.532577ms]
Feb 19 04:54:30.152: INFO: Got endpoints: latency-svc-2b7kr [749.2891ms]
Feb 19 04:54:30.158: INFO: Created: latency-svc-rpfjx
Feb 19 04:54:30.165: INFO: Created: latency-svc-v8snj
Feb 19 04:54:30.174: INFO: Created: latency-svc-h5pzn
Feb 19 04:54:30.181: INFO: Created: latency-svc-jplbp
Feb 19 04:54:30.195: INFO: Created: latency-svc-g4zlt
Feb 19 04:54:30.201: INFO: Got endpoints: latency-svc-dlnn5 [749.149748ms]
Feb 19 04:54:30.218: INFO: Created: latency-svc-q4lck
Feb 19 04:54:30.252: INFO: Got endpoints: latency-svc-pdmfv [750.289778ms]
Feb 19 04:54:30.268: INFO: Created: latency-svc-fg4cp
Feb 19 04:54:30.300: INFO: Got endpoints: latency-svc-5fsj6 [748.014147ms]
Feb 19 04:54:30.314: INFO: Created: latency-svc-sc5sk
Feb 19 04:54:30.351: INFO: Got endpoints: latency-svc-86vhx [748.994668ms]
Feb 19 04:54:30.366: INFO: Created: latency-svc-fmsmz
Feb 19 04:54:30.401: INFO: Got endpoints: latency-svc-pzpk7 [748.480515ms]
Feb 19 04:54:30.419: INFO: Created: latency-svc-jrt5j
Feb 19 04:54:30.450: INFO: Got endpoints: latency-svc-tzrqx [749.200849ms]
Feb 19 04:54:30.466: INFO: Created: latency-svc-bdfxt
Feb 19 04:54:30.687: INFO: Got endpoints: latency-svc-fjnhw [937.047868ms]
Feb 19 04:54:30.690: INFO: Got endpoints: latency-svc-rltcp [889.29856ms]
Feb 19 04:54:30.691: INFO: Got endpoints: latency-svc-kl4mm [790.564422ms]
Feb 19 04:54:30.691: INFO: Got endpoints: latency-svc-v2tgl [839.917748ms]
Feb 19 04:54:30.702: INFO: Got endpoints: latency-svc-rpfjx [561.361036ms]
Feb 19 04:54:30.707: INFO: Created: latency-svc-mf9f5
Feb 19 04:54:30.715: INFO: Created: latency-svc-lvgfj
Feb 19 04:54:30.722: INFO: Created: latency-svc-g6gwf
Feb 19 04:54:30.729: INFO: Created: latency-svc-lg757
Feb 19 04:54:30.735: INFO: Created: latency-svc-7ks2l
Feb 19 04:54:30.750: INFO: Got endpoints: latency-svc-v8snj [609.283021ms]
Feb 19 04:54:30.771: INFO: Created: latency-svc-zjtc7
Feb 19 04:54:30.801: INFO: Got endpoints: latency-svc-h5pzn [659.955089ms]
Feb 19 04:54:30.817: INFO: Created: latency-svc-jvxzh
Feb 19 04:54:30.850: INFO: Got endpoints: latency-svc-jplbp [708.548002ms]
Feb 19 04:54:30.865: INFO: Created: latency-svc-hnmls
Feb 19 04:54:31.086: INFO: Got endpoints: latency-svc-g4zlt [933.992116ms]
Feb 19 04:54:31.100: INFO: Got endpoints: latency-svc-q4lck [898.970267ms]
Feb 19 04:54:31.108: INFO: Got endpoints: latency-svc-fg4cp [855.276669ms]
Feb 19 04:54:31.216: INFO: Created: latency-svc-nppgr
Feb 19 04:54:31.216: INFO: Got endpoints: latency-svc-fmsmz [865.284398ms]
Feb 19 04:54:31.216: INFO: Got endpoints: latency-svc-sc5sk [916.039537ms]
Feb 19 04:54:31.225: INFO: Got endpoints: latency-svc-jrt5j [823.686406ms]
Feb 19 04:54:31.225: INFO: Created: latency-svc-n2ttz
Feb 19 04:54:31.225: INFO: Created: latency-svc-fnmq6
Feb 19 04:54:31.249: INFO: Got endpoints: latency-svc-bdfxt [798.101982ms]
Feb 19 04:54:31.278: INFO: Created: latency-svc-mxmf5
Feb 19 04:54:31.278: INFO: Created: latency-svc-6xn7n
Feb 19 04:54:31.284: INFO: Created: latency-svc-9ctv4
Feb 19 04:54:31.288: INFO: Created: latency-svc-lphn7
Feb 19 04:54:31.421: INFO: Got endpoints: latency-svc-lvgfj [731.636873ms]
Feb 19 04:54:31.422: INFO: Got endpoints: latency-svc-mf9f5 [734.145513ms]
Feb 19 04:54:31.429: INFO: Got endpoints: latency-svc-g6gwf [737.456502ms]
Feb 19 04:54:31.429: INFO: Got endpoints: latency-svc-lg757 [737.816787ms]
Feb 19 04:54:31.442: INFO: Created: latency-svc-ktwnt
Feb 19 04:54:31.450: INFO: Created: latency-svc-t87tj
Feb 19 04:54:31.451: INFO: Got endpoints: latency-svc-7ks2l [748.345561ms]
Feb 19 04:54:31.457: INFO: Created: latency-svc-22fk5
Feb 19 04:54:31.466: INFO: Created: latency-svc-8fvbk
Feb 19 04:54:31.473: INFO: Created: latency-svc-4kqlf
Feb 19 04:54:31.505: INFO: Got endpoints: latency-svc-zjtc7 [754.554333ms]
Feb 19 04:54:31.536: INFO: Created: latency-svc-jjktb
Feb 19 04:54:31.550: INFO: Got endpoints: latency-svc-jvxzh [749.712344ms]
Feb 19 04:54:31.565: INFO: Created: latency-svc-nn489
Feb 19 04:54:31.601: INFO: Got endpoints: latency-svc-hnmls [750.981158ms]
Feb 19 04:54:31.617: INFO: Created: latency-svc-wbzfw
Feb 19 04:54:31.650: INFO: Got endpoints: latency-svc-nppgr [564.604999ms]
Feb 19 04:54:31.665: INFO: Created: latency-svc-qt62l
Feb 19 04:54:31.700: INFO: Got endpoints: latency-svc-n2ttz [600.409412ms]
Feb 19 04:54:31.715: INFO: Created: latency-svc-86fgr
Feb 19 04:54:31.752: INFO: Got endpoints: latency-svc-fnmq6 [644.201482ms]
Feb 19 04:54:31.767: INFO: Created: latency-svc-q628h
Feb 19 04:54:31.800: INFO: Got endpoints: latency-svc-mxmf5 [583.711526ms]
Feb 19 04:54:31.816: INFO: Created: latency-svc-4c8j7
Feb 19 04:54:31.852: INFO: Got endpoints: latency-svc-6xn7n [635.14795ms]
Feb 19 04:54:31.866: INFO: Created: latency-svc-d56zm
Feb 19 04:54:31.901: INFO: Got endpoints: latency-svc-9ctv4 [675.951025ms]
Feb 19 04:54:31.916: INFO: Created: latency-svc-trf2l
Feb 19 04:54:31.951: INFO: Got endpoints: latency-svc-lphn7 [702.850945ms]
Feb 19 04:54:31.967: INFO: Created: latency-svc-fg5jc
Feb 19 04:54:32.000: INFO: Got endpoints: latency-svc-ktwnt [578.762972ms]
Feb 19 04:54:32.015: INFO: Created: latency-svc-8ckgx
Feb 19 04:54:32.051: INFO: Got endpoints: latency-svc-t87tj [629.851323ms]
Feb 19 04:54:32.067: INFO: Created: latency-svc-2svjb
Feb 19 04:54:32.101: INFO: Got endpoints: latency-svc-22fk5 [672.354118ms]
Feb 19 04:54:32.115: INFO: Created: latency-svc-872md
Feb 19 04:54:32.151: INFO: Got endpoints: latency-svc-8fvbk [721.614487ms]
Feb 19 04:54:32.361: INFO: Got endpoints: latency-svc-4kqlf [909.676108ms]
Feb 19 04:54:32.361: INFO: Got endpoints: latency-svc-wbzfw [759.240296ms]
Feb 19 04:54:32.361: INFO: Got endpoints: latency-svc-jjktb [855.983998ms]
Feb 19 04:54:32.361: INFO: Got endpoints: latency-svc-nn489 [810.143922ms]
Feb 19 04:54:32.372: INFO: Created: latency-svc-db8h6
Feb 19 04:54:32.377: INFO: Created: latency-svc-qdqpc
Feb 19 04:54:32.385: INFO: Created: latency-svc-9grfr
Feb 19 04:54:32.393: INFO: Created: latency-svc-mvv9k
Feb 19 04:54:32.401: INFO: Created: latency-svc-zv2xp
Feb 19 04:54:32.401: INFO: Got endpoints: latency-svc-qt62l [750.300428ms]
Feb 19 04:54:32.417: INFO: Created: latency-svc-r2h6x
Feb 19 04:54:32.450: INFO: Got endpoints: latency-svc-86fgr [749.628514ms]
Feb 19 04:54:32.464: INFO: Created: latency-svc-9mcww
Feb 19 04:54:32.500: INFO: Got endpoints: latency-svc-q628h [748.306181ms]
Feb 19 04:54:32.515: INFO: Created: latency-svc-gwrc5
Feb 19 04:54:32.550: INFO: Got endpoints: latency-svc-4c8j7 [749.926209ms]
Feb 19 04:54:32.565: INFO: Created: latency-svc-l8g8b
Feb 19 04:54:32.601: INFO: Got endpoints: latency-svc-d56zm [749.210449ms]
Feb 19 04:54:32.616: INFO: Created: latency-svc-mnl69
Feb 19 04:54:32.651: INFO: Got endpoints: latency-svc-trf2l [749.875793ms]
Feb 19 04:54:32.667: INFO: Created: latency-svc-2jgr4
Feb 19 04:54:32.701: INFO: Got endpoints: latency-svc-fg5jc [749.416568ms]
Feb 19 04:54:32.927: INFO: Got endpoints: latency-svc-8ckgx [926.017534ms]
Feb 19 04:54:32.927: INFO: Got endpoints: latency-svc-db8h6 [775.826729ms]
Feb 19 04:54:32.927: INFO: Got endpoints: latency-svc-2svjb [875.33843ms]
Feb 19 04:54:32.927: INFO: Got endpoints: latency-svc-872md [825.986363ms]
Feb 19 04:54:32.933: INFO: Created: latency-svc-6l9s7
Feb 19 04:54:32.953: INFO: Got endpoints: latency-svc-qdqpc [592.612912ms]
Feb 19 04:54:32.958: INFO: Created: latency-svc-x4vbl
Feb 19 04:54:32.959: INFO: Created: latency-svc-r6npw
Feb 19 04:54:32.961: INFO: Created: latency-svc-pdhdj
Feb 19 04:54:32.969: INFO: Created: latency-svc-mn28v
Feb 19 04:54:32.975: INFO: Created: latency-svc-g4q6k
Feb 19 04:54:33.001: INFO: Got endpoints: latency-svc-9grfr [640.551583ms]
Feb 19 04:54:33.017: INFO: Created: latency-svc-f7lcd
Feb 19 04:54:33.050: INFO: Got endpoints: latency-svc-mvv9k [688.95368ms]
Feb 19 04:54:33.067: INFO: Created: latency-svc-9bcqz
Feb 19 04:54:33.101: INFO: Got endpoints: latency-svc-zv2xp [739.450076ms]
Feb 19 04:54:33.332: INFO: Created: latency-svc-h7bdg
Feb 19 04:54:33.332: INFO: Got endpoints: latency-svc-r2h6x [931.080473ms]
Feb 19 04:54:33.338: INFO: Got endpoints: latency-svc-9mcww [887.445657ms]
Feb 19 04:54:33.346: INFO: Got endpoints: latency-svc-gwrc5 [845.491694ms]
Feb 19 04:54:33.435: INFO: Got endpoints: latency-svc-mnl69 [833.399097ms]
Feb 19 04:54:33.435: INFO: Got endpoints: latency-svc-l8g8b [884.749051ms]
Feb 19 04:54:33.441: INFO: Created: latency-svc-qdwtt
Feb 19 04:54:33.441: INFO: Created: latency-svc-2ldwj
Feb 19 04:54:33.441: INFO: Created: latency-svc-46cbk
Feb 19 04:54:33.445: INFO: Got endpoints: latency-svc-2jgr4 [793.948129ms]
Feb 19 04:54:33.482: INFO: Created: latency-svc-hdv28
Feb 19 04:54:33.482: INFO: Created: latency-svc-qx7km
Feb 19 04:54:33.482: INFO: Got endpoints: latency-svc-6l9s7 [781.175789ms]
Feb 19 04:54:33.482: INFO: Created: latency-svc-96crj
Feb 19 04:54:33.504: INFO: Created: latency-svc-6gzpn
Feb 19 04:54:33.657: INFO: Got endpoints: latency-svc-r6npw [730.254192ms]
Feb 19 04:54:33.658: INFO: Got endpoints: latency-svc-x4vbl [731.238938ms]
Feb 19 04:54:33.660: INFO: Got endpoints: latency-svc-pdhdj [733.039167ms]
Feb 19 04:54:33.661: INFO: Got endpoints: latency-svc-mn28v [707.170501ms]
Feb 19 04:54:33.671: INFO: Created: latency-svc-hbhjm
Feb 19 04:54:33.680: INFO: Created: latency-svc-bn9tf
Feb 19 04:54:33.688: INFO: Created: latency-svc-vbl2d
Feb 19 04:54:33.695: INFO: Created: latency-svc-ktmq7
Feb 19 04:54:33.700: INFO: Got endpoints: latency-svc-g4q6k [773.088793ms]
Feb 19 04:54:33.714: INFO: Created: latency-svc-4ccq6
Feb 19 04:54:33.751: INFO: Got endpoints: latency-svc-f7lcd [749.186407ms]
Feb 19 04:54:33.767: INFO: Created: latency-svc-kjcqs
Feb 19 04:54:33.800: INFO: Got endpoints: latency-svc-9bcqz [750.387801ms]
Feb 19 04:54:33.815: INFO: Created: latency-svc-tbvw6
Feb 19 04:54:33.852: INFO: Got endpoints: latency-svc-h7bdg [751.331538ms]
Feb 19 04:54:33.866: INFO: Created: latency-svc-dxnzk
Feb 19 04:54:33.903: INFO: Got endpoints: latency-svc-qdwtt [571.480146ms]
Feb 19 04:54:33.920: INFO: Created: latency-svc-8kcg8
Feb 19 04:54:33.951: INFO: Got endpoints: latency-svc-46cbk [613.315972ms]
Feb 19 04:54:33.965: INFO: Created: latency-svc-r6t8l
Feb 19 04:54:34.002: INFO: Got endpoints: latency-svc-2ldwj [655.5285ms]
Feb 19 04:54:34.017: INFO: Created: latency-svc-rsf2d
Feb 19 04:54:34.051: INFO: Got endpoints: latency-svc-qx7km [616.156568ms]
Feb 19 04:54:34.067: INFO: Created: latency-svc-fw2q7
Feb 19 04:54:34.100: INFO: Got endpoints: latency-svc-96crj [665.114273ms]
Feb 19 04:54:34.115: INFO: Created: latency-svc-dc94m
Feb 19 04:54:34.151: INFO: Got endpoints: latency-svc-hdv28 [706.169445ms]
Feb 19 04:54:34.168: INFO: Created: latency-svc-x5plm
Feb 19 04:54:34.200: INFO: Got endpoints: latency-svc-6gzpn [718.226537ms]
Feb 19 04:54:34.215: INFO: Created: latency-svc-wsk8g
Feb 19 04:54:34.251: INFO: Got endpoints: latency-svc-hbhjm [593.336413ms]
Feb 19 04:54:34.269: INFO: Created: latency-svc-slkpq
Feb 19 04:54:34.301: INFO: Got endpoints: latency-svc-bn9tf [643.355232ms]
Feb 19 04:54:34.317: INFO: Created: latency-svc-69kf6
Feb 19 04:54:35.178: INFO: Got endpoints: latency-svc-ktmq7 [1.517156747s]
Feb 19 04:54:35.178: INFO: Got endpoints: latency-svc-vbl2d [1.517746623s]
Feb 19 04:54:35.178: INFO: Got endpoints: latency-svc-4ccq6 [1.4781453s]
Feb 19 04:54:35.182: INFO: Got endpoints: latency-svc-kjcqs [1.431634203s]
Feb 19 04:54:35.182: INFO: Got endpoints: latency-svc-tbvw6 [1.382043177s]
Feb 19 04:54:35.197: INFO: Created: latency-svc-7646d
Feb 19 04:54:35.204: INFO: Created: latency-svc-bsp5g
Feb 19 04:54:35.212: INFO: Created: latency-svc-dszn7
Feb 19 04:54:35.222: INFO: Created: latency-svc-wxp52
Feb 19 04:54:35.228: INFO: Created: latency-svc-mwcmw
Feb 19 04:54:35.239: INFO: Got endpoints: latency-svc-r6t8l [1.288265096s]
Feb 19 04:54:35.240: INFO: Got endpoints: latency-svc-dxnzk [1.388298487s]
Feb 19 04:54:35.241: INFO: Got endpoints: latency-svc-rsf2d [1.239432572s]
Feb 19 04:54:35.241: INFO: Got endpoints: latency-svc-8kcg8 [1.337724217s]
Feb 19 04:54:35.255: INFO: Created: latency-svc-9jhmz
Feb 19 04:54:35.263: INFO: Created: latency-svc-bl5fk
Feb 19 04:54:35.270: INFO: Created: latency-svc-jgvn9
Feb 19 04:54:35.278: INFO: Created: latency-svc-92kq2
Feb 19 04:54:35.278: INFO: Got endpoints: latency-svc-fw2q7 [1.226703976s]
Feb 19 04:54:35.285: INFO: Got endpoints: latency-svc-dc94m [1.184908253s]
Feb 19 04:54:35.321: INFO: Got endpoints: latency-svc-x5plm [1.170065619s]
Feb 19 04:54:35.322: INFO: Got endpoints: latency-svc-slkpq [1.071870688s]
Feb 19 04:54:35.322: INFO: Got endpoints: latency-svc-wsk8g [1.121980682s]
Feb 19 04:54:35.336: INFO: Got endpoints: latency-svc-69kf6 [1.034356458s]
Feb 19 04:54:35.336: INFO: Got endpoints: latency-svc-7646d [157.897223ms]
Feb 19 04:54:35.564: INFO: Got endpoints: latency-svc-dszn7 [385.99318ms]
Feb 19 04:54:35.564: INFO: Got endpoints: latency-svc-wxp52 [381.47267ms]
Feb 19 04:54:35.564: INFO: Got endpoints: latency-svc-bsp5g [386.194606ms]
Feb 19 04:54:35.571: INFO: Got endpoints: latency-svc-9jhmz [331.259627ms]
Feb 19 04:54:35.571: INFO: Got endpoints: latency-svc-mwcmw [388.158147ms]
Feb 19 04:54:35.577: INFO: Got endpoints: latency-svc-bl5fk [336.272438ms]
Feb 19 04:54:35.615: INFO: Got endpoints: latency-svc-92kq2 [373.504058ms]
Feb 19 04:54:35.615: INFO: Got endpoints: latency-svc-jgvn9 [373.53726ms]
Feb 19 04:54:35.615: INFO: Latencies: [18.899442ms 26.876967ms 35.940017ms 37.913419ms 45.816492ms 51.461584ms 58.794638ms 66.935638ms 74.904216ms 83.726813ms 92.258979ms 100.896606ms 107.727326ms 110.737526ms 112.742308ms 114.420821ms 114.648819ms 115.820767ms 116.815515ms 118.399186ms 118.448765ms 118.67556ms 119.370668ms 119.585554ms 119.841767ms 121.001419ms 121.151211ms 121.182011ms 121.250951ms 121.298523ms 123.273446ms 123.866636ms 124.010252ms 124.920698ms 136.872876ms 157.897223ms 174.531021ms 215.460338ms 256.951299ms 297.451479ms 331.259627ms 336.272438ms 343.708372ms 373.504058ms 373.53726ms 381.47267ms 385.66894ms 385.99318ms 386.194606ms 388.158147ms 429.056527ms 470.487408ms 542.205626ms 561.361036ms 564.604999ms 568.552432ms 571.230843ms 571.480146ms 578.762972ms 583.711526ms 585.178882ms 592.612912ms 593.336413ms 600.409412ms 609.283021ms 613.315972ms 613.484809ms 616.156568ms 620.986891ms 629.851323ms 635.14795ms 635.202026ms 640.551583ms 643.355232ms 644.201482ms 655.5285ms 659.955089ms 664.539933ms 665.114273ms 669.498226ms 671.27045ms 672.354118ms 675.951025ms 676.254576ms 680.633697ms 682.171418ms 686.674551ms 688.95368ms 692.511019ms 693.286034ms 702.850945ms 706.169445ms 707.170501ms 708.548002ms 713.117203ms 716.316918ms 718.226537ms 719.004781ms 720.342923ms 721.614487ms 730.254192ms 731.238938ms 731.636873ms 731.833223ms 733.039167ms 734.145513ms 737.456502ms 737.816787ms 737.887931ms 738.929867ms 739.450076ms 740.540129ms 741.404729ms 747.262761ms 748.014147ms 748.306181ms 748.345561ms 748.480515ms 748.912466ms 748.994668ms 749.149748ms 749.186407ms 749.200849ms 749.210449ms 749.2891ms 749.416568ms 749.419268ms 749.628514ms 749.651233ms 749.712344ms 749.875793ms 749.926209ms 750.289778ms 750.300428ms 750.387801ms 750.403595ms 750.502157ms 750.981158ms 751.189568ms 751.230588ms 751.331538ms 752.079994ms 754.554333ms 759.240296ms 766.868278ms 773.088793ms 775.826729ms 781.175789ms 783.49609ms 789.532577ms 790.564422ms 793.948129ms 798.101982ms 798.405119ms 809.06433ms 810.143922ms 818.734657ms 823.686406ms 825.986363ms 833.399097ms 839.167991ms 839.917748ms 842.753962ms 845.491694ms 855.276669ms 855.983998ms 865.284398ms 865.664029ms 875.33843ms 884.749051ms 887.445657ms 889.29856ms 890.046308ms 892.992315ms 898.970267ms 909.676108ms 916.039537ms 916.730874ms 926.017534ms 931.080473ms 933.992116ms 937.047868ms 940.527506ms 941.201282ms 957.496088ms 1.034356458s 1.071870688s 1.121980682s 1.170065619s 1.184908253s 1.226703976s 1.239432572s 1.288265096s 1.337724217s 1.382043177s 1.388298487s 1.431634203s 1.4781453s 1.517156747s 1.517746623s]
Feb 19 04:54:35.615: INFO: 50 %ile: 730.254192ms
Feb 19 04:54:35.615: INFO: 90 %ile: 933.992116ms
Feb 19 04:54:35.615: INFO: 99 %ile: 1.517156747s
Feb 19 04:54:35.615: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:54:35.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3008" for this suite.
Feb 19 04:54:49.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:54:49.974: INFO: namespace svc-latency-3008 deletion completed in 14.269206634s

• [SLOW TEST:25.260 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:54:49.974: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8653
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Feb 19 04:54:50.058: INFO: Found 0 stateful pods, waiting for 3
Feb 19 04:55:00.327: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:55:00.327: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:55:00.327: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 04:55:00.464: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 19 04:55:10.523: INFO: Updating stateful set ss2
Feb 19 04:55:10.535: INFO: Waiting for Pod statefulset-8653/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Feb 19 04:55:20.631: INFO: Found 1 stateful pods, waiting for 3
Feb 19 04:55:30.641: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:55:30.641: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 04:55:30.641: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 19 04:55:30.678: INFO: Updating stateful set ss2
Feb 19 04:55:30.689: INFO: Waiting for Pod statefulset-8653/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 19 04:55:40.862: INFO: Updating stateful set ss2
Feb 19 04:55:40.917: INFO: Waiting for StatefulSet statefulset-8653/ss2 to complete update
Feb 19 04:55:40.917: INFO: Waiting for Pod statefulset-8653/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Feb 19 04:55:50.930: INFO: Deleting all statefulset in ns statefulset-8653
Feb 19 04:55:50.938: INFO: Scaling statefulset ss2 to 0
Feb 19 04:56:21.178: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 04:56:21.184: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:56:21.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8653" for this suite.
Feb 19 04:56:27.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:56:27.955: INFO: namespace statefulset-8653 deletion completed in 6.731843212s

• [SLOW TEST:97.981 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:56:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7465
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 04:56:28.012: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 04:56:48.162: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.45:8080/dial?request=hostName&protocol=udp&host=10.244.0.44&port=8081&tries=1'] Namespace:pod-network-test-7465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:56:48.162: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:56:48.443: INFO: Waiting for endpoints: map[]
Feb 19 04:56:48.450: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.45:8080/dial?request=hostName&protocol=udp&host=10.244.1.179&port=8081&tries=1'] Namespace:pod-network-test-7465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:56:48.450: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:56:48.654: INFO: Waiting for endpoints: map[]
Feb 19 04:56:48.660: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.45:8080/dial?request=hostName&protocol=udp&host=10.244.2.43&port=8081&tries=1'] Namespace:pod-network-test-7465 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 04:56:48.660: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 04:56:48.853: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:56:48.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7465" for this suite.
Feb 19 04:57:13.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:57:13.288: INFO: namespace pod-network-test-7465 deletion completed in 24.428026946s

• [SLOW TEST:45.332 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:57:13.289: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 19 04:57:15.419: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:57:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1934" for this suite.
Feb 19 04:57:21.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:57:21.905: INFO: namespace container-runtime-1934 deletion completed in 6.454035965s

• [SLOW TEST:8.616 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:57:21.905: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 19 04:57:21.983: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 04:57:21.997: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 04:57:22.003: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Feb 19 04:57:22.017: INFO: kube-flannel-ds-dd7gd from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 04:57:22.017: INFO: kube-proxy-8l2fs from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:57:22.017: INFO: csi-oci-node-jgr72 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 04:57:22.017: INFO: proxymux-client-l94j2 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 04:57:22.017: INFO: coredns-547fdd776c-rcf7n from kube-system started at 2020-02-19 03:31:37 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container coredns ready: true, restart count 0
Feb 19 04:57:22.017: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-wsrnl from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 04:57:22.017: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:57:22.017: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 04:57:22.017: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Feb 19 04:57:22.351: INFO: kube-proxy-pwtwx from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 04:57:22.351: INFO: kube-flannel-ds-72bk6 from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 04:57:22.351: INFO: proxymux-client-6nkcq from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 04:57:22.351: INFO: csi-oci-node-9khcs from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 04:57:22.351: INFO: coredns-547fdd776c-tw6q6 from kube-system started at 2020-02-19 03:31:34 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container coredns ready: true, restart count 0
Feb 19 04:57:22.351: INFO: sonobuoy-e2e-job-178c4b4f618042e4 from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container e2e ready: true, restart count 0
Feb 19 04:57:22.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 04:57:22.351: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-p8mkj from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 04:57:22.351: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:57:22.351: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 04:57:22.351: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Feb 19 04:57:22.373: INFO: kube-dns-autoscaler-94bd7f68f-5t8sl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container autoscaler ready: true, restart count 0
Feb 19 04:57:22.373: INFO: sonobuoy from sonobuoy started at 2020-02-19 03:35:32 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 04:57:22.373: INFO: kube-flannel-ds-9wq2s from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 04:57:22.373: INFO: csi-oci-node-676ns from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 04:57:22.373: INFO: proxymux-client-2p6d4 from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 04:57:22.373: INFO: coredns-547fdd776c-l9qgl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container coredns ready: true, restart count 0
Feb 19 04:57:22.373: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-ngs5t from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 04:57:22.373: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 04:57:22.373: INFO: kube-proxy-tsmqs from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 04:57:22.373: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node 10.0.10.2
STEP: verifying the node has the label node 10.0.10.3
STEP: verifying the node has the label node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod coredns-547fdd776c-l9qgl requesting resource cpu=100m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod coredns-547fdd776c-rcf7n requesting resource cpu=100m on Node 10.0.10.2
Feb 19 04:57:22.447: INFO: Pod coredns-547fdd776c-tw6q6 requesting resource cpu=100m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod csi-oci-node-676ns requesting resource cpu=0m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod csi-oci-node-9khcs requesting resource cpu=0m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod csi-oci-node-jgr72 requesting resource cpu=0m on Node 10.0.10.2
Feb 19 04:57:22.447: INFO: Pod kube-dns-autoscaler-94bd7f68f-5t8sl requesting resource cpu=20m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod kube-flannel-ds-72bk6 requesting resource cpu=100m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod kube-flannel-ds-9wq2s requesting resource cpu=100m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod kube-flannel-ds-dd7gd requesting resource cpu=100m on Node 10.0.10.2
Feb 19 04:57:22.447: INFO: Pod kube-proxy-8l2fs requesting resource cpu=0m on Node 10.0.10.2
Feb 19 04:57:22.447: INFO: Pod kube-proxy-pwtwx requesting resource cpu=0m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod kube-proxy-tsmqs requesting resource cpu=0m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod proxymux-client-2p6d4 requesting resource cpu=50m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod proxymux-client-6nkcq requesting resource cpu=50m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod proxymux-client-l94j2 requesting resource cpu=50m on Node 10.0.10.2
Feb 19 04:57:22.447: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod sonobuoy-e2e-job-178c4b4f618042e4 requesting resource cpu=0m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-ngs5t requesting resource cpu=0m on Node 10.0.10.4
Feb 19 04:57:22.447: INFO: Pod sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-p8mkj requesting resource cpu=0m on Node 10.0.10.3
Feb 19 04:57:22.447: INFO: Pod sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-wsrnl requesting resource cpu=0m on Node 10.0.10.2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450.15f4b4dfcfc71a57], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7331/filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450 to 10.0.10.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450.15f4b4e00b240f96], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450.15f4b4e00d9fa19c], Reason = [Created], Message = [Created container filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450.15f4b4e014a31e50], Reason = [Started], Message = [Started container filler-pod-03469f8a-8241-432d-9d23-0c121b1d7450]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457.15f4b4dfd0b1ba23], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7331/filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457 to 10.0.10.4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457.15f4b4dff8a84cbb], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457.15f4b4dffaf58f3e], Reason = [Created], Message = [Created container filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457.15f4b4e006be0ab0], Reason = [Started], Message = [Started container filler-pod-4f5c8d08-7d7d-49b4-a247-2934e005b457]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a.15f4b4dfd043067f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7331/filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a to 10.0.10.3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a.15f4b4e00b17de10], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a.15f4b4e00dfff4ac], Reason = [Created], Message = [Created container filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a.15f4b4e014ff9caa], Reason = [Started], Message = [Started container filler-pod-b537c6b6-0149-4a32-b081-ddd420cf076a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f4b4e04abf9332], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.0.10.2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.10.3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.10.4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:57:25.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7331" for this suite.
Feb 19 04:57:31.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:57:31.904: INFO: namespace sched-pred-7331 deletion completed in 6.22413196s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.999 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:57:31.904: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:57:32.348: INFO: (0) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 13.182834ms)
Feb 19 04:57:32.357: INFO: (1) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.935801ms)
Feb 19 04:57:32.366: INFO: (2) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.568186ms)
Feb 19 04:57:32.374: INFO: (3) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.892689ms)
Feb 19 04:57:32.391: INFO: (4) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 17.766592ms)
Feb 19 04:57:32.401: INFO: (5) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.490675ms)
Feb 19 04:57:32.409: INFO: (6) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.415384ms)
Feb 19 04:57:32.418: INFO: (7) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.695355ms)
Feb 19 04:57:32.427: INFO: (8) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.365158ms)
Feb 19 04:57:32.435: INFO: (9) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.267357ms)
Feb 19 04:57:32.443: INFO: (10) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.245204ms)
Feb 19 04:57:32.453: INFO: (11) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.388472ms)
Feb 19 04:57:32.461: INFO: (12) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.270227ms)
Feb 19 04:57:32.470: INFO: (13) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.274728ms)
Feb 19 04:57:32.479: INFO: (14) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.482944ms)
Feb 19 04:57:32.488: INFO: (15) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.678315ms)
Feb 19 04:57:32.712: INFO: (16) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 223.5984ms)
Feb 19 04:57:32.996: INFO: (17) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 284.124996ms)
Feb 19 04:57:33.015: INFO: (18) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 18.861041ms)
Feb 19 04:57:33.029: INFO: (19) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 13.330651ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:57:33.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3152" for this suite.
Feb 19 04:57:39.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:57:39.256: INFO: namespace proxy-3152 deletion completed in 6.217658035s

• [SLOW TEST:7.352 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:57:39.257: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 04:57:39.581: INFO: Creating deployment "nginx-deployment"
Feb 19 04:57:39.618: INFO: Waiting for observed generation 1
Feb 19 04:57:41.913: INFO: Waiting for all required pods to come up
Feb 19 04:57:41.947: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 19 04:57:44.075: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 19 04:57:44.153: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 19 04:57:44.203: INFO: Updating deployment nginx-deployment
Feb 19 04:57:44.203: INFO: Waiting for observed generation 2
Feb 19 04:57:46.251: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 19 04:57:46.287: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 19 04:57:46.311: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 04:57:46.362: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 19 04:57:46.362: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 19 04:57:46.376: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 04:57:46.403: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 19 04:57:46.403: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 19 04:57:46.430: INFO: Updating deployment nginx-deployment
Feb 19 04:57:46.430: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 19 04:57:46.453: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 19 04:57:48.538: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 19 04:57:48.652: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2403,SelfLink:/apis/apps/v1/namespaces/deployment-2403/deployments/nginx-deployment,UID:e3648763-06a0-4abf-bcfe-c5d2521bdb56,ResourceVersion:26998,Generation:3,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2020-02-19 04:57:46 +0000 UTC 2020-02-19 04:57:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-02-19 04:57:46 +0000 UTC 2020-02-19 04:57:39 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 19 04:57:48.695: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-2403,SelfLink:/apis/apps/v1/namespaces/deployment-2403/replicasets/nginx-deployment-55fb7cb77f,UID:4ff74ff4-e7aa-47e9-86c0-34a398c6f279,ResourceVersion:26992,Generation:3,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e3648763-06a0-4abf-bcfe-c5d2521bdb56 0xc002fe3c97 0xc002fe3c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 04:57:48.695: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 19 04:57:48.695: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-2403,SelfLink:/apis/apps/v1/namespaces/deployment-2403/replicasets/nginx-deployment-7b8c6f4498,UID:53cd87b6-d36e-4426-bd31-f02821a51578,ResourceVersion:26989,Generation:3,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e3648763-06a0-4abf-bcfe-c5d2521bdb56 0xc002fe3d67 0xc002fe3d68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 19 04:57:48.757: INFO: Pod "nginx-deployment-55fb7cb77f-6s7zn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6s7zn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-6s7zn,UID:fe01226e-7b28-43de-8f70-a948034ddc1a,ResourceVersion:26917,Generation:0,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c806c7 0xc002c806c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c80740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c80760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.185,StartTime:2020-02-19 04:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.758: INFO: Pod "nginx-deployment-55fb7cb77f-7b8n2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7b8n2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-7b8n2,UID:d1eb5111-995a-4815-93d2-c3b85e8807f4,ResourceVersion:27063,Generation:0,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c80850 0xc002c80851}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c808d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c808f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.48,StartTime:2020-02-19 04:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.758: INFO: Pod "nginx-deployment-55fb7cb77f-7h768" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7h768,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-7h768,UID:c48487f3-e8d3-4ed4-8ad7-69644b05c4f4,ResourceVersion:26928,Generation:0,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c809e0 0xc002c809e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c80a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c80a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.49,StartTime:2020-02-19 04:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.758: INFO: Pod "nginx-deployment-55fb7cb77f-8mvsq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8mvsq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-8mvsq,UID:24ab3d08-ba6c-44d6-9416-53f95f1bfa59,ResourceVersion:27050,Generation:0,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c80b70 0xc002c80b71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c80bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c80c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.51,StartTime:2020-02-19 04:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.758: INFO: Pod "nginx-deployment-55fb7cb77f-9st2k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9st2k,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-9st2k,UID:b66d5d71-e28f-441a-bd26-265228d30904,ResourceVersion:26915,Generation:0,CreationTimestamp:2020-02-19 04:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c80d00 0xc002c80d01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c80d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c80da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.186,StartTime:2020-02-19 04:57:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.758: INFO: Pod "nginx-deployment-55fb7cb77f-bs556" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bs556,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-bs556,UID:76440798-04a4-42fc-852b-602e18694e4e,ResourceVersion:26978,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c80e90 0xc002c80e91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c80f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c80f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.759: INFO: Pod "nginx-deployment-55fb7cb77f-cf27b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-cf27b,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-cf27b,UID:98f15922-ce1b-4124-aa7b-dad6d092c4a8,ResourceVersion:27030,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c81000 0xc002c81001}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c810a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.759: INFO: Pod "nginx-deployment-55fb7cb77f-d6bnq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d6bnq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-d6bnq,UID:b7d6f958-1557-4a36-b6e6-57c4910c4570,ResourceVersion:27045,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c81180 0xc002c81181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.759: INFO: Pod "nginx-deployment-55fb7cb77f-g7qpj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-g7qpj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-g7qpj,UID:85c4e311-d072-4f02-b9ce-89ffb94f400c,ResourceVersion:27018,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c812f0 0xc002c812f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.759: INFO: Pod "nginx-deployment-55fb7cb77f-j9zhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-j9zhv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-j9zhv,UID:ff610dfa-3abc-447d-bd64-bd70a2996751,ResourceVersion:27036,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c81480 0xc002c81481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.760: INFO: Pod "nginx-deployment-55fb7cb77f-r8scf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r8scf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-r8scf,UID:3e55a219-ff06-497c-b3c5-3fb37c1e5ba0,ResourceVersion:27024,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c815f0 0xc002c815f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.760: INFO: Pod "nginx-deployment-55fb7cb77f-vxwvd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-vxwvd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-vxwvd,UID:6f746c85-ff42-44e3-adb6-0df54905c21b,ResourceVersion:27094,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c81760 0xc002c81761}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c817e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.53,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.760: INFO: Pod "nginx-deployment-55fb7cb77f-w9sc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w9sc2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-55fb7cb77f-w9sc2,UID:f4c42e32-fa6b-482a-a07b-81a746e1f70d,ResourceVersion:27093,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 4ff74ff4-e7aa-47e9-86c0-34a398c6f279 0xc002c818f0 0xc002c818f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.56,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.763: INFO: Pod "nginx-deployment-7b8c6f4498-29klm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-29klm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-29klm,UID:14612937-7d9c-42d8-9f3e-ea2503c8557a,ResourceVersion:26970,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc002c81a80 0xc002c81a81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.763: INFO: Pod "nginx-deployment-7b8c6f4498-6skmd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6skmd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-6skmd,UID:2671dd66-7993-41fa-b1ed-19a56958bcfa,ResourceVersion:27015,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc002c81bd0 0xc002c81bd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.764: INFO: Pod "nginx-deployment-7b8c6f4498-6sx9s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6sx9s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-6sx9s,UID:da5b3ddd-d46a-4bae-be57-8ba27fd21f59,ResourceVersion:26824,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc002c81d20 0xc002c81d21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.47,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e4212cc0fc8917bf1e7d2a3dcad98ab7f0ec69ac8366896aa62e99a738057e93}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.764: INFO: Pod "nginx-deployment-7b8c6f4498-8lq6d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8lq6d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-8lq6d,UID:7108e31f-6ab3-46f1-b4b8-1352f8871ecf,ResourceVersion:26833,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc002c81e80 0xc002c81e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c81ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c81f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.2.46,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b9da4996e14da7af06f16d2c310e0994200f86e869b51ec7432d31e404b29c89}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.764: INFO: Pod "nginx-deployment-7b8c6f4498-8w64q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8w64q,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-8w64q,UID:0a885f8b-cbe4-4a9e-9411-984de5559019,ResourceVersion:26807,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc002c81fe0 0xc002c81fe1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.182,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://94156e817e1e11e82f853366895ef6e33f8d8e94738b884d89db12797797d037}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.764: INFO: Pod "nginx-deployment-7b8c6f4498-brbcz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-brbcz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-brbcz,UID:18f98310-cada-4bb0-be76-bf313dc58adb,ResourceVersion:26804,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630140 0xc003630141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036301b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036301d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.184,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://07d40b628ab19933cec002f2feb1e862c9fa1322cfaa3354ceb112d36ee7e874}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.765: INFO: Pod "nginx-deployment-7b8c6f4498-cfssk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cfssk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-cfssk,UID:684ed709-8765-4e65-8b33-de5603364665,ResourceVersion:26817,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc0036302a0 0xc0036302a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.48,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f5387b8acc5cbb414094e5bd8e0cb459bcfd3a21951145d3205dd835b3d06cff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.765: INFO: Pod "nginx-deployment-7b8c6f4498-dfzs4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dfzs4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-dfzs4,UID:378c4654-597f-4052-874d-0e1d18304c76,ResourceVersion:27053,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630400 0xc003630401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.765: INFO: Pod "nginx-deployment-7b8c6f4498-fqn9t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fqn9t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-fqn9t,UID:9842ad8e-0921-42ac-81d2-acad2516d5aa,ResourceVersion:27025,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630550 0xc003630551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036305c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036305e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.765: INFO: Pod "nginx-deployment-7b8c6f4498-gc527" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gc527,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-gc527,UID:4a2275f6-3efe-4dd7-b8d3-21d44fdc09e4,ResourceVersion:27021,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc0036306a0 0xc0036306a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.766: INFO: Pod "nginx-deployment-7b8c6f4498-hs8s8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hs8s8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-hs8s8,UID:7f83a5d6-6ee7-4710-b5c2-618ceef1c3a0,ResourceVersion:26999,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc0036307f0 0xc0036307f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.766: INFO: Pod "nginx-deployment-7b8c6f4498-j8mhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j8mhk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-j8mhk,UID:eee99d8e-30dc-4faa-8b45-e14092f07f81,ResourceVersion:26996,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630940 0xc003630941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036309b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036309d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.766: INFO: Pod "nginx-deployment-7b8c6f4498-jj6pn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jj6pn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-jj6pn,UID:5f410a57-ae38-4c0c-9805-5703c1beeab0,ResourceVersion:26823,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630a90 0xc003630a91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.49,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0616b25598fc6515e60b418ef805989ae12e539ce1384aa8f02753d1d97512ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.766: INFO: Pod "nginx-deployment-7b8c6f4498-jp2kb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jp2kb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-jp2kb,UID:d8a1420b-7b57-4d21-abef-a03c3a7f9d2b,ResourceVersion:27020,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630bf0 0xc003630bf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.767: INFO: Pod "nginx-deployment-7b8c6f4498-n2dlx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n2dlx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-n2dlx,UID:ba8f5d4d-5d02-40bf-90f6-27be834967b7,ResourceVersion:27033,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630d40 0xc003630d41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.767: INFO: Pod "nginx-deployment-7b8c6f4498-nggbf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nggbf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-nggbf,UID:a17fbdaf-0d52-426b-b029-c91a12a5cd00,ResourceVersion:26811,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630e90 0xc003630e91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003630f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003630f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.183,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9fb204078e553f05d60979fe3cfc77aa4ea92bcc3027ed2ade2969781ac01ccf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.767: INFO: Pod "nginx-deployment-7b8c6f4498-rfqds" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rfqds,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-rfqds,UID:db781623-a9d7-460b-b36d-c83bc9c2b6e7,ResourceVersion:26990,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003630ff0 0xc003630ff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003631060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003631080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.3,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.767: INFO: Pod "nginx-deployment-7b8c6f4498-rp8kj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rp8kj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-rp8kj,UID:f13d2990-8fa5-4280-bd5b-2f4e47d09664,ResourceVersion:27002,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003631140 0xc003631141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036311b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036311d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.768: INFO: Pod "nginx-deployment-7b8c6f4498-w48xz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w48xz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-w48xz,UID:798994bc-0464-45b0-b05c-dcc09f9b72e0,ResourceVersion:27023,Generation:0,CreationTimestamp:2020-02-19 04:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc003631290 0xc003631291}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003631300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003631320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-02-19 04:57:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 04:57:48.768: INFO: Pod "nginx-deployment-7b8c6f4498-z8bbf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z8bbf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2403,SelfLink:/api/v1/namespaces/deployment-2403/pods/nginx-deployment-7b8c6f4498-z8bbf,UID:7ea07660-20a2-4bd7-b7a7-93555ad81853,ResourceVersion:26815,Generation:0,CreationTimestamp:2020-02-19 04:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 53cd87b6-d36e-4426-bd31-f02821a51578 0xc0036313e0 0xc0036313e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8wxrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wxrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8wxrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003631450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003631470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 04:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.4,PodIP:10.244.0.47,StartTime:2020-02-19 04:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 04:57:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2a8ae4668b15f3ef9397cc68fc2963d34f69456194bec5cbbab8b1d2c8e959d0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:57:48.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2403" for this suite.
Feb 19 04:57:56.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:57:57.618: INFO: namespace deployment-2403 deletion completed in 8.834659262s

• [SLOW TEST:18.362 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:57:57.619: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Feb 19 04:57:59.831: INFO: Pod pod-hostip-54b43a18-7ca7-4915-a893-6f054e8d9017 has hostIP: 10.0.10.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:57:59.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9424" for this suite.
Feb 19 04:58:23.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:58:24.119: INFO: namespace pods-9424 deletion completed in 24.25536809s

• [SLOW TEST:26.501 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:58:24.119: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 04:58:24.186: INFO: Waiting up to 5m0s for pod "pod-932e7896-8579-4c58-8aef-fb80bfe9e690" in namespace "emptydir-7714" to be "success or failure"
Feb 19 04:58:24.193: INFO: Pod "pod-932e7896-8579-4c58-8aef-fb80bfe9e690": Phase="Pending", Reason="", readiness=false. Elapsed: 6.746925ms
Feb 19 04:58:26.199: INFO: Pod "pod-932e7896-8579-4c58-8aef-fb80bfe9e690": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013037479s
Feb 19 04:58:28.401: INFO: Pod "pod-932e7896-8579-4c58-8aef-fb80bfe9e690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214485791s
STEP: Saw pod success
Feb 19 04:58:28.401: INFO: Pod "pod-932e7896-8579-4c58-8aef-fb80bfe9e690" satisfied condition "success or failure"
Feb 19 04:58:28.407: INFO: Trying to get logs from node 10.0.10.2 pod pod-932e7896-8579-4c58-8aef-fb80bfe9e690 container test-container: <nil>
STEP: delete the pod
Feb 19 04:58:28.455: INFO: Waiting for pod pod-932e7896-8579-4c58-8aef-fb80bfe9e690 to disappear
Feb 19 04:58:28.461: INFO: Pod pod-932e7896-8579-4c58-8aef-fb80bfe9e690 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:58:28.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7714" for this suite.
Feb 19 04:58:35.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:58:35.304: INFO: namespace emptydir-7714 deletion completed in 6.837260558s

• [SLOW TEST:11.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:58:35.304: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:58:37.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9943" for this suite.
Feb 19 04:59:17.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:59:18.120: INFO: namespace kubelet-test-9943 deletion completed in 40.242038721s

• [SLOW TEST:42.815 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:59:18.120: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:59:20.520: INFO: DNS probes using dns-test-38ed6e7d-ba77-438b-84e3-ef8262b96c13 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:59:24.706: INFO: File jessie_udp@dns-test-service-3.dns-3840.svc.cluster.local from pod  dns-3840/dns-test-ecfaf674-26fc-4dc3-866a-001f5243655b contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 19 04:59:24.706: INFO: Lookups using dns-3840/dns-test-ecfaf674-26fc-4dc3-866a-001f5243655b failed for: [jessie_udp@dns-test-service-3.dns-3840.svc.cluster.local]

Feb 19 04:59:30.146: INFO: DNS probes using dns-test-ecfaf674-26fc-4dc3-866a-001f5243655b succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3840.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3840.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 04:59:34.506: INFO: DNS probes using dns-test-759d41a4-b29d-4b6b-a54b-dd7fa377d4dc succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:59:34.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3840" for this suite.
Feb 19 04:59:40.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:59:40.787: INFO: namespace dns-3840 deletion completed in 6.225992957s

• [SLOW TEST:22.668 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:59:40.789: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-32ff150a-561f-406c-b11f-6184e94c4388
STEP: Creating a pod to test consume secrets
Feb 19 04:59:41.191: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad" in namespace "projected-6473" to be "success or failure"
Feb 19 04:59:41.200: INFO: Pod "pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad": Phase="Pending", Reason="", readiness=false. Elapsed: 8.932574ms
Feb 19 04:59:43.329: INFO: Pod "pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137179349s
Feb 19 04:59:45.529: INFO: Pod "pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.337933844s
STEP: Saw pod success
Feb 19 04:59:45.529: INFO: Pod "pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad" satisfied condition "success or failure"
Feb 19 04:59:45.566: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 04:59:45.668: INFO: Waiting for pod pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad to disappear
Feb 19 04:59:45.677: INFO: Pod pod-projected-secrets-e284194d-2ee3-4a33-b880-0d32ebaacaad no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:59:45.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6473" for this suite.
Feb 19 04:59:51.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 04:59:51.901: INFO: namespace projected-6473 deletion completed in 6.216540636s

• [SLOW TEST:11.112 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 04:59:51.901: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 19 04:59:51.969: INFO: Waiting up to 5m0s for pod "downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf" in namespace "downward-api-5467" to be "success or failure"
Feb 19 04:59:51.978: INFO: Pod "downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.580308ms
Feb 19 04:59:53.985: INFO: Pod "downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015470922s
STEP: Saw pod success
Feb 19 04:59:53.985: INFO: Pod "downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf" satisfied condition "success or failure"
Feb 19 04:59:53.992: INFO: Trying to get logs from node 10.0.10.4 pod downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf container dapi-container: <nil>
STEP: delete the pod
Feb 19 04:59:54.027: INFO: Waiting for pod downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf to disappear
Feb 19 04:59:54.034: INFO: Pod downward-api-9a0ce040-30c5-4488-9f5d-9e0a3a3688bf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 04:59:54.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5467" for this suite.
Feb 19 05:00:00.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:00:00.498: INFO: namespace downward-api-5467 deletion completed in 6.457641906s

• [SLOW TEST:8.597 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:00:00.498: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 19 05:00:00.568: INFO: Waiting up to 5m0s for pod "pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd" in namespace "emptydir-2163" to be "success or failure"
Feb 19 05:00:00.576: INFO: Pod "pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885405ms
Feb 19 05:00:02.606: INFO: Pod "pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038861737s
Feb 19 05:00:04.842: INFO: Pod "pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.27486924s
STEP: Saw pod success
Feb 19 05:00:04.842: INFO: Pod "pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd" satisfied condition "success or failure"
Feb 19 05:00:04.853: INFO: Trying to get logs from node 10.0.10.2 pod pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd container test-container: <nil>
STEP: delete the pod
Feb 19 05:00:04.931: INFO: Waiting for pod pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd to disappear
Feb 19 05:00:04.938: INFO: Pod pod-dfec6cbb-0b57-422c-8aba-5d472801d1cd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:00:04.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2163" for this suite.
Feb 19 05:00:10.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:00:11.161: INFO: namespace emptydir-2163 deletion completed in 6.21688701s

• [SLOW TEST:10.663 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:00:11.162: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-9f20bda5-c838-4cc9-b5b3-e91914d284c6
STEP: Creating a pod to test consume secrets
Feb 19 05:00:11.244: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e" in namespace "projected-9964" to be "success or failure"
Feb 19 05:00:11.251: INFO: Pod "pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.520616ms
Feb 19 05:00:13.257: INFO: Pod "pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013474117s
STEP: Saw pod success
Feb 19 05:00:13.257: INFO: Pod "pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e" satisfied condition "success or failure"
Feb 19 05:00:13.263: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 05:00:13.298: INFO: Waiting for pod pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e to disappear
Feb 19 05:00:13.304: INFO: Pod pod-projected-secrets-9375d72d-ec32-4167-9b02-2285f61cd32e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:00:13.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9964" for this suite.
Feb 19 05:00:19.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:00:19.584: INFO: namespace projected-9964 deletion completed in 6.274062362s

• [SLOW TEST:8.423 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:00:19.585: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-97a0a4a1-c129-4d95-b73d-b08fbc3b0b5c
STEP: Creating configMap with name cm-test-opt-upd-ea014220-2abb-4008-91b1-aeffc6351577
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-97a0a4a1-c129-4d95-b73d-b08fbc3b0b5c
STEP: Updating configmap cm-test-opt-upd-ea014220-2abb-4008-91b1-aeffc6351577
STEP: Creating configMap with name cm-test-opt-create-76dfd778-d265-4034-963e-a23220e702bc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:01:56.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3154" for this suite.
Feb 19 05:02:20.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:02:20.928: INFO: namespace projected-3154 deletion completed in 24.731665261s

• [SLOW TEST:121.343 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:02:20.928: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 05:02:25.361: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:25.368: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:27.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:27.559: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:29.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:29.404: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:31.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:31.555: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:33.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:33.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:35.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:35.502: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:37.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:37.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:39.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:39.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:41.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:41.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:43.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:43.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:45.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:45.500: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:47.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:47.405: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:49.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:49.515: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:51.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:51.375: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:53.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:53.508: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 05:02:55.369: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 05:02:55.375: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:02:55.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9466" for this suite.
Feb 19 05:03:19.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:03:19.731: INFO: namespace container-lifecycle-hook-9466 deletion completed in 24.220200054s

• [SLOW TEST:58.803 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:03:19.731: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-23f3bdd7-0289-41ee-9d74-d3cad9db95bf
STEP: Creating a pod to test consume secrets
Feb 19 05:03:19.864: INFO: Waiting up to 5m0s for pod "pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9" in namespace "secrets-6845" to be "success or failure"
Feb 19 05:03:19.871: INFO: Pod "pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.103347ms
Feb 19 05:03:21.878: INFO: Pod "pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013959917s
Feb 19 05:03:23.885: INFO: Pod "pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020656986s
STEP: Saw pod success
Feb 19 05:03:23.885: INFO: Pod "pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9" satisfied condition "success or failure"
Feb 19 05:03:23.891: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 05:03:23.928: INFO: Waiting for pod pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9 to disappear
Feb 19 05:03:23.934: INFO: Pod pod-secrets-b56ddbdd-5077-4fc3-8e5b-1785dcc132e9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:03:23.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6845" for this suite.
Feb 19 05:03:29.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:03:30.442: INFO: namespace secrets-6845 deletion completed in 6.500610277s
STEP: Destroying namespace "secret-namespace-8071" for this suite.
Feb 19 05:03:36.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:03:37.163: INFO: namespace secret-namespace-8071 deletion completed in 6.721689964s

• [SLOW TEST:17.432 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:03:37.163: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-83b2ffec-7815-4ee7-8be6-1ba6ade738fa in namespace container-probe-8208
Feb 19 05:03:39.253: INFO: Started pod busybox-83b2ffec-7815-4ee7-8be6-1ba6ade738fa in namespace container-probe-8208
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 05:03:39.259: INFO: Initial restart count of pod busybox-83b2ffec-7815-4ee7-8be6-1ba6ade738fa is 0
Feb 19 05:04:30.392: INFO: Restart count of pod container-probe-8208/busybox-83b2ffec-7815-4ee7-8be6-1ba6ade738fa is now 1 (51.132586406s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:04:30.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8208" for this suite.
Feb 19 05:04:36.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:04:37.639: INFO: namespace container-probe-8208 deletion completed in 7.089131398s

• [SLOW TEST:60.476 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:04:37.640: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 05:04:37.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7070'
Feb 19 05:04:37.894: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 19 05:04:37.894: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 19 05:04:37.908: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-rmpg4]
Feb 19 05:04:37.908: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-rmpg4" in namespace "kubectl-7070" to be "running and ready"
Feb 19 05:04:37.917: INFO: Pod "e2e-test-nginx-rc-rmpg4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.878043ms
Feb 19 05:04:39.928: INFO: Pod "e2e-test-nginx-rc-rmpg4": Phase="Running", Reason="", readiness=true. Elapsed: 2.020054767s
Feb 19 05:04:39.928: INFO: Pod "e2e-test-nginx-rc-rmpg4" satisfied condition "running and ready"
Feb 19 05:04:39.928: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-rmpg4]
Feb 19 05:04:39.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 logs rc/e2e-test-nginx-rc --namespace=kubectl-7070'
Feb 19 05:04:40.031: INFO: stderr: ""
Feb 19 05:04:40.031: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Feb 19 05:04:40.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete rc e2e-test-nginx-rc --namespace=kubectl-7070'
Feb 19 05:04:40.202: INFO: stderr: ""
Feb 19 05:04:40.202: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:04:40.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7070" for this suite.
Feb 19 05:05:04.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:05:04.618: INFO: namespace kubectl-7070 deletion completed in 24.409896252s

• [SLOW TEST:26.979 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:05:04.619: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-bbea1965-bc3c-4663-8fb5-9bf2475cfed7
STEP: Creating a pod to test consume secrets
Feb 19 05:05:04.693: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740" in namespace "projected-8901" to be "success or failure"
Feb 19 05:05:04.700: INFO: Pod "pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740": Phase="Pending", Reason="", readiness=false. Elapsed: 7.304756ms
Feb 19 05:05:06.707: INFO: Pod "pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014394204s
STEP: Saw pod success
Feb 19 05:05:06.707: INFO: Pod "pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740" satisfied condition "success or failure"
Feb 19 05:05:06.715: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 05:05:06.753: INFO: Waiting for pod pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740 to disappear
Feb 19 05:05:06.760: INFO: Pod pod-projected-secrets-31b7fdb2-5a50-4177-8fcd-8a333c879740 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:05:06.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8901" for this suite.
Feb 19 05:05:12.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:05:13.561: INFO: namespace projected-8901 deletion completed in 6.795584244s

• [SLOW TEST:8.943 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:05:13.562: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-ccxp
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 05:05:13.649: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ccxp" in namespace "subpath-1861" to be "success or failure"
Feb 19 05:05:13.656: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.934506ms
Feb 19 05:05:15.662: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 2.013368142s
Feb 19 05:05:17.901: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 4.252595233s
Feb 19 05:05:20.158: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 6.509342451s
Feb 19 05:05:22.216: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 8.566871577s
Feb 19 05:05:24.498: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 10.848823376s
Feb 19 05:05:26.903: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 13.25438625s
Feb 19 05:05:28.953: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 15.303781588s
Feb 19 05:05:31.106: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 17.457364588s
Feb 19 05:05:33.341: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Running", Reason="", readiness=true. Elapsed: 19.692570271s
Feb 19 05:05:35.557: INFO: Pod "pod-subpath-test-downwardapi-ccxp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 21.908022311s
STEP: Saw pod success
Feb 19 05:05:35.557: INFO: Pod "pod-subpath-test-downwardapi-ccxp" satisfied condition "success or failure"
Feb 19 05:05:35.609: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-downwardapi-ccxp container test-container-subpath-downwardapi-ccxp: <nil>
STEP: delete the pod
Feb 19 05:05:35.867: INFO: Waiting for pod pod-subpath-test-downwardapi-ccxp to disappear
Feb 19 05:05:35.874: INFO: Pod pod-subpath-test-downwardapi-ccxp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ccxp
Feb 19 05:05:35.874: INFO: Deleting pod "pod-subpath-test-downwardapi-ccxp" in namespace "subpath-1861"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:05:35.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1861" for this suite.
Feb 19 05:05:41.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:05:42.643: INFO: namespace subpath-1861 deletion completed in 6.757544707s

• [SLOW TEST:29.081 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:05:42.643: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-84fb6036-d92a-49d3-9947-96a3e0622f99
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:05:47.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7091" for this suite.
Feb 19 05:06:09.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:06:09.705: INFO: namespace configmap-7091 deletion completed in 22.609089744s

• [SLOW TEST:27.062 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:06:09.705: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 05:06:09.778: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4633040-3090-4167-8c78-026079184c77" in namespace "downward-api-1736" to be "success or failure"
Feb 19 05:06:09.785: INFO: Pod "downwardapi-volume-a4633040-3090-4167-8c78-026079184c77": Phase="Pending", Reason="", readiness=false. Elapsed: 6.74969ms
Feb 19 05:06:11.791: INFO: Pod "downwardapi-volume-a4633040-3090-4167-8c78-026079184c77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012787569s
Feb 19 05:06:13.990: INFO: Pod "downwardapi-volume-a4633040-3090-4167-8c78-026079184c77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211328058s
STEP: Saw pod success
Feb 19 05:06:13.990: INFO: Pod "downwardapi-volume-a4633040-3090-4167-8c78-026079184c77" satisfied condition "success or failure"
Feb 19 05:06:13.998: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-a4633040-3090-4167-8c78-026079184c77 container client-container: <nil>
STEP: delete the pod
Feb 19 05:06:14.032: INFO: Waiting for pod downwardapi-volume-a4633040-3090-4167-8c78-026079184c77 to disappear
Feb 19 05:06:14.038: INFO: Pod downwardapi-volume-a4633040-3090-4167-8c78-026079184c77 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:06:14.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1736" for this suite.
Feb 19 05:06:20.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:06:20.812: INFO: namespace downward-api-1736 deletion completed in 6.768726899s

• [SLOW TEST:11.107 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:06:20.812: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Feb 19 05:06:20.863: INFO: PodSpec: initContainers in spec.initContainers
Feb 19 05:07:07.560: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d21f27bb-1f50-40cf-bb47-f5b4d4c23986", GenerateName:"", Namespace:"init-container-2538", SelfLink:"/api/v1/namespaces/init-container-2538/pods/pod-init-d21f27bb-1f50-40cf-bb47-f5b4d4c23986", UID:"f565d232-198f-4227-912b-749696db20c5", ResourceVersion:"29684", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63717685580, loc:(*time.Location)(0x7ed0a00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"863084463"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-22jt5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0016359c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-22jt5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-22jt5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-22jt5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002e303c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.10.2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002567c20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e30450)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e30470)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002e30478), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002e3047c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685580, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685580, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685580, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685580, loc:(*time.Location)(0x7ed0a00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.10.2", PodIP:"10.244.1.207", StartTime:(*v1.Time)(0xc00319db40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e653b0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000e65420)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://1ec53122e871eacc291ef0a311a9c173e50bc908835d64a2d8ca300a7adc66fd"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00319dbe0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00319db80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:07:07.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2538" for this suite.
Feb 19 05:07:31.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:07:31.937: INFO: namespace init-container-2538 deletion completed in 24.366488161s

• [SLOW TEST:71.125 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:07:31.938: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 19 05:07:32.265: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 05:07:32.479: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 05:07:32.486: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Feb 19 05:07:32.500: INFO: csi-oci-node-jgr72 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:07:32.500: INFO: coredns-547fdd776c-rcf7n from kube-system started at 2020-02-19 03:31:37 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:07:32.500: INFO: proxymux-client-l94j2 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:07:32.500: INFO: kube-flannel-ds-dd7gd from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:07:32.500: INFO: kube-proxy-8l2fs from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:07:32.500: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-wsrnl from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:07:32.500: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:07:32.500: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:07:32.500: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Feb 19 05:07:32.548: INFO: kube-proxy-pwtwx from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:07:32.548: INFO: proxymux-client-6nkcq from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:07:32.548: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-p8mkj from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:07:32.548: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:07:32.548: INFO: kube-flannel-ds-72bk6 from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:07:32.548: INFO: csi-oci-node-9khcs from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:07:32.548: INFO: coredns-547fdd776c-tw6q6 from kube-system started at 2020-02-19 03:31:34 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:07:32.548: INFO: sonobuoy-e2e-job-178c4b4f618042e4 from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:07:32.548: INFO: 	Container e2e ready: true, restart count 0
Feb 19 05:07:32.548: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 05:07:32.548: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Feb 19 05:07:32.563: INFO: kube-proxy-tsmqs from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.563: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:07:32.563: INFO: proxymux-client-2p6d4 from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.563: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:07:32.563: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-ngs5t from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:07:32.563: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:07:32.563: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:07:32.563: INFO: kube-flannel-ds-9wq2s from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.563: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:07:32.563: INFO: sonobuoy from sonobuoy started at 2020-02-19 03:35:32 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.563: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 05:07:32.564: INFO: csi-oci-node-676ns from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.564: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:07:32.564: INFO: coredns-547fdd776c-l9qgl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.564: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:07:32.564: INFO: kube-dns-autoscaler-94bd7f68f-5t8sl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 05:07:32.564: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f4b56dde5c65be], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:07:33.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7687" for this suite.
Feb 19 05:07:39.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:07:39.884: INFO: namespace sched-pred-7687 deletion completed in 6.270648062s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.947 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:07:39.885: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 05:07:46.095: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:46.102: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:48.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:48.170: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:50.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:50.160: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:52.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:52.108: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:54.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:54.215: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:56.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:56.109: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:07:58.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:07:58.109: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:00.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:00.108: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:02.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:02.108: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:04.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:04.108: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:06.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:06.109: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:08.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:08.336: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 05:08:10.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 05:08:10.109: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:08:10.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9834" for this suite.
Feb 19 05:08:32.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:08:33.148: INFO: namespace container-lifecycle-hook-9834 deletion completed in 23.031605504s

• [SLOW TEST:53.263 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:08:33.148: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Feb 19 05:08:33.204: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 05:08:33.216: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 05:08:33.221: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Feb 19 05:08:33.232: INFO: csi-oci-node-jgr72 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:08:33.232: INFO: coredns-547fdd776c-rcf7n from kube-system started at 2020-02-19 03:31:37 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:08:33.232: INFO: kube-flannel-ds-dd7gd from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:08:33.232: INFO: kube-proxy-8l2fs from kube-system started at 2020-02-19 03:30:46 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:08:33.232: INFO: proxymux-client-l94j2 from kube-system started at 2020-02-19 03:31:06 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:08:33.232: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-wsrnl from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:08:33.232: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:08:33.232: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:08:33.232: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Feb 19 05:08:33.258: INFO: kube-flannel-ds-72bk6 from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:08:33.258: INFO: csi-oci-node-9khcs from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:08:33.258: INFO: coredns-547fdd776c-tw6q6 from kube-system started at 2020-02-19 03:31:34 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:08:33.258: INFO: sonobuoy-e2e-job-178c4b4f618042e4 from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container e2e ready: true, restart count 0
Feb 19 05:08:33.258: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 05:08:33.258: INFO: kube-proxy-pwtwx from kube-system started at 2020-02-19 03:31:10 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:08:33.258: INFO: proxymux-client-6nkcq from kube-system started at 2020-02-19 03:31:20 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:08:33.258: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-p8mkj from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:08:33.258: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:08:33.258: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:08:33.258: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.4 before test
Feb 19 05:08:33.270: INFO: csi-oci-node-676ns from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container csi-node-driver ready: true, restart count 0
Feb 19 05:08:33.270: INFO: coredns-547fdd776c-l9qgl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container coredns ready: true, restart count 0
Feb 19 05:08:33.270: INFO: kube-dns-autoscaler-94bd7f68f-5t8sl from kube-system started at 2020-02-19 03:31:05 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container autoscaler ready: true, restart count 0
Feb 19 05:08:33.270: INFO: kube-proxy-tsmqs from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 05:08:33.270: INFO: proxymux-client-2p6d4 from kube-system started at 2020-02-19 03:31:04 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container proxymux-client ready: true, restart count 0
Feb 19 05:08:33.270: INFO: sonobuoy-systemd-logs-daemon-set-521c0c0d4c4a4723-ngs5t from sonobuoy started at 2020-02-19 03:35:38 +0000 UTC (2 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 05:08:33.270: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 19 05:08:33.270: INFO: kube-flannel-ds-9wq2s from kube-system started at 2020-02-19 03:30:44 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container kube-flannel ready: true, restart count 1
Feb 19 05:08:33.270: INFO: sonobuoy from sonobuoy started at 2020-02-19 03:35:32 +0000 UTC (1 container statuses recorded)
Feb 19 05:08:33.270: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b28787aa-aa18-466a-8067-e1f3ea266a4f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b28787aa-aa18-466a-8067-e1f3ea266a4f off the node 10.0.10.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b28787aa-aa18-466a-8067-e1f3ea266a4f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:08:37.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1718" for this suite.
Feb 19 05:08:47.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:08:47.760: INFO: namespace sched-pred-1718 deletion completed in 10.221167714s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:14.612 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:08:47.760: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 19 05:08:49.856: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8938ca9e-d255-497e-b63a-d132588cfb13,GenerateName:,Namespace:events-1249,SelfLink:/api/v1/namespaces/events-1249/pods/send-events-8938ca9e-d255-497e-b63a-d132588cfb13,UID:2e354f4f-f2a4-4a9b-8816-8ea913d4a653,ResourceVersion:30115,Generation:0,CreationTimestamp:2020-02-19 05:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 812174501,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-fhn2q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fhn2q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-fhn2q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036319c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036319e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:08:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:08:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:08:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:08:47 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.211,StartTime:2020-02-19 05:08:47 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-02-19 05:08:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://8913dbbbd0b3ea0e7d4bf2d83fec20d59a1d63161f8f2ca575088d2369872464}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 19 05:08:51.864: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 19 05:08:53.874: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:08:53.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1249" for this suite.
Feb 19 05:09:40.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:09:40.642: INFO: namespace events-1249 deletion completed in 46.746602785s

• [SLOW TEST:52.881 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:09:40.642: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 05:09:40.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104" in namespace "projected-2769" to be "success or failure"
Feb 19 05:09:40.715: INFO: Pod "downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.422697ms
Feb 19 05:09:42.723: INFO: Pod "downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015050539s
STEP: Saw pod success
Feb 19 05:09:42.723: INFO: Pod "downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104" satisfied condition "success or failure"
Feb 19 05:09:42.728: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104 container client-container: <nil>
STEP: delete the pod
Feb 19 05:09:42.766: INFO: Waiting for pod downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104 to disappear
Feb 19 05:09:42.774: INFO: Pod downwardapi-volume-b799a589-92e7-4b03-9d3f-207d3c023104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:09:42.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2769" for this suite.
Feb 19 05:09:48.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:09:49.559: INFO: namespace projected-2769 deletion completed in 6.776078746s

• [SLOW TEST:8.916 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:09:49.559: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 05:09:49.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8128'
Feb 19 05:09:49.696: INFO: stderr: ""
Feb 19 05:09:49.696: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 19 05:09:54.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pod e2e-test-nginx-pod --namespace=kubectl-8128 -o json'
Feb 19 05:09:54.825: INFO: stderr: ""
Feb 19 05:09:54.825: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-02-19T05:09:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8128\",\n        \"resourceVersion\": \"30353\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8128/pods/e2e-test-nginx-pod\",\n        \"uid\": \"706501f9-5ceb-47bf-8edc-694bb58cc635\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-49dhz\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.10.2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-49dhz\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-49dhz\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-19T05:09:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-19T05:09:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-19T05:09:52Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-19T05:09:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b91759fd9585e692e7cc41ca4dd6019f29cd4b67c20a12ad245557378aeaa391\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-19T05:09:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.10.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.213\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-19T05:09:50Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 19 05:09:54.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 replace -f - --namespace=kubectl-8128'
Feb 19 05:09:55.083: INFO: stderr: ""
Feb 19 05:09:55.083: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Feb 19 05:09:55.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 delete pods e2e-test-nginx-pod --namespace=kubectl-8128'
Feb 19 05:10:06.571: INFO: stderr: ""
Feb 19 05:10:06.571: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:10:06.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8128" for this suite.
Feb 19 05:10:12.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:10:12.794: INFO: namespace kubectl-8128 deletion completed in 6.215885464s

• [SLOW TEST:23.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:10:12.794: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Feb 19 05:10:12.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 cluster-info'
Feb 19 05:10:12.921: INFO: stderr: ""
Feb 19 05:10:12.921: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:10:12.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8730" for this suite.
Feb 19 05:10:18.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:10:19.136: INFO: namespace kubectl-8730 deletion completed in 6.209456508s

• [SLOW TEST:6.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:10:19.137: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1712
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 05:10:19.258: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 05:10:43.400: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.60:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1712 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 05:10:43.400: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 05:10:43.916: INFO: Found all expected endpoints: [netserver-0]
Feb 19 05:10:43.923: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.63:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1712 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 05:10:43.923: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 05:10:44.120: INFO: Found all expected endpoints: [netserver-1]
Feb 19 05:10:44.126: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.214:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1712 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 05:10:44.126: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
Feb 19 05:10:44.346: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:10:44.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1712" for this suite.
Feb 19 05:11:08.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:11:08.585: INFO: namespace pod-network-test-1712 deletion completed in 24.232166163s

• [SLOW TEST:49.449 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:11:08.586: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 05:11:12.969: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 05:11:12.976: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 05:11:14.976: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 05:11:14.983: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 05:11:16.976: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 05:11:16.983: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 05:11:18.976: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 05:11:19.098: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 05:11:20.976: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 05:11:21.080: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:11:21.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5846" for this suite.
Feb 19 05:11:43.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:11:43.901: INFO: namespace container-lifecycle-hook-5846 deletion completed in 22.813725855s

• [SLOW TEST:35.315 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:11:43.901: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Feb 19 05:11:43.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8" in namespace "projected-7464" to be "success or failure"
Feb 19 05:11:43.974: INFO: Pod "downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.413764ms
Feb 19 05:11:45.982: INFO: Pod "downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014881557s
Feb 19 05:11:48.194: INFO: Pod "downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.227209762s
STEP: Saw pod success
Feb 19 05:11:48.194: INFO: Pod "downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8" satisfied condition "success or failure"
Feb 19 05:11:48.200: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8 container client-container: <nil>
STEP: delete the pod
Feb 19 05:11:48.237: INFO: Waiting for pod downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8 to disappear
Feb 19 05:11:48.243: INFO: Pod downwardapi-volume-ba78b9cc-e989-4fc6-9102-98a90ca471e8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:11:48.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7464" for this suite.
Feb 19 05:11:54.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:11:55.092: INFO: namespace projected-7464 deletion completed in 6.842789925s

• [SLOW TEST:11.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:11:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:11:57.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9155" for this suite.
Feb 19 05:12:39.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:12:39.915: INFO: namespace kubelet-test-9155 deletion completed in 42.699590936s

• [SLOW TEST:44.822 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:12:39.915: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 05:12:39.986: INFO: Waiting up to 5m0s for pod "pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6" in namespace "emptydir-3694" to be "success or failure"
Feb 19 05:12:39.993: INFO: Pod "pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.630327ms
Feb 19 05:12:42.084: INFO: Pod "pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.098122433s
STEP: Saw pod success
Feb 19 05:12:42.084: INFO: Pod "pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6" satisfied condition "success or failure"
Feb 19 05:12:42.090: INFO: Trying to get logs from node 10.0.10.2 pod pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6 container test-container: <nil>
STEP: delete the pod
Feb 19 05:12:42.124: INFO: Waiting for pod pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6 to disappear
Feb 19 05:12:42.137: INFO: Pod pod-30ac5999-6f0b-4e76-95b8-bbd6c6d996f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:12:42.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3694" for this suite.
Feb 19 05:12:48.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:12:48.883: INFO: namespace emptydir-3694 deletion completed in 6.73969695s

• [SLOW TEST:8.968 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:12:48.884: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 05:12:48.958: INFO: Waiting up to 5m0s for pod "pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef" in namespace "emptydir-2928" to be "success or failure"
Feb 19 05:12:48.966: INFO: Pod "pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef": Phase="Pending", Reason="", readiness=false. Elapsed: 7.739536ms
Feb 19 05:12:51.049: INFO: Pod "pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.091212201s
STEP: Saw pod success
Feb 19 05:12:51.049: INFO: Pod "pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef" satisfied condition "success or failure"
Feb 19 05:12:51.055: INFO: Trying to get logs from node 10.0.10.2 pod pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef container test-container: <nil>
STEP: delete the pod
Feb 19 05:12:51.091: INFO: Waiting for pod pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef to disappear
Feb 19 05:12:51.097: INFO: Pod pod-fd534af1-04f9-4e74-8f25-7016eb6b93ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:12:51.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2928" for this suite.
Feb 19 05:12:57.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:12:57.943: INFO: namespace emptydir-2928 deletion completed in 6.840264585s

• [SLOW TEST:9.060 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:12:57.944: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Feb 19 05:12:57.995: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Feb 19 05:12:58.531: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 19 05:13:00.595: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:02.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:04.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:06.732: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:08.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:11.194: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:12.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717685978, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 05:13:15.426: INFO: Waited 815.236011ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:13:16.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1062" for this suite.
Feb 19 05:13:22.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:13:22.745: INFO: namespace aggregator-1062 deletion completed in 6.21294346s

• [SLOW TEST:24.802 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:13:22.746: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Feb 19 05:13:22.923: INFO: Waiting up to 5m0s for pod "downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312" in namespace "downward-api-1654" to be "success or failure"
Feb 19 05:13:22.930: INFO: Pod "downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312": Phase="Pending", Reason="", readiness=false. Elapsed: 6.472277ms
Feb 19 05:13:24.937: INFO: Pod "downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013231193s
STEP: Saw pod success
Feb 19 05:13:24.937: INFO: Pod "downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312" satisfied condition "success or failure"
Feb 19 05:13:24.942: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312 container dapi-container: <nil>
STEP: delete the pod
Feb 19 05:13:25.209: INFO: Waiting for pod downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312 to disappear
Feb 19 05:13:25.214: INFO: Pod downward-api-ab11381b-148e-42fb-8706-01ee4fd6f312 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:13:25.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1654" for this suite.
Feb 19 05:13:31.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:13:31.581: INFO: namespace downward-api-1654 deletion completed in 6.360832297s

• [SLOW TEST:8.835 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:13:31.582: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 05:13:31.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 version'
Feb 19 05:13:31.909: INFO: stderr: ""
Feb 19 05:13:31.909: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:42:56Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"4f504dd9ee54a3621502518bc64f0df487587d12\", GitTreeState:\"clean\", BuildDate:\"2020-01-23T00:34:28Z\", GoVersion:\"go1.12.7 BoringCrypto\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:13:31.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1470" for this suite.
Feb 19 05:13:38.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:13:38.284: INFO: namespace kubectl-1470 deletion completed in 6.367884206s

• [SLOW TEST:6.703 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:13:38.284: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-cd8e0fec-63f6-4798-923f-faaaac0629ef
STEP: Creating a pod to test consume secrets
Feb 19 05:13:38.356: INFO: Waiting up to 5m0s for pod "pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d" in namespace "secrets-1541" to be "success or failure"
Feb 19 05:13:38.362: INFO: Pod "pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106719ms
Feb 19 05:13:40.368: INFO: Pod "pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012517146s
Feb 19 05:13:42.555: INFO: Pod "pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.199495279s
STEP: Saw pod success
Feb 19 05:13:42.555: INFO: Pod "pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d" satisfied condition "success or failure"
Feb 19 05:13:42.562: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 05:13:42.599: INFO: Waiting for pod pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d to disappear
Feb 19 05:13:42.605: INFO: Pod pod-secrets-77d17c55-e09f-4302-96f3-527c9167223d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:13:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1541" for this suite.
Feb 19 05:13:48.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:13:49.422: INFO: namespace secrets-1541 deletion completed in 6.810788742s

• [SLOW TEST:11.138 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:13:49.423: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 05:13:49.785: INFO: (0) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 308.031871ms)
Feb 19 05:13:49.805: INFO: (1) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 19.632842ms)
Feb 19 05:13:49.825: INFO: (2) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 20.423893ms)
Feb 19 05:13:49.845: INFO: (3) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 19.864005ms)
Feb 19 05:13:49.865: INFO: (4) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 19.891936ms)
Feb 19 05:13:49.879: INFO: (5) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 13.773967ms)
Feb 19 05:13:49.892: INFO: (6) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 12.894318ms)
Feb 19 05:13:49.901: INFO: (7) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.215168ms)
Feb 19 05:13:49.910: INFO: (8) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.759284ms)
Feb 19 05:13:49.918: INFO: (9) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.303243ms)
Feb 19 05:13:49.928: INFO: (10) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.565447ms)
Feb 19 05:13:49.938: INFO: (11) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.554978ms)
Feb 19 05:13:49.946: INFO: (12) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.326646ms)
Feb 19 05:13:49.956: INFO: (13) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.541696ms)
Feb 19 05:13:49.965: INFO: (14) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.549862ms)
Feb 19 05:13:49.974: INFO: (15) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.728977ms)
Feb 19 05:13:49.984: INFO: (16) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.557523ms)
Feb 19 05:13:49.992: INFO: (17) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.889627ms)
Feb 19 05:13:50.000: INFO: (18) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.688715ms)
Feb 19 05:13:50.009: INFO: (19) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.182963ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:13:50.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7328" for this suite.
Feb 19 05:13:56.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:13:56.273: INFO: namespace proxy-7328 deletion completed in 6.257405924s

• [SLOW TEST:6.851 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:13:56.274: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:14:00.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3488" for this suite.
Feb 19 05:14:06.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:14:07.412: INFO: namespace kubelet-test-3488 deletion completed in 6.862905074s

• [SLOW TEST:11.138 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:14:07.413: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 05:14:07.477: INFO: Waiting up to 5m0s for pod "pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d" in namespace "emptydir-2880" to be "success or failure"
Feb 19 05:14:07.483: INFO: Pod "pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020694ms
Feb 19 05:14:09.609: INFO: Pod "pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.131794589s
Feb 19 05:14:11.616: INFO: Pod "pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138620186s
STEP: Saw pod success
Feb 19 05:14:11.616: INFO: Pod "pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d" satisfied condition "success or failure"
Feb 19 05:14:11.622: INFO: Trying to get logs from node 10.0.10.2 pod pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d container test-container: <nil>
STEP: delete the pod
Feb 19 05:14:11.901: INFO: Waiting for pod pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d to disappear
Feb 19 05:14:11.908: INFO: Pod pod-87dc8a2c-cdd6-4ce3-a091-f96683f5fd7d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:14:11.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2880" for this suite.
Feb 19 05:14:18.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:14:18.628: INFO: namespace emptydir-2880 deletion completed in 6.714132423s

• [SLOW TEST:11.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:14:18.628: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-vfvh
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 05:14:18.921: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vfvh" in namespace "subpath-6483" to be "success or failure"
Feb 19 05:14:18.929: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Pending", Reason="", readiness=false. Elapsed: 7.382323ms
Feb 19 05:14:20.935: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 2.014003896s
Feb 19 05:14:23.090: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 4.168623s
Feb 19 05:14:25.322: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 6.400817238s
Feb 19 05:14:27.330: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 8.408182378s
Feb 19 05:14:29.386: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 10.464434917s
Feb 19 05:14:31.638: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 12.716280248s
Feb 19 05:14:33.879: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 14.957451433s
Feb 19 05:14:35.989: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 17.067565162s
Feb 19 05:14:38.255: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 19.333304941s
Feb 19 05:14:40.478: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Running", Reason="", readiness=true. Elapsed: 21.556602494s
Feb 19 05:14:42.844: INFO: Pod "pod-subpath-test-secret-vfvh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.923010827s
STEP: Saw pod success
Feb 19 05:14:42.844: INFO: Pod "pod-subpath-test-secret-vfvh" satisfied condition "success or failure"
Feb 19 05:14:42.874: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-secret-vfvh container test-container-subpath-secret-vfvh: <nil>
STEP: delete the pod
Feb 19 05:14:42.919: INFO: Waiting for pod pod-subpath-test-secret-vfvh to disappear
Feb 19 05:14:42.926: INFO: Pod pod-subpath-test-secret-vfvh no longer exists
STEP: Deleting pod pod-subpath-test-secret-vfvh
Feb 19 05:14:42.926: INFO: Deleting pod "pod-subpath-test-secret-vfvh" in namespace "subpath-6483"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:14:42.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6483" for this suite.
Feb 19 05:14:48.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:14:49.165: INFO: namespace subpath-6483 deletion completed in 6.22490905s

• [SLOW TEST:30.537 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:14:49.165: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 05:14:49.530: INFO: Creating ReplicaSet my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f
Feb 19 05:14:49.573: INFO: Pod name my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f: Found 1 pods out of 1
Feb 19 05:14:49.573: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f" is running
Feb 19 05:14:51.853: INFO: Pod "my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f-sdc48" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-19 05:14:49 +0000 UTC Reason: Message:}])
Feb 19 05:14:51.853: INFO: Trying to dial the pod
Feb 19 05:14:57.987: INFO: Controller my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f: Got expected result from replica 1 [my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f-sdc48]: "my-hostname-basic-2e349483-9390-452f-b1e8-c1a9fea5264f-sdc48", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:14:57.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9849" for this suite.
Feb 19 05:15:04.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:15:04.204: INFO: namespace replicaset-9849 deletion completed in 6.21076522s

• [SLOW TEST:15.039 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:15:04.205: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 19 05:15:04.291: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-765,SelfLink:/api/v1/namespaces/watch-765/configmaps/e2e-watch-test-watch-closed,UID:2b772c95-9675-4fa2-a654-8049c0cda5e8,ResourceVersion:31788,Generation:0,CreationTimestamp:2020-02-19 05:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 05:15:04.291: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-765,SelfLink:/api/v1/namespaces/watch-765/configmaps/e2e-watch-test-watch-closed,UID:2b772c95-9675-4fa2-a654-8049c0cda5e8,ResourceVersion:31789,Generation:0,CreationTimestamp:2020-02-19 05:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 19 05:15:04.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-765,SelfLink:/api/v1/namespaces/watch-765/configmaps/e2e-watch-test-watch-closed,UID:2b772c95-9675-4fa2-a654-8049c0cda5e8,ResourceVersion:31790,Generation:0,CreationTimestamp:2020-02-19 05:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 05:15:04.319: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-765,SelfLink:/api/v1/namespaces/watch-765/configmaps/e2e-watch-test-watch-closed,UID:2b772c95-9675-4fa2-a654-8049c0cda5e8,ResourceVersion:31791,Generation:0,CreationTimestamp:2020-02-19 05:15:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:15:04.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-765" for this suite.
Feb 19 05:15:10.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:15:10.542: INFO: namespace watch-765 deletion completed in 6.216930578s

• [SLOW TEST:6.337 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:15:10.542: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Feb 19 05:15:10.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 create -f - --namespace=kubectl-4546'
Feb 19 05:15:10.965: INFO: stderr: ""
Feb 19 05:15:10.965: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 05:15:10.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4546'
Feb 19 05:15:11.047: INFO: stderr: ""
Feb 19 05:15:11.047: INFO: stdout: "update-demo-nautilus-999zl update-demo-nautilus-s2d29 "
Feb 19 05:15:11.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-999zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:11.405: INFO: stderr: ""
Feb 19 05:15:11.405: INFO: stdout: ""
Feb 19 05:15:11.405: INFO: update-demo-nautilus-999zl is created but not running
Feb 19 05:15:16.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4546'
Feb 19 05:15:16.483: INFO: stderr: ""
Feb 19 05:15:16.483: INFO: stdout: "update-demo-nautilus-999zl update-demo-nautilus-s2d29 "
Feb 19 05:15:16.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-999zl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:16.870: INFO: stderr: ""
Feb 19 05:15:16.870: INFO: stdout: "true"
Feb 19 05:15:16.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-999zl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:16.942: INFO: stderr: ""
Feb 19 05:15:16.942: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 05:15:16.942: INFO: validating pod update-demo-nautilus-999zl
Feb 19 05:15:17.186: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 05:15:17.186: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 05:15:17.186: INFO: update-demo-nautilus-999zl is verified up and running
Feb 19 05:15:17.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-s2d29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:17.511: INFO: stderr: ""
Feb 19 05:15:17.511: INFO: stdout: "true"
Feb 19 05:15:17.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-nautilus-s2d29 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:17.581: INFO: stderr: ""
Feb 19 05:15:17.581: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 05:15:17.581: INFO: validating pod update-demo-nautilus-s2d29
Feb 19 05:15:17.873: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 05:15:17.873: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 05:15:17.873: INFO: update-demo-nautilus-s2d29 is verified up and running
STEP: rolling-update to new replication controller
Feb 19 05:15:17.874: INFO: scanned /root for discovery docs: <nil>
Feb 19 05:15:17.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4546'
Feb 19 05:15:46.453: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 05:15:46.453: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 05:15:46.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4546'
Feb 19 05:15:46.527: INFO: stderr: ""
Feb 19 05:15:46.527: INFO: stdout: "update-demo-kitten-n56lv update-demo-kitten-wsq88 "
Feb 19 05:15:46.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-kitten-n56lv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:46.597: INFO: stderr: ""
Feb 19 05:15:46.598: INFO: stdout: "true"
Feb 19 05:15:46.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-kitten-n56lv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:46.687: INFO: stderr: ""
Feb 19 05:15:46.687: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 05:15:46.687: INFO: validating pod update-demo-kitten-n56lv
Feb 19 05:15:47.114: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 05:15:47.114: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 05:15:47.114: INFO: update-demo-kitten-n56lv is verified up and running
Feb 19 05:15:47.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-kitten-wsq88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:47.191: INFO: stderr: ""
Feb 19 05:15:47.191: INFO: stdout: "true"
Feb 19 05:15:47.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 get pods update-demo-kitten-wsq88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4546'
Feb 19 05:15:47.262: INFO: stderr: ""
Feb 19 05:15:47.262: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 05:15:47.262: INFO: validating pod update-demo-kitten-wsq88
Feb 19 05:15:47.346: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 05:15:47.347: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 05:15:47.347: INFO: update-demo-kitten-wsq88 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:15:47.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4546" for this suite.
Feb 19 05:16:11.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:16:11.807: INFO: namespace kubectl-4546 deletion completed in 24.452484205s

• [SLOW TEST:61.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:16:11.807: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 19 05:16:14.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-152545945 exec pod-sharedvolume-c7d2f2ce-9dce-42c5-b583-36c3f12b16cd -c busybox-main-container --namespace=emptydir-1776 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 19 05:16:14.394: INFO: stderr: ""
Feb 19 05:16:14.394: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:16:14.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1776" for this suite.
Feb 19 05:16:20.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:16:20.896: INFO: namespace emptydir-1776 deletion completed in 6.320275462s

• [SLOW TEST:9.088 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:16:20.897: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 05:16:20.968: INFO: Waiting up to 5m0s for pod "pod-df920793-0770-42bf-a4fc-77ff6da1ea93" in namespace "emptydir-3332" to be "success or failure"
Feb 19 05:16:20.976: INFO: Pod "pod-df920793-0770-42bf-a4fc-77ff6da1ea93": Phase="Pending", Reason="", readiness=false. Elapsed: 7.745392ms
Feb 19 05:16:22.983: INFO: Pod "pod-df920793-0770-42bf-a4fc-77ff6da1ea93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014580459s
Feb 19 05:16:25.126: INFO: Pod "pod-df920793-0770-42bf-a4fc-77ff6da1ea93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.158128522s
STEP: Saw pod success
Feb 19 05:16:25.126: INFO: Pod "pod-df920793-0770-42bf-a4fc-77ff6da1ea93" satisfied condition "success or failure"
Feb 19 05:16:25.132: INFO: Trying to get logs from node 10.0.10.2 pod pod-df920793-0770-42bf-a4fc-77ff6da1ea93 container test-container: <nil>
STEP: delete the pod
Feb 19 05:16:25.299: INFO: Waiting for pod pod-df920793-0770-42bf-a4fc-77ff6da1ea93 to disappear
Feb 19 05:16:25.305: INFO: Pod pod-df920793-0770-42bf-a4fc-77ff6da1ea93 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:16:25.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3332" for this suite.
Feb 19 05:16:31.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:16:31.558: INFO: namespace emptydir-3332 deletion completed in 6.245890985s

• [SLOW TEST:10.662 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:16:31.558: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Feb 19 05:16:31.859: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 05:16:34.070: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Feb 19 05:16:34.104: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2865,SelfLink:/apis/apps/v1/namespaces/deployment-2865/deployments/test-cleanup-deployment,UID:954a5eb8-fadc-43b6-9043-c517330b2411,ResourceVersion:32269,Generation:1,CreationTimestamp:2020-02-19 05:16:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 05:16:34.110: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-2865,SelfLink:/apis/apps/v1/namespaces/deployment-2865/replicasets/test-cleanup-deployment-55bbcbc84c,UID:3057523e-7f0e-401b-bf07-52d025342d6b,ResourceVersion:32271,Generation:1,CreationTimestamp:2020-02-19 05:16:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 954a5eb8-fadc-43b6-9043-c517330b2411 0xc0028d6067 0xc0028d6068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 05:16:34.110: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 19 05:16:34.110: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2865,SelfLink:/apis/apps/v1/namespaces/deployment-2865/replicasets/test-cleanup-controller,UID:52acec15-cbab-492a-82fe-418306f35d9a,ResourceVersion:32270,Generation:1,CreationTimestamp:2020-02-19 05:16:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 954a5eb8-fadc-43b6-9043-c517330b2411 0xc003327f87 0xc003327f88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 05:16:34.117: INFO: Pod "test-cleanup-controller-cgzgf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-cgzgf,GenerateName:test-cleanup-controller-,Namespace:deployment-2865,SelfLink:/api/v1/namespaces/deployment-2865/pods/test-cleanup-controller-cgzgf,UID:7de2cdc8-5824-4568-85c5-4d35a38a526b,ResourceVersion:32262,Generation:0,CreationTimestamp:2020-02-19 05:16:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 52acec15-cbab-492a-82fe-418306f35d9a 0xc0028d6a87 0xc0028d6a88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nk6z8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nk6z8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nk6z8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028d6b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028d6b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:16:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:16:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:16:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-19 05:16:31 +0000 UTC  }],Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.229,StartTime:2020-02-19 05:16:31 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-19 05:16:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f96649e50dfe156a051aca93f564b25efb243c3944fb9fc0dd1f46feda83df5f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 05:16:34.117: INFO: Pod "test-cleanup-deployment-55bbcbc84c-bhtq2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-bhtq2,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-2865,SelfLink:/api/v1/namespaces/deployment-2865/pods/test-cleanup-deployment-55bbcbc84c-bhtq2,UID:9e6cd6ac-c3df-4d54-be1a-6255c6f2042c,ResourceVersion:32272,Generation:0,CreationTimestamp:2020-02-19 05:16:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 3057523e-7f0e-401b-bf07-52d025342d6b 0xc0028d6bf7 0xc0028d6bf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nk6z8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nk6z8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nk6z8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028d6c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028d6c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:16:34.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2865" for this suite.
Feb 19 05:16:40.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:16:40.352: INFO: namespace deployment-2865 deletion completed in 6.227202496s

• [SLOW TEST:8.794 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:16:40.354: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 19 05:16:46.466: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0219 05:16:46.466729      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 05:16:46.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5256" for this suite.
Feb 19 05:16:52.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:16:53.063: INFO: namespace gc-5256 deletion completed in 6.5905354s

• [SLOW TEST:12.709 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Feb 19 05:16:53.063: INFO: >>> kubeConfig: /tmp/kubeconfig-152545945
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Feb 19 05:16:53.135: INFO: Waiting up to 5m0s for pod "client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8" in namespace "containers-9370" to be "success or failure"
Feb 19 05:16:53.145: INFO: Pod "client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.413971ms
Feb 19 05:16:55.152: INFO: Pod "client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01604104s
Feb 19 05:16:57.190: INFO: Pod "client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054978273s
STEP: Saw pod success
Feb 19 05:16:57.191: INFO: Pod "client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8" satisfied condition "success or failure"
Feb 19 05:16:57.228: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8 container test-container: <nil>
STEP: delete the pod
Feb 19 05:16:57.285: INFO: Waiting for pod client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8 to disappear
Feb 19 05:16:57.292: INFO: Pod client-containers-4d4de63d-0672-4311-86e3-72d9f9c8bba8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Feb 19 05:16:57.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9370" for this suite.
Feb 19 05:17:03.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 05:17:03.513: INFO: namespace containers-9370 deletion completed in 6.215631526s

• [SLOW TEST:10.450 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSFeb 19 05:17:03.514: INFO: Running AfterSuite actions on all nodes
Feb 19 05:17:03.514: INFO: Running AfterSuite actions on node 1
Feb 19 05:17:03.514: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 6026.307 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h40m27.668956095s
Test Suite Passed
